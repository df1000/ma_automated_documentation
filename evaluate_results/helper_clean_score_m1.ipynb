{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23021e3e",
   "metadata": {},
   "source": [
    "**Author:** Lisa Wallner  \n",
    "**Description:** This file contains the code to clean the generated scores of the README files. The output of each LLM has to treat in a different way because the output of the LLM has not necessarily the demanded format.  \n",
    "For each LLM there is a specified cleaning file.  \n",
    "\n",
    "*Hint: If lines are created with support of a Large Language Model or the code is taken from another source, you find following hint at the end of the line: (generated with Microsoft Copilot) or (source: link_to_source)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5588e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # package to work with .json\n",
    "import pandas as pd # package for data manipulation\n",
    "import re # package for regex pattern\n",
    "from pathlib import Path # package to work with paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ae825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variabel is set manualley\n",
    "path_range = Path('../data/output_evaluation_data_jamba_mod/model1') # create a path from given string \n",
    "all_files_range = [file.name for file in path_range.iterdir() if file.is_file()] # iterate through all elements in path_range, check if element is a file and save it in variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for dataframe\n",
    "cols = ['repo_owner','repo_name','readme_g_score','readme_g_score_q1','readme_g_score_q1_txt','readme_g_score_q2','readme_g_score_q2_txt','readme_g_score_q3','readme_g_score_q3_txt','readme_g_score_q4','readme_g_score_q4_txt','readme_g_score_q5','readme_g_score_q5_txt','readme_o_score','readme_o_score_q1','readme_o_score_q1_txt','readme_o_score_q2','readme_o_score_q2_txt','readme_o_score_q3','readme_o_score_q3_txt','readme_o_score_q4','readme_o_score_q4_txt','readme_o_score_q5','readme_o_score_q5_txt']\n",
    "df_clean_scores = pd.DataFrame(columns=cols) # create empty dataframe with specified columns from cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a36566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_files_range: # iterate over all elements in all_files_range\n",
    "    new_entry = {} # create a empty dictionary for each element\n",
    "\n",
    "    # variabel is set manualley\n",
    "    with open(f'../data/output_evaluation_data_jamba_mod/model1/{i}', 'r') as f: # open each file and save its content in variable\n",
    "        loaded_data = json.load(f)\n",
    "\n",
    "    repo_owner = loaded_data['repo_owner'] # specifiy repo_owner\n",
    "    repo_name = loaded_data['repo_name'] # specify repo_name\n",
    "    readme_g_score = loaded_data['readme_genereated']['evaluation'] # get score values for generated readme\n",
    "    readme_o_score = loaded_data['readme_original']['evaluation'] # get score values for original readme\n",
    "\n",
    "    # generated readme\n",
    "    if loaded_data['readme_genereated']['score'] == [] or loaded_data['readme_genereated']['score'] == {}: # check if value of key 'score' is an empty list or dictionary\n",
    "        # set variabels to '0'\n",
    "        readme_g_score_q1 = '0'\n",
    "        readme_g_score_q1_txt = '0'\n",
    "        readme_g_score_q2 = '0'\n",
    "        readme_g_score_q2_txt = '0'\n",
    "        readme_g_score_q3 = '0'\n",
    "        readme_g_score_q3_txt = '0'\n",
    "        readme_g_score_q4 = '0'\n",
    "        readme_g_score_q4_txt = '0'\n",
    "        readme_g_score_q5 = '0'\n",
    "        readme_g_score_q5_txt = '0'\n",
    "\n",
    "    else: # if value for key 'score' is not empty save specific values in variabels\n",
    "        readme_g_score_q1 = loaded_data['readme_genereated']['score'][0]['score']\n",
    "        readme_g_score_q1_txt = loaded_data['readme_genereated']['score'][0]['explanation']\n",
    "        readme_g_score_q2 = loaded_data['readme_genereated']['score'][1]['score']\n",
    "        readme_g_score_q2_txt = loaded_data['readme_genereated']['score'][1]['explanation']\n",
    "        readme_g_score_q3 = loaded_data['readme_genereated']['score'][2]['score']\n",
    "        readme_g_score_q3_txt = loaded_data['readme_genereated']['score'][2]['explanation']\n",
    "        readme_g_score_q4 = loaded_data['readme_genereated']['score'][3]['score']\n",
    "        readme_g_score_q4_txt = loaded_data['readme_genereated']['score'][3]['explanation']\n",
    "        readme_g_score_q5 = loaded_data['readme_genereated']['score'][4]['score']\n",
    "        readme_g_score_q5_txt = loaded_data['readme_genereated']['score'][4]['explanation']\n",
    "    \n",
    "    # original readme\n",
    "    if loaded_data['readme_original']['score'] == [] or loaded_data['readme_original']['score'] == {}: # check if value of key 'score' is an empty list or dictionary\n",
    "        # set variabels to '0'\n",
    "        readme_o_score_q1 = '0'\n",
    "        readme_o_score_q1_txt = '0'\n",
    "        readme_o_score_q2 = '0'\n",
    "        readme_o_score_q2_txt = '0'\n",
    "        readme_o_score_q3 = '0'\n",
    "        readme_o_score_q3_txt = '0'\n",
    "        readme_o_score_q4 = '0'\n",
    "        readme_o_score_q4_txt = '0'\n",
    "        readme_o_score_q5 = '0'\n",
    "        readme_o_score_q5_txt = '0'\n",
    "\n",
    "    else:  # if value for key 'score' is not empty save specific values in variabels\n",
    "        readme_o_score_q1 = \"0\"\n",
    "        readme_o_score_q1_txt = \"0\"\n",
    "        readme_o_score_q2 = \"0\"\n",
    "        readme_o_score_q2_txt = \"0\"\n",
    "        readme_o_score_q3 = \"0\"\n",
    "        readme_o_score_q3_txt = \"0\"\n",
    "        readme_o_score_q4 = \"0\"\n",
    "        readme_o_score_q4_txt = \"0\"\n",
    "        readme_o_score_q5 = \"0\"\n",
    "        readme_o_score_q5_txt = \"0\"\n",
    "        \n",
    "        # this steps are only required for the results of the first evaluation from the original readme files\n",
    "        # original data are alread processed\n",
    "        # readme_o_score_q1 = loaded_data['readme_original']['score'][0]['score']\n",
    "        # readme_o_score_q1_txt = loaded_data['readme_original']['score'][0]['explanation']\n",
    "        # readme_o_score_q2 = loaded_data['readme_original']['score'][1]['score']\n",
    "        # readme_o_score_q2_txt = loaded_data['readme_original']['score'][1]['explanation']\n",
    "        # readme_o_score_q3 = loaded_data['readme_original']['score'][2]['score']\n",
    "        # readme_o_score_q3_txt = loaded_data['readme_original']['score'][2]['explanation']\n",
    "        # readme_o_score_q4 = loaded_data['readme_original']['score'][3]['score']\n",
    "        # readme_o_score_q4_txt = loaded_data['readme_original']['score'][3]['explanation']\n",
    "        # readme_o_score_q5 = loaded_data['readme_original']['score'][4]['score']\n",
    "        # readme_o_score_q5_txt = loaded_data['readme_original']['score'][4]['explanation']\n",
    "\n",
    "    # create a dictionary with all requiered elements for the processed file\n",
    "    new_entry = {\n",
    "        'repo_owner': repo_owner,\n",
    "        'repo_name': repo_name,\n",
    "        'readme_g_score': readme_g_score,\n",
    "        'readme_g_score_q1': readme_g_score_q1,\n",
    "        'readme_g_score_q1_txt': readme_g_score_q1_txt,\n",
    "        'readme_g_score_q2':  readme_g_score_q2,\n",
    "        'readme_g_score_q2_txt':  readme_g_score_q2_txt,\n",
    "        'readme_g_score_q3':  readme_g_score_q3,\n",
    "        'readme_g_score_q3_txt':  readme_g_score_q3_txt,\n",
    "        'readme_g_score_q4':  readme_g_score_q4,\n",
    "        'readme_g_score_q4_txt':  readme_g_score_q4_txt,\n",
    "        'readme_g_score_q5':  readme_g_score_q5,\n",
    "        'readme_g_score_q5_txt':  readme_g_score_q5_txt,\n",
    "        'readme_o_score':  readme_o_score,    \n",
    "        'readme_o_score_q1':  readme_o_score_q1,\n",
    "        'readme_o_score_q1_txt':  readme_o_score_q1_txt, \n",
    "        'readme_o_score_q2':  readme_o_score_q2,\n",
    "        'readme_o_score_q2_txt':  readme_o_score_q2_txt,\n",
    "        'readme_o_score_q3':  readme_o_score_q3,\n",
    "        'readme_o_score_q3_txt':  readme_o_score_q3_txt,\n",
    "        'readme_o_score_q4':  readme_o_score_q4,\n",
    "        'readme_o_score_q4_txt':  readme_o_score_q4_txt,\n",
    "        'readme_o_score_q5':  readme_o_score_q5,\n",
    "        'readme_o_score_q5_txt':  readme_o_score_q5_txt\n",
    "    }\n",
    "\n",
    "    df_clean_scores = pd.concat([df_clean_scores, pd.DataFrame([new_entry])], ignore_index=True) # add new_entry to the existing dataframe df_clean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0737948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean_scores) # check length of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083a553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z4nzu</td>\n",
       "      <td>hackingtool</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitwise-01</td>\n",
       "      <td>Instagram-</td>\n",
       "      <td>### \"q1\": [ \\n    ##\"score\": 5##,\\n    ##\"expl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slavfox</td>\n",
       "      <td>Cozette</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>huggingface</td>\n",
       "      <td>alignment-handbook</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grapeot</td>\n",
       "      <td>devin.cursorrules</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    repo_owner           repo_name  \\\n",
       "0        Z4nzu         hackingtool   \n",
       "1   Bitwise-01          Instagram-   \n",
       "2      slavfox             Cozette   \n",
       "3  huggingface  alignment-handbook   \n",
       "4      grapeot   devin.cursorrules   \n",
       "\n",
       "                                      readme_g_score readme_g_score_q1  \\\n",
       "0  ### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...                 0   \n",
       "1  ### \"q1\": [ \\n    ##\"score\": 5##,\\n    ##\"expl...                 0   \n",
       "2  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "3  ### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...                 0   \n",
       "4  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "\n",
       "  readme_g_score_q1_txt readme_g_score_q2 readme_g_score_q2_txt  \\\n",
       "0                     0                 0                     0   \n",
       "1                     0                 0                     0   \n",
       "2                     0                 0                     0   \n",
       "3                     0                 0                     0   \n",
       "4                     0                 0                     0   \n",
       "\n",
       "  readme_g_score_q3 readme_g_score_q3_txt readme_g_score_q4  ...  \\\n",
       "0                 0                     0                 0  ...   \n",
       "1                 0                     0                 0  ...   \n",
       "2                 0                     0                 0  ...   \n",
       "3                 0                     0                 0  ...   \n",
       "4                 0                     0                 0  ...   \n",
       "\n",
       "  readme_o_score_q1 readme_o_score_q1_txt readme_o_score_q2  \\\n",
       "0                 0                     0                 0   \n",
       "1                 0                     0                 0   \n",
       "2                 0                     0                 0   \n",
       "3                 0                     0                 0   \n",
       "4                 0                     0                 0   \n",
       "\n",
       "  readme_o_score_q2_txt readme_o_score_q3 readme_o_score_q3_txt  \\\n",
       "0                     0                 0                     0   \n",
       "1                     0                 0                     0   \n",
       "2                     0                 0                     0   \n",
       "3                     0                 0                     0   \n",
       "4                     0                 0                     0   \n",
       "\n",
       "  readme_o_score_q4 readme_o_score_q4_txt readme_o_score_q5  \\\n",
       "0                 0                     0                 0   \n",
       "1                 0                     0                 0   \n",
       "2                 0                     0                 0   \n",
       "3                 0                     0                 0   \n",
       "4                 0                     0                 0   \n",
       "\n",
       "  readme_o_score_q5_txt  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_scores.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c03f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1 = df_clean_scores.copy() # create copy of df_clean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec895c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_score_num(txt): # function to find score value in given text\n",
    "    score_pattern = r'[sS]core\\b\\W*(\\d)\\W*\\b[eE]xplanation\\b' # pattern to identify the score value # (generated with Microsoft Copilot)\n",
    "    match = re.search(score_pattern, txt) # search for pattern in txt\n",
    "\n",
    "    if match: # if match true\n",
    "        number = match.group(1) # extract group 1 from match\n",
    "        number = int(number) # convert number into integer\n",
    "        \n",
    "        return(number) # return number\n",
    "    else: # if match not true return '0'\n",
    "        return '0'\n",
    "\n",
    "\n",
    "def search_explanation(txt): # function to find score text value in given text\n",
    "    score_pattern = r'\\b[eE]xplanation\\W*(.*)' # pattern to identify the score text # (generated with Microsoft Copilot)\n",
    "    match = re.search(score_pattern, txt) # search for pattern in txt\n",
    "\n",
    "    if match:\n",
    "        explanation = match.group(1) # extract group 1 from match\n",
    "        \n",
    "        return(explanation) # return explanation\n",
    "    else:  # if match not true return '0'\n",
    "        return '0'\n",
    "\n",
    "\n",
    "def clean_score(df): # function to clean scores in provided dataframe\n",
    "    for idx, row in df.iterrows(): # iterate through all index and rows from dataframe\n",
    "        # types = ['g', 'o'] # list with types for the first evaluation (generated readmes and orginal readmes)\n",
    "        types = ['g']\n",
    "        for t in types: # iterate trough list of types\n",
    "            score = row[f'readme_{t}_score'] # extract score from llm\n",
    "            score = score.replace('\\n', '').replace('  ', '') # call replace() for cleaning\n",
    "            score_list = score.split('###') # split score into list \n",
    "            if len(score_list) == 1: # check if split worked, if there are no # in the string, the next row should be processed\n",
    "                continue\n",
    "\n",
    "            num = 1 # set num to track progress\n",
    "            for i in score_list: # iterate over each element (i) in score_list (score from llm split into multiple parts)\n",
    "                if num == 6: # check if num is equal 6 --> there are no more scores than 5\n",
    "                    continue\n",
    "                if i.strip() != '': # strip() --> remove white spaces from string # check if the func strip() applied to i is unequal '' # (generated with Microsoft Copilot)\n",
    "                    # search for q-digit\n",
    "                    q_digit = search_score_num(txt=i) # call search_score_num()\n",
    "                    q_txt = search_explanation(txt=i) # call search_explanation()\n",
    "\n",
    "                    # save q-txt & q-digit in dataframe\n",
    "                    df.at[idx, f'readme_{t}_score_q{num}'] = q_digit # save q_digit into df at specified index\n",
    "                    df.at[idx, f'readme_{t}_score_q{num}_txt'] = q_txt # save q_txt into df at specified index\n",
    "                    num += 1 # increase num by 1\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37dcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score(df=df_model1) # call clean_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af64eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_model1) # check length of df_model1 after cleaning of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddae19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1.to_json('../data/df_score_jamba_mod/df_score_model1.json', orient='records') # save df_model1 in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e12c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [repo_owner, repo_name, readme_g_score, readme_g_score_q1, readme_g_score_q1_txt, readme_g_score_q2, readme_g_score_q2_txt, readme_g_score_q3, readme_g_score_q3_txt, readme_g_score_q4, readme_g_score_q4_txt, readme_g_score_q5, readme_g_score_q5_txt, readme_o_score, readme_o_score_q1, readme_o_score_q1_txt, readme_o_score_q2, readme_o_score_q2_txt, readme_o_score_q3, readme_o_score_q3_txt, readme_o_score_q4, readme_o_score_q4_txt, readme_o_score_q5, readme_o_score_q5_txt]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1[df_model1['readme_g_score_q4'] == '0'] # check if cleaning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ad8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>taki0112</td>\n",
       "      <td>Tensorflow-Cookbook</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...</td>\n",
       "      <td>4</td>\n",
       "      <td>The README clearly states the purpose of the p...</td>\n",
       "      <td>5</td>\n",
       "      <td>The README clearly explains why the project is...</td>\n",
       "      <td>4</td>\n",
       "      <td>The README provides a clear step-by-step guide...</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   repo_owner            repo_name  \\\n",
       "13   taki0112  Tensorflow-Cookbook   \n",
       "\n",
       "                                       readme_g_score readme_g_score_q1  \\\n",
       "13  ### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...                 4   \n",
       "\n",
       "                                readme_g_score_q1_txt readme_g_score_q2  \\\n",
       "13  The README clearly states the purpose of the p...                 5   \n",
       "\n",
       "                                readme_g_score_q2_txt readme_g_score_q3  \\\n",
       "13  The README clearly explains why the project is...                 4   \n",
       "\n",
       "                                readme_g_score_q3_txt readme_g_score_q4  ...  \\\n",
       "13  The README provides a clear step-by-step guide...                 2  ...   \n",
       "\n",
       "   readme_o_score_q1 readme_o_score_q1_txt readme_o_score_q2  \\\n",
       "13                 0                     0                 0   \n",
       "\n",
       "   readme_o_score_q2_txt readme_o_score_q3 readme_o_score_q3_txt  \\\n",
       "13                     0                 0                     0   \n",
       "\n",
       "   readme_o_score_q4 readme_o_score_q4_txt readme_o_score_q5  \\\n",
       "13                 0                     0                 0   \n",
       "\n",
       "   readme_o_score_q5_txt  \n",
       "13                     0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1[df_model1['repo_name'] == 'Tensorflow-Cookbook'] # check values for specific GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc348941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### \"q1\": [\n",
      "    ##\"score\": 4##,\n",
      "    ##\"explanation\": The README clearly states the purpose of the project, which is a TensorFlow repository for deep learning model, specifically designed for image processing and generation tasks. However, it would be even better if the goal of the project was more specific, e.g., \"This project aims to provide a comprehensive collection of neural network architectures and functions for image processing and generation tasks, with a focus on convolutional neural networks (CNNs) and generative adversarial networks (GANs)\".##\n",
      "]\n",
      "\n",
      "### \"q2\": [\n",
      "    ##\"score\": 5##,\n",
      "    ##\"explanation\": The README clearly explains why the project is useful, which is that it provides a collection of various neural network architectures and functions for image processing and generation tasks. This is a very good answer, as it highlights the benefits of the project and its potential applications.##\n",
      "]\n",
      "\n",
      "### \"q3\": [\n",
      "    ##\"score\": 4##,\n",
      "    ##\"explanation\": The README provides a clear step-by-step guide on how to get started with the project, including installation and usage instructions. However, it would be even better if the README included more detailed information on how to use the repository, such as example use cases, tutorials, or code snippets.##\n",
      "]\n",
      "\n",
      "### \"q4\": [\n",
      "    ##\"score\": 2##,\n",
      "    ##\"explanation\": The README mentions that contributions are welcome, but it does not provide any information on how to get help with the project, such as a mailing list, forum, or issue tracker. This is a sufficient answer, but it could be improved by providing more information on how to get help.##\n",
      "]\n",
      "\n",
      "### \"q5\": [\n",
      "    ##\"score\": 2##,\n",
      "    ##\"explanation\": The README mentions that the repository is maintained by Junho Kim, but it does not provide any information on how to contact him or other contributors. This is a sufficient answer, but it could be improved by providing more information on the project's governance and maintenance.##\n"
     ]
    }
   ],
   "source": [
    "print(df_model1.loc[13, 'readme_g_score']) # print scores for specific index "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
