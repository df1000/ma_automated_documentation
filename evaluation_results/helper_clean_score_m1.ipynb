{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5588e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477ae825",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_range = Path('../data/output_evaluation_data_jamba/model1') \n",
    "all_files_range = [file.name for file in path_range.iterdir() if file.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9249d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['repo_owner','repo_name','readme_g_score','readme_g_score_q1','readme_g_score_q1_txt','readme_g_score_q2','readme_g_score_q2_txt','readme_g_score_q3','readme_g_score_q3_txt','readme_g_score_q4','readme_g_score_q4_txt','readme_g_score_q5','readme_g_score_q5_txt','readme_o_score','readme_o_score_q1','readme_o_score_q1_txt','readme_o_score_q2','readme_o_score_q2_txt','readme_o_score_q3','readme_o_score_q3_txt','readme_o_score_q4','readme_o_score_q4_txt','readme_o_score_q5','readme_o_score_q5_txt']\n",
    "df_clean_scores = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a36566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_files_range:\n",
    "    new_entry = {}\n",
    "\n",
    "    with open(f'../data/output_evaluation_data_jamba/model1/{i}', 'r') as f:\n",
    "        loaded_data = json.load(f)\n",
    "\n",
    "    repo_owner = loaded_data['repo_owner']\n",
    "    repo_name = loaded_data['repo_name']\n",
    "    readme_g_score = loaded_data['readme_genereated']['evaluation']\n",
    "    readme_o_score = loaded_data['readme_original']['evaluation']\n",
    "\n",
    "    if loaded_data['readme_genereated']['score'] == [] or loaded_data['readme_genereated']['score'] == {}:\n",
    "        readme_g_score_q1 = '0'\n",
    "        readme_g_score_q1_txt = '0'\n",
    "        readme_g_score_q2 = '0'\n",
    "        readme_g_score_q2_txt = '0'\n",
    "        readme_g_score_q3 = '0'\n",
    "        readme_g_score_q3_txt = '0'\n",
    "        readme_g_score_q4 = '0'\n",
    "        readme_g_score_q4_txt = '0'\n",
    "        readme_g_score_q5 = '0'\n",
    "        readme_g_score_q5_txt = '0'\n",
    "\n",
    "    else:\n",
    "        readme_g_score_q1 = loaded_data['readme_genereated']['score'][0]['score']\n",
    "        readme_g_score_q1_txt = loaded_data['readme_genereated']['score'][0]['explanation']\n",
    "        readme_g_score_q2 = loaded_data['readme_genereated']['score'][1]['score']\n",
    "        readme_g_score_q2_txt = loaded_data['readme_genereated']['score'][1]['explanation']\n",
    "        readme_g_score_q3 = loaded_data['readme_genereated']['score'][2]['score']\n",
    "        readme_g_score_q3_txt = loaded_data['readme_genereated']['score'][2]['explanation']\n",
    "        readme_g_score_q4 = loaded_data['readme_genereated']['score'][3]['score']\n",
    "        readme_g_score_q4_txt = loaded_data['readme_genereated']['score'][3]['explanation']\n",
    "        readme_g_score_q5 = loaded_data['readme_genereated']['score'][4]['score']\n",
    "        readme_g_score_q5_txt = loaded_data['readme_genereated']['score'][4]['explanation']\n",
    "    \n",
    "    if loaded_data['readme_original']['score'] == [] or loaded_data['readme_original']['score'] == {}:\n",
    "        readme_o_score_q1 = '0'\n",
    "        readme_o_score_q1_txt = '0'\n",
    "        readme_o_score_q2 = '0'\n",
    "        readme_o_score_q2_txt = '0'\n",
    "        readme_o_score_q3 = '0'\n",
    "        readme_o_score_q3_txt = '0'\n",
    "        readme_o_score_q4 = '0'\n",
    "        readme_o_score_q4_txt = '0'\n",
    "        readme_o_score_q5 = '0'\n",
    "        readme_o_score_q5_txt = '0'\n",
    "\n",
    "    else:\n",
    "        readme_o_score_q1 = loaded_data['readme_original']['score'][0]['score']\n",
    "        readme_o_score_q1_txt = loaded_data['readme_original']['score'][0]['explanation']\n",
    "        readme_o_score_q2 = loaded_data['readme_original']['score'][1]['score']\n",
    "        readme_o_score_q2_txt = loaded_data['readme_original']['score'][1]['explanation']\n",
    "        readme_o_score_q3 = loaded_data['readme_original']['score'][2]['score']\n",
    "        readme_o_score_q3_txt = loaded_data['readme_original']['score'][2]['explanation']\n",
    "        readme_o_score_q4 = loaded_data['readme_original']['score'][3]['score']\n",
    "        readme_o_score_q4_txt = loaded_data['readme_original']['score'][3]['explanation']\n",
    "        readme_o_score_q5 = loaded_data['readme_original']['score'][4]['score']\n",
    "        readme_o_score_q5_txt = loaded_data['readme_original']['score'][4]['explanation']\n",
    "\n",
    "    new_entry = {\n",
    "        'repo_owner': repo_owner,\n",
    "        'repo_name': repo_name,\n",
    "        'readme_g_score': readme_g_score,\n",
    "        'readme_g_score_q1': readme_g_score_q1,\n",
    "        'readme_g_score_q1_txt': readme_g_score_q1_txt,\n",
    "        'readme_g_score_q2':  readme_g_score_q2,\n",
    "        'readme_g_score_q2_txt':  readme_g_score_q2_txt,\n",
    "        'readme_g_score_q3':  readme_g_score_q3,\n",
    "        'readme_g_score_q3_txt':  readme_g_score_q3_txt,\n",
    "        'readme_g_score_q4':  readme_g_score_q4,\n",
    "        'readme_g_score_q4_txt':  readme_g_score_q4_txt,\n",
    "        'readme_g_score_q5':  readme_g_score_q5,\n",
    "        'readme_g_score_q5_txt':  readme_g_score_q5_txt,\n",
    "        'readme_o_score':  readme_o_score,    \n",
    "        'readme_o_score_q1':  readme_o_score_q1,\n",
    "        'readme_o_score_q1_txt':  readme_o_score_q1_txt, \n",
    "        'readme_o_score_q2':  readme_o_score_q2,\n",
    "        'readme_o_score_q2_txt':  readme_o_score_q2_txt,\n",
    "        'readme_o_score_q3':  readme_o_score_q3,\n",
    "        'readme_o_score_q3_txt':  readme_o_score_q3_txt,\n",
    "        'readme_o_score_q4':  readme_o_score_q4,\n",
    "        'readme_o_score_q4_txt':  readme_o_score_q4_txt,\n",
    "        'readme_o_score_q5':  readme_o_score_q5,\n",
    "        'readme_o_score_q5_txt':  readme_o_score_q5_txt\n",
    "    }\n",
    "\n",
    "    df_clean_scores = pd.concat([df_clean_scores, pd.DataFrame([new_entry])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0737948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083a553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gleitz</td>\n",
       "      <td>howdoi</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxh</td>\n",
       "      <td>xxh</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realpython</td>\n",
       "      <td>cookiecutter-flask-skeleton</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taki0112</td>\n",
       "      <td>Tensorflow-Cookbook</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sebastianruder</td>\n",
       "      <td>NLP-progress</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       repo_owner                    repo_name  \\\n",
       "0          gleitz                       howdoi   \n",
       "1             xxh                          xxh   \n",
       "2      realpython  cookiecutter-flask-skeleton   \n",
       "3        taki0112          Tensorflow-Cookbook   \n",
       "4  sebastianruder                 NLP-progress   \n",
       "\n",
       "                                      readme_g_score readme_g_score_q1  \\\n",
       "0  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "1  ### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...                 0   \n",
       "2  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "3  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "4  ### \"q1\": [\\n    ##\"score\": 5##,\\n    ##\"expla...                 0   \n",
       "\n",
       "  readme_g_score_q1_txt readme_g_score_q2 readme_g_score_q2_txt  \\\n",
       "0                     0                 0                     0   \n",
       "1                     0                 0                     0   \n",
       "2                     0                 0                     0   \n",
       "3                     0                 0                     0   \n",
       "4                     0                 0                     0   \n",
       "\n",
       "  readme_g_score_q3 readme_g_score_q3_txt readme_g_score_q4  ...  \\\n",
       "0                 0                     0                 0  ...   \n",
       "1                 0                     0                 0  ...   \n",
       "2                 0                     0                 0  ...   \n",
       "3                 0                     0                 0  ...   \n",
       "4                 0                     0                 0  ...   \n",
       "\n",
       "  readme_o_score_q1 readme_o_score_q1_txt readme_o_score_q2  \\\n",
       "0                 0                     0                 0   \n",
       "1                 0                     0                 0   \n",
       "2                 0                     0                 0   \n",
       "3                 0                     0                 0   \n",
       "4                 0                     0                 0   \n",
       "\n",
       "  readme_o_score_q2_txt readme_o_score_q3 readme_o_score_q3_txt  \\\n",
       "0                     0                 0                     0   \n",
       "1                     0                 0                     0   \n",
       "2                     0                 0                     0   \n",
       "3                     0                 0                     0   \n",
       "4                     0                 0                     0   \n",
       "\n",
       "  readme_o_score_q4 readme_o_score_q4_txt readme_o_score_q5  \\\n",
       "0                 0                     0                 0   \n",
       "1                 0                     0                 0   \n",
       "2                 0                     0                 0   \n",
       "3                 0                     0                 0   \n",
       "4                 0                     0                 0   \n",
       "\n",
       "  readme_o_score_q5_txt  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_scores.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85976f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_clean_scores[df_clean_scores['readme_o_score'] == '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c03f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1 = df_clean_scores.copy()\n",
    "#df_test = df_test.iloc[7:9]\n",
    "#df_test = df_test.loc[:,'repo_owner':'readme_g_score_q5_txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec895c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_score_num(txt):\n",
    "    score_pattern = r'[sS]core\\b\\W*(\\d)\\W*\\b[eE]xplanation\\b'\n",
    "    match = re.search(score_pattern, txt)\n",
    "\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        number = int(number)\n",
    "        \n",
    "        return(number)\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def search_explanation(txt):\n",
    "    score_pattern = r'\\b[eE]xplanation\\W*(.*)'\n",
    "    match = re.search(score_pattern, txt)\n",
    "\n",
    "    if match:\n",
    "        explanation = match.group(1)\n",
    "        \n",
    "        return(explanation)\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def clean_score(df):\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        types = ['g', 'o']\n",
    "        for t in types:\n",
    "            score = row[f'readme_{t}_score']#.iloc[idx]\n",
    "            score = score.replace('\\n', '').replace('  ', '')\n",
    "            score_list = score.split('###')\n",
    "            if len(score_list) == 1: # check if split worked, if there are no # in the string, the next row should be processed\n",
    "                continue\n",
    "\n",
    "            num = 1\n",
    "            # print(f'score_list: {score_list}')\n",
    "            # print(len(score_list))\n",
    "            for i in score_list:\n",
    "                # print(f'i:{i}')\n",
    "                # print(type(i))\n",
    "                if num == 6:\n",
    "                    continue\n",
    "                if i.strip() != '':\n",
    "                    # search for q-digit\n",
    "                    q_digit = search_score_num(txt=i)\n",
    "                    # print(\"q_digit:\", q_digit)\n",
    "                    # print(f'num: {num}')\n",
    "\n",
    "                    q_txt = search_explanation(txt=i)\n",
    "\n",
    "                    # save q-mark & q-digit in dataframe\n",
    "                    #row[f'readme_g_score_q{num}'] = q_digit\n",
    "                    df.at[idx, f'readme_{t}_score_q{num}'] = int(q_digit)\n",
    "                    df.at[idx, f'readme_{t}_score_q{num}_txt'] = q_txt\n",
    "                    num += 1\n",
    "                    \n",
    "                else:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37dcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_score(df=df_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39ddbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_model3['readme_g_score_q1'].iloc[0:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af64eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddae19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model1.to_json('../data/df_score_jamba/df_score_model1.json', orient='records') # write df_to_save in JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6e12c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [repo_owner, repo_name, readme_g_score, readme_g_score_q1, readme_g_score_q1_txt, readme_g_score_q2, readme_g_score_q2_txt, readme_g_score_q3, readme_g_score_q3_txt, readme_g_score_q4, readme_g_score_q4_txt, readme_g_score_q5, readme_g_score_q5_txt, readme_o_score, readme_o_score_q1, readme_o_score_q1_txt, readme_o_score_q2, readme_o_score_q2_txt, readme_o_score_q3, readme_o_score_q3_txt, readme_o_score_q4, readme_o_score_q4_txt, readme_o_score_q5, readme_o_score_q5_txt]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1[df_model1['readme_o_score_q5'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "134ad8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>readme_g_score</th>\n",
       "      <th>readme_g_score_q1</th>\n",
       "      <th>readme_g_score_q1_txt</th>\n",
       "      <th>readme_g_score_q2</th>\n",
       "      <th>readme_g_score_q2_txt</th>\n",
       "      <th>readme_g_score_q3</th>\n",
       "      <th>readme_g_score_q3_txt</th>\n",
       "      <th>readme_g_score_q4</th>\n",
       "      <th>...</th>\n",
       "      <th>readme_o_score_q1</th>\n",
       "      <th>readme_o_score_q1_txt</th>\n",
       "      <th>readme_o_score_q2</th>\n",
       "      <th>readme_o_score_q2_txt</th>\n",
       "      <th>readme_o_score_q3</th>\n",
       "      <th>readme_o_score_q3_txt</th>\n",
       "      <th>readme_o_score_q4</th>\n",
       "      <th>readme_o_score_q4_txt</th>\n",
       "      <th>readme_o_score_q5</th>\n",
       "      <th>readme_o_score_q5_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qqwweee</td>\n",
       "      <td>keras-yolo3</td>\n",
       "      <td>### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...</td>\n",
       "      <td>4</td>\n",
       "      <td>The README clearly states the purpose of the p...</td>\n",
       "      <td>2</td>\n",
       "      <td>The README does not explicitly state why the p...</td>\n",
       "      <td>2</td>\n",
       "      <td>The README provides a general instruction on h...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>The goal of the project is clearly stated in t...</td>\n",
       "      <td>3</td>\n",
       "      <td>The project is useful because it provides a Ke...</td>\n",
       "      <td>5</td>\n",
       "      <td>The README provides a clear and step-by-step g...</td>\n",
       "      <td>2</td>\n",
       "      <td>The README does not explicitly mention where u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   repo_owner    repo_name                                     readme_g_score  \\\n",
       "31    qqwweee  keras-yolo3  ### \"q1\": [\\n    ##\"score\": 4##,\\n    ##\"expla...   \n",
       "\n",
       "   readme_g_score_q1                              readme_g_score_q1_txt  \\\n",
       "31                 4  The README clearly states the purpose of the p...   \n",
       "\n",
       "   readme_g_score_q2                              readme_g_score_q2_txt  \\\n",
       "31                 2  The README does not explicitly state why the p...   \n",
       "\n",
       "   readme_g_score_q3                              readme_g_score_q3_txt  \\\n",
       "31                 2  The README provides a general instruction on h...   \n",
       "\n",
       "   readme_g_score_q4  ... readme_o_score_q1 readme_o_score_q1_txt  \\\n",
       "31                 1  ...                 0                     0   \n",
       "\n",
       "   readme_o_score_q2                              readme_o_score_q2_txt  \\\n",
       "31                 4  The goal of the project is clearly stated in t...   \n",
       "\n",
       "   readme_o_score_q3                              readme_o_score_q3_txt  \\\n",
       "31                 3  The project is useful because it provides a Ke...   \n",
       "\n",
       "   readme_o_score_q4                              readme_o_score_q4_txt  \\\n",
       "31                 5  The README provides a clear and step-by-step g...   \n",
       "\n",
       "   readme_o_score_q5                              readme_o_score_q5_txt  \n",
       "31                 2  The README does not explicitly mention where u...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model1[df_model1['repo_name'] == 'keras-yolo3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc348941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the evaluations of the README based on the provided questions:\n",
      "\n",
      "### q1: What is the goal of the project?\n",
      "## \"score\": 4,\n",
      "## \"explanation\": The goal of the project is clearly stated in the \"Introduction\" section, which is to provide a Keras implementation of YOLOv3 with a Tensorflow backend. The project is inspired by another repository, but it is not explicitly stated what the main goal of this specific project is. However, it can be inferred that the goal is to provide a Keras implementation of YOLOv3 for object detection tasks.\n",
      "\n",
      "### q2: Why is the project useful?\n",
      "## \"score\": 3,\n",
      "## \"explanation\": The project is useful because it provides a Keras implementation of YOLOv3, which is a popular object detection algorithm. The project also provides a simple way to use YOLOv3 for image and video detection. However, the README does not explicitly state why this project is useful or what benefits it provides over other object detection algorithms.\n",
      "\n",
      "### q3: How can users get started with the project?\n",
      "## \"score\": 5,\n",
      "## \"explanation\": The README provides a clear and step-by-step guide on how to get started with the project. The \"Quick Start\" section provides a simple and concise guide on how to download the YOLOv3 weights, convert the Darknet model to a Keras model, and run the YOLO detection. The usage of the `yolo_video.py` script is also clearly explained.\n",
      "\n",
      "### q4: Where can users get help with your project?\n",
      "## \"score\": 2,\n",
      "## \"explanation\": The README does not explicitly mention where users can get help with the project. However, it does mention some issues to know, which may be helpful for users who encounter problems. It would be better to provide a clear link to the project's issue tracker or a support email.\n",
      "\n",
      "### q5: Who maintains and contributes to the project?\n",
      "## \"score\": 1,\n",
      "## \"explanation\": The README does not mention who maintains and contributes to the project. It would be helpful to provide information on the project's maintainers, contributors, and contact information.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_model1.loc[31, 'readme_o_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603922fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_owner                                                  databrickslabs\n",
      "repo_name                                                            dolly\n",
      "readme_g_score            ###\\n\"q1\": [\\n    \"score\": 5,\\n    \"explanati...\n",
      "readme_g_score_q1                                                        5\n",
      "readme_g_score_q1_txt    The goal of the project is clearly stated in t...\n",
      "readme_g_score_q2                                                        5\n",
      "readme_g_score_q2_txt    The project's usefulness is implied in the des...\n",
      "readme_g_score_q3                                                        4\n",
      "readme_g_score_q3_txt    The installation and usage instructions are pr...\n",
      "readme_g_score_q4                                                        3\n",
      "readme_g_score_q4_txt    While the repository link is provided, there i...\n",
      "readme_g_score_q5                                                        3\n",
      "readme_g_score_q5_txt    The README mentions that contributions are wel...\n",
      "readme_o_score            ### q1: What is the goal of the project?\\n\\n*...\n",
      "readme_o_score_q1                                                        5\n",
      "readme_o_score_q1_txt    The goal of the project is clearly stated in t...\n",
      "readme_o_score_q2_txt    The README provides a good explanation of the ...\n",
      "readme_o_score_q3                                                        5\n",
      "readme_o_score_q3_txt    The README offers detailed instructions on how...\n",
      "readme_o_score_q4                                                        3\n",
      "readme_o_score_q4_txt    The README does not explicitly mention where u...\n",
      "readme_o_score_q5                                                        4\n",
      "readme_o_score_q5_txt    The README mentions that Databricks is committ...\n",
      "readme_o_score_q2                                                        4\n",
      "Name: 197, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_model1.iloc[197])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_owner                                             Genesis-Embodied-AI\n",
      "repo_name                                                          Genesis\n",
      "readme_g_score            ###\\n\"q1\": [\\n    \"score\": 5,\\n    \"explanati...\n",
      "readme_g_score_q1                                                        5\n",
      "readme_g_score_q1_txt    The goal of the project is clearly stated in t...\n",
      "readme_g_score_q2                                                        5\n",
      "readme_g_score_q2_txt    The project's usefulness is implied in the des...\n",
      "readme_g_score_q3                                                        4\n",
      "readme_g_score_q3_txt    The README provides clear instructions on how ...\n",
      "readme_g_score_q4                                                        3\n",
      "readme_g_score_q4_txt    The README mentions the issue tracker for repo...\n",
      "readme_g_score_q5                                                        5\n",
      "readme_g_score_q5_txt    The README clearly states that contributions a...\n",
      "readme_o_score            ### q1: What is the goal of the project?\\n\\n*...\n",
      "readme_o_score_q1                                                        5\n",
      "readme_o_score_q1_txt    The goal of the project is clearly stated in t...\n",
      "readme_o_score_q2_txt    The project is described as useful for several...\n",
      "readme_o_score_q3                                                        4\n",
      "readme_o_score_q3_txt    The README provides clear instructions on how ...\n",
      "readme_o_score_q4                                                        5\n",
      "readme_o_score_q4_txt    The README provides multiple avenues for users...\n",
      "readme_o_score_q5                                                        5\n",
      "readme_o_score_q5_txt    The README does not explicitly state who maint...\n",
      "readme_o_score_q2                                                        5\n",
      "Name: 198, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_model1.iloc[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/df_score_model3.json', 'r') as f:\n",
    "#     d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9998b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', 50) # default value\n",
    "#pd.reset_option('display.max_colwidth', None) # turn off max coldwidth --> so i can see the whole column\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
