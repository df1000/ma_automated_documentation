{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3be5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hint: If lines are created with support of a Large Language Model or the code is taken from another source, you find following hint at the end of the line:\n",
    "#       (generated with Microsoft Copilot) or (source: link_to_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e9f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.cortex import Complete\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0adc1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# set up connection parameters for Snowflake connection\n",
    "connection_params = {\n",
    "    \"account\": os.environ['SNOWFLAKE_ACCOUNT'],\n",
    "    \"user\": os.environ['SNOWFLAKE_USER'],\n",
    "    \"password\": os.environ['SNOWFLAKE_USER_PASSWORD'],\n",
    "    \"role\": 'ACCOUNTADMIN',\n",
    "    \"warehouse\": 'COMPUTE_WH',\n",
    "    'paramstyle': 'qmark'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd72cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama3.1-8b'\n",
    "model_summary_params = {\n",
    "   'temperature': 0, # default: 0 https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex --> Internetrecherche hat keine anderen Empfehlungen ergeben\n",
    "   # 'top_p': # default: 0 https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex\n",
    "    'max_tokens': 4000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78481959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake sessions is build.\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "snowflake_session = Session.builder.configs(connection_params).create()\n",
    "print('Snowflake sessions is build.')\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1097a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/input_readme_data/jianchang512_stt.json', 'r')  as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "source_code_cleaned_comments = loaded_data['source_code_cleaned_comments']\n",
    "license = loaded_data['license']\n",
    "requirements = loaded_data['requirements']\n",
    "\n",
    "input_txt = source_code_cleaned_comments\n",
    "\n",
    "repo_name = 'stt'\n",
    "repo_owner = 'jianchang512'\n",
    "# license = ''\n",
    "# requirements = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5935829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary_prompt(repo_name, input_txt):\n",
    "    prompt_summary = f'''\n",
    "        You are acting as a software development expert for the following GitHub repository \"{repo_name}\".\n",
    "        Your task is to summarize the given source code string \"{input_txt}\" in natural language, so a specialist is able to understand\n",
    "        the purpose of the repository.\n",
    "        Identify its purpose, key functions, main components and dependencies. Focus on the overall architecture and structure \n",
    "        rather than line-by-line details. Do not add any recommendations or improvement suggestions, but concentrate on the summary. \n",
    "        Present the summary in a clear and concise language.\n",
    "        You are not allowed to add any small talk. \n",
    "    ''' \n",
    "    #prompt_summary = prompt_summary.replace(\"'\", \"\\\\'\").replace(\";\", \"\\\\;\").replace('\"', '\\\\\"')\n",
    "\n",
    "    return prompt_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4720d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = write_summary_prompt(repo_name, input_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327886f",
   "metadata": {},
   "source": [
    "https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.Session.sql  \n",
    "Doku f√ºr bind variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "479308c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "            SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "                ?,\n",
    "                [\n",
    "                    {{\n",
    "                        'role': 'user', \n",
    "                        'content': ?\n",
    "                    }}\n",
    "                ],\n",
    "                {{\n",
    "                    'temperature': ?,\n",
    "                    'max_tokens':  ?\n",
    "                }} \n",
    "            ) AS response\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e953503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = snowflake_session.sql(query, params=[model, prompt_summary, model_summary_params['temperature'], model_summary_params['max_tokens']]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c49487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "#             SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "#                 '{model}',\n",
    "#                 [\n",
    "#                     {{\n",
    "#                         'role': 'user', \n",
    "#                         'content': '{prompt}'\n",
    "#                     }}\n",
    "#                 ],\n",
    "#                 {{\n",
    "#                     'temperature': {model_params['temperature']},\n",
    "#                     'max_tokens':  {model_params['max_tokens']}\n",
    "#                 }} \n",
    "#             ) AS response\n",
    "#         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5d63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = snowflake_session.sql(query).collect()\n",
    "res = json.loads(response[0]['RESPONSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08f17544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'messages': '**Repository Purpose:**\\nThe repository is a web application for automatic speech recognition (ASR) and text-to-speech (TTS) tasks. It utilizes the Whisper model, a state-of-the-art ASR model, and provides a user-friendly interface for uploading audio files, selecting models, and configuring settings.\\n\\n**Key Functions:**\\n\\n1. **Audio Upload**: Users can upload audio files in various formats, and the application will convert them to WAV format.\\n2. **Model Selection**: Users can choose from a list of pre-trained models for ASR and TTS tasks.\\n3. **Configuration**: Users can configure settings such as device type (CPU or CUDA), beam size, and temperature.\\n4. **ASR and TTS Processing**: The application will process the uploaded audio file using the selected model and settings, and return the recognized text or synthesized speech.\\n5. **Progress Bar**: The application displays a progress bar to indicate the status of the processing task.\\n\\n**Main Components:**\\n\\n1. **Flask Web Server**: The application uses Flask to create a web server for handling HTTP requests and serving static files.\\n2. **Whisper Model**: The application utilizes the Whisper model for ASR and TTS tasks.\\n3. **FFmpeg**: The application uses FFmpeg for audio file conversion and processing.\\n4. **Config File**: The application reads configuration settings from a `set.ini` file.\\n\\n**Dependencies:**\\n\\n1. **Python**: The application is built using Python 3.x.\\n2. **Flask**: The application uses Flask for web development.\\n3. **Whisper**: The application uses the Whisper model for ASR and TTS tasks.\\n4. **FFmpeg**: The application uses FFmpeg for audio file conversion and processing.\\n5. **PyTorch**: The application uses PyTorch for deep learning tasks.\\n6. **Gevent**: The application uses Gevent for concurrent processing.\\n7. **Requests**: The application uses Requests for making HTTP requests.\\n8. **Subprocess**: The application uses Subprocess for executing external commands.'}],\n",
       " 'created': 1748783893,\n",
       " 'model': 'llama3.1-8b',\n",
       " 'usage': {'completion_tokens': 420,\n",
       "  'prompt_tokens': 4274,\n",
       "  'total_tokens': 4694}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b237b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = res['choices'][0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a220d5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Repository Purpose:**\n",
      "The repository is a web application for automatic speech recognition (ASR) and text-to-speech (TTS) tasks. It utilizes the Whisper model, a state-of-the-art ASR model, and provides a user-friendly interface for uploading audio files, selecting models, and configuring settings.\n",
      "\n",
      "**Key Functions:**\n",
      "\n",
      "1. **Audio Upload**: Users can upload audio files in various formats, and the application will convert them to WAV format.\n",
      "2. **Model Selection**: Users can choose from a list of pre-trained models for ASR and TTS tasks.\n",
      "3. **Configuration**: Users can configure settings such as device type (CPU or CUDA), beam size, and temperature.\n",
      "4. **ASR and TTS Processing**: The application will process the uploaded audio file using the selected model and settings, and return the recognized text or synthesized speech.\n",
      "5. **Progress Bar**: The application displays a progress bar to indicate the status of the processing task.\n",
      "\n",
      "**Main Components:**\n",
      "\n",
      "1. **Flask Web Server**: The application uses Flask to create a web server for handling HTTP requests and serving static files.\n",
      "2. **Whisper Model**: The application utilizes the Whisper model for ASR and TTS tasks.\n",
      "3. **FFmpeg**: The application uses FFmpeg for audio file conversion and processing.\n",
      "4. **Config File**: The application reads configuration settings from a `set.ini` file.\n",
      "\n",
      "**Dependencies:**\n",
      "\n",
      "1. **Python**: The application is built using Python 3.x.\n",
      "2. **Flask**: The application uses Flask for web development.\n",
      "3. **Whisper**: The application uses the Whisper model for ASR and TTS tasks.\n",
      "4. **FFmpeg**: The application uses FFmpeg for audio file conversion and processing.\n",
      "5. **PyTorch**: The application uses PyTorch for deep learning tasks.\n",
      "6. **Gevent**: The application uses Gevent for concurrent processing.\n",
      "7. **Requests**: The application uses Requests for making HTTP requests.\n",
      "8. **Subprocess**: The application uses Subprocess for executing external commands.\n"
     ]
    }
   ],
   "source": [
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45dc4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Snowflake session is closed.\n"
     ]
    }
   ],
   "source": [
    "snowflake_session.close()\n",
    "print('---------------------------------------------')\n",
    "print('Snowflake session is closed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
