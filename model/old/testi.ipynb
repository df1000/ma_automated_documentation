{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22471bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd8d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c401d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(path):\n",
    "    try:\n",
    "        with open(path, 'r') as file:\n",
    "            loaded_data = json.load(file)\n",
    "        return loaded_data\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6195b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe is created.\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "loaded_data = open_json(path='../../data/df_repos_counts_filtered.json')\n",
    "df = pd.DataFrame(loaded_data)\n",
    "print('Dataframe is created.')\n",
    "print('---------------------------------------------')\n",
    "repo_list = [(row.repo_owner, row.repo_name, row.source_code_cleaned_comments) for row in df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85faec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59cfa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>source_code_comments</th>\n",
       "      <th>source_code</th>\n",
       "      <th>source_code_cleaned_comments</th>\n",
       "      <th>source_code_cleaned</th>\n",
       "      <th>comments</th>\n",
       "      <th>formatting</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rochacbruno</td>\n",
       "      <td>python-week-2022</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>floydhub</td>\n",
       "      <td>dl-docker</td>\n",
       "      <td>1044</td>\n",
       "      <td>314</td>\n",
       "      <td>850</td>\n",
       "      <td>263</td>\n",
       "      <td>730</td>\n",
       "      <td>51</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    repo_owner         repo_name  source_code_comments  source_code  \\\n",
       "0  rochacbruno  python-week-2022                   313          313   \n",
       "1     floydhub         dl-docker                  1044          314   \n",
       "\n",
       "   source_code_cleaned_comments  source_code_cleaned  comments  formatting  \\\n",
       "0                           260                  260         0          53   \n",
       "1                           850                  263       730          51   \n",
       "\n",
       "    sum  \n",
       "0   313  \n",
       "1  1044  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11fa6379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1fb32d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('floydhub', 'dl-docker', 850)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f068019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "repo_list = [1, 2, 3, 4]\n",
    "cnt = 0\n",
    "for i in repo_list:\n",
    "    print(i)\n",
    "    cnt += 1\n",
    "    if cnt >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c115d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1018fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/output_data/floydhub_dl-docker_output.json', 'r')  as file:\n",
    "    loaded_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d4094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo_owner': 'floydhub',\n",
       " 'repo_name': 'dl-docker',\n",
       " 'summaries': ['**Repository Summary:**\\n\\nThe `dl-docker` repository is a Dockerized environment for deep learning with TensorFlow. The primary purpose of this repository is to provide a pre-configured Docker container for running Jupyter Notebooks with TensorFlow, allowing users to easily set up and use a deep learning environment without the need for manual installation and configuration.\\n\\n**Key Functionalities:**\\n\\n1. **Jupyter Notebook Server**: The repository sets up a Jupyter Notebook server, allowing users to create and run notebooks for deep learning tasks.\\n2. **TensorFlow Integration**: The environment is pre-configured with TensorFlow, enabling users to leverage the popular deep learning framework.\\n3. **Password Protection**: The repository includes a password protection mechanism, ensuring that the Jupyter Notebook server is secure and only accessible to authorized users.\\n4. **Multi-Kernel Support**: The environment supports multiple kernel options, including Python 2, allowing users to switch between different kernel versions.\\n\\n**Main Components:**\\n\\n1. **Dockerfile**: The Dockerfile is the core component of the repository, defining the environment and dependencies required for the Jupyter Notebook server and TensorFlow.\\n2. **Jupyter Notebook Server**: The Jupyter Notebook server is the primary application running within the Docker container, providing an interface for users to create and run notebooks.\\n3. **TensorFlow**: The repository includes TensorFlow as a pre-installed dependency, allowing users to leverage the deep learning framework within their notebooks.\\n\\n**Dependencies:**\\n\\n1. **Docker**: The repository relies on Docker to create and manage the containerized environment.\\n2. **Jupyter Notebook**: The Jupyter Notebook server is the core application running within the container.\\n3. **TensorFlow**: The repository includes TensorFlow as a pre-installed dependency.\\n4. **IPython**: The repository uses IPython as a dependency for the Jupyter Notebook server.\\n\\n**Overall Architecture:**\\n\\nThe repository uses a simple and straightforward architecture, with the Dockerfile defining the environment and dependencies, and the Jupyter Notebook server running within the container. The password protection mechanism is implemented using environment variables, ensuring secure access to the Jupyter Notebook server. The multi-kernel support is achieved through the use of the `c.MultiKernelManager` class.'],\n",
       " 'readme': \"## dl-docker\\n================\\n\\n### Repository Summary\\n\\nThe `dl-docker` repository provides a pre-configured Docker container for running Jupyter Notebooks with TensorFlow, allowing users to easily set up and use a deep learning environment without manual installation and configuration.\\n\\n### Installation\\n\\nTo get started, follow these steps:\\n\\n1. Install Docker on your machine if you haven't already.\\n2. Clone the repository using `git clone https://github.com/floydhub/dl-docker.git`.\\n3. Navigate to the repository directory and run `docker build -t dl-docker .` to build the Docker image.\\n4. Run `docker run -p 8888:8888 dl-docker` to start the Docker container.\\n5. Open a web browser and navigate to `http://localhost:8888` to access the Jupyter Notebook server.\\n\\n### Usage\\n\\nThe Jupyter Notebook server is pre-configured with TensorFlow and password protection. To access the server, use the password specified in the `PASSWORD` environment variable. You can switch between different kernel options, including Python 2, using the `c.MultiKernelManager` class.\\n\\n### Contributing\\n\\nContributions are welcome! If you'd like to contribute to the project, please fork the repository and submit a pull request. Make sure to follow the standard guidelines for contributing to open-source projects.\\n\\n### License\\n\\nThis project is licensed under the [MIT License](https://opensource.org/licenses/MIT).\\n\\n### Overall Architecture\\n\\nThe repository uses a simple and straightforward architecture, with the Dockerfile defining the environment and dependencies, and the Jupyter Notebook server running within the container. The password protection mechanism is implemented using environment variables, ensuring secure access to the Jupyter Notebook server. The multi-kernel support is achieved through the use of the `c.MultiKernelManager` class.\",\n",
       " 'readme_tokens': {'total_tokens': 1059,\n",
       "  'completion_tokens': 368,\n",
       "  'prompt_tokens': 691}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7508f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = loaded_data['readme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b3988a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## dl-docker\n",
      "================\n",
      "\n",
      "### Repository Summary\n",
      "\n",
      "The `dl-docker` repository provides a pre-configured Docker container for running Jupyter Notebooks with TensorFlow, allowing users to easily set up and use a deep learning environment without manual installation and configuration.\n",
      "\n",
      "### Installation\n",
      "\n",
      "To get started, follow these steps:\n",
      "\n",
      "1. Install Docker on your machine if you haven't already.\n",
      "2. Clone the repository using `git clone https://github.com/floydhub/dl-docker.git`.\n",
      "3. Navigate to the repository directory and run `docker build -t dl-docker .` to build the Docker image.\n",
      "4. Run `docker run -p 8888:8888 dl-docker` to start the Docker container.\n",
      "5. Open a web browser and navigate to `http://localhost:8888` to access the Jupyter Notebook server.\n",
      "\n",
      "### Usage\n",
      "\n",
      "The Jupyter Notebook server is pre-configured with TensorFlow and password protection. To access the server, use the password specified in the `PASSWORD` environment variable. You can switch between different kernel options, including Python 2, using the `c.MultiKernelManager` class.\n",
      "\n",
      "### Contributing\n",
      "\n",
      "Contributions are welcome! If you'd like to contribute to the project, please fork the repository and submit a pull request. Make sure to follow the standard guidelines for contributing to open-source projects.\n",
      "\n",
      "### License\n",
      "\n",
      "This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).\n",
      "\n",
      "### Overall Architecture\n",
      "\n",
      "The repository uses a simple and straightforward architecture, with the Dockerfile defining the environment and dependencies, and the Jupyter Notebook server running within the container. The password protection mechanism is implemented using environment variables, ensuring secure access to the Jupyter Notebook server. The multi-kernel support is achieved through the use of the `c.MultiKernelManager` class.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d384a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test_readme/my_test_readme.md', 'w') as file:\n",
    "    file.write(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8710c45",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m../../data/helper/repos_processed.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m         data_list = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open('../../data/helper/repos_processed.json', 'r') as file:\n",
    "        data_list = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80794de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preprocessed_repo():\n",
    "    try:\n",
    "        with open('../../data/helper/repos_processed.json', 'r') as file:\n",
    "            data_list = json.load(file)\n",
    "    except json.JSONDecodeError as e:\n",
    "        data_list = []\n",
    "\n",
    "    new_entry = list((\"test_repo_2\", \"test_owner_2\")) # input\n",
    "    data_list.append(new_entry)\n",
    "\n",
    "    with open('../../data/helper/repos_processed.json', 'w') as file:\n",
    "        json.dump(data_list, file)\n",
    "\n",
    "\n",
    "def check_processed_repos():\n",
    "    try:\n",
    "        repo_to_check = list((\"test_repo_2\", \"test_owner_2\"))\n",
    "        with open('../../data/helper/repos_processed.json', 'r') as file:\n",
    "            data_list = json.load(file)\n",
    "    except json.JSONDecodeError as e:\n",
    "        data_list = []\n",
    "\n",
    "    if repo_to_check in data_list:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd745529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_processed_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c06a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_preprocessed_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a52ae66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo is not processed and will be added to file\n"
     ]
    }
   ],
   "source": [
    "#repo_to_check = list((\"test_repo_4\", \"test_name_4\"))\n",
    "\n",
    "if check_processed_repos():\n",
    "    print('Repo is processed')\n",
    "else: \n",
    "    print('Repo is not processed and will be added to file')\n",
    "    write_preprocessed_repo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ce00b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_list = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "209de363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in tmp_list:\n",
    "    if i / 2 == 1:\n",
    "        continue\n",
    "    else:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
