{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8533da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.cortex import Summarize, Complete, ExtractAnswer, Sentiment, Translate\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d53b07",
   "metadata": {},
   "source": [
    "### Build Snowflake session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3957a221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85edd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_params = {\n",
    "    \"account\": os.environ['SNOWFLAKE_ACCOUNT'],\n",
    "    \"user\": os.environ['SNOWFLAKE_USER'],\n",
    "    \"password\": os.environ['SNOWFLAKE_USER_PASSWORD'],\n",
    "    \"role\": 'ACCOUNTADMIN',\n",
    "    #\"database\": 'SNOWFLAKE_LEARNING_DB',\n",
    "    \"warehouse\": 'COMPUTE_WH',\n",
    "    \"paramstyle\": \"qmark\"\n",
    "    #\"schema\": 'PUBLIC',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc98a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d963185",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e80de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'mistral-7b'\n",
    "# max number of input tokens = 32,000\n",
    "# max number of output tokens =  8,192\n",
    "# credits per 1 million token = 0.12 ~ 8 million tokens\n",
    "# model = 'llama3.1-8b'\n",
    "# model = 'llama3.2-3b'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d157ca",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json\n",
    "#with open('../../data/input_readme_data/lyst_lightfm.json', 'r')  as file:\n",
    "with open('../../data/input_readme_data/lyst_lightfm.json', 'r')  as file:\n",
    "    loaded_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edca640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code_cleaned_comments = loaded_data['source_code_cleaned_comments']\n",
    "license = loaded_data['license']\n",
    "requirements = loaded_data['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02bbd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = source_code_cleaned_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44b22a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = 'lightfm'\n",
    "repo_owner = 'lyst'\n",
    "# license = ''\n",
    "# requirements = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc6856",
   "metadata": {},
   "source": [
    "### Create summary prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41adc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary_prompt(repo_name, input_txt):\n",
    "    prompt_summary = f'''\n",
    "        You are acting as a software development expert for the following GitHub repository \"{repo_name}\".\n",
    "        Your task is to summarize the given source code string \"{input_txt}\" in natural language, so a specialist is able to understand\n",
    "        the purpose of the repository.\n",
    "        Identify its purpose, key functions, main components and dependencies. Focus on the overall architecture and structure \n",
    "        rather than line-by-line details. Do not add any recommendations or improvement suggestions, but concentrate on the summary. \n",
    "        Present the summary in a clear and concise language.\n",
    "        You are not allowed to add any small talk. \n",
    "    ''' \n",
    "    #prompt_summary = prompt_summary.replace(\"'\", \"\\\\'\")\n",
    "    \n",
    "    return prompt_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbe6699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = write_summary_prompt(repo_name, input_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9649036",
   "metadata": {},
   "source": [
    "### Count input tokens before send to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6de9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama3.1-8b'\n",
    "model_summary_params = {\n",
    "   'temperature': 0, # default: 0 https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex --> Internetrecherche hat keine anderen Empfehlungen ergeben\n",
    "   # 'top_p': # default: 0 https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex\n",
    "    'max_tokens': 4000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6afb098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "            SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS(\n",
    "                ?,\n",
    "                ?\n",
    "            ) AS response\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62a0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = snowflake_session.sql(query, params=[model, prompt_summary]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "789394be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(RESPONSE=162178)]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41b8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_cnt_input = snowflake_session.sql(f\"SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS('{model}', '{prompt_summary}') AS token_count\").collect()\n",
    "input_tokens = response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b17b91c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162178"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ada223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "677c0854",
   "metadata": {},
   "source": [
    "### Execute summary query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'llama3.1-8b'\n",
    "model_summary_params = {\n",
    "   'temperature': 0, \n",
    "    'max_tokens': 3000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91de3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "        '{model}',\n",
    "        [\n",
    "            {{\n",
    "                'role': 'user', \n",
    "                'content': '{prompt_summary}'\n",
    "            }}\n",
    "        ],\n",
    "        {{\n",
    "            'temperature': {model_summary_params['temperature']},\n",
    "            'max_tokens':  {model_summary_params['max_tokens']}\n",
    "        }} \n",
    "    ) AS response\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = snowflake_session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07eecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = snowflake_session.sql(f\"select snowflake.cortex.complete('{model}', '{prompt_summary}') as response\").to_pandas()\n",
    "#query_id = snowflake_session.sql(\"SELECT last_query_id()\").collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = snowflake_session.sql(f\"select snowflake.cortex.complete('{model}', '{prompt_summary}') as response\").to_pandas()\n",
    "# lama3.2-1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574420e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(RESPONSE='{\\n  \"choices\": [\\n    {\\n      \"messages\": \"**Repository Purpose and Overview**\\\\n\\\\nThis repository is a GitHub repository list generator that fetches and displays the most popular repositories for a given programming language. The repository provides a simple command-line interface to generate a README file in markdown format, listing the top repositories for a specified language.\\\\n\\\\n**Key Functionalities**\\\\n\\\\n1. **Repository Information Provider**: The repository uses a `RepositoryInformationProvider` class to interact with the GitHub API, fetching repository information for a given language.\\\\n2. **GitHub API Interaction**: The provider uses the `requests` library to make HTTP requests to the GitHub API, handling rate limiting and retrying failed requests.\\\\n3. **Repository Data Processing**: The provider extracts relevant information from the API responses, including repository names, descriptions, star counts, fork counts, issue counts, and last commit dates.\\\\n4. **README Generation**: The `generate_readme` function takes the repository information and generates a markdown table listing the top repositories for a given language.\\\\n\\\\n**Main Components**\\\\n\\\\n1. `RepositoryInformationProvider` class: responsible for interacting with the GitHub API and fetching repository information.\\\\n2. `generate_readme` function: generates the markdown table listing the top repositories for a given language.\\\\n3. `argparse` library: used for parsing command-line arguments.\\\\n\\\\n**Dependencies**\\\\n\\\\n1. `requests` library: for making HTTP requests to the GitHub API.\\\\n2. `urllib3` library: used by `requests` for handling HTTP connections.\\\\n3. `argparse` library: for parsing command-line arguments.\\\\n4. `humanize` library: used for formatting dates in a human-readable format.\\\\n5. `datetime` library: used for date and time calculations.\\\\n\\\\n**Overall Architecture**\\\\n\\\\nThe repository uses a simple, modular architecture, with a clear separation of concerns between the repository information provider and the README generator. The `RepositoryInformationProvider` class encapsulates the GitHub API interaction, while the `generate_readme` function takes care of generating the markdown table. The `argparse` library is used to parse command-line arguments, making it easy to run the script with different language inputs.\"\\n    }\\n  ],\\n  \"created\": 1747668847,\\n  \"model\": \"llama3.1-8b\",\\n  \"usage\": {\\n    \"completion_tokens\": 425,\\n    \"prompt_tokens\": 1352,\\n    \"total_tokens\": 1777\\n  }\\n}')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"messages\": \"**Repository Purpose and Overview**\\n\\nThis repository is a GitHub repository list generator that fetches and displays the most popular repositories for a given programming language. The repository provides a simple command-line interface to generate a README file in markdown format, listing the top repositories for a specified language.\\n\\n**Key Functionalities**\\n\\n1. **Repository Information Provider**: The repository uses a `RepositoryInformationProvider` class to interact with the GitHub API, fetching repository information for a given language.\\n2. **GitHub API Interaction**: The provider uses the `requests` library to make HTTP requests to the GitHub API, handling rate limiting and retrying failed requests.\\n3. **Repository Data Processing**: The provider extracts relevant information from the API responses, including repository names, descriptions, star counts, fork counts, issue counts, and last commit dates.\\n4. **README Generation**: The `generate_readme` function takes the repository information and generates a markdown table listing the top repositories for a given language.\\n\\n**Main Components**\\n\\n1. `RepositoryInformationProvider` class: responsible for interacting with the GitHub API and fetching repository information.\\n2. `generate_readme` function: generates the markdown table listing the top repositories for a given language.\\n3. `argparse` library: used for parsing command-line arguments.\\n\\n**Dependencies**\\n\\n1. `requests` library: for making HTTP requests to the GitHub API.\\n2. `urllib3` library: used by `requests` for handling HTTP connections.\\n3. `argparse` library: for parsing command-line arguments.\\n4. `humanize` library: used for formatting dates in a human-readable format.\\n5. `datetime` library: used for date and time calculations.\\n\\n**Overall Architecture**\\n\\nThe repository uses a simple, modular architecture, with a clear separation of concerns between the repository information provider and the README generator. The `RepositoryInformationProvider` class encapsulates the GitHub API interaction, while the `generate_readme` function takes care of generating the markdown table. The `argparse` library is used to parse command-line arguments, making it easy to run the script with different language inputs.\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1747668847,\n",
      "  \"model\": \"llama3.1-8b\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 425,\n",
      "    \"prompt_tokens\": 1352,\n",
      "    \"total_tokens\": 1777\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "summary_txt = res[0]['RESPONSE']\n",
    "print(summary_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = res[0]['RESPONSE']\n",
    "test_str = json.loads(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1777\n"
     ]
    }
   ],
   "source": [
    "print(test_str['usage']['total_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Repository Purpose and Overview**\n",
      "\n",
      "This repository is a GitHub repository list generator that fetches and displays the most popular repositories for a given programming language. The repository provides a simple command-line interface to generate a README file in markdown format, listing the top repositories for a specified language.\n",
      "\n",
      "**Key Functionalities**\n",
      "\n",
      "1. **Repository Information Provider**: The repository uses a `RepositoryInformationProvider` class to interact with the GitHub API, fetching repository information for a given language.\n",
      "2. **GitHub API Interaction**: The provider uses the `requests` library to make HTTP requests to the GitHub API, handling rate limiting and retrying failed requests.\n",
      "3. **Repository Data Processing**: The provider extracts relevant information from the API responses, including repository names, descriptions, star counts, fork counts, issue counts, and last commit dates.\n",
      "4. **README Generation**: The `generate_readme` function takes the repository information and generates a markdown table listing the top repositories for a given language.\n",
      "\n",
      "**Main Components**\n",
      "\n",
      "1. `RepositoryInformationProvider` class: responsible for interacting with the GitHub API and fetching repository information.\n",
      "2. `generate_readme` function: generates the markdown table listing the top repositories for a given language.\n",
      "3. `argparse` library: used for parsing command-line arguments.\n",
      "\n",
      "**Dependencies**\n",
      "\n",
      "1. `requests` library: for making HTTP requests to the GitHub API.\n",
      "2. `urllib3` library: used by `requests` for handling HTTP connections.\n",
      "3. `argparse` library: for parsing command-line arguments.\n",
      "4. `humanize` library: used for formatting dates in a human-readable format.\n",
      "5. `datetime` library: used for date and time calculations.\n",
      "\n",
      "**Overall Architecture**\n",
      "\n",
      "The repository uses a simple, modular architecture, with a clear separation of concerns between the repository information provider and the README generator. The `RepositoryInformationProvider` class encapsulates the GitHub API interaction, while the `generate_readme` function takes care of generating the markdown table. The `argparse` library is used to parse command-line arguments, making it easy to run the script with different language inputs.\n"
     ]
    }
   ],
   "source": [
    "print(test_str['choices'][0]['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1b336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734ae20",
   "metadata": {},
   "source": [
    "### Create README prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3454351",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_readme = f'''\n",
    "    You are acting like software development expert for the following GitHub repository {repo_name} from the owner {repo_owner}. \n",
    "    Your task is to create a README file for the repository in Markdown format. \n",
    "    Use the provided summary: \"{summary_txt}\", the license: \"{license}\" and the given requirements: \"{requirements}\" \n",
    "    The README file should contain information about what the project does, why it is useful, how users \n",
    "    can get started, where they can get help, and how to maintain and contribute to the project.\n",
    "    If you don't know the answer add a hint following this style [â€¦]. You're not allowed to create \n",
    "    made-up content to fill gaps and you're not allowed to add additional paragraphs.\n",
    "    Use the following Markdown template and fill each paragraph. \n",
    "\n",
    "    ## Titel\n",
    "\n",
    "    ## Installation\n",
    "\n",
    "    ## Usage\n",
    "\n",
    "    ## Contributing\n",
    "\n",
    "    ## License\n",
    "\n",
    "    Do not include any sensitive data like names or emails. Keep the markdown file clean and structured.\n",
    "'''\n",
    "prompt_readme = prompt_readme.replace(\"'\", \"\\\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e82682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = snowflake_session.sql(f\"select snowflake.cortex.complete('{model}', '{prompt_readme}') as response\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readme = df.iloc[0]['RESPONSE']\n",
    "readme_txt = df_readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa2019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## Popular GitHub Repositories by Programming Language\n",
      "\n",
      "This repository is a Python script that fetches and generates a list of most popular repositories on GitHub based on the given programming language. It uses the GitHub API to retrieve the required information and stores the access token in a local file named \"token.json\". The script supports multiple programming languages and can fetch up to 10 pages of results per language.\n",
      "\n",
      "## Installation\n",
      "\n",
      "To use this script, you need to have Python installed on your system. You can install the required dependencies using pip:\n",
      "\n",
      "```bash\n",
      "pip install requests argparse json humanize\n",
      "```\n",
      "\n",
      "## Usage\n",
      "\n",
      "To run the script, save the provided code in a file named `github_popular_repos.py` and execute it using the following command:\n",
      "\n",
      "```bash\n",
      "python github_popular_repos.py [--language LANG1, LANG2, ...]\n",
      "```\n",
      "\n",
      "Replace `LANG1, LANG2, ...` with the desired programming languages, separated by commas. If no languages are specified, the script will fetch the popular repositories for all supported languages.\n",
      "\n",
      "The script generates a markdown file named `repos.md` in the same directory with the most popular repositories for the given languages.\n",
      "\n",
      "## Contributing\n",
      "\n",
      "Contributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request.\n",
      "\n",
      "## License\n",
      "\n",
      "This project is licensed under the [MIT License](LICENSE).\n",
      "\n",
      "[MIT License](LICENSE)\n",
      "\n",
      "## Development\n",
      "\n",
      "To run the script in development mode, you can use the following command:\n",
      "\n",
      "```bash\n",
      "python -m unittest tests.test_github_popular_repos.py\n",
      "```\n",
      "\n",
      "This will run the unit tests for the script. The tests cover the main functionality of the script and ensure that the expected results are generated.\n",
      "\n",
      "## Dependencies\n",
      "\n",
      "The script depends on the following Python libraries:\n",
      "\n",
      "- `requests`: for making HTTP requests\n",
      "- `argparse`: for parsing command-line arguments\n",
      "- `json`: for parsing JSON responses\n",
      "- `time`: for handling time-related functionality\n",
      "- `humanize`: for formatting dates\n",
      "- `datetime`: for parsing and manipulating dates\n",
      "\n",
      "You can install these dependencies using pip:\n",
      "\n",
      "```bash\n",
      "pip install requests argparse json humanize\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(df_readme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9bc15a",
   "metadata": {},
   "source": [
    "### Save summary and README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = {\n",
    "    'repo_owner': repo_owner,\n",
    "    'repo_name': repo_name,\n",
    "    'summary': summary_txt,\n",
    "    'readme': readme_txt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cda829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'repo_owner': 'kaxap',\n",
       " 'repo_name': 'arl',\n",
       " 'summary': ' This repository is a Python script that fetches and generates a list of most popular repositories on GitHub based on the given programming language. The script uses the GitHub API to retrieve the required information and stores the access token in a local file named \"token.json\". The script supports multiple programming languages and can fetch up to 10 pages of results per language.\\n\\nThe script defines a class `RepositoryInformationProvider` that initializes a `requests.Session` object with retries and rate limit handling. It also defines methods to get the next page of results for a given language and to get the last commit date for a given repository.\\n\\nThe `generate_readme` function generates a markdown file with a table of most popular repositories for a given language. It fetches the data using the `RepositoryInformationProvider` and formats the data into a markdown table.\\n\\nThe script uses several constants and variables to store the API URLs, headers, and other configuration options. It also defines some helper functions for formatting and humanizing dates.\\n\\nThe script uses the `argparse` module to parse command-line arguments and supports specifying multiple languages using a comma-separated list.\\n\\nThe main components of the script are:\\n\\n* `RepositoryInformationProvider` class for fetching and handling GitHub API responses\\n* `generate_readme` function for generating the markdown file\\n* Use of `requests` library for making HTTP requests\\n* Use of `argparse` module for parsing command-line arguments\\n* Use of `json`, `time`, `humanize`, `datetime`, and `argparse` modules for various utility functions\\n\\nThe dependencies of the script are:\\n\\n* `requests` library for making HTTP requests\\n* `argparse` module for parsing command-line arguments\\n* `json` module for parsing JSON responses\\n* `time` module for handling time-related functionality\\n* `humanize` module for formatting dates\\n* `datetime` module for parsing and manipulating dates\\n\\nThe overall architecture of the script is simple and modular, with clear separation of concerns between fetching data from the API and generating the markdown file. The script is well-documented with clear variable and function names, making it easy to understand and maintain.',\n",
       " 'readme': ' ## Popular GitHub Repositories by Programming Language\\n\\nThis repository is a Python script that fetches and generates a list of most popular repositories on GitHub based on the given programming language. It uses the GitHub API to retrieve the required information and stores the access token in a local file named \"token.json\". The script supports multiple programming languages and can fetch up to 10 pages of results per language.\\n\\n## Installation\\n\\nTo use this script, you need to have Python installed on your system. You can install the required dependencies using pip:\\n\\n```bash\\npip install requests argparse json humanize\\n```\\n\\n## Usage\\n\\nTo run the script, save the provided code in a file named `github_popular_repos.py` and execute it using the following command:\\n\\n```bash\\npython github_popular_repos.py [--language LANG1, LANG2, ...]\\n```\\n\\nReplace `LANG1, LANG2, ...` with the desired programming languages, separated by commas. If no languages are specified, the script will fetch the popular repositories for all supported languages.\\n\\nThe script generates a markdown file named `repos.md` in the same directory with the most popular repositories for the given languages.\\n\\n## Contributing\\n\\nContributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request.\\n\\n## License\\n\\nThis project is licensed under the [MIT License](LICENSE).\\n\\n[MIT License](LICENSE)\\n\\n## Development\\n\\nTo run the script in development mode, you can use the following command:\\n\\n```bash\\npython -m unittest tests.test_github_popular_repos.py\\n```\\n\\nThis will run the unit tests for the script. The tests cover the main functionality of the script and ensure that the expected results are generated.\\n\\n## Dependencies\\n\\nThe script depends on the following Python libraries:\\n\\n- `requests`: for making HTTP requests\\n- `argparse`: for parsing command-line arguments\\n- `json`: for parsing JSON responses\\n- `time`: for handling time-related functionality\\n- `humanize`: for formatting dates\\n- `datetime`: for parsing and manipulating dates\\n\\nYou can install these dependencies using pip:\\n\\n```bash\\npip install requests argparse json humanize\\n```'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../model/test_readme.json', 'w') as file:\n",
    "    json.dump(tmp_json, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f41557",
   "metadata": {},
   "source": [
    "### Count output tokens from prompt and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = snowflake_session.sql(\"SELECT last_query_id()\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01bc4ca8-0305-3f74-0008-537300054062\n"
     ]
    }
   ],
   "source": [
    "print(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cnt_output = snowflake_session.sql(f\"SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY WHERE query_id='{query_id}'\").to_pandas()\n",
    "output_tokens = res_cnt_output['TOKENS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_ID</th>\n",
       "      <th>WAREHOUSE_ID</th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>FUNCTION_NAME</th>\n",
       "      <th>TOKENS</th>\n",
       "      <th>TOKEN_CREDITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [QUERY_ID, WAREHOUSE_ID, MODEL_NAME, FUNCTION_NAME, TOKENS, TOKEN_CREDITS]\n",
       "Index: []"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cnt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782\n",
      "Series([], Name: TOKENS, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(input_tokens)\n",
    "print(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count input tokens of prompt\n",
    "\n",
    "\n",
    "# # Get current Snowflake session\n",
    "# #session = get_active_session()\n",
    "\n",
    "# # Define model and input text\n",
    "# model_name = model #0.06 credits per 1M token\n",
    "\n",
    "# # Execute token count function\n",
    "# result = session.sql(f\"SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS('{model_name}', '{prompt_summary}') AS token_count\").collect()\n",
    "\n",
    "# print(f\"Token count: {result[0]['TOKEN_COUNT']}\") # 204 tokens (snowflake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query id of last session\n",
    "# query_id = session.sql(\"SELECT last_query_id()\").collect()[0][0]\n",
    "# print(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_id = '01bc4c11-0305-3f6c-0008-53730004c00e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#session = get_active_session()\n",
    "# get tokens for query id\n",
    "#res = snowflake_session.sql(f\"SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY WHERE query_id='{query_id}'\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tokens = result[0]['TOKEN_COUNT']\n",
    "# output_tokens = res['TOKENS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eebdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowflake_session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daea7f7",
   "metadata": {},
   "source": [
    "Interessant wird das repo tensorflow models! Es hat die meiste Anzahl an Characters ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be850b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/df_repos_counts_filtered.json','r') as file:\n",
    "    loaded_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63139730",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [f\"{row['repo_owner']}_{row['repo_name']}\" for index, row in df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = [(row.repo_owner, row.repo_name) for row in df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29c992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rochacbruno'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_preprocessed_repo(repo_owner, repo_name):\n",
    "    tmp_tuple = (repo_owner, repo_name)\n",
    "    with open('../../data/helper/repos_processed.txt', 'a') as file:\n",
    "        file.write(str(tmp_tuple) + '\\n')\n",
    "\n",
    "write_preprocessed_repo(repo_owner='lisa', repo_name='nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = {\n",
    "    'summary_1': 'some text 1',\n",
    "    'summary_2': 'some text 2',\n",
    "    'summary_3': 'some text 3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9325126",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [value for value in tmp_json.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641e574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08d5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
