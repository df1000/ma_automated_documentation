{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b34d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisa-linux/stuff/ma_automated_documentation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a003fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# log to huggingface\n",
    "HF_TOKEN = os.environ['HUGGINGFACE']\n",
    "login(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8221c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_prompt = '''\n",
    "#     This repository is a Python script that fetches and generates a list of most popular repositories on GitHub based on the given programming language. The script uses the GitHub API to retrieve the required information and stores the access token in a local file named \\\"token.json\\\". The script supports multiple programming languages and can fetch up to 10 pages of results per language.\\n\\nThe script defines a class `RepositoryInformationProvider` that initializes a `requests.Session` object with retries and rate limit handling. It also defines methods to get the next page of results for a given language and to get the last commit date for a given repository.\\n\\nThe `generate_readme` function generates a markdown file with a table of most popular repositories for a given language. It fetches the data using the `RepositoryInformationProvider` and formats the data into a markdown table.\\n\\nThe script uses several constants and variables to store the API URLs, headers, and other configuration options. It also defines some helper functions for formatting and humanizing dates.\\n\\nThe script uses the `argparse` module to parse command-line arguments and supports specifying multiple languages using a comma-separated list.\\n\\nThe main components of the script are:\\n\\n* `RepositoryInformationProvider` class for fetching and handling GitHub API responses\\n* `generate_readme` function for generating the markdown file\\n* Use of `requests` library for making HTTP requests\\n* Use of `argparse` module for parsing command-line arguments\\n* Use of `json`, `time`, `humanize`, `datetime`, and `argparse` modules for various utility functions\\n\\nThe dependencies of the script are:\\n\\n* `requests` library for making HTTP requests\\n* `argparse` module for parsing command-line arguments\\n* `json` module for parsing JSON responses\\n* `time` module for handling time-related functionality\\n* `humanize` module for formatting dates\\n* `datetime` module for parsing and manipulating dates\\n\\nThe overall architecture of the script is simple and modular, with clear separation of concerns between fetching data from the API and generating the markdown file. The script is well-documented with clear variable and function names, making it easy to understand and maintain.\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def split_prompt(prompt, max_tokens):\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "#     tokenized_prompt = tokenizer.encode(prompt)\n",
    "    \n",
    "#     chunks = [tokenized_prompt[i:i+max_tokens] for i in range(0, len(tokenized_prompt), max_tokens)] # (generated with Microsoft Copilot)\n",
    "#     return [tokenizer.decode(chunk) for chunk in chunks] # (generated with Microsoft Copilot)\n",
    "\n",
    "\n",
    "# sub_prompts = split_prompt(full_prompt, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc5869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subprompts(prompt):\n",
    "    '''\n",
    "    Function creates multiple chunks from given prompt to prevent limits of input tokens of choosed LLM.\n",
    "\n",
    "    Args:\n",
    "        prompt: Input which should be tokenized.\n",
    "    \n",
    "    Return:\n",
    "        decoded_chunks\n",
    "    '''\n",
    "    max_tokens = 100000 # max number of tokens is 128000, but Snowflake requieres tokens for processing (see estimate_tokens())\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\") # load Autotokenizer.from_pretrained() from transformers with llm specification\n",
    "    tokenized_prompt = tokenizer.encode(prompt) # encode prompt into a list of tokens\n",
    "    print('Step create_subprompts: Tokens are encoded.')\n",
    "\n",
    "    # iterates over tokenized_prompts and split content into smaller chunks (each chunks contains a max. of 124000 tokens)\n",
    "    # start at i = 0 and get a chunk until max_tokens (stepsize) from tokenized_prompt\n",
    "    # next chunk --> previous chunk + max_tokens\n",
    "    chunks = [tokenized_prompt[i:i+max_tokens] for i in range(0, len(tokenized_prompt), max_tokens)] # (generated with Microsoft Copilot)\n",
    "    decoded_chunks = [tokenizer.decode(chunk) for chunk in chunks] # decode each chunk to text # (generated with Microsoft Copilot)\n",
    "    print('Step create_subprompts: Tokens are decoded.')\n",
    "\n",
    "    return decoded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(input):\n",
    "    max_tokens = 120000 # 1 token ~ 4 character\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "    tokenized_input = tokenizer.encode(input)\n",
    "    #chunks = [tokenized_prompt[i:i+min(max_tokens, len(tokenized_prompt)-i)] for i in range(0, len(tokenized_prompt), max_tokens)]\n",
    "    chunks = [tokenized_input[i:i+max_tokens] for i in range(0, len(tokenized_input), max_tokens)]\n",
    "    decoded_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    return decoded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a0583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/input_readme_data/facebookresearch_Detectron.json', 'r') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb569cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502686"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_data['source_code_cleaned_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7963d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 131072\n",
    "#max_sequence_length = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faf60fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'thisismytest1234testsuperdupie89testititvonlisi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fff2ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f74c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loaded_data['source_code_cleaned_comments']\n",
    "#data = test\n",
    "input = [data[i:i+max_sequence_length] for i in range(0, len(data), max_sequence_length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025a1333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfromCython.BuildimportcythonizefromsetuptoolsimportExtensionfromsetuptoolsimportsetupimportnumpyasnp_NP_INCLUDE_DIRS=np.get_include()#Extensionmodulesext_modules=[Extension(name=\\'detectron.utils.cython_bbox\\',sources=[\\'detectron/utils/cython_bbox.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS]),Extension(name=\\'detectron.utils.cython_nms\\',sources=[\\'detectron/utils/cython_nms.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS])]setup(name=\\'Detectron\\',packages=[\\'detectron\\'],ext_modules=cythonize(ext_modules))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ComputeminibatchblobsfortrainingaRetinaNetnetwork.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportdetectron.utils.boxesasbox_utilsimportdetectron.roi_data.data_utilsasdata_utilsfromdetectron.core.configimportcfglogger=logging.getLogger(__name__)defget_retinanet_blob_names(is_training=True):\"\"\"Returnsblobnamesintheorderinwhichtheyarereadbythedataloader.N=numberofimagesperminibatchA=numberofanchors=num_scales*num_aspect_ratios(forexample9usedinRetinaNetpaper)H,W=spatialdimensions(differentforeachFPNlevel)M=Outofalltheanchorsgenerated,dependingonthepositive/negativeIoUoverlapthresholds,wewillhaveMpositiveanchors.Thesearetheanchorsthatboundingboxbranchwillregresson.retnet_cls_labels->labelsfortheclsbranchforeachFPNlevelShape:NxAxHxWretnet_roi_bbox_targets->targetsforthebboxregressionbranchShape:Mx4retnet_roi_fg_bbox_locs->forthebboxregression,sinceweareonlyinterestedinregressingonfgbboxeswhichareMinnumberandtheoutputpredictionofthenetworkisofshapeNx(A*4)xHxW(incaseofnonclass-specificbbox),sowestorethelocationsofpositivefgboxesinthisblobretnet_roi_fg_bbox_locsofshapeMx4whereeachrowlookslike:[img_id,anchor_id,x_loc,y_loc]\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']assertcfg.FPN.FPN_ON,\"RetinaNetusesFPNfordensedetection\"#SameformatasRPNblobs,butoneperFPNlevelifis_training:blob_names+=[\\'retnet_fg_num\\',\\'retnet_bg_num\\']forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):suffix=\\'fpn{}\\'.format(lvl)blob_names+=[\\'retnet_cls_labels_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,]returnblob_namesdefadd_retinanet_blobs(blobs,im_scales,roidb,image_width,image_height):\"\"\"AddRetinaNetblobs.\"\"\"#RetinaNetisappliedtomanyfeaturelevels,asintheFPNpaperk_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEnum_aspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)aspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALE#getanchorsfromalllevelsforallscales/aspectratiosfoas=[]forlvlinrange(k_min,k_max+1):stride=2.**lvlforoctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foridxinrange(num_aspect_ratios):anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect_ratios[idx],)foa=data_utils.get_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave,idx)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])blobs[\\'retnet_fg_num\\'],blobs[\\'retnet_bg_num\\']=0.0,0.0forim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]assertlen(gt_inds)>0,\\\\\\'Emptygroundtruthemptyforimageisnotallowed.Pleasecheck.\\'gt_rois=entry[\\'boxes\\'][gt_inds,:]*scalegt_classes=entry[\\'gt_classes\\'][gt_inds]im_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)retinanet_blobs,fg_num,bg_num=_get_retinanet_blobs(foas,all_anchors,gt_rois,gt_classes,image_width,image_height)fori,foainenumerate(foas):fork,vinretinanet_blobs[i].items():#thewayitstacksis:#[[anchorsforimage1]+[anchorsforimages2]]level=int(np.log2(foa.stride))key=\\'{}_fpn{}\\'.format(k,level)ifk==\\'retnet_roi_fg_bbox_locs\\':v[:,0]=im_i#loc_stride:80*4ifcls_specificelse4loc_stride=4#4coordinatecorrespondingtobboxpredictionifcfg.RETINANET.CLASS_SPECIFIC_BBOX:loc_stride*=(cfg.MODEL.NUM_CLASSES-1)anchor_ind=foa.octave*num_aspect_ratios+foa.aspect#v[:,1]istheclasslabel[range0-80]ifwedo#class-specficbboxotherwiseitis0.Incaseofclass#specific,basedonthelabel,thelocationofcurrent#anchorisclass_label*4andthenwetakeintoaccount#theanchor_indiftheanchorsv[:,1]*=4v[:,1]+=loc_stride*anchor_indblobs[key].append(v)blobs[\\'retnet_fg_num\\']+=fg_numblobs[\\'retnet_bg_num\\']+=bg_numblobs[\\'retnet_fg_num\\']=blobs[\\'retnet_fg_num\\'].astype(np.float32)blobs[\\'retnet_bg_num\\']=blobs[\\'retnet_bg_num\\'].astype(np.float32)N=len(roidb)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:#computenumberofanchorsA=int(len(v)/N)#fortheclsbranchlabels[perfpnlevel],#wehaveblobs[\\'retnet_cls_labels_fpn{}\\']asalistuntilthisstep#andlengthofthislistisNxAwhere#N=num_images,A=num_anchorsforexample,N=2,A=9#Eachelementofthelisthastheshape1x1xHxWwhereH,Ware#spatialdimensionofcurretfpnlvl.Leta{i}denotetheelement#correspondingtoanchori[9anchorstotal]inthelist.#Theelementsinthelistareinorder[[a0,...,a9],[a0,...,a9]]#howeverthenetworkwillmakepredictionslike2x(9*80)xHxW#sowefirstconcatenatetheelementsofeachimagetoanumpyarray#andthenconcatenatethetwoimagestogetthe2x9xHxWifk.find(\\'retnet_cls_labels\\')>=0:tmp=[]#concatanchorswithinanimageforiinrange(0,len(v),A):tmp.append(np.concatenate(v[i:i+A],axis=1))#concatimagesblobs[k]=np.concatenate(tmp,axis=0)else:#forthebboxbranchelements[perFPNlevel],#wehavethetargetsandthefgboxeslocations#intheshape:Mx4whereMisthenumberoffglocationsina#givenimageatthecurrentFPNlevel.Forthegivenlevel,#thebboxpredictionswillbe.Theelementsinthelistarein#order[[a0,...,a9],[a0,...,a9]]#ConcatenatethemtoformMx4blobs[k]=np.concatenate(v,axis=0)returnTruedef_get_retinanet_blobs(foas,all_anchors,gt_boxes,gt_classes,im_width,im_height):total_anchors=all_anchors.shape[0]logger.debug(\\'Gettingmadblobs:im_height{}im_width:{}\\'.format(im_height,im_width))inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.float32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)gt_inds=anchor_to_gt_argmax[anchors_with_max_overlap]labels[anchors_with_max_overlap]=gt_classes[gt_inds]#Fglabel:abovethresholdIOUinds=anchor_to_gt_max>=cfg.RETINANET.POSITIVE_OVERLAPgt_inds=anchor_to_gt_argmax[inds]labels[inds]=gt_classes[gt_inds]fg_inds=np.where(labels>=1)[0]bg_inds=np.where(anchor_to_gt_max<cfg.RETINANET.NEGATIVE_OVERLAP)[0]labels[bg_inds]=0num_fg,num_bg=len(fg_inds),len(bg_inds)bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeend_idx=start_idx+H*W_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,height,width)_labels=_labels.reshape((1,1,H,W))#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,4)).transpose(0,3,1,2)stride=foa.stridew=int(im_width/stride)h=int(im_height/stride)#dataforselect_smooth_l1lossnum_classes=cfg.MODEL.NUM_CLASSES-1inds_4d=np.where(_labels>0)M=len(inds_4d)_roi_bbox_targets=np.zeros((0,4))_roi_fg_bbox_locs=np.zeros((0,4))ifM>0:im_inds,y,x=inds_4d[0],inds_4d[2],inds_4d[3]_roi_bbox_targets=np.zeros((len(im_inds),4))_roi_fg_bbox_locs=np.zeros((len(im_inds),4))lbls=_labels[im_inds,:,y,x]fori,lblinenumerate(lbls):l=lbl[0]-1ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:l=0assertl>=0andl<num_classes,\\'labeloutoftherange\\'_roi_bbox_targets[i,:]=_bbox_targets[:,:,y[i],x[i]]_roi_fg_bbox_locs[i,:]=np.array([[0,l,y[i],x[i]]])blobs_out.append(dict(retnet_cls_labels=_labels[:,:,0:h,0:w].astype(np.int32),retnet_roi_bbox_targets=_roi_bbox_targets.astype(np.float32),retnet_roi_fg_bbox_locs=_roi_fg_bbox_locs.astype(np.float32),))out_num_fg=np.array([num_fg+1.0],dtype=np.float32)out_num_bg=(np.array([num_bg+1.0])*(cfg.MODEL.NUM_CLASSES-1)+out_num_fg*(cfg.MODEL.NUM_CLASSES-2))returnblobs_out,out_num_fg,out_num_bg#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"CommonutilityfunctionsforRPNandRetinaNetminibtachblobspreparation.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportnamedtupleimportloggingimportnumpyasnpimportthreadingfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)#octaveandaspectfieldsareonlyusedonRetinaNet.Octavecorrespondstothe#scaleoftheanchorandaspectdenoteswhichaspectratioisusedintherange#ofaspectratiosFieldOfAnchors=namedtuple(\\'FieldOfAnchors\\',[\\'field_of_anchors\\',\\'num_cell_anchors\\',\\'stride\\',\\'field_size\\',\\'octave\\',\\'aspect\\'])#Cacheformemoizing_get_field_of_anchors_threadlocal_foa=threading.local()defget_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave=None,aspect=None):global_threadlocal_foaifnothasattr(_threadlocal_foa,\\'cache\\'):_threadlocal_foa.cache={}cache_key=str(stride)+str(anchor_sizes)+str(anchor_aspect_ratios)ifcache_keyin_threadlocal_foa.cache:return_threadlocal_foa.cache[cache_key]#Anchorsatasinglefeaturecellcell_anchors=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)num_cell_anchors=cell_anchors.shape[0]#Generatecanonicalproposalsfromshiftedanchors#Enumerateallshiftedpositionsonthe(H,W)gridfpn_max_size=cfg.FPN.COARSEST_STRIDE*np.ceil(cfg.TRAIN.MAX_SIZE/float(cfg.FPN.COARSEST_STRIDE))field_size=int(np.ceil(fpn_max_size/float(stride)))shifts=np.arange(0,field_size)*strideshift_x,shift_y=np.meshgrid(shifts,shifts)shift_x=shift_x.ravel()shift_y=shift_y.ravel()shifts=np.vstack((shift_x,shift_y,shift_x,shift_y)).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAcellanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsA=num_cell_anchorsK=shifts.shape[0]field_of_anchors=(cell_anchors.reshape((1,A,4))+shifts.reshape((1,K,4)).transpose((1,0,2)))field_of_anchors=field_of_anchors.reshape((K*A,4))foa=FieldOfAnchors(field_of_anchors=field_of_anchors.astype(np.float32),num_cell_anchors=num_cell_anchors,stride=stride,field_size=field_size,octave=octave,aspect=aspect)_threadlocal_foa.cache[cache_key]=foareturnfoadefunmap(data,count,inds,fill=0):\"\"\"Unmapasubsetofitem(data)backtotheoriginalsetofitems(ofsizecount)\"\"\"ifcount==len(inds):returndataiflen(data.shape)==1:ret=np.empty((count,),dtype=data.dtype)ret.fill(fill)ret[inds]=dataelse:ret=np.empty((count,)+data.shape[1:],dtype=data.dtype)ret.fill(fill)ret[inds,:]=datareturnretdefcompute_targets(ex_rois,gt_rois,weights=(1.0,1.0,1.0,1.0)):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"returnbox_utils.bbox_transform_inv(ex_rois,gt_rois,weights).astype(np.float32,copy=False)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectrondataloader.Thedesignisgenericandabstractedawayfromanydetailsoftheminibatch.Aminibatchisadictionaryofblobnamekeysandtheirassociatednumpy(float32orint32)ndarrayvalues.Outlineofthedataloaderdesign:loaderthread\\\\loaderthread\\\\/GPU1enqueuethread->feed->EnqueueOp...->minibatchqueue->...loaderthread/\\\\GPUNenqueuethread->feed->EnqueueOploaderthread/Apoolofloaderthreadsconstructminibatchesthatareputontothesharedminibatchqueue.EachGPUhasanenqueuethreadthatpullsaminibatchofftheminibatchqueue,feedstheminibatchblobsintotheworkspace,andthenrunsanEnqueueBlobsOptoplacetheminibatchblobsintotheGPU\\'sblobsqueue.DuringeachfpropthefirstthingthenetworkdoesisrunaDequeueBlobsOpinordertopopulatetheworkspacewiththeblobsfromaqueuedminibatch.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportsignalimportthreadingimporttimeimportuuidfromsix.movesimportqueueasQueuefromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.roi_data.minibatchimportget_minibatchfromdetectron.roi_data.minibatchimportget_minibatch_blob_namesfromdetectron.utils.coordinatorimportcoordinated_getfromdetectron.utils.coordinatorimportcoordinated_putfromdetectron.utils.coordinatorimportCoordinatorimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classRoIDataLoader:def__init__(self,roidb,num_loaders=4,minibatch_queue_size=64,blobs_queue_capacity=8):self._roidb=roidbself._lock=threading.Lock()self._perm=deque(range(len(self._roidb)))self._cur=0#_permcursor#Theminibatchqueueholdspreparedtrainingdatainhost(CPU)memory#WhentrainingwithN>1GPUs,eachelementintheminibatchqueue#isactuallyapartialminibatchwhichcontributes1/Nofthe#examplestotheoverallminibatchself._minibatch_queue=Queue.Queue(maxsize=minibatch_queue_size)self._blobs_queue_capacity=blobs_queue_capacity#RandomqueuenameincaseoneinstantiatesmultpleRoIDataLoadersself._loader_id=uuid.uuid4()self._blobs_queue_name=\\'roi_blobs_queue_{}\\'.format(self._loader_id)#Loaderthreadsconstruct(partial)minibatchesandputthemonthe#minibatchqueueself._num_loaders=num_loadersself._num_gpus=cfg.NUM_GPUSself.coordinator=Coordinator()self._output_names=get_minibatch_blob_names()self._shuffle_roidb_inds()self.create_threads()defminibatch_loader_thread(self):\"\"\"Loadmini-batchesandputthemontothemini-batchqueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():blobs=self.get_next_minibatch()#Blobsmustbequeuedintheorderspecifiedby#self.get_output_namesordered_blobs=OrderedDict()forkeyinself.get_output_names():assertblobs[key].dtypein(np.int32,np.float32),\\\\\\'Blob{}ofdtype{}musthavedtypeof\\'\\\\\\'np.int32ornp.float32\\'.format(key,blobs[key].dtype)ordered_blobs[key]=blobs[key]coordinated_put(self.coordinator,self._minibatch_queue,ordered_blobs)logger.info(\\'Stoppingmini-batchloadingthread\\')defenqueue_blobs_thread(self,gpu_id,blob_names):\"\"\"Transfermini-batchesfromamini-batchqueuetoaBlobsQueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():ifself._minibatch_queue.qsize==0:logger.warning(\\'Mini-batchqueueisempty\\')blobs=coordinated_get(self.coordinator,self._minibatch_queue)self.enqueue_blobs(gpu_id,blob_names,blobs.values())logger.debug(\\'batchqueuesize{}\\'.format(self._minibatch_queue.qsize()))logger.info(\\'Stoppingenqueuethread\\')defget_next_minibatch(self):\"\"\"Returntheblobstobeusedforthenextminibatch.Threadsafe.\"\"\"valid=Falsewhilenotvalid:db_inds=self._get_next_minibatch_inds()minibatch_db=[self._roidb[i]foriindb_inds]blobs,valid=get_minibatch(minibatch_db)returnblobsdef_shuffle_roidb_inds(self):\"\"\"Randomlypermutethetrainingroidb.Notthreadsafe.\"\"\"ifcfg.TRAIN.ASPECT_GROUPING:widths=np.array([r[\\'width\\']forrinself._roidb])heights=np.array([r[\\'height\\']forrinself._roidb])horz=(widths>=heights)vert=np.logical_not(horz)horz_inds=np.where(horz)[0]vert_inds=np.where(vert)[0]horz_inds=np.random.permutation(horz_inds)vert_inds=np.random.permutation(vert_inds)mb=cfg.TRAIN.IMS_PER_BATCHhorz_inds=horz_inds[:(len(horz_inds)//mb)*mb]vert_inds=vert_inds[:(len(vert_inds)//mb)*mb]inds=np.hstack((horz_inds,vert_inds))inds=np.reshape(inds,(-1,mb))row_perm=np.random.permutation(np.arange(inds.shape[0]))inds=np.reshape(inds[row_perm,:],(-1,))self._perm=indselse:self._perm=np.random.permutation(np.arange(len(self._roidb)))self._perm=deque(self._perm)self._cur=0def_get_next_minibatch_inds(self):\"\"\"Returntheroidbindicesforthenextminibatch.Threadsafe.\"\"\"withself._lock:#Weuseadequeandalwaystakethe*first*IMS_PER_BATCHitems#followedby*rotating*thedequesothatweseefreshitems#eachtime.Ifthelengthof_permisnotdivisibleby#IMS_PER_BATCH,thenweendupwrappingaroundthepermutation.db_inds=[self._perm[i]foriinrange(cfg.TRAIN.IMS_PER_BATCH)]self._perm.rotate(-cfg.TRAIN.IMS_PER_BATCH)self._cur+=cfg.TRAIN.IMS_PER_BATCHifself._cur>=len(self._perm):self._shuffle_roidb_inds()returndb_indsdefget_output_names(self):returnself._output_namesdefenqueue_blobs(self,gpu_id,blob_names,blobs):\"\"\"Putamini-batchonaBlobsQueue.\"\"\"assertlen(blob_names)==len(blobs)t=time.time()dev=c2_utils.CudaDevice(gpu_id)queue_name=\\'gpu_{}/{}\\'.format(gpu_id,self._blobs_queue_name)blob_names=[\\'gpu_{}/{}\\'.format(gpu_id,b)forbinblob_names]for(blob_name,blob)inzip(blob_names,blobs):workspace.FeedBlob(blob_name,blob,device_option=dev)logger.debug(\\'enqueue_blobs{}:workspace.FeedBlob:{}\\'.format(gpu_id,time.time()-t))t=time.time()op=core.CreateOperator(\\'SafeEnqueueBlobs\\',[queue_name]+blob_names,blob_names+[queue_name+\\'_enqueue_status\\'],device_option=dev)workspace.RunOperatorOnce(op)logger.debug(\\'enqueue_blobs{}:workspace.RunOperatorOnce:{}\\'.format(gpu_id,time.time()-t))defcreate_threads(self):#Createmini-batchloaderthreads,eachofwhichbuildsmini-batches#andplacesthemintoaqueueinCPUmemoryself._workers=[threading.Thread(target=self.minibatch_loader_thread)for_inrange(self._num_loaders)]#CreateoneBlobsQueueperGPU#(enqueue_blob_namesareunscoped)enqueue_blob_names=self.create_blobs_queues()#CreateoneenqueuerthreadperGPUself._enqueuers=[threading.Thread(target=self.enqueue_blobs_thread,args=(gpu_id,enqueue_blob_names))forgpu_idinrange(self._num_gpus)]defstart(self,prefill=False):forwinself._workers+self._enqueuers:w.setDaemon(True)w.start()ifprefill:logger.info(\\'Pre-fillingmini-batchqueue...\\')whilenotself._minibatch_queue.full():logger.info(\\'[{:d}/{:d}]\\'.format(self._minibatch_queue.qsize(),self._minibatch_queue.maxsize))time.sleep(0.1)#Detectfailureandshutdownifself.coordinator.should_stop():self.shutdown()breakdefhas_stopped(self):returnself.coordinator.should_stop()defshutdown(self):self.coordinator.request_stop()self.coordinator.wait_for_stop()self.close_blobs_queues()forwinself._workers+self._enqueuers:w.join()defcreate_blobs_queues(self):\"\"\"CreateoneBlobsQueueforeachGPUtoholdmini-batches.\"\"\"forgpu_idinrange(self._num_gpus):withc2_utils.GpuNameScope(gpu_id):workspace.RunOperatorOnce(core.CreateOperator(\\'CreateBlobsQueue\\',[],[self._blobs_queue_name],num_blobs=len(self.get_output_names()),capacity=self._blobs_queue_capacity))returnself.create_enqueue_blobs()defclose_blobs_queues(self):\"\"\"CloseaBlobsQueue.\"\"\"forgpu_idinrange(self._num_gpus):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):workspace.RunOperatorOnce(core.CreateOperator(\\'CloseBlobsQueue\\',[self._blobs_queue_name],[]))defcreate_enqueue_blobs(self):blob_names=self.get_output_names()enqueue_blob_names=[\\'{}_enqueue_{}\\'.format(b,self._loader_id)forbinblob_names]forgpu_idinrange(self._num_gpus):withc2_utils.NamedCudaScope(gpu_id):forblobinenqueue_blob_names:workspace.CreateBlob(core.ScopedName(blob))returnenqueue_blob_namesdefregister_sigint_handler(self):defsignal_handler(signal,frame):logger.info(\\'SIGINT:ShuttingdownRoIDataLoaderthreadsandexiting...\\')self.shutdown()signal.signal(signal.SIGINT,signal_handler)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"ConstructminibatchesforDetectronnetworks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.roi_data.retinanetasretinanet_roi_dataimportdetectron.roi_data.rpnasrpn_roi_dataimportdetectron.utils.blobasblob_utilslogger=logging.getLogger(__name__)defget_minibatch_blob_names(is_training=True):\"\"\"Returnblobnamesintheorderinwhichtheyarereadbythedataloader.\"\"\"#datablob:holdsabatchofNimages,eachwith3channelsblob_names=[\\'data\\']ifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFasterR-CNNblob_names+=rpn_roi_data.get_rpn_blob_names(is_training=is_training)elifcfg.RETINANET.RETINANET_ON:blob_names+=retinanet_roi_data.get_retinanet_blob_names(is_training=is_training)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsblob_names+=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=is_training)returnblob_namesdefget_minibatch(roidb):\"\"\"Givenaroidb,constructaminibatchsampledfromit.\"\"\"#Wecollectblobsfromeachimageontoalistandthenconcatthemintoa#singletensor,henceweinitializeeachblobtoanemptylistblobs={k:[]forkinget_minibatch_blob_names()}#Gettheinputimageblob,formattedforcaffe2im_blob,im_scales=_get_image_blob(roidb)blobs[\\'data\\']=im_blobifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFaster/MaskR-CNNvalid=rpn_roi_data.add_rpn_blobs(blobs,im_scales,roidb)elifcfg.RETINANET.RETINANET_ON:im_width,im_height=im_blob.shape[3],im_blob.shape[2]#im_width,im_heightcorrespondstothenetworkinput:paddedimage#(ifneeded)widthandheight.Wepassitasinputandslicethedata#accordinglysothatwedon\\'tneedtouseSampleAsOpvalid=retinanet_roi_data.add_retinanet_blobs(blobs,im_scales,roidb,im_width,im_height)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsvalid=fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)returnblobs,validdef_get_image_blob(roidb):\"\"\"Buildsaninputblobfromtheimagesintheroidbatthespecifiedscales.\"\"\"num_images=len(roidb)#Samplerandomscalestouseforeachimageinthisbatchscale_inds=np.random.randint(0,high=len(cfg.TRAIN.SCALES),size=num_images)processed_ims=[]im_scales=[]foriinrange(num_images):im=cv2.imread(roidb[i][\\'image\\'])assertimisnotNone,\\\\\\'Failedtoreadimage\\\\\\'{}\\\\\\'\\'.format(roidb[i][\\'image\\'])ifroidb[i][\\'flipped\\']:im=im[:,::-1,:]target_size=cfg.TRAIN.SCALES[scale_inds[i]]im,im_scale=blob_utils.prep_im_for_blob(im,cfg.PIXEL_MEANS,target_size,cfg.TRAIN.MAX_SIZE)im_scales.append(im_scale)processed_ims.append(im)#Createablobtoholdtheinputimagesblob=blob_utils.im_list_to_blob(processed_ims)returnblob,im_scales#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforFastR-CNNtraining.HandlestheminibatchblobsthatarespecifictoFastR-CNN.OtherblobsthataregenerictoRPN,etc.arehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.keypoint_rcnnaskeypoint_rcnn_roi_dataimportdetectron.roi_data.mask_rcnnasmask_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_fast_rcnn_blob_names(is_training=True):\"\"\"FastR-CNNblobnames.\"\"\"#roisblob:holdsRregionsofinterest,eachisa5-tuple#(batch_idx,x1,y1,x2,y2)specifyinganimagebatchindexanda#rectangle(x1,y1,x2,y2)blob_names=[\\'rois\\']ifis_training:#labels_int32blob:Rcategoricallabelsin[0,...,K]forK#foregroundclassesplusbackgroundblob_names+=[\\'labels_int32\\']ifis_training:#bbox_targetsblob:Rbounding-boxregressiontargetswith4#targetsperclassblob_names+=[\\'bbox_targets\\']#bbox_inside_weightsblob:Atmost4targetsperroiareactive#thisbinaryvectorsepcifiesthesubsetofactivetargetsblob_names+=[\\'bbox_inside_weights\\']blob_names+=[\\'bbox_outside_weights\\']ifis_trainingandcfg.MODEL.MASK_ON:#\\'mask_rois\\':RoIssampledfortrainingthemaskpredictionbranch.#Shapeis(#masks,5)informat(batch_idx,x1,y1,x2,y2).blob_names+=[\\'mask_rois\\']#\\'roi_has_mask\\':binarylabelsfortheRoIsspecifiedin\\'rois\\'#indicatingifeachRoIhasamaskornot.Notethatinsomecases#a*bg*RoIwillhaveanall-1(ignore)maskassociatedwithitin#thecasethatnofgRoIscanbesampled.Shapeis(batchsize).blob_names+=[\\'roi_has_mask_int32\\']#\\'masks_int32\\'holdsbinarymasksfortheRoIsspecifiedin#\\'mask_rois\\'.Shapeis(#fg,M*M)whereMisthegroundtruth#masksize.blob_names+=[\\'masks_int32\\']ifis_trainingandcfg.MODEL.KEYPOINTS_ON:#\\'keypoint_rois\\':RoIssampledfortrainingthekeypointprediction#branch.Shapeis(#instances,5)informat(batch_idx,x1,y1,x2,#y2).blob_names+=[\\'keypoint_rois\\']#\\'keypoint_locations_int32\\':indexofkeypointin#KRCNN.HEATMAP_SIZE**2sizedarray.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_locations_int32\\']#\\'keypoint_weights\\':weightassignedtoeachtargetin#\\'keypoint_locations_int32\\'.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_weights\\']#\\'keypoint_loss_normalizer\\':optionalnormalizationfactortouseif#cfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.blob_names+=[\\'keypoint_loss_normalizer\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:#SupportforFPNmulti-levelroiswithoutbboxregisn\\'t#implemented(...andmayneverbeimplemented)k_max=cfg.FPN.ROI_MAX_LEVELk_min=cfg.FPN.ROI_MIN_LEVEL#Sameformatasroisblob,butoneperFPNlevelforlvlinrange(k_min,k_max+1):blob_names+=[\\'rois_fpn\\'+str(lvl)]blob_names+=[\\'rois_idx_restore_int32\\']ifis_training:ifcfg.MODEL.MASK_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'mask_rois_fpn\\'+str(lvl)]blob_names+=[\\'mask_rois_idx_restore_int32\\']ifcfg.MODEL.KEYPOINTS_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'keypoint_rois_fpn\\'+str(lvl)]blob_names+=[\\'keypoint_rois_idx_restore_int32\\']returnblob_namesdefadd_fast_rcnn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededfortrainingFastR-CNNstylemodels.\"\"\"#SampletrainingRoIsfromeachimageandappendthemtothebloblistsforim_i,entryinenumerate(roidb):frcn_blobs=_sample_rois(entry,im_scales[im_i],im_i)fork,vinfrcn_blobs.items():blobs[k].append(v)#Concatthetrainingbloblistsintotensorsfork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)#AddFPNmultileveltrainingRoIs,ifconfiguredifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois(blobs)#Performanyfinalworkandvaliditychecksafterthecollatingblobsfor#allminibatchimagesvalid=Trueifcfg.MODEL.KEYPOINTS_ON:valid=keypoint_rcnn_roi_data.finalize_keypoint_minibatch(blobs,valid)returnvaliddef_sample_rois(roidb,im_scale,batch_idx):\"\"\"GeneratearandomsampleofRoIscomprisingforegroundandbackgroundexamples.\"\"\"rois_per_image=int(cfg.TRAIN.BATCH_SIZE_PER_IM)fg_rois_per_image=int(np.round(cfg.TRAIN.FG_FRACTION*rois_per_image))max_overlaps=roidb[\\'max_overlaps\\']#SelectforegroundRoIsasthosewith>=FG_THRESHoverlapfg_inds=np.where(max_overlaps>=cfg.TRAIN.FG_THRESH)[0]#Guardagainstthecasewhenanimagehasfewerthanfg_rois_per_image#foregroundRoIsfg_rois_per_this_image=np.minimum(fg_rois_per_image,fg_inds.size)#Sampleforegroundregionswithoutreplacementiffg_inds.size>0:fg_inds=npr.choice(fg_inds,size=fg_rois_per_this_image,replace=False)#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((max_overlaps<cfg.TRAIN.BG_THRESH_HI)&(max_overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#ComputenumberofbackgroundRoIstotakefromthisimage(guarding#againsttherebeingfewerthandesired)bg_rois_per_this_image=rois_per_image-fg_rois_per_this_imagebg_rois_per_this_image=np.minimum(bg_rois_per_this_image,bg_inds.size)#Sampleforegroundregionswithoutreplacementifbg_inds.size>0:bg_inds=npr.choice(bg_inds,size=bg_rois_per_this_image,replace=False)#Theindicesthatwe\\'reselecting(bothfgandbg)keep_inds=np.append(fg_inds,bg_inds)#LabelistheclasseachRoIhasmaxoverlapwithsampled_labels=roidb[\\'max_classes\\'][keep_inds]sampled_labels[fg_rois_per_this_image:]=0#LabelbgRoIswithclass0sampled_boxes=roidb[\\'boxes\\'][keep_inds]bbox_targets,bbox_inside_weights=_expand_bbox_targets(roidb[\\'bbox_targets\\'][keep_inds,:])bbox_outside_weights=np.array(bbox_inside_weights>0,dtype=bbox_inside_weights.dtype)#Scaleroisandformatas(batch_idx,x1,y1,x2,y2)sampled_rois=sampled_boxes*im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_rois.shape[0],1))sampled_rois=np.hstack((repeated_batch_idx,sampled_rois))#BaseFastR-CNNblobsblob_dict=dict(labels_int32=sampled_labels.astype(np.int32,copy=False),rois=sampled_rois,bbox_targets=bbox_targets,bbox_inside_weights=bbox_inside_weights,bbox_outside_weights=bbox_outside_weights)#OptionallyaddMaskR-CNNblobsifcfg.MODEL.MASK_ON:mask_rcnn_roi_data.add_mask_rcnn_blobs(blob_dict,sampled_boxes,roidb,im_scale,batch_idx)#OptionallyaddKeypointR-CNNblobsifcfg.MODEL.KEYPOINTS_ON:keypoint_rcnn_roi_data.add_keypoint_rcnn_blobs(blob_dict,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx)returnblob_dictdef_expand_bbox_targets(bbox_target_data):\"\"\"Bounding-boxregressiontargetsarestoredinacompactformintheroidb.Thisfunctionexpandsthosetargetsintothe4-of-4*Krepresentationusedbythenetwork(i.e.onlyoneclasshasnon-zerotargets).Thelossweightsaresimilarlyexpanded.Returns:bbox_target_data(ndarray):Nx4Kblobofregressiontargetsbbox_inside_weights(ndarray):Nx4Kbloboflossweights\"\"\"num_bbox_reg_classes=cfg.MODEL.NUM_CLASSESifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:num_bbox_reg_classes=2#bgandfgclss=bbox_target_data[:,0]bbox_targets=blob_utils.zeros((clss.size,4*num_bbox_reg_classes))bbox_inside_weights=blob_utils.zeros(bbox_targets.shape)inds=np.where(clss>0)[0]forindininds:cls=int(clss[ind])start=4*clsend=start+4bbox_targets[ind,start:end]=bbox_target_data[ind,1:]bbox_inside_weights[ind,start:end]=(1.0,1.0,1.0,1.0)returnbbox_targets,bbox_inside_weightsdef_add_multilevel_rois(blobs):\"\"\"BydefaulttrainingRoIsareaddedforasinglefeaturemaplevelonly.WhenusingFPN,theRoIsmustbedistributedoverdifferentFPNlevelsaccordingthelevelassignmentheuristic(see:modeling.FPN.map_rois_to_fpn_levels).\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELdef_distribute_rois_over_fpn_levels(rois_blob_name):\"\"\"DistributeroisoverthedifferentFPNlevels.\"\"\"#Gettargetlevelforeachroi#Recallblobroisarein(batch_idx,x1,y1,x2,y2)format,hencetake#theboxcoordinatesfromcolumns1:5target_lvls=fpn.map_rois_to_fpn_levels(blobs[rois_blob_name][:,1:5],lvl_min,lvl_max)#AddperFPNlevelroiblobsnamedlike:_fpnfpn.add_multilevel_roi_blobs(blobs,rois_blob_name,blobs[rois_blob_name],target_lvls,lvl_min,lvl_max)_distribute_rois_over_fpn_levels(\\'rois\\')ifcfg.MODEL.MASK_ON:_distribute_rois_over_fpn_levels(\\'mask_rois\\')ifcfg.MODEL.KEYPOINTS_ON:_distribute_rois_over_fpn_levels(\\'keypoint_rois\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtraining.HandlestheminibatchblobsthatarespecifictoMaskR-CNN.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defadd_mask_rcnn_blobs(blobs,sampled_boxes,roidb,im_scale,batch_idx):\"\"\"AddMaskR-CNNspecificblobstotheinputblobdictionary.\"\"\"#Preparethemasktargetsbyassociatingonegtmasktoeachtrainingroi#thathasafg(non-bg)classlabel.M=cfg.MRCNN.RESOLUTIONpolys_gt_inds=np.where((roidb[\\'gt_classes\\']>0)&(roidb[\\'is_crowd\\']==0))[0]polys_gt=[roidb[\\'segms\\'][i]foriinpolys_gt_inds]boxes_from_polys=segm_utils.polys_to_boxes(polys_gt)fg_inds=np.where(blobs[\\'labels_int32\\']>0)[0]roi_has_mask=blobs[\\'labels_int32\\'].copy()roi_has_mask[roi_has_mask>0]=1iffg_inds.shape[0]>0:#Classlabelsfortheforegroundroismask_class_labels=blobs[\\'labels_int32\\'][fg_inds]masks=blob_utils.zeros((fg_inds.shape[0],M**2),int32=True)#Findoverlapbetweenallforegroundroisandtheboundingboxes#enclosingeachsegmentationrois_fg=sampled_boxes[fg_inds]overlaps_bbfg_bbpolys=box_utils.bbox_overlaps(rois_fg.astype(np.float32,copy=False),boxes_from_polys.astype(np.float32,copy=False))#Mapfromeachfgroistotheindexofthemaskwithhighestoverlap#(measuredbybboxoverlap)fg_polys_inds=np.argmax(overlaps_bbfg_bbpolys,axis=1)#addfgtargetsforiinrange(rois_fg.shape[0]):fg_polys_ind=fg_polys_inds[i]poly_gt=polys_gt[fg_polys_ind]roi_fg=rois_fg[i]#Rasterizetheportionofthepolygonmaskwithinthegivenfgroi#toanMxMbinaryimagemask=segm_utils.polys_to_mask_wrt_box(poly_gt,roi_fg,M)mask=np.array(mask>0,dtype=np.int32)#Ensureit\\'sbinarymasks[i,:]=np.reshape(mask,M**2)else:#Iftherearenofgmasks(itdoeshappen)#Thenetworkcannothandleemptyblobs,sowemustprovideamask#Wesimplytakethefirstbgroi,givenitanall-1\\'smask(ignore#label),andlabelitwithclasszero(bg).bg_inds=np.where(blobs[\\'labels_int32\\']==0)[0]#rois_fgisactuallyonebackgroundroi,butthat\\'sokbecause...rois_fg=sampled_boxes[bg_inds[0]].reshape((1,-1))#Wegiveitan-1\\'sblob(ignorelabel)masks=-blob_utils.ones((1,M**2),int32=True)#Welabelitwithclass=0(background)mask_class_labels=blob_utils.zeros((1,))#Markthatthefirstroihasamaskroi_has_mask[0]=1ifcfg.MRCNN.CLS_SPECIFIC_MASK:masks=_expand_to_class_specific_mask_targets(masks,mask_class_labels)#Scalerois_fgandformatas(batch_idx,x1,y1,x2,y2)rois_fg*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((rois_fg.shape[0],1))rois_fg=np.hstack((repeated_batch_idx,rois_fg))#UpdateblobsdictwithMaskR-CNNblobsblobs[\\'mask_rois\\']=rois_fgblobs[\\'roi_has_mask_int32\\']=roi_has_maskblobs[\\'masks_int32\\']=masksdef_expand_to_class_specific_mask_targets(masks,mask_class_labels):\"\"\"Expandmasksfromshape(#masks,M**2)to(#masks,#classes*M**2)toencodeclassspecificmasktargets.\"\"\"assertmasks.shape[0]==mask_class_labels.shape[0]M=cfg.MRCNN.RESOLUTION#Targetvaluesof-1are\"don\\'tcare\"/ignorelabelsmask_targets=-blob_utils.ones((masks.shape[0],cfg.MODEL.NUM_CLASSES*M**2),int32=True)foriinrange(masks.shape[0]):cls=int(mask_class_labels[i])start=M**2*clsend=start+M**2#Ignorebackgroundinstance#(onlyhappenswhenthereisnofgsamplesinanimage)ifcls>0:mask_targets[i,start:end]=masks[i,:]returnmask_targets#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"MinibatchconstructionforRegionProposalNetworks(RPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.roi_data.data_utilsasdata_utilsimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_rpn_blob_names(is_training=True):\"\"\"BlobnamesusedbyRPN.\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']ifis_training:#gtboxes:(batch_idx,x1,y1,x2,y2,cls)blob_names+=[\\'roidb\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#SameformatasRPNblobs,butoneperFPNlevelforlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):blob_names+=[\\'rpn_labels_int32_wide_fpn\\'+str(lvl),\\'rpn_bbox_targets_wide_fpn\\'+str(lvl),\\'rpn_bbox_inside_weights_wide_fpn\\'+str(lvl),\\'rpn_bbox_outside_weights_wide_fpn\\'+str(lvl)]else:#SinglelevelRPNblobsblob_names+=[\\'rpn_labels_int32_wide\\',\\'rpn_bbox_targets_wide\\',\\'rpn_bbox_inside_weights_wide\\',\\'rpn_bbox_outside_weights_wide\\']returnblob_namesdefadd_rpn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededtrainingRPN-onlyandend-to-endFasterR-CNNmodels.\"\"\"ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELfoas=[]forlvlinrange(k_min,k_max+1):field_stride=2.**lvlanchor_sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),)anchor_aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOSfoa=data_utils.get_field_of_anchors(field_stride,anchor_sizes,anchor_aspect_ratios)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])else:foa=data_utils.get_field_of_anchors(cfg.RPN.STRIDE,cfg.RPN.SIZES,cfg.RPN.ASPECT_RATIOS)all_anchors=foa.field_of_anchorsforim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_rois=entry[\\'boxes\\'][gt_inds,:]*scaleim_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)#AddRPNtargetsifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperrpn_blobs=_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_rois)fori,lvlinenumerate(range(k_min,k_max+1)):fork,vinrpn_blobs[i].items():blobs[k+\\'_fpn\\'+str(lvl)].append(v)else:#ClassicalRPN,appliedtoasinglefeaturelevelrpn_blobs=_get_rpn_blobs(im_height,im_width,[foa],all_anchors,gt_rois)fork,vinrpn_blobs.items():blobs[k].append(v)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)valid_keys=[\\'has_visible_keypoints\\',\\'boxes\\',\\'segms\\',\\'seg_areas\\',\\'gt_classes\\',\\'gt_overlaps\\',\\'is_crowd\\',\\'box_to_gt_ind_map\\',\\'gt_keypoints\\']minimal_roidb=[{}for_inrange(len(roidb))]fori,einenumerate(roidb):forkinvalid_keys:ifkine:minimal_roidb[i][k]=e[k]blobs[\\'roidb\\']=blob_utils.serialize(minimal_roidb)#Alwaysreturnvalid=True,sinceRPNminibatchesarevalidbydesignreturnTruedef_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_boxes):total_anchors=all_anchors.shape[0]straddle_thresh=cfg.TRAIN.RPN_STRADDLE_THRESHifstraddle_thresh>=0:#Onlykeepanchorsinsidetheimagebyamarginofstraddle_thresh#SetTRAIN.RPN_STRADDLE_THRESHto-1(oralargevalue)tokeepall#anchorsinds_inside=np.where((all_anchors[:,0]>=-straddle_thresh)&(all_anchors[:,1]>=-straddle_thresh)&(all_anchors[:,2]<im_width+straddle_thresh)&(all_anchors[:,3]<im_height+straddle_thresh))[0]#keeponlyinsideanchorsanchors=all_anchors[inds_inside,:]else:inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.int32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)labels[anchors_with_max_overlap]=1#Fglabel:abovethresholdIOUlabels[anchor_to_gt_max>=cfg.TRAIN.RPN_POSITIVE_OVERLAP]=1#subsamplepositivelabelsifwehavetoomanynum_fg=int(cfg.TRAIN.RPN_FG_FRACTION*cfg.TRAIN.RPN_BATCH_SIZE_PER_IM)fg_inds=np.where(labels==1)[0]iflen(fg_inds)>num_fg:disable_inds=npr.choice(fg_inds,size=(len(fg_inds)-num_fg),replace=False)labels[disable_inds]=-1fg_inds=np.where(labels==1)[0]#subsamplenegativelabelsifwehavetoomany#(sampleswithreplacement,butsincethesetofbgindsislargemost#sampleswillnothaverepeats)num_bg=cfg.TRAIN.RPN_BATCH_SIZE_PER_IM-np.sum(labels==1)bg_inds=np.where(anchor_to_gt_max<cfg.TRAIN.RPN_NEGATIVE_OVERLAP)[0]iflen(bg_inds)>num_bg:enable_inds=bg_inds[npr.randint(len(bg_inds),size=num_bg)]else:enable_inds=bg_indslabels[enable_inds]=0bg_inds=np.where(labels==0)[0]bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Bboxregressionlosshastheform:#loss(x)=weight_outside*L(weight_inside*x)#Insideweightsallowustosetzerolossonanelement-wisebasis#Bboxregressionisonlytrainedonpositiveexamplessowesettheir#weightsto1.0(orotherwiseifconfigisdifferent)and0otherwisebbox_inside_weights=np.zeros((num_inside,4),dtype=np.float32)bbox_inside_weights[labels==1,:]=(1.0,1.0,1.0,1.0)#Thebboxregressionlossonlyaveragesbythenumberofimagesinthe#mini-batch,whereasweneedtoaveragebythetotalnumberofexample#anchorsselected#Outsideweightsareusedtoscaleeachelement-wiselosssothefinal#averageoverthemini-batchiscorrectbbox_outside_weights=np.zeros((num_inside,4),dtype=np.float32)#uniformweightingofexamples(givennon-uniformsampling)num_examples=np.sum(labels>=0)bbox_outside_weights[labels==1,:]=1.0/num_examplesbbox_outside_weights[labels==0,:]=1.0/num_examples#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)bbox_inside_weights=data_utils.unmap(bbox_inside_weights,total_anchors,inds_inside,fill=0)bbox_outside_weights=data_utils.unmap(bbox_outside_weights,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeA=foa.num_cell_anchorsend_idx=start_idx+H*W*A_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]_bbox_inside_weights=bbox_inside_weights[start_idx:end_idx,:]_bbox_outside_weights=bbox_outside_weights[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,A,height,width)_labels=_labels.reshape((1,H,W,A)).transpose(0,3,1,2)#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_inside_weightsoutputwithshape(1,4*A,height,width)_bbox_inside_weights=_bbox_inside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_outside_weightsoutputwithshape(1,4*A,height,width)_bbox_outside_weights=_bbox_outside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)blobs_out.append(dict(rpn_labels_int32_wide=_labels,rpn_bbox_targets_wide=_bbox_targets,rpn_bbox_inside_weights_wide=_bbox_inside_weights,rpn_bbox_outside_weights_wide=_bbox_outside_weights))returnblobs_out[0]iflen(blobs_out)==1elseblobs_out#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtrainingwhenkeypointsareenabled.HandlestheminibatchblobsthatarespecifictotrainingMaskR-CNNforkeypointdetection.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defadd_keypoint_rcnn_blobs(blobs,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx):\"\"\"AddMaskR-CNNkeypointspecificblobstothegivenblobsdictionary.\"\"\"#Note:gt_indsmustmatchhowthey\\'recomputedin#datasets.json_dataset._merge_proposal_boxes_into_roidbgt_inds=np.where(roidb[\\'gt_classes\\']>0)[0]max_overlaps=roidb[\\'max_overlaps\\']gt_keypoints=roidb[\\'gt_keypoints\\']ind_kp=gt_inds[roidb[\\'box_to_gt_ind_map\\']]within_box=_within_box(gt_keypoints[ind_kp,:,:],roidb[\\'boxes\\'])vis_kp=gt_keypoints[ind_kp,2,:]>0is_visible=np.sum(np.logical_and(vis_kp,within_box),axis=1)>0kp_fg_inds=np.where(np.logical_and(max_overlaps>=cfg.TRAIN.FG_THRESH,is_visible))[0]kp_fg_rois_per_this_image=np.minimum(fg_rois_per_image,kp_fg_inds.size)ifkp_fg_inds.size>kp_fg_rois_per_this_image:kp_fg_inds=np.random.choice(kp_fg_inds,size=kp_fg_rois_per_this_image,replace=False)sampled_fg_rois=roidb[\\'boxes\\'][kp_fg_inds]box_to_gt_ind_map=roidb[\\'box_to_gt_ind_map\\'][kp_fg_inds]num_keypoints=gt_keypoints.shape[2]sampled_keypoints=-np.ones((len(sampled_fg_rois),gt_keypoints.shape[1],num_keypoints),dtype=gt_keypoints.dtype)foriiinrange(len(sampled_fg_rois)):ind=box_to_gt_ind_map[ii]ifind>=0:sampled_keypoints[ii,:,:]=gt_keypoints[gt_inds[ind],:,:]assertnp.sum(sampled_keypoints[ii,2,:])>0heats,weights=keypoint_utils.keypoints_to_heatmap_labels(sampled_keypoints,sampled_fg_rois)shape=(sampled_fg_rois.shape[0]*cfg.KRCNN.NUM_KEYPOINTS,1)heats=heats.reshape(shape)weights=weights.reshape(shape)sampled_fg_rois*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_fg_rois.shape[0],1))sampled_fg_rois=np.hstack((repeated_batch_idx,sampled_fg_rois))blobs[\\'keypoint_rois\\']=sampled_fg_roisblobs[\\'keypoint_locations_int32\\']=heats.astype(np.int32,copy=False)blobs[\\'keypoint_weights\\']=weightsdeffinalize_keypoint_minibatch(blobs,valid):\"\"\"Finalizetheminibatchafterblobsforallminibatchimageshavebeencollated.\"\"\"min_count=cfg.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCHnum_visible_keypoints=np.sum(blobs[\\'keypoint_weights\\'])valid=(validandlen(blobs[\\'keypoint_weights\\'])>0andnum_visible_keypoints>min_count)#Normalizertouseifcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.#Seemodeling.model_builder.add_keypoint_lossesnorm=num_visible_keypoints/(cfg.TRAIN.IMS_PER_BATCH*cfg.TRAIN.BATCH_SIZE_PER_IM*cfg.TRAIN.FG_FRACTION*cfg.KRCNN.NUM_KEYPOINTS)blobs[\\'keypoint_loss_normalizer\\']=np.array(norm,dtype=np.float32)returnvaliddef_within_box(points,boxes):\"\"\"Validatewhichkeypointsarecontainedinsideagivenbox.points:Nx2xKboxes:Nx4output:NxK\"\"\"x_within=np.logical_and(points[:,0,:]>=np.expand_dims(boxes[:,0],axis=1),points[:,0,:]<=np.expand_dims(boxes[:,2],axis=1))y_within=np.logical_and(points[:,1,:]>=np.expand_dims(boxes[:,1],axis=1),points[:,1,:]<=np.expand_dims(boxes[:,3],axis=1))returnnp.logical_and(x_within,y_within)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSmoothL1LossTest(unittest.TestCase):deftest_forward_and_gradient(self):Y=np.random.randn(128,4*21).astype(np.float32)Y_hat=np.random.randn(128,4*21).astype(np.float32)inside_weights=np.random.randn(128,4*21).astype(np.float32)inside_weights[inside_weights<0]=0outside_weights=np.random.randn(128,4*21).astype(np.float32)outside_weights[outside_weights<0]=0scale=np.random.random()beta=np.random.random()op=core.CreateOperator(\\'SmoothL1Loss\\',[\\'Y_hat\\',\\'Y\\',\\'inside_weights\\',\\'outside_weights\\'],[\\'loss\\'],scale=scale,beta=beta)gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[Y_hat,Y,inside_weights,outside_weights],0,[0])self.assertTrue(grad.shape==grad_estimated.shape,\\'Failcheck:grad.shape!=grad_estimated.shape\\')#Toinspectthegradientandestimatedgradient:#np.set_printoptions(precision=3,suppress=True)#print(\\'grad:\\')#print(grad)#print(\\'grad_estimated:\\')#print(grad_estimated)self.assertTrue(res)if__name__==\\'__main__\\':c2_utils.import_detectron_ops()assert\\'SmoothL1Loss\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfrompycocotoolsimportmaskasCOCOmaskimportdetectron.utils.boxesasbox_utilsdefrandom_boxes(mean_box,stdev,N):boxes=np.random.randn(N,4)*stdev+mean_boxreturnboxes.astype(dtype=np.float32)classTestBboxTransform(unittest.TestCase):deftest_bbox_transform_and_inverse(self):weights=(5,5,10,10)src_boxes=random_boxes([10,10,20,20],1,10)dst_boxes=random_boxes([10,10,20,20],1,10)deltas=box_utils.bbox_transform_inv(src_boxes,dst_boxes,weights=weights)dst_boxes_reconstructed=box_utils.bbox_transform(src_boxes,deltas,weights=weights)np.testing.assert_array_almost_equal(dst_boxes,dst_boxes_reconstructed,decimal=5)deftest_bbox_dataset_to_prediction_roundtrip(self):\"\"\"Simulatetheprocessofreadingaground-truthboxfromadataset,makepredictionsfromproposals,convertthepredictionsbacktothedatasetformat,andthenusetheCOCOAPItocomputeIoUoverlapbetweenthegtboxandthepredictions.TheseshouldhaveIoUof1.\"\"\"weights=(5,5,10,10)#1/\"read\"aboxfromadatasetinthedefault(x1,y1,w,h)formatgt_xywh_box=[10,20,100,150]#2/convertittoourinternal(x1,y1,x2,y2)formatgt_xyxy_box=box_utils.xywh_to_xyxy(gt_xywh_box)#3/considernearbyproposalboxesprop_xyxy_boxes=random_boxes(gt_xyxy_box,10,10)#4/computeproposal-to-gttransformationdeltasdeltas=box_utils.bbox_transform_inv(prop_xyxy_boxes,np.array([gt_xyxy_box]),weights=weights)#5/usedeltastotransformproposalstoxyxypredictedboxpred_xyxy_boxes=box_utils.bbox_transform(prop_xyxy_boxes,deltas,weights=weights)#6/convertxyxypredictedboxtoxywhpredictedboxpred_xywh_boxes=box_utils.xyxy_to_xywh(pred_xyxy_boxes)#7/useCOCOAPItocomputeIoUnot_crowd=[int(False)]*pred_xywh_boxes.shape[0]ious=COCOmask.iou(pred_xywh_boxes,np.array([gt_xywh_box]),not_crowd)np.testing.assert_array_almost_equal(ious,np.ones(ious.shape))deftest_cython_bbox_iou_against_coco_api_bbox_iou(self):\"\"\"CheckthatourcythonimplementationofboundingboxIoUoverlapmatchestheCOCOAPIimplementation.\"\"\"def_do_test(b1,b2):#ComputeIoUoverlapwiththecythonimplementationcython_iou=box_utils.bbox_overlaps(b1,b2)#ComputeIoUoverlapwiththeCOCOAPIimplementation#(requiresconvertingboxesfromxyxytoxywhformat)xywh_b1=box_utils.xyxy_to_xywh(b1)xywh_b2=box_utils.xyxy_to_xywh(b2)not_crowd=[int(False)]*b2.shape[0]coco_ious=COCOmask.iou(xywh_b1,xywh_b2,not_crowd)#IoUsshouldbesimilarnp.testing.assert_array_almost_equal(cython_iou,coco_ious,decimal=5)#Testsmallboxesb1=random_boxes([10,10,20,20],5,10)b2=random_boxes([10,10,20,20],5,10)_do_test(b1,b2)#Testbiggerboxesb1=random_boxes([10,10,110,20],20,10)b2=random_boxes([10,10,110,20],20,10)_do_test(b1,b2)if__name__==\\'__main__\\':unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimporttempfilefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.netasnuc2_utils.import_detectron_ops()defget_params(model):blobs={}#gpu_0blobswithunscoped_nameaskeyall_blobs={}#allblobswithscopednameaskey#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)forparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)returnblobs,all_blobsdefadd_momentum_init_ops(model):forparaminmodel.TrainableParams(gpu_id=0):model.param_init_net.GaussianFill([param+\\'_momentum\\'],param+\\'_momentum\\',mean=0.0,std=1.0)definit_weights(model):#initweightsingpu_id=0andthenbroadcastworkspace.RunNetOnce(model.param_init_net)nu.broadcast_parameters(model)deftest_restore_checkpoint():#CreateModelmodel=model_builder.create(cfg.MODEL.TYPE,train=True)add_momentum_init_ops(model)init_weights(model)#Fillinputblobsroidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)model_builder.add_training_inputs(model,roidb=roidb)workspace.CreateNet(model.net)#Bookkeepingforcheckpointcreationiter_num=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)chk_file_path=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(iter_num))checkpoints[iter_num]=chk_file_path#Savemodelweightsnu.save_model_to_weights_file(checkpoints[iter_num],model)orig_gpu_0_params,orig_all_params=get_params(model)#Changethemodelweightsinit_weights(model)#Reloadtheweightsinthemodelnu.initialize_gpu_from_weights_file(model,chk_file_path,gpu_id=0)nu.broadcast_parameters(model)shutil.rmtree(cfg.OUTPUT_DIR)_,restored_all_params=get_params(model)#Checkifallparamsareloadedcorrectlyforscoped_name,blobinorig_all_params.items():np.testing.assert_array_equal(blob,restored_all_params[scoped_name])#Checkifbroadcast_parametersworksforscoped_name,blobinrestored_all_params.items():unscoped_name=c2_utils.UnscopeName(scoped_name)np.testing.assert_array_equal(blob,orig_gpu_0_params[unscoped_name])if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)output_dir=tempfile.mkdtemp()#Generateconfigfortestcfg.MODEL.TYPE=\\'generalized_rcnn\\'cfg.MODEL.CONV_BODY=\\'FPN.add_fpn_ResNet50_conv5_body\\'cfg.MODEL.NUM_CLASSES=81cfg.MODEL.FASTER_RCNN=Truecfg.FPN.FPN_ON=Truecfg.FPN.MULTILEVEL_ROIS=Truecfg.FPN.MULTILEVEL_RPN=Truecfg.FAST_RCNN.ROI_BOX_HEAD=\\'fast_rcnn_heads.add_roi_2mlp_head\\'cfg.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'cfg.OUTPUT_DIR=output_dircfg.TRAIN.DATASETS=(\\'coco_2014_minival\\',)cfg.TRAIN.WEIGHTS=b\\'\\'fornum_gpuinrange(workspace.NumCudaDevices()):cfg.immutable(False)cfg.NUM_GPUS=num_gpu+1assert_and_infer_cfg()test_restore_checkpoint()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsclassZeroEvenOpTest(unittest.TestCase):def_run_zero_even_op(self,X):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdef_run_zero_even_op_gpu(self,X):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdeftest_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op(X)deftest_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op_gpu(X)deftest_gpu_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_gpu_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_gpu_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_custom_ops()assert\\'ZeroEven\\'inworkspace.RegisteredOperators()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.loggingaslogging_utilsimportdetectron.utils.c2asc2_utilsclassBatchPermutationOpTest(unittest.TestCase):def_run_op_test(self,X,I,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'BatchPermutation\\',[\\'X\\',\\'I\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.FeedBlob(\\'I\\',I)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.1,threshold=0.001,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[X,I],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')Y_ref=X[I]np.testing.assert_allclose(Y,Y_ref,rtol=1e-5,atol=1e-08)def_run_speed_test(self,iters=5,N=1024):\"\"\"ThisfunctionprovidesanexampleofhowtobenchmarkcustomoperatorsusingtheCaffe2\\'prof_dag\\'networkexecutiontype.Pleasenotethatfor\\'prof_dag\\'towork,Caffe2mustbecompiledwithprofilingsupportusingthe`-DUSE_PROF=ON`optionpassedto`cmake`whenbuildingCaffe2.\"\"\"net=core.Net(\\'test\\')net.Proto().type=\\'prof_dag\\'net.Proto().num_workers=2Y=net.BatchPermutation([\\'X\\',\\'I\\'],\\'Y\\')Y_flat=net.FlattenToVec([Y],\\'Y_flat\\')loss=net.AveragedLoss([Y_flat],\\'loss\\')net.AddGradientOperators([loss])workspace.CreateNet(net)X=np.random.randn(N,256,14,14)for_iinrange(iters):I=np.random.permutation(N)workspace.FeedBlob(\\'X\\',X.astype(np.float32))workspace.FeedBlob(\\'I\\',I.astype(np.int32))workspace.RunNet(net.Proto().name)np.testing.assert_allclose(workspace.FetchBlob(\\'Y\\'),X[I],rtol=1e-5,atol=1e-08)deftest_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([0,1],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([1,0],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(10,3,5,7).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)self._run_op_test(A,I,check_grad=True)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)withself.assertRaises(RuntimeError):self._run_op_test(A,I)#Seedocstringin_run_speed_test#deftest_perf(self):#withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):#self._run_speed_test()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'BatchPermutation\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportunittestimportunittest.mockasmockfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.utils.loggingaslogging_utilsdefget_roidb_blobs(roidb):blobs={}blobs[\\'data\\']=np.stack([entry[\\'data\\']forentryinroidb])returnblobs,Truedefget_net(data_loader,name):logger=logging.getLogger(__name__)blob_names=data_loader.get_output_names()net=core.Net(name)net.type=\\'dag\\'forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)workspace.CreateBlob(blob)net.DequeueBlobs(data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))returnnetdefget_roidb_sample_data(sample_data):roidb=[]for_inrange(np.random.randint(4,10)):roidb.append({\\'data\\':sample_data})returnroidbdefcreate_loader_and_network(sample_data,name):roidb=get_roidb_sample_data(sample_data)loader=RoIDataLoader(roidb)net=get_net(loader,\\'dequeue_net_train\\')loader.register_sigint_handler()loader.start(prefill=False)returnloader,netdefrun_net(net):workspace.RunNetOnce(net)gpu_dev=core.DeviceOption(caffe2_pb2.CUDA,0)name_scope=\\'gpu_{}\\'.format(0)withcore.NameScope(name_scope):withcore.DeviceScope(gpu_dev):data=workspace.FetchBlob(core.ScopedName(\\'data\\'))returndataclassTestRoIDataLoader(unittest.TestCase):@mock.patch(\\'detectron.roi_data.loader.get_minibatch_blob_names\\',return_value=[u\\'data\\'])@mock.patch(\\'detectron.roi_data.loader.get_minibatch\\',side_effect=get_roidb_blobs)deftest_two_parallel_loaders(self,_1,_2):train_data=np.random.rand(2,3,3).astype(np.float32)train_loader,train_net=create_loader_and_network(train_data,\\'dequeue_net_train\\')test_data=np.random.rand(2,4,4).astype(np.float32)test_loader,test_net=create_loader_and_network(test_data,\\'dequeue_net_test\\')for_inrange(5):data=run_net(train_net)self.assertEqual(data[0].tolist(),train_data.tolist())data=run_net(test_net)self.assertEqual(data[0].tolist(),test_data.tolist())test_loader.shutdown()train_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=logging_utils.setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)cfg.TRAIN.ASPECT_GROUPING=Falsecfg.NUM_GPUS=2assert_and_infer_cfg()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Exampleusage:#data_loader_benchmark.par\\\\#NUM_GPUS2\\\\#TRAIN.DATASETS\"(\\'voc_2007_trainval\\',)\"\\\\#TRAIN.PROPOSAL_FILES/path/to/voc_2007_trainval/proposals.pkl\\\\#DATA_LOADER.NUM_THREADS4\\\\#DATA_LOADER.MINIBATCH_QUEUE_SIZE64\\\\#DATA_LOADER.BLOBS_QUEUE_CAPACITY8from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportloggingimportnumpyasnpimportpprintimportsysimporttimefromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.roi_data.loaderimportRoIDataLoaderfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--num-batches\\',dest=\\'num_batches\\',help=\\'Numberofminibatchestorun\\',default=200,type=int)parser.add_argument(\\'--sleep\\',dest=\\'sleep_time\\',help=\\'Secondssleeptoemulateanetworkrunning\\',default=0.1,type=float)parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--x-factor\\',dest=\\'x_factor\\',help=\\'simulatesx-factormoreGPUs\\',default=1,type=int)parser.add_argument(\\'--profiler\\',dest=\\'profiler\\',help=\\'profileminibatchloadtime\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefloader_loop(roi_data_loader):load_timer=Timer()iters=100foriinrange(iters):load_timer.tic()roi_data_loader.get_next_minibatch()load_timer.toc()print(\\'{:d}/{:d}:Averageget_next_minibatchtime:{:.3f}s\\'.format(i+1,iters,load_timer.average_time))defmain(opts):logger=logging.getLogger(__name__)roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)blob_names=roi_data_loader.get_output_names()net=core.Net(\\'dequeue_net\\')net.type=\\'dag\\'all_blobs=[]forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)all_blobs.append(blob)workspace.CreateBlob(blob)logger.info(\\'Creatingblob:{}\\'.format(blob))net.DequeueBlobs(roi_data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))ifopts.profiler:importcProfilecProfile.runctx(\\'loader_loop(roi_data_loader)\\',globals(),locals(),sort=\\'cumulative\\')else:loader_loop(roi_data_loader)roi_data_loader.register_sigint_handler()roi_data_loader.start(prefill=True)total_time=0foriinrange(opts.num_batches):start_t=time.time()for_inrange(opts.x_factor):workspace.RunNetOnce(net)total_time+=(time.time()-start_t)/opts.x_factorlogger.info(\\'{:d}/{:d}:Avergedequeuetime:{:.3f}s[{:d}/{:d}]\\'.format(i+1,opts.num_batches,total_time/(i+1),roi_data_loader._minibatch_queue.qsize(),cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE))#Sleeptosimulatethetimetakenbyrunningalittlenetworktime.sleep(opts.sleep_time)#Toinspect:#blobs=workspace.FetchBlobs(all_blobs)#fromIPythonimportembed;embed()logger.info(\\'Shuttingdowndataloader...\\')roi_data_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Runningwithconfig:\\')logger.info(pprint.pformat(cfg))main(args)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSpatialNarrowAsOpTest(unittest.TestCase):def_run_test(self,A,B,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'SpatialNarrowAs\\',[\\'A\\',\\'B\\'],[\\'C\\'])workspace.FeedBlob(\\'A\\',A)workspace.FeedBlob(\\'B\\',B)workspace.RunOperatorOnce(op)C=workspace.FetchBlob(\\'C\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[A,B],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')dims=C.shapeC_ref=A[:dims[0],:dims[1],:dims[2],:dims[3]]np.testing.assert_allclose(C,C_ref,rtol=1e-5,atol=1e-08)deftest_small_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,2,2).astype(np.float32)self._run_test(A,B,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,5).astype(np.float32)self._run_test(A,B,check_grad=True)deftest_large_forward(self):A=np.random.randn(2,256,42,100).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)A=np.random.randn(2,256,42,87).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)A=np.random.randn(2,255,42,88).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'SpatialNarrowAs\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimporttempfileimportunittestfromdetectron.core.configimportcfgfromdetectron.utils.collectionsimportAttrDictimportdetectron.core.configascore_configimportdetectron.utils.envasenvuimportdetectron.utils.loggingaslogging_utilsclassTestAttrDict(unittest.TestCase):deftest_immutability(self):#Toplevelimmutablea=AttrDict()a.foo=0a.immutable(True)withself.assertRaises(AttributeError):a.foo=1a.bar=1asserta.is_immutable()asserta.foo==0a.immutable(False)assertnota.is_immutable()a.foo=1asserta.foo==1#Recursivelyimmutablea.level1=AttrDict()a.level1.foo=0a.level1.level2=AttrDict()a.level1.level2.foo=0a.immutable(True)asserta.is_immutable()withself.assertRaises(AttributeError):a.level1.level2.foo=1a.level1.bar=1asserta.level1.level2.foo==0#Serializeimmutabilitystatea.immutable(True)a2=core_config.load_cfg(envu.yaml_dump(a))asserta.is_immutable()asserta2.is_immutable()classTestCfg(unittest.TestCase):deftest_copy_cfg(self):cfg2=copy.deepcopy(cfg)s=cfg.MODEL.TYPEcfg2.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_cfg(self):#Test:mergefromdeepcopys=\\'dummy0\\'cfg2=copy.deepcopy(cfg)cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergefromyamls=\\'dummy1\\'cfg2=core_config.load_cfg(envu.yaml_dump(cfg))cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithavalidkeys=\\'dummy2\\'cfg2=AttrDict()cfg2.MODEL=AttrDict()cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithaninvalidkeys=\\'dummy3\\'cfg2=AttrDict()cfg2.FOO=AttrDict()cfg2.FOO.BAR=swithself.assertRaises(KeyError):core_config.merge_cfg_from_cfg(cfg2)#Test:mergewithconvertedtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=[1]core_config.merge_cfg_from_cfg(cfg2)asserttype(cfg.TRAIN.SCALES)istupleassertcfg.TRAIN.SCALES[0]==1#Test:mergewithinvalidtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=1withself.assertRaises(ValueError):core_config.merge_cfg_from_cfg(cfg2)deftest_merge_cfg_from_file(self):withtempfile.NamedTemporaryFile()asf:envu.yaml_dump(cfg,f)s=cfg.MODEL.TYPEcfg.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE!=score_config.merge_cfg_from_file(f.name)assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_list(self):opts=[\\'TRAIN.SCALES\\',\\'(100,)\\',\\'MODEL.TYPE\\',u\\'foobar\\',\\'NUM_GPUS\\',2]assertlen(cfg.TRAIN.SCALES)>0assertcfg.TRAIN.SCALES[0]!=100assertcfg.MODEL.TYPE!=\\'foobar\\'assertcfg.NUM_GPUS!=2core_config.merge_cfg_from_list(opts)asserttype(cfg.TRAIN.SCALES)istupleassertlen(cfg.TRAIN.SCALES)==1assertcfg.TRAIN.SCALES[0]==100assertcfg.MODEL.TYPE==\\'foobar\\'assertcfg.NUM_GPUS==2deftest_deprecated_key_from_list(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"opts=[\\'FINAL_MSG\\',\\'foobar\\',\\'MODEL.DILATION\\',2]withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_list(opts)withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_deprecated_key_from_file(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.MODEL.DILATION=2envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_file(f.name)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_renamed_key_from_list(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"opts=[\\'EXAMPLE.RENAMED.KEY\\',\\'foobar\\']withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_list(opts)deftest_renamed_key_from_file(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.EXAMPLE=AttrDict()cfg2.EXAMPLE.RENAMED=AttrDict()cfg2.EXAMPLE.RENAMED.KEY=\\'foobar\\'envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_file(f.name)if__name__==\\'__main__\\':logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Primitivesforrunningmultiplesingle-GPUjobsinparalleloversubrangesofdata.Theseareusedforrunningmulti-GPUinference.SubprocessesareusedtoavoidtheGILsinceinferencemayinvolvenon-trivialamountsofPythoncode.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportnumpyasnpimportsubprocessfromsix.movesimportshlex_quotefromdetectron.core.configimportcfgfromdetectron.utils.ioimportload_objectimportdetectron.utils.envasenvuimportlogginglogger=logging.getLogger(__name__)defprocess_in_parallel(tag,total_range_size,binary,output_dir,opts=\\'\\'):\"\"\"Runthespecifiedbinarycfg.NUM_GPUStimesinparallel,eachtimeasasubprocessthatusesoneGPU.Thebinarymustacceptthecommandlinearguments`--range{start}{end}`thatspecifyadataprocessingrange.\"\"\"#Snapshotthecurrentcfgstateinordertopasstotheinference#subprocessescfg_file=os.path.join(output_dir,\\'{}_range_config.yaml\\'.format(tag))withopen(cfg_file,\\'w\\')asf:envu.yaml_dump(cfg,stream=f)subprocess_env=os.environ.copy()processes=[]subinds=np.array_split(range(total_range_size),cfg.NUM_GPUS)#DetermineGPUstousecuda_visible_devices=os.environ.get(\\'CUDA_VISIBLE_DEVICES\\')ifcuda_visible_devices:gpu_inds=map(int,cuda_visible_devices.split(\\',\\'))assert-1notingpu_inds,\\\\\\'HidingGPUindicesusingthe\\\\\\'-1\\\\\\'indexisnotsupported\\'else:gpu_inds=range(cfg.NUM_GPUS)#Runthebinaryincfg.NUM_GPUSsubprocessesfori,gpu_indinenumerate(gpu_inds):start=subinds[i][0]end=subinds[i][-1]+1subprocess_env[\\'CUDA_VISIBLE_DEVICES\\']=str(gpu_ind)cmd=\\'{binary}--range{start}{end}--cfg{cfg_file}NUM_GPUS1{opts}\\'cmd=cmd.format(binary=shlex_quote(binary),start=int(start),end=int(end),cfg_file=shlex_quote(cfg_file),opts=\\'\\'.join([shlex_quote(opt)foroptinopts]))logger.info(\\'{}rangecommand{}:{}\\'.format(tag,i,cmd))ifi==0:subprocess_stdout=subprocess.PIPEelse:filename=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))subprocess_stdout=open(filename,\\'w\\')#NOQA(closebelow)p=subprocess.Popen(cmd,shell=True,env=subprocess_env,stdout=subprocess_stdout,stderr=subprocess.STDOUT,bufsize=1)processes.append((i,p,start,end,subprocess_stdout))#Logoutputfrominferenceprocessesandcollatetheirresultsoutputs=[]fori,p,start,end,subprocess_stdoutinprocesses:log_subprocess_output(i,p,output_dir,tag,start,end)ifi>0:subprocess_stdout.close()range_file=os.path.join(output_dir,\\'%s_range_%s_%s.pkl\\'%(tag,start,end))range_data=load_object(range_file)outputs.append(range_data)returnoutputsdeflog_subprocess_output(i,p,output_dir,tag,start,end):\"\"\"Capturetheoutputofeachsubprocessandlogitintheparentprocess.Thefirstsubprocess\\'soutputisloggedinrealtime.Theoutputfromtheothersubprocessesisbufferedandthenprintedallatonce(inorder)whensubprocessesfinish.\"\"\"outfile=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')logger.info(\\'stdoutofsubprocess%swithrange[%s,%s]\\'%(i,start+1,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')ifi==0:#Streamthepipedstdoutfromthefirstsubprocessinrealtimewithopen(outfile,\\'wb\\')asf:forlineiniter(p.stdout.readline,b\\'\\'):print(line.rstrip().decode(\"utf8\"))f.write(line)p.stdout.close()ret=p.wait()else:#Forsubprocesses>=1,waitanddumptheirlogfileret=p.wait()withopen(outfile,\\'r\\')asf:print(\\'\\'.join(f.readlines()))assertret==0,\\'Rangesubprocessfailed(exitcode:{})\\'.format(ret)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforinteractingwithsegmentationmasksintheCOCOformat.Thefollowingtermsareusedinthismodulemask:abinarymaskencodedasa2Dnumpyarraysegm:asegmentationmaskinoneofthetwoCOCOformats(polygonorRLE)polygon:COCO\\'spolygonformatRLE:COCO\\'srunlengthencodingformat\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportpycocotools.maskasmask_util#Typeusedforstoringmasksinpolygonformat_POLY_TYPE=list#TypeusedforstoringmasksinRLEformat_RLE_TYPE=dictdefis_poly(segm):\"\"\"Determineifsegmisapolygon.Validsegmexpected(polygonorRLE).\"\"\"assertisinstance(segm,(_POLY_TYPE,_RLE_TYPE)),\\\\\\'Invalidsegmtype:{}\\'.format(type(segm))returnisinstance(segm,_POLY_TYPE)defflip_segms(segms,height,width):\"\"\"Left/rightflipeachmaskinalistofmasks.\"\"\"def_flip_poly(poly,width):flipped_poly=np.array(poly)flipped_poly[0::2]=width-np.array(poly[0::2])-1returnflipped_poly.tolist()def_flip_rle(rle,height,width):if\\'counts\\'inrleandtype(rle[\\'counts\\'])==list:#MagicRLEformathandlingpainfullydiscoveredbylookingatthe#COCOAPIshowAnnsfunction.rle=mask_util.frPyObjects([rle],height,width)mask=mask_util.decode(rle)mask=mask[:,::-1,:]rle=mask_util.encode(np.array(mask,order=\\'F\\',dtype=np.uint8))returnrleflipped_segms=[]forsegminsegms:ifis_poly(segm):#Polygonformatflipped_segms.append([_flip_poly(poly,width)forpolyinsegm])else:#RLEformatflipped_segms.append(_flip_rle(segm,height,width))returnflipped_segmsdefpolys_to_mask(polygons,height,width):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.Thepolygonsegmentationisunderstoodtobeenclosedinsideaheightxwidthimage.Theresultingmaskisthereforeofshape(height,width).\"\"\"rle=mask_util.frPyObjects(polygons,height,width)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefmask_to_bbox(mask):\"\"\"Computethetightboundingboxofabinarymask.\"\"\"xs=np.where(np.sum(mask,axis=0)>0)[0]ys=np.where(np.sum(mask,axis=1)>0)[0]iflen(xs)==0orlen(ys)==0:returnNonex0=xs[0]x1=xs[-1]y0=ys[0]y1=ys[-1]returnnp.array((x0,y0,x1,y1),dtype=np.float32)defpolys_to_mask_wrt_box(polygons,box,M):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.ThepolygonsegmentationisunderstoodtobeenclosedinthegivenboxandrasterizedtoanMxMmask.Theresultingmaskisthereforeofshape(M,M).\"\"\"w=box[2]-box[0]h=box[3]-box[1]w=np.maximum(w,1)h=np.maximum(h,1)polygons_norm=[]forpolyinpolygons:p=np.array(poly,dtype=np.float32)p[0::2]=(p[0::2]-box[0])*M/wp[1::2]=(p[1::2]-box[1])*M/hpolygons_norm.append(p)rle=mask_util.frPyObjects(polygons_norm,M,M)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefpolys_to_boxes(polys):\"\"\"Convertalistofpolygonsintoanarrayoftightboundingboxes.\"\"\"boxes_from_polys=np.zeros((len(polys),4),dtype=np.float32)foriinrange(len(polys)):poly=polys[i]x0=min(min(p[::2])forpinpoly)x1=max(max(p[::2])forpinpoly)y0=min(min(p[1::2])forpinpoly)y1=max(max(p[1::2])forpinpoly)boxes_from_polys[i,:]=[x0,y0,x1,y1]returnboxes_from_polysdefrle_mask_voting(top_masks,all_masks,all_dets,iou_thresh,binarize_thresh,method=\\'AVG\\'):\"\"\"Returnsnewmasks(incorrespondencewith`top_masks`)bycombiningmultipleoverlappingmaskscomingfromthepoolof`all_masks`.Twomethodsforcombiningmasksaresupported:\\'AVG\\'usesaweightedaverageofoverlappingmaskpixels;\\'UNION\\'takestheunionofallmaskpixels.\"\"\"iflen(top_masks)==0:returnall_not_crowd=[False]*len(all_masks)top_to_all_overlaps=mask_util.iou(top_masks,all_masks,all_not_crowd)decoded_all_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinall_masks]decoded_top_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleintop_masks]all_boxes=all_dets[:,:4].astype(np.int32)all_scores=all_dets[:,4]#Fillboxsupportwithweightsmask_shape=decoded_all_masks[0].shapemask_weights=np.zeros((len(all_masks),mask_shape[0],mask_shape[1]))forkinrange(len(all_masks)):ref_box=all_boxes[k]x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,mask_shape[1])y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,mask_shape[0])mask_weights[k,y_0:y_1,x_0:x_1]=all_scores[k]mask_weights=np.maximum(mask_weights,1e-5)top_segms_out=[]forkinrange(len(top_masks)):#Cornercaseofemptymaskifdecoded_top_masks[k].sum()==0:top_segms_out.append(top_masks[k])continueinds_to_vote=np.where(top_to_all_overlaps[k]>=iou_thresh)[0]#Onlymatchesitselfiflen(inds_to_vote)==1:top_segms_out.append(top_masks[k])continuemasks_to_vote=[decoded_all_masks[i]foriininds_to_vote]ifmethod==\\'AVG\\':ws=mask_weights[inds_to_vote]soft_mask=np.average(masks_to_vote,axis=0,weights=ws)mask=np.array(soft_mask>binarize_thresh,dtype=np.uint8)elifmethod==\\'UNION\\':#Anypixelthat\\'sonjoinsthemasksoft_mask=np.sum(masks_to_vote,axis=0)mask=np.array(soft_mask>1e-5,dtype=np.uint8)else:raiseNotImplementedError(\\'Method{}isunknown\\'.format(method))rle=mask_util.encode(np.array(mask[:,:,np.newaxis],order=\\'F\\'))[0]top_segms_out.append(rle)returntop_segms_outdefrle_mask_nms(masks,dets,thresh,mode=\\'IOU\\'):\"\"\"Performsgreedynon-maximumsuppressionbasedonanoverlapmeasurementbetweenmasks.Thetypeofmeasurementisdeterminedby`mode`andcanbeeither\\'IOU\\'(standardintersectionoverunion)or\\'IOMA\\'(intersectionovermininumarea).\"\"\"iflen(masks)==0:return[]iflen(masks)==1:return[0]ifmode==\\'IOU\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(union(m1,m2))all_not_crowds=[False]*len(masks)ious=mask_util.iou(masks,masks,all_not_crowds)elifmode==\\'IOMA\\':#Computesious[m1,m2]=area(intersect(m1,m2))/min(area(m1),area(m2))all_crowds=[True]*len(masks)#ious[m1,m2]=area(intersect(m1,m2))/area(m2)ious=mask_util.iou(masks,masks,all_crowds)#...=max(area(intersect(m1,m2))/area(m2),#area(intersect(m2,m1))/area(m1))ious=np.maximum(ious,ious.transpose())elifmode==\\'CONTAINMENT\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(m2)#Whichmeasureshowmuchm2iscontainedinsidem1all_crowds=[True]*len(masks)ious=mask_util.iou(masks,masks,all_crowds)else:raiseNotImplementedError(\\'Mode{}isunknown\\'.format(mode))scores=dets[:,4]order=np.argsort(-scores)keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=ious[i,order[1:]]inds_to_keep=np.where(ovr<=thresh)[0]order=order[inds_to_keep+1]returnkeepdefrle_masks_to_boxes(masks):\"\"\"ComputestheboundingboxofeachmaskinalistofRLEencodedmasks.\"\"\"iflen(masks)==0:return[]decoded_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinmasks]defget_bounds(flat_mask):inds=np.where(flat_mask>0)[0]returninds.min(),inds.max()boxes=np.zeros((len(decoded_masks),4))keep=[True]*len(decoded_masks)fori,maskinenumerate(decoded_masks):ifmask.sum()==0:keep[i]=Falsecontinueflat_mask=mask.sum(axis=0)x0,x1=get_bounds(flat_mask)flat_mask=mask.sum(axis=1)y0,y1=get_bounds(flat_mask)boxes[i,:]=(x0,y0,x1,y1)returnboxes,np.where(keep)[0]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Anawesomecolormapforreallyneatvisualizations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpdefcolormap(rgb=False):color_list=np.array([0.000,0.447,0.741,0.850,0.325,0.098,0.929,0.694,0.125,0.494,0.184,0.556,0.466,0.674,0.188,0.301,0.745,0.933,0.635,0.078,0.184,0.300,0.300,0.300,0.600,0.600,0.600,1.000,0.000,0.000,1.000,0.500,0.000,0.749,0.749,0.000,0.000,1.000,0.000,0.000,0.000,1.000,0.667,0.000,1.000,0.333,0.333,0.000,0.333,0.667,0.000,0.333,1.000,0.000,0.667,0.333,0.000,0.667,0.667,0.000,0.667,1.000,0.000,1.000,0.333,0.000,1.000,0.667,0.000,1.000,1.000,0.000,0.000,0.333,0.500,0.000,0.667,0.500,0.000,1.000,0.500,0.333,0.000,0.500,0.333,0.333,0.500,0.333,0.667,0.500,0.333,1.000,0.500,0.667,0.000,0.500,0.667,0.333,0.500,0.667,0.667,0.500,0.667,1.000,0.500,1.000,0.000,0.500,1.000,0.333,0.500,1.000,0.667,0.500,1.000,1.000,0.500,0.000,0.333,1.000,0.000,0.667,1.000,0.000,1.000,1.000,0.333,0.000,1.000,0.333,0.333,1.000,0.333,0.667,1.000,0.333,1.000,1.000,0.667,0.000,1.000,0.667,0.333,1.000,0.667,0.667,1.000,0.667,1.000,1.000,1.000,0.000,1.000,1.000,0.333,1.000,1.000,0.667,1.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.143,0.143,0.143,0.286,0.286,0.286,0.429,0.429,0.429,0.571,0.571,0.571,0.714,0.714,0.714,0.857,0.857,0.857,1.000,1.000,1.000]).astype(np.float32)color_list=color_list.reshape((-1,3))*255ifnotrgb:color_list=color_list[:,::-1]returncolor_list#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Environmenthelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportsysimportyaml#DefaultvalueoftheCMakeinstallprefix_CMAKE_INSTALL_PREFIX=\\'/usr/local\\'#Detectronopslib_DETECTRON_OPS_LIB=\\'libcaffe2_detectron_ops_gpu.so\\'defget_runtime_dir():\"\"\"Retrievethepathtotheruntimedirectory.\"\"\"returnsys.path[0]defget_py_bin_ext():\"\"\"Retrievepythonbinaryextension.\"\"\"return\\'.py\\'defset_up_matplotlib():\"\"\"Setmatplotlibup.\"\"\"importmatplotlib#Useanon-interactivebackendmatplotlib.use(\\'Agg\\')defexit_on_error():\"\"\"Exitfromadetectrontoolwhenthere\\'sanerror.\"\"\"sys.exit(1)defimport_nccl_ops():\"\"\"ImportNCCLops.\"\"\"#ThereisnoneedtoloadNCCLopssincethe#NCCLdependencyisbuiltintotheCaffe2gpulibpassdefget_detectron_ops_lib():\"\"\"RetrieveDetectronopslibrary.\"\"\"#Candidateprefixesfordetectronopslibpathprefixes=[_CMAKE_INSTALL_PREFIX,sys.prefix,sys.exec_prefix]+sys.path#Candidatesubdirsfordetectronopslibsubdirs=[\\'lib\\',\\'torch/lib\\']#Trytofinddetectronopslibforprefixinprefixes:forsubdirinsubdirs:ops_path=os.path.join(prefix,subdir,_DETECTRON_OPS_LIB)ifos.path.exists(ops_path):print(\\'FoundDetectronopslib:{}\\'.format(ops_path))returnops_pathraiseException(\\'Detectronopslibnotfound\\')defget_custom_ops_lib():\"\"\"Retrievecustomopslibrary.\"\"\"det_dir,_=os.path.split(os.path.dirname(__file__))root_dir,_=os.path.split(det_dir)custom_ops_lib=os.path.join(root_dir,\\'build/libcaffe2_detectron_custom_ops_gpu.so\\')assertos.path.exists(custom_ops_lib),\\\\\\'Customopslibnotfoundat\\\\\\'{}\\\\\\'\\'.format(custom_ops_lib)returncustom_ops_lib#YAMLload/dumpfunctionaliasesyaml_load=yaml.loadyaml_dump=yaml.dump#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectionoutputvisualizationmodule.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpimportosimportpycocotools.maskasmask_utilfromdetectron.utils.colormapimportcolormapimportdetectron.utils.envasenvuimportdetectron.utils.keypointsaskeypoint_utils#Matplotlibrequirescertainadjustmentsinsomeenvironments#Musthappenbeforeimportingmatplotlibenvu.set_up_matplotlib()importmatplotlib.pyplotaspltfrommatplotlib.patchesimportPolygonplt.rcParams[\\'pdf.fonttype\\']=42#ForeditinginAdobeIllustrator_GRAY=(218,227,218)_GREEN=(18,127,15)_WHITE=(255,255,255)defkp_connections(keypoints):kp_lines=[[keypoints.index(\\'left_eye\\'),keypoints.index(\\'right_eye\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'right_ear\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'left_ear\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'right_elbow\\')],[keypoints.index(\\'right_elbow\\'),keypoints.index(\\'right_wrist\\')],[keypoints.index(\\'left_shoulder\\'),keypoints.index(\\'left_elbow\\')],[keypoints.index(\\'left_elbow\\'),keypoints.index(\\'left_wrist\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'right_knee\\')],[keypoints.index(\\'right_knee\\'),keypoints.index(\\'right_ankle\\')],[keypoints.index(\\'left_hip\\'),keypoints.index(\\'left_knee\\')],[keypoints.index(\\'left_knee\\'),keypoints.index(\\'left_ankle\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'left_shoulder\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'left_hip\\')],]returnkp_linesdefconvert_from_cls_format(cls_boxes,cls_segms,cls_keyps):\"\"\"Convertfromtheclassboxes/segms/keypsformatgeneratedbythetestingcode.\"\"\"box_list=[bforbincls_boxesiflen(b)>0]iflen(box_list)>0:boxes=np.concatenate(box_list)else:boxes=Noneifcls_segmsisnotNone:segms=[sforslistincls_segmsforsinslist]else:segms=Noneifcls_keypsisnotNone:keyps=[kforklistincls_keypsforkinklist]else:keyps=Noneclasses=[]forjinrange(len(cls_boxes)):classes+=[j]*len(cls_boxes[j])returnboxes,segms,keyps,classesdefget_class_string(class_index,score,dataset):class_text=dataset.classes[class_index]ifdatasetisnotNoneelse\\\\\\'id{:d}\\'.format(class_index)returnclass_text+\\'{:0.2f}\\'.format(score).lstrip(\\'0\\')defvis_mask(img,mask,col,alpha=0.4,show_border=True,border_thick=1):\"\"\"Visualizesasinglebinarymask.\"\"\"img=img.astype(np.float32)idx=np.nonzero(mask)img[idx[0],idx[1],:]*=1.0-alphaimg[idx[0],idx[1],:]+=alpha*colifshow_border:contours=cv2.findContours(mask.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]cv2.drawContours(img,contours,-1,_WHITE,border_thick,cv2.LINE_AA)returnimg.astype(np.uint8)defvis_class(img,pos,class_str,font_scale=0.35):\"\"\"Visualizestheclass.\"\"\"img=img.astype(np.uint8)x0,y0=int(pos[0]),int(pos[1])#Computetextsize.txt=class_strfont=cv2.FONT_HERSHEY_SIMPLEX((txt_w,txt_h),_)=cv2.getTextSize(txt,font,font_scale,1)#Placetextbackground.back_tl=x0,y0-int(1.3*txt_h)back_br=x0+txt_w,y0cv2.rectangle(img,back_tl,back_br,_GREEN,-1)#Showtext.txt_tl=x0,y0-int(0.3*txt_h)cv2.putText(img,txt,txt_tl,font,font_scale,_GRAY,lineType=cv2.LINE_AA)returnimgdefvis_bbox(img,bbox,thick=1):\"\"\"Visualizesaboundingbox.\"\"\"img=img.astype(np.uint8)(x0,y0,w,h)=bboxx1,y1=int(x0+w),int(y0+h)x0,y0=int(x0),int(y0)cv2.rectangle(img,(x0,y0),(x1,y1),_GREEN,thickness=thick)returnimgdefvis_keypoints(img,kps,kp_thresh=2,alpha=0.7):\"\"\"Visualizeskeypoints(adaptedfromvis_one_image).kpshasshape(4,#keypoints)where4rowsare(x,y,logit,prob).\"\"\"dataset_keypoints,_=keypoint_utils.get_keypoints()kp_lines=kp_connections(dataset_keypoints)#Convertfromplt0-1RGBAcolorsto0-255BGRcolorsforopencv.cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]colors=[(c[2]*255,c[1]*255,c[0]*255)forcincolors]#Performthedrawingonacopyoftheimage,toallowforblending.kp_mask=np.copy(img)#Drawmidshoulder/midhipfirstforbettervisualization.mid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])nose_idx=dataset_keypoints.index(\\'nose\\')ifsc_mid_shoulder>kp_threshandkps[2,nose_idx]>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(kps[:2,nose_idx]),color=colors[len(kp_lines)],thickness=2,lineType=cv2.LINE_AA)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(mid_hip),color=colors[len(kp_lines)+1],thickness=2,lineType=cv2.LINE_AA)#Drawthekeypoints.forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]p1=kps[0,i1],kps[1,i1]p2=kps[0,i2],kps[1,i2]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:cv2.line(kp_mask,p1,p2,color=colors[l],thickness=2,lineType=cv2.LINE_AA)ifkps[2,i1]>kp_thresh:cv2.circle(kp_mask,p1,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)ifkps[2,i2]>kp_thresh:cv2.circle(kp_mask,p2,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)#Blendthekeypoints.returncv2.addWeighted(img,1.0-alpha,kp_mask,alpha,0)defvis_one_image_opencv(im,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,show_box=False,dataset=None,show_class=False):\"\"\"Constructsanumpyarraywiththedetectionsvisualized.\"\"\"ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)ifboxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh:returnimifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap()mask_color_id=0#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ifshow_box:im=vis_bbox(im,(bbox[0],bbox[1],bbox[2]-bbox[0],bbox[3]-bbox[1]))#showclass(offbydefault)ifshow_class:class_str=get_class_string(classes[i],score,dataset)im=vis_class(im,(bbox[0],bbox[1]-2),class_str)#showmaskifsegmsisnotNoneandlen(segms)>i:color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1im=vis_mask(im,masks[...,i],color_mask)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:im=vis_keypoints(im,keypoints[i],kp_thresh)returnimdefvis_one_image(im,im_name,output_dir,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,dpi=200,box_alpha=0.0,dataset=None,show_class=False,ext=\\'pdf\\',out_when_no_box=False):\"\"\"Visualdebuggingofdetections.\"\"\"ifnotos.path.exists(output_dir):os.makedirs(output_dir)ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)if(boxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh)andnotout_when_no_box:returndataset_keypoints,_=keypoint_utils.get_keypoints()ifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap(rgb=True)/255kp_lines=kp_connections(dataset_keypoints)cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]fig=plt.figure(frameon=False)fig.set_size_inches(im.shape[1]/dpi,im.shape[0]/dpi)ax=plt.Axes(fig,[0.,0.,1.,1.])ax.axis(\\'off\\')fig.add_axes(ax)ax.imshow(im)ifboxesisNone:sorted_inds=[]#avoidcrashwhen\\'boxes\\'isNoneelse:#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)mask_color_id=0foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ax.add_patch(plt.Rectangle((bbox[0],bbox[1]),bbox[2]-bbox[0],bbox[3]-bbox[1],fill=False,edgecolor=\\'g\\',linewidth=0.5,alpha=box_alpha))ifshow_class:ax.text(bbox[0],bbox[1]-2,get_class_string(classes[i],score,dataset),fontsize=3,family=\\'serif\\',bbox=dict(facecolor=\\'g\\',alpha=0.4,pad=0,edgecolor=\\'none\\'),color=\\'white\\')#showmaskifsegmsisnotNoneandlen(segms)>i:img=np.ones(im.shape)color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1w_ratio=.4forcinrange(3):color_mask[c]=color_mask[c]*(1-w_ratio)+w_ratioforcinrange(3):img[:,:,c]=color_mask[c]e=masks[:,:,i]contour=cv2.findContours(e.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]forcincontour:polygon=Polygon(c.reshape((-1,2)),fill=True,facecolor=color_mask,edgecolor=\\'w\\',linewidth=1.2,alpha=0.5)ax.add_patch(polygon)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:kps=keypoints[i]plt.autoscale(False)forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:x=[kps[0,i1],kps[0,i2]]y=[kps[1,i1],kps[1,i2]]line=plt.plot(x,y)plt.setp(line,color=colors[l],linewidth=1.0,alpha=0.7)ifkps[2,i1]>kp_thresh:plt.plot(kps[0,i1],kps[1,i1],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)ifkps[2,i2]>kp_thresh:plt.plot(kps[0,i2],kps[1,i2],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)#addmidshoulder/midhipforbettervisualizationmid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])if(sc_mid_shoulder>kp_threshandkps[2,dataset_keypoints.index(\\'nose\\')]>kp_thresh):x=[mid_shoulder[0],kps[0,dataset_keypoints.index(\\'nose\\')]]y=[mid_shoulder[1],kps[1,dataset_keypoints.index(\\'nose\\')]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)],linewidth=1.0,alpha=0.7)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:x=[mid_shoulder[0],mid_hip[0]]y=[mid_shoulder[1],mid_hip[1]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)+1],linewidth=1.0,alpha=0.7)output_name=os.path.basename(im_name)+\\'.\\'+extfig.savefig(os.path.join(output_dir,\\'{}\\'.format(output_name)),dpi=dpi)plt.close(\\'all\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelpfulutilitiesforworkingwithCaffe2.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromsiximportstring_typesimportcontextlibimportsubprocessfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportdyndepfromcaffe2.pythonimportscopefromcaffe2.pythonimportworkspaceimportdetectron.utils.envasenvudefimport_contrib_ops():\"\"\"ImportcontribopsneededbyDetectron.\"\"\"envu.import_nccl_ops()defimport_detectron_ops():\"\"\"ImportDetectronops.\"\"\"detectron_ops_lib=envu.get_detectron_ops_lib()dyndep.InitOpsLibrary(detectron_ops_lib)defimport_custom_ops():\"\"\"Importcustomops.\"\"\"custom_ops_lib=envu.get_custom_ops_lib()dyndep.InitOpsLibrary(custom_ops_lib)defSuffixNet(name,net,prefix_len,outputs):\"\"\"ReturnsanewNetfromthegivenNet(`net`)thatincludesonlytheopsafterremovingthefirst`prefix_len`numberofops.ThenewNetisthusasuffixof`net`.Blobslistedin`outputs`areregisteredasexternaloutputblobs.\"\"\"outputs=BlobReferenceList(outputs)foroutputinoutputs:assertnet.BlobIsDefined(output)new_net=net.Clone(name)delnew_net.Proto().op[:]delnew_net.Proto().external_input[:]delnew_net.Proto().external_output[:]#Addsuffixopsnew_net.Proto().op.extend(net.Proto().op[prefix_len:])#Addexternalinputblobs#Treatanyundefinedblobsasexternalinputsinput_names=[iforopinnew_net.Proto().opforiinop.inputifnotnew_net.BlobIsDefined(i)]new_net.Proto().external_input.extend(input_names)#Addexternaloutputblobsoutput_names=[str(o)foroinoutputs]new_net.Proto().external_output.extend(output_names)returnnew_net,[new_net.GetBlobRef(o)foroinoutput_names]defBlobReferenceList(blob_ref_or_list):\"\"\"EnsurethattheargumentisreturnedasalistofBlobReferences.\"\"\"ifisinstance(blob_ref_or_list,core.BlobReference):return[blob_ref_or_list]eliftype(blob_ref_or_list)in(list,tuple):forbinblob_ref_or_list:assertisinstance(b,core.BlobReference)returnblob_ref_or_listelse:raiseTypeError(\\'blob_ref_or_listmustbeaBlobReferenceoralist/tupleof\\'\\'BlobReferences\\')defUnscopeName(possibly_scoped_name):\"\"\"Removeanynamescopingfroma(possibly)scopedname.Forexample,convertthename\\'gpu_0/foo\\'to\\'foo\\'.\"\"\"assertisinstance(possibly_scoped_name,string_types)returnpossibly_scoped_name[possibly_scoped_name.rfind(scope._NAMESCOPE_SEPARATOR)+1:]@contextlib.contextmanagerdefNamedCudaScope(gpu_id):\"\"\"CreatesaGPUnamescopeandCUDAdevicescope.Thisfunctionisprovidedtoreduce`with...`nestinglevels.\"\"\"withGpuNameScope(gpu_id):withCudaScope(gpu_id):yield@contextlib.contextmanagerdefGpuNameScope(gpu_id):\"\"\"CreateanamescopeforGPUdevice`gpu_id`.\"\"\"withcore.NameScope(\\'gpu_{:d}\\'.format(gpu_id)):yield@contextlib.contextmanagerdefCudaScope(gpu_id):\"\"\"CreateaCUDAdevicescopeforGPUdevice`gpu_id`.\"\"\"gpu_dev=CudaDevice(gpu_id)withcore.DeviceScope(gpu_dev):yield@contextlib.contextmanagerdefCpuScope():\"\"\"CreateaCPUdevicescope.\"\"\"cpu_dev=core.DeviceOption(caffe2_pb2.CPU)withcore.DeviceScope(cpu_dev):yielddefCudaDevice(gpu_id):\"\"\"CreateaCudadevice.\"\"\"returncore.DeviceOption(caffe2_pb2.CUDA,gpu_id)defgauss_fill(std):\"\"\"Gaussianfillhelpertoreduceverbosity.\"\"\"return(\\'GaussianFill\\',{\\'std\\':std})defconst_fill(value):\"\"\"Constantfillhelpertoreduceverbosity.\"\"\"return(\\'ConstantFill\\',{\\'value\\':value})defget_nvidia_info():return(get_nvidia_smi_output(),workspace.GetCUDAVersion(),workspace.GetCuDNNVersion(),)defget_nvidia_smi_output():try:info=subprocess.check_output([\"nvidia-smi\"],stderr=subprocess.STDOUT)info=info.decode(\"utf8\")exceptExceptionase:info=\"Executingnvidia-smifailed:\"+str(e)returninfo.strip()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelperfunctionsforworkingwithCaffe2networks(i.e.,operatorgraphs).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportosimportpprintfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvulogger=logging.getLogger(__name__)logger.setLevel(logging.INFO)definitialize_from_weights_file(model,weights_file,broadcast=True):\"\"\"Initializeamodelfromweightsstoredinapickleddictionary.IfmultipleGPUsareused,theloadedweightsaresynchronizedonallGPUs,unless\\'broadcast\\'isFalse.\"\"\"initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)ifbroadcast:broadcast_parameters(model)definitialize_gpu_from_weights_file(model,weights_file,gpu_id=0):\"\"\"InitializeanetworkwithopsonaspecificGPU.IfyouuseCUDA_VISIBLE_DEVICEStotargetspecificGPUs,Caffe2willautomaticallymaplogicalGPUids(startingfrom0)tothephysicalGPUsspecifiedinCUDA_VISIBLE_DEVICES.\"\"\"logger.info(\\'Loadingweightsfrom:{}\\'.format(weights_file))ws_blobs=workspace.Blobs()src_blobs=load_object(weights_file)if\\'cfg\\'insrc_blobs:saved_cfg=load_cfg(src_blobs[\\'cfg\\'])configure_bbox_reg_weights(model,saved_cfg)if\\'blobs\\'insrc_blobs:#Backwardscompat--dictionaryusedtobeonlyblobs,nowtheyare#storedunderthe\\'blobs\\'keysrc_blobs=src_blobs[\\'blobs\\']#InitializeweightsonGPUgpu_idonlyunscoped_param_names=OrderedDict()#Printtheseoutinmodelorderforblobinmodel.params:unscoped_param_names[c2_utils.UnscopeName(str(blob))]=Truewithc2_utils.NamedCudaScope(gpu_id):forunscoped_param_nameinunscoped_param_names.keys():if(unscoped_param_name.find(\\']_\\')>=0andunscoped_param_namenotinsrc_blobs):#Specialcaseforsharinginitializationfromapretrained#model:#Ifablobnamed\\'_[xyz]_foo\\'isinmodel.paramsandnotin#theinitializationblobdictionary,thenloadsourceblob#\\'foo\\'intodestinationblob\\'_[xyz]_foo\\'src_name=unscoped_param_name[unscoped_param_name.find(\\']_\\')+2:]else:src_name=unscoped_param_nameifsrc_namenotinsrc_blobs:logger.info(\\'{:s}notfound\\'.format(src_name))continuedst_name=core.ScopedName(unscoped_param_name)has_momentum=src_name+\\'_momentum\\'insrc_blobshas_momentum_str=\\'[+momentum]\\'ifhas_momentumelse\\'\\'logger.info(\\'{:s}{:}loadedfromweightsfileinto{:s}:{}\\'.format(src_name,has_momentum_str,dst_name,src_blobs[src_name].shape))ifdst_nameinws_blobs:#Iftheblobisalreadyintheworkspace,makesurethatit#matchestheshapeoftheloadedblobws_blob=workspace.FetchBlob(dst_name)assertws_blob.shape==src_blobs[src_name].shape,\\\\(\\'Workspaceblob{}withshape{}doesnotmatch\\'\\'weightsfileshape{}\\').format(src_name,ws_blob.shape,src_blobs[src_name].shape)workspace.FeedBlob(dst_name,src_blobs[src_name].astype(np.float32,copy=False))ifhas_momentum:workspace.FeedBlob(dst_name+\\'_momentum\\',src_blobs[src_name+\\'_momentum\\'].astype(np.float32,copy=False))#Wepreserveblobsthatareintheweightsfilebutnotusedbythecurrent#model.WeloadtheseintoCPUmemoryunderthe\\'__preserve__/\\'namescope.#Theseblobswillbestoredwhensavingamodeltoaweightsfile.This#featureallowsforalternatingoptimizationofFasterR-CNNinwhichblobs#unusedbyonestepcanstillbepreservedforwardandusedtoinitialize#anotherstep.forsrc_nameinsrc_blobs.keys():if(src_namenotinunscoped_param_namesandnotsrc_name.endswith(\\'_momentum\\')andsrc_blobs[src_name]isnotNone):withc2_utils.CpuScope():workspace.FeedBlob(\\'__preserve__/{:s}\\'.format(src_name),src_blobs[src_name])logger.info(\\'{:s}preservedinworkspace(unused)\\'.format(src_name))defsave_model_to_weights_file(weights_file,model):\"\"\"Stashmodelweightsinadictionaryandpicklethemtoafile.WemapGPUdevicescopednamestounscopednames(e.g.,\\'gpu_0/conv1_w\\'->\\'conv1_w\\').\"\"\"logger.info(\\'Savingparametersandmomentumto{}\\'.format(os.path.abspath(weights_file)))blobs={}#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savemomentumforparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savepreservedblobsforscoped_nameinworkspace.Blobs():ifscoped_name.startswith(\\'__preserve__/\\'):unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}(preserved)\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)cfg_yaml=envu.yaml_dump(cfg)save_object(dict(blobs=blobs,cfg=cfg_yaml),weights_file)defbroadcast_parameters(model):\"\"\"CopyparameterblobsfromGPU0overthecorrespondingparameterblobsonGPUs1throughcfg.NUM_GPUS-1.\"\"\"ifcfg.NUM_GPUS==1:#no-opifonlyrunningonasingleGPUreturndef_do_broadcast(all_blobs):assertlen(all_blobs)%cfg.NUM_GPUS==0,\\\\(\\'UnexpectedvalueforNUM_GPUS.Makesureyouarenot\\'\\'runningsingle-GPUinferencewithNUM_GPUS>1.\\')blobs_per_gpu=int(len(all_blobs)/cfg.NUM_GPUS)foriinrange(blobs_per_gpu):blobs=[pforpinall_blobs[i::blobs_per_gpu]]data=workspace.FetchBlob(blobs[0])logger.debug(\\'Broadcasting{}to\\'.format(str(blobs[0])))fori,pinenumerate(blobs[1:]):logger.debug(\\'|->{}\\'.format(str(p)))withc2_utils.CudaScope(i+1):workspace.FeedBlob(p,data)_do_broadcast(model.params)_do_broadcast([b+\\'_momentum\\'forbinmodel.TrainableParams()])defsum_multi_gpu_blob(blob_name):\"\"\"ReturnthesumofascalarblobheldonmultipleGPUs.\"\"\"val=0foriinrange(cfg.NUM_GPUS):val+=float(workspace.FetchBlob(\\'gpu_{}/{}\\'.format(i,blob_name)))returnvaldefaverage_multi_gpu_blob(blob_name):\"\"\"ReturntheaverageofascalarblobheldonmultipleGPUs.\"\"\"returnsum_multi_gpu_blob(blob_name)/cfg.NUM_GPUSdefprint_net(model,namescope=\\'gpu_0\\'):\"\"\"Printthemodelnetwork.\"\"\"logger.info(\\'Printingmodel:{}\\'.format(model.net.Name()))op_list=model.net.Proto().opforopinop_list:input_name=op.input#Forsimplicity:onlyprintthefirstoutput#Notrecommendediftherearesplitlayersoutput_name=str(op.output[0])op_type=op.typeop_name=op.nameifnamescopeisNoneoroutput_name.startswith(namescope):#Onlyprinttheforwardpassnetworkifoutput_name.find(\\'grad\\')>=0oroutput_name.find(\\'__m\\')>=0:continuetry:#Undersomeconditions(e.g.,dynamicmemoryoptimization)#itispossiblethatthenetworkfreessomeblobswhentheyare#nolongerneeded.Handlethiscase...output_shape=workspace.FetchBlob(output_name).shapeexceptBaseException:output_shape=\\'\\'first_blob=Trueop_label=op_type+(op_nameifop_name==\\'\\'else\\':\\'+op_name)suffix=\\'-------(op:{})\\'.format(op_label)forjinrange(len(input_name)):ifinput_name[j]inmodel.params:continueinput_blob=workspace.FetchBlob(input_name[j])ifisinstance(input_blob,np.ndarray):input_shape=input_blob.shapelogger.info(\\'{:28s}:{:20s}=>{:28s}:{:20s}{}\\'.format(c2_utils.UnscopeName(str(input_name[j])),\\'{}\\'.format(input_shape),c2_utils.UnscopeName(str(output_name)),\\'{}\\'.format(output_shape),suffix))iffirst_blob:first_blob=Falsesuffix=\\'------|\\'logger.info(\\'Endofmodel:{}\\'.format(model.net.Name()))defconfigure_bbox_reg_weights(model,saved_cfg):\"\"\"Compatibilityforoldmodelstrainedwithboundingboxregressionmean/stdnormalization(insteadoffixedweights).\"\"\"if\\'MODEL\\'notinsaved_cfgor\\'BBOX_REG_WEIGHTS\\'notinsaved_cfg.MODEL:logger.warning(\\'Modelfromweightsfilewastrainedbeforeconfigkey\\'\\'MODEL.BBOX_REG_WEIGHTSwasadded.Forcing\\'\\'MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)toensure\\'\\'correct**inference**behavior.\\')#Generallywedon\\'tallowmodifyingtheconfig,butthisisaone-off#hacktosupportsomeveryoldmodelsis_immutable=cfg.is_immutable()cfg.immutable(False)cfg.MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)cfg.immutable(is_immutable)logger.info(\\'Newconfig:\\')logger.info(pprint.pformat(cfg))assertnotmodel.train,(\\'Thismodelwastrainedwithanolderversionofthecodethat\\'\\'usedboundingboxregressionmean/stdnormalization.Itcanno\\'\\'longerbeusedfortraining.Toupgradeittoatrainablemodel\\'\\'pleaseusefb/compat/convert_bbox_reg_normalized_model.py.\\')defget_group_gn(dim):\"\"\"getnumberofgroupsusedbyGroupNorm,basedonnumberofchannels\"\"\"dim_per_gp=cfg.GROUP_NORM.DIM_PER_GPnum_groups=cfg.GROUP_NORM.NUM_GROUPSassertdim_per_gp==-1ornum_groups==-1,\\\\\"GroupNorm:canonlyspecifyGorC/G.\"ifdim_per_gp>0:assertdim%dim_per_gp==0group_gn=dim//dim_per_gpelse:assertdim%num_groups==0group_gn=num_groupsreturngroup_gn#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesfortraining.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportdatetimeimportnumpyasnpfromcaffe2.pythonimportutilsasc2_py_utilsfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportlog_json_statsfromdetectron.utils.loggingimportSmoothedValuefromdetectron.utils.timerimportTimerimportdetectron.utils.netasnuclassTrainingStats:\"\"\"Trackvitaltrainingstatistics.\"\"\"def__init__(self,model):#Windowsizeforsmoothingtrackedvalues(withmedianfiltering)self.WIN_SZ=20#OutputloggingperiodinSGDiterationsself.LOG_PERIOD=20self.smoothed_losses_and_metrics={key:SmoothedValue(self.WIN_SZ)forkeyinmodel.losses+model.metrics}self.losses_and_metrics={key:0forkeyinmodel.losses+model.metrics}self.smoothed_total_loss=SmoothedValue(self.WIN_SZ)self.smoothed_mb_qsize=SmoothedValue(self.WIN_SZ)self.iter_total_loss=np.nanself.iter_timer=Timer()self.model=modeldefIterTic(self):self.iter_timer.tic()defIterToc(self):returnself.iter_timer.toc(average=False)defResetIterTimer(self):self.iter_timer.reset()defUpdateIterStats(self):\"\"\"Updatetrackediterationstatistics.\"\"\"forkinself.losses_and_metrics.keys():ifkinself.model.losses:self.losses_and_metrics[k]=nu.sum_multi_gpu_blob(k)else:self.losses_and_metrics[k]=nu.average_multi_gpu_blob(k)fork,vinself.smoothed_losses_and_metrics.items():v.AddValue(self.losses_and_metrics[k])self.iter_total_loss=np.sum(np.array([self.losses_and_metrics[k]forkinself.model.losses]))self.smoothed_total_loss.AddValue(self.iter_total_loss)self.smoothed_mb_qsize.AddValue(self.model.roi_data_loader._minibatch_queue.qsize())defLogIterStats(self,cur_iter,lr):\"\"\"Logthetrackedstatistics.\"\"\"if(cur_iter%self.LOG_PERIOD==0orcur_iter==cfg.SOLVER.MAX_ITER-1):stats=self.GetStats(cur_iter,lr)log_json_stats(stats)defGetStats(self,cur_iter,lr):eta_seconds=self.iter_timer.average_time*(cfg.SOLVER.MAX_ITER-cur_iter)eta=str(datetime.timedelta(seconds=int(eta_seconds)))mem_stats=c2_py_utils.GetGPUMemoryUsageStats()mem_usage=np.max(mem_stats[\\'max_by_gpu\\'][:cfg.NUM_GPUS])stats=dict(iter=cur_iter,lr=float(lr),time=self.iter_timer.average_time,loss=self.smoothed_total_loss.GetMedianValue(),eta=eta,mb_qsize=int(np.round(self.smoothed_mb_qsize.GetMedianValue())),mem=int(np.ceil(mem_usage/1024/1024)))fork,vinself.smoothed_losses_and_metrics.items():stats[k]=v.GetMedianValue()returnstats#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\\'\\'\\'Helperfunctionsformodelconversiontopb\\'\\'\\'from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromfunctoolsimportwrapsimportcopyimportnumpyasnpfromcaffe2.pythonimportcore,workspacefromcaffe2.protoimportcaffe2_pb2classOpFilter:def__init__(self,**kwargs):self.type=Noneself.type_in=Noneself.inputs=Noneself.outputs=Noneself.input_has=Noneself.output_has=Noneself.cond=Noneself.reverse=Falseassertall([xinself.__dict__forxinkwargs])self.__dict__.update(kwargs)defcheck(self,op):ret=self.reverseifself.typeandop.type!=self.type:returnretifself.type_inandop.typenotinself.type_in:returnretifself.inputsandset(op.input)!=set(self.inputs):returnretifself.outputsandset(op.output)!=set(self.outputs):returnretifself.input_hasandself.input_hasnotinop.input:returnretifself.output_hasandself.output_hasnotinop.output:returnretifself.condisnotNoneandnotself.cond:returnretreturnnotretdeffilter_op(op,**kwargs):\\'\\'\\'Returnstrueifpassedallchecks\\'\\'\\'returnOpFilter(**kwargs).check(op)defop_filter(**filter_args):\\'\\'\\'ReturnsNoneifnoconditionissatisfied\\'\\'\\'defactual_decorator(f):@wraps(f)defwrapper(op,**params):ifnotfilter_op(op,**filter_args):returnNonereturnf(op,**params)returnwrapperreturnactual_decoratordefop_func_chain(convert_func_list):\\'\\'\\'RunfuncsonebyoneuntilfuncreturnisnotNone\\'\\'\\'assertisinstance(convert_func_list,list)def_chain(op):forxinconvert_func_list:ret=x(op)ifretisnotNone:returnretreturnNonereturn_chaindefconvert_op_in_ops(ops_ref,func_or_list):func=func_or_listifisinstance(func_or_list,list):func=op_func_chain(func_or_list)ops=[opforopinops_ref]converted_ops=[]foropinops:new_ops=func(op)ifnew_opsisnotNoneandnotisinstance(new_ops,list):new_ops=[new_ops]converted_ops.extend(new_opsifnew_opsisnotNoneelse[op])delops_ref[:]#ops_refmaybeoftypeRepeatedCompositeFieldContainer#whichdoesnothaveappend()ops_ref.extend(converted_ops)defconvert_op_in_proto(proto,func_or_list):convert_op_in_ops(proto.op,func_or_list)defget_op_arg(op,arg_name):forxinop.arg:ifx.name==arg_name:returnxreturnNonedefget_op_arg_valf(op,arg_name,default_val):arg=get_op_arg(op,arg_name)returnarg.fifargisnotNoneelsedefault_valdefupdate_mobile_engines(net):foropinnet.op:ifop.type==\"Conv\":op.engine=\"NNPACK\"ifop.type==\"ConvTranspose\":op.engine=\"BLOCK\"defpairwise(iterable):\"s->(s0,s1),(s1,s2),(s2,s3),...\"fromitertoolsimportteea,b=tee(iterable)next(b,None)returnzip(a,b)defblob_uses(net,blob):u=[]fori,opinenumerate(net.op):ifblobinop.inputorblobinop.control_input:u.append(i)returnudeffuse_first_affine(net,params,removed_tensors):net=copy.deepcopy(net)params=copy.deepcopy(params)for((i,current),(j,next_))inpairwise(enumerate(net.op)):ifnext_.input[0]!=current.output[0]:continueifcurrent.typenotin(\"Conv\",\"ConvTranspose\")\\\\ornext_.type!=\"AffineChannel\":continueifcurrent.output[0]!=next_.output[0]and\\\\len(blob_uses(net,current.output[0]))!=1:#Can\\'tfuseifmorethanoneuserunlessAffineChannelisinplacecontinue#else,canfuseconv=currentaffine=next_fused_conv=copy.deepcopy(conv)fused_conv.output[0]=affine.output[0]conv_weight=params[conv.input[1]]conv_has_bias=len(conv.input)>2conv_bias=params[conv.input[2]]ifconv_has_biaselse0A=params[affine.input[1]]B=params[affine.input[2]]#Thus,canjusthavetheaffinetransform#X*A+B#where#A=bn_scale*1.0/(sqrt(running_var+eps))#B=(bias-running_mean*(1.0/sqrt(running_var+eps))#*bn_scale)#Thisidentifyshouldholdifwehavecorrectlyfused#np.testing.assert_array_equal(#params[conv.output[0]]*A+B,#params[bn.output[0]])#Now,wehavethatthecomputationmadeisthefollowing:#((X`conv`W)+b)*A+B#Then,wecansimplyfusethisasfollows:#(X`conv`(W*A))+b*A+B#whichissimply#(X`conv`Q)+C#where#Q=W*A#C=b*A+B#ForConvTranspose,fromtheviewofconvolutionsasa#Toepelizmultiplication,wehaveW_=W^T,sotheweights#arelaidoutas(R,S,K,K)(vs(S,R,K,K)foraConv),#sotheweightsbroadcastslightlydifferently.Remember,our#BNscale\\'B\\'isofsize(S,)A_=A.reshape(-1,1,1,1)ifconv.type==\"Conv\"else\\\\A.reshape(1,-1,1,1)C=conv_bias*A+BQ=conv_weight*A_assertparams[conv.input[1]].shape==Q.shapeparams[conv.input[1]]=Qifconv_has_bias:assertparams[conv.input[2]].shape==C.shapeparams[conv.input[2]]=Celse:#makeaf_biastobebiasoftheconvlayerfused_conv.input.append(affine.input[2])params[affine.input[2]]=Bnew_ops=net.op[:i]+[fused_conv]+net.op[j+1:]delnet.op[:]ifconv_has_bias:delparams[affine.input[2]]removed_tensors.append(affine.input[2])removed_tensors.append(affine.input[1])delparams[affine.input[1]]net.op.extend(new_ops)breakreturnnet,params,removed_tensorsdeffuse_affine(net,params,ignore_failure):#Rununtilwehitafixedpointremoved_tensors=[]whileTrue:(next_net,next_params,removed_tensors)=\\\\fuse_first_affine(net,params,removed_tensors)iflen(next_net.op)==len(net.op):if(any(op.type==\"AffineChannel\"foropinnext_net.op)andnotignore_failure):raiseException(\"ModelcontainsAffineChannelopafterfusion:%s\",next_net)return(next_net,next_params,removed_tensors)net,params,removed_tensors=(next_net,next_params,removed_tensors)deffuse_net(fuse_func,net,blobs,ignore_failure=False):is_core_net=isinstance(net,core.Net)ifis_core_net:net=net.Proto()net,params,removed_tensors=fuse_func(net,blobs,ignore_failure)forrtinremoved_tensors:net.external_input.remove(rt)ifis_core_net:net=core.Net(net)returnnet,paramsdeffuse_net_affine(net,blobs):returnfuse_net(fuse_affine,net,blobs)defadd_tensor(net,name,blob):\\'\\'\\'Createanoperatortostorethetensor\\'blob\\',runtheoperatortoputtheblobtoworkspace.uint8isstoredasanarrayofstringwithoneelement.\\'\\'\\'kTypeNameMapper={np.dtype(\\'float32\\'):\"GivenTensorFill\",np.dtype(\\'int32\\'):\"GivenTensorIntFill\",np.dtype(\\'int64\\'):\"GivenTensorInt64Fill\",np.dtype(\\'uint8\\'):\"GivenTensorStringFill\",}shape=blob.shapevalues=blob#passarrayofuint8asastringtosavestorage#storinguint8_thasalargeoverheadfornowifblob.dtype==np.dtype(\\'uint8\\'):shape=[1]values=[str(blob.data)]op=core.CreateOperator(kTypeNameMapper[blob.dtype],[],[name],shape=shape,values=values,#arg=[#putils.MakeArgument(\"shape\",shape),#putils.MakeArgument(\"values\",values),#])net.op.extend([op])defgen_init_net_from_blobs(blobs,blobs_to_use=None,excluded_blobs=None):\\'\\'\\'Generateaninitializationnetbasedonablobdict\\'\\'\\'ret=caffe2_pb2.NetDef()ifblobs_to_useisNone:blobs_to_use={xforxinblobs}else:blobs_to_use=copy.deepcopy(blobs_to_use)ifexcluded_blobsisnotNone:blobs_to_use=[xforxinblobs_to_useifxnotinexcluded_blobs]fornameinblobs_to_use:blob=blobs[name]ifisinstance(blob,str):print(\\'Blob{}withtype{}isnots',\n",
       " 'upportedingeneratinginitnet,\\'\\'skipped.\\'.format(name,type(blob)))continueadd_tensor(ret,name,blob)returnretdefget_ws_blobs(blob_names=None):\\'\\'\\'Getblobsin\\'blob_names\\'inthedefaultworkspace,getallblobsifblob_namesisNone\\'\\'\\'blobs={}ifblob_namesisNone:blob_names=workspace.Blobs()blobs={x:workspace.FetchBlob(x)forxinblob_names}returnblobsdefget_device_option_cpu():device_option=core.DeviceOption(caffe2_pb2.CPU)returndevice_optiondefget_device_option_cuda(gpu_id=0):device_option=caffe2_pb2.DeviceOption()device_option.device_type=caffe2_pb2.CUDAdevice_option.device_id=gpu_idreturndevice_optiondefcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)defcompare_model(model1_func,model2_func,test_image,check_blobs):\\'\\'\\'model_func(test_image,check_blobs)\\'\\'\\'cb1,cb2=check_blobs,check_blobsifisinstance(check_blobs,dict):cb1=check_blobs.keys()cb2=check_blobs.values()print(\\'Runningthefirstmodel...\\')res1=model1_func(test_image,check_blobs)print(\\'Runningthesecondmodel...\\')res2=model2_func(test_image,check_blobs)foridxinrange(len(cb1)):print(\\'Checking{}->{}...\\'.format(cb1[idx],cb2[idx]))n1,n2=cb1[idx],cb2[idx]r1=res1[n1]ifn1inres1elseNoner2=res2[n2]ifn2inres2elseNoneassertr1isnotNoneorr2isNone,\\\\\"Blob{}inmodel1isNone\".format(n1)assertr2isnotNoneorr1isNone,\\\\\"Blob{}inmodel2isNone\".format(n2)assertr1.shape==r2.shape,\\\\\"Blob{}and{}shapemismatched:{}vs{}\".format(n1,n2,r1.shape,r2.shape)np.testing.assert_array_almost_equal(r1,r2,decimal=3,err_msg=\\'{}and{}notmatched.Maxdiff:{}\\'.format(n1,n2,np.amax(np.absolute(r1-r2))))returnTrue#graph_namecouldnotcontainword\\'graph\\'defsave_graph(net,file_name,graph_name=\"net\",op_only=True):fromcaffe2.pythonimportnet_drawergraph=Noneops=net.opifnotop_only:graph=net_drawer.GetPydotGraph(ops,graph_name,rankdir=\"TB\")else:graph=net_drawer.GetPydotGraphMinimal(ops,graph_name,rankdir=\"TB\",minimal_dependency=True)try:graph.write_png(file_name)exceptExceptionase:print(\\'Errorwhenwritinggraphtoimage{}\\'.format(e))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Caffe2blobhelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromsix.movesimportcPickleaspicklefromcaffe2.protoimportcaffe2_pb2fromdetectron.core.configimportcfgdefget_image_blob(im,target_scale,target_max_size):\"\"\"Convertanimageintoanetworkinput.Arguments:im(ndarray):acolorimageinBGRorderReturns:blob(ndarray):adatablobholdinganimagepyramidim_scale(float):imagescale(targetsize)/(originalsize)im_info(ndarray)\"\"\"processed_im,im_scale=prep_im_for_blob(im,cfg.PIXEL_MEANS,target_scale,target_max_size)blob=im_list_to_blob(processed_im)#NOTE:thisheightandwidthmaybelargerthanactualscaledinputimage#duetotheFPN.COARSEST_STRIDErelatedpaddinginim_list_to_blob.Weare#maintainingthisbehaviorfornowtomakeexistingresultsexactly#reproducible(inpracticeusingthetrueinputimageheightandwidth#yieldsnearlythesameresults,buttheyaresometimesslightlydifferent#becausepredictionsneartheedgeoftheimagewillbeprunedmore#aggressively).height,width=blob.shape[2],blob.shape[3]im_info=np.hstack((height,width,im_scale))[np.newaxis,:]returnblob,im_scale,im_info.astype(np.float32)defim_list_to_blob(ims):\"\"\"Convertalistofimagesintoanetworkinput.Assumesimageswerepreparedusingprep_im_for_bloborequivalent:i.e.-BGRchannelorder-pixelmeanssubtracted-resizedtothedesiredinputsize-float32numpyndarrayformatOutputisa4DHCHWtensoroftheimagesconcatenatedalongaxis0withshape.\"\"\"ifnotisinstance(ims,list):ims=[ims]max_shape=np.array([im.shapeforiminims]).max(axis=0)#Padtheimagesotheycanbedivisiblebyastrideifcfg.FPN.FPN_ON:stride=float(cfg.FPN.COARSEST_STRIDE)max_shape[0]=int(np.ceil(max_shape[0]/stride)*stride)max_shape[1]=int(np.ceil(max_shape[1]/stride)*stride)num_images=len(ims)blob=np.zeros((num_images,max_shape[0],max_shape[1],3),dtype=np.float32)foriinrange(num_images):im=ims[i]blob[i,0:im.shape[0],0:im.shape[1],:]=im#Movechannels(axis3)toaxis1#Axisorderwillbecome:(batchelem,channel,height,width)channel_swap=(0,3,1,2)blob=blob.transpose(channel_swap)returnblobdefprep_im_for_blob(im,pixel_means,target_size,max_size):\"\"\"Prepareanimageforuseasanetworkinputblob.Specially:-Subtractper-channelpixelmean-Converttofloat32-Rescaletoeachofthespecifiedtargetsize(cappedatmax_size)Returnsalistoftransformedimages,oneforeachtargetsize.Alsoreturnsthescalefactorsthatwereusedtocomputeeachreturnedimage.\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)#Preventthebiggestaxisfrombeingmorethanmax_sizeifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)returnim,im_scaledefzeros(shape,int32=False):\"\"\"Returnablobofallzerosofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.zeros(shape,dtype=np.int32ifint32elsenp.float32)defones(shape,int32=False):\"\"\"Returnablobofallonesofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.ones(shape,dtype=np.int32ifint32elsenp.float32)defpy_op_copy_blob(blob_in,blob_out):\"\"\"Copyanumpyndarraygivenasblob_inintotheCaffe2CPUTensorblobgivenasblob_out.Supportsfloat32andint32blobdatatypes.ThisfunctionisintendedforcopyingnumpydataintoaCaffe2blobinPythonOps.\"\"\"#SomeawkwardvoodoorequiredbyCaffe2tosupportint32blobsneeds_int32_init=Falsetry:_=blob.data.dtype#noqaexceptException:needs_int32_init=blob_in.dtype==np.int32ifneeds_int32_init:#initcanonlytakealist(failedontuple)blob_out.init(list(blob_in.shape),caffe2_pb2.TensorProto.INT32)else:blob_out.reshape(blob_in.shape)blob_out.data[...]=blob_indefget_loss_gradients(model,loss_blobs):\"\"\"Generateagradientof1foreachlossspecifiedin\\'loss_blobs\\'\"\"\"loss_gradients={}forbinloss_blobs:loss_grad=model.net.ConstantFill(b,[b+\\'_grad\\'],value=1.0)loss_gradients[str(b)]=str(loss_grad)returnloss_gradientsdefserialize(obj):\"\"\"SerializeaPythonobjectusingpickleandencodeitasanarrayoffloat32valuessothatitcanbefeedintotheworkspace.Seedeserialize().\"\"\"returnnp.fromstring(pickle.dumps(obj),dtype=np.uint8).astype(np.float32)defdeserialize(arr):\"\"\"UnserializeaPythonobjectfromanarrayoffloat32valuesfetchedfromaworkspace.Seeserialize().\"\"\"returnpickle.loads(arr.astype(np.uint8).tobytes())#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Asimpleattributedictionaryusedforrepresentingconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsclassAttrDict(dict):IMMUTABLE=\\'__immutable__\\'def__init__(self,*args,**kwargs):super(AttrDict,self).__init__(*args,**kwargs)self.__dict__[AttrDict.IMMUTABLE]=Falsedef__getattr__(self,name):ifnameinself.__dict__:returnself.__dict__[name]elifnameinself:returnself[name]else:raiseAttributeError(name)def__setattr__(self,name,value):ifnotself.__dict__[AttrDict.IMMUTABLE]:ifnameinself.__dict__:self.__dict__[name]=valueelse:self[name]=valueelse:raiseAttributeError(\\'Attemptedtoset\"{}\"to\"{}\",butAttrDictisimmutable\\'.format(name,value))defimmutable(self,is_immutable):\"\"\"Setimmutabilitytois_immutableandrecursivelyapplythesettingtoallnestedAttrDicts.\"\"\"self.__dict__[AttrDict.IMMUTABLE]=is_immutable#Recursivelysetimmutablestateforvinself.__dict__.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)forvinself.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)defis_immutable(self):returnself.__dict__[AttrDict.IMMUTABLE]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Boxmanipulationfunctions.TheinternalDetectronboxformatis[x1,y1,x2,y2]where(x1,y1)specifythetop-leftboxcornerand(x2,y2)specifythebottom-rightboxcorner.Boxesfromexternalsources,e.g.,datasets,maybeinotherformats(suchas[x,y,w,h])andrequireconversion.Thismoduleusesaconventionthatmayseemstrangeatfirst:thewidthofaboxiscomputedasx2-x1+1(likewiseforheight).The\"+1\"datesbacktooldobjectdetectiondayswhenthecoordinateswereintegerpixelindices,ratherthanfloatingpointcoordinatesinasubpixelcoordinateframe.Aboxwithx2=x1andy2=y1wastakentoincludeasinglepixel,havingawidthof1,andhencerequiringthe\"+1\".Now,mostdatasetswilllikelyprovideboxeswithfloatingpointcoordinatesandthewidthshouldbemorereasonablycomputedasx2-x1.Inpractice,aslongasamodelistrainedandtestedwithaconsistentconventioneitherdecisionseemstobeok(atleastinourexperienceonCOCO).Sincewehavealonghistoryoftrainingmodelswiththe\"+1\"convention,wearereluctanttochangeitevenifourmoderntastesprefernottouseit.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.cython_bboxascython_bboximportdetectron.utils.cython_nmsascython_nmsbbox_overlaps=cython_bbox.bbox_overlapsdefboxes_area(boxes):\"\"\"Computetheareaofanarrayofboxes.\"\"\"w=(boxes[:,2]-boxes[:,0]+1)h=(boxes[:,3]-boxes[:,1]+1)areas=w*hassertnp.all(areas>=0),\\'Negativeareasfounds\\'returnareasdefunique_boxes(boxes,scale=1.0):\"\"\"Returnindicesofuniqueboxes.\"\"\"v=np.array([1,1e3,1e6,1e9])hashes=np.round(boxes*scale).dot(v)_,index=np.unique(hashes,return_index=True)returnnp.sort(index)defxywh_to_xyxy(xywh):\"\"\"Convert[x1y1wh]boxformatto[x1y1x2y2]format.\"\"\"ifisinstance(xywh,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xywh)==4x1,y1=xywh[0],xywh[1]x2=x1+np.maximum(0.,xywh[2]-1.)y2=y1+np.maximum(0.,xywh[3]-1.)return(x1,y1,x2,y2)elifisinstance(xywh,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xywh[:,0:2],xywh[:,0:2]+np.maximum(0,xywh[:,2:4]-1)))else:raiseTypeError(\\'Argumentxywhmustbealist,tuple,ornumpyarray.\\')defxyxy_to_xywh(xyxy):\"\"\"Convert[x1y1x2y2]boxformatto[x1y1wh]format.\"\"\"ifisinstance(xyxy,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xyxy)==4x1,y1=xyxy[0],xyxy[1]w=xyxy[2]-x1+1h=xyxy[3]-y1+1return(x1,y1,w,h)elifisinstance(xyxy,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xyxy[:,0:2],xyxy[:,2:4]-xyxy[:,0:2]+1))else:raiseTypeError(\\'Argumentxyxymustbealist,tuple,ornumpyarray.\\')deffilter_small_boxes(boxes,min_size):\"\"\"Keepboxeswithwidthandheightbothgreaterthanmin_size.\"\"\"w=boxes[:,2]-boxes[:,0]+1h=boxes[:,3]-boxes[:,1]+1keep=np.where((w>min_size)&(h>min_size))[0]returnkeepdefclip_boxes_to_image(boxes,height,width):\"\"\"Clipanarrayofboxestoanimagewiththegivenheightandwidth.\"\"\"boxes[:,[0,2]]=np.minimum(width-1.,np.maximum(0.,boxes[:,[0,2]]))boxes[:,[1,3]]=np.minimum(height-1.,np.maximum(0.,boxes[:,[1,3]]))returnboxesdefclip_xyxy_to_image(x1,y1,x2,y2,height,width):\"\"\"Clipcoordinatestoanimagewiththegivenheightandwidth.\"\"\"x1=np.minimum(width-1.,np.maximum(0.,x1))y1=np.minimum(height-1.,np.maximum(0.,y1))x2=np.minimum(width-1.,np.maximum(0.,x2))y2=np.minimum(height-1.,np.maximum(0.,y2))returnx1,y1,x2,y2defclip_tiled_boxes(boxes,im_shape):\"\"\"Clipboxestoimageboundaries.im_shapeis[height,width]andboxeshasshape(N,4*num_tiled_boxes).\"\"\"assertboxes.shape[1]%4==0,\\\\\\'boxes.shape[1]is{:d},butmustbedivisibleby4.\\'.format(boxes.shape[1])#x1>=0boxes[:,0::4]=np.maximum(np.minimum(boxes[:,0::4],im_shape[1]-1),0)#y1>=0boxes[:,1::4]=np.maximum(np.minimum(boxes[:,1::4],im_shape[0]-1),0)#x2<im_shape[1]boxes[:,2::4]=np.maximum(np.minimum(boxes[:,2::4],im_shape[1]-1),0)#y2<im_shape[0]boxes[:,3::4]=np.maximum(np.minimum(boxes[:,3::4],im_shape[0]-1),0)returnboxesdefbbox_transform(boxes,deltas,weights=(1.0,1.0,1.0,1.0)):\"\"\"Forwardtransformthatmapsproposalboxestopredictedground-truthboxesusingbounding-boxregressiondeltas.Seebbox_transform_invforadescriptionoftheweightsargument.\"\"\"ifboxes.shape[0]==0:returnnp.zeros((0,deltas.shape[1]),dtype=deltas.dtype)boxes=boxes.astype(deltas.dtype,copy=False)widths=boxes[:,2]-boxes[:,0]+1.0heights=boxes[:,3]-boxes[:,1]+1.0ctr_x=boxes[:,0]+0.5*widthsctr_y=boxes[:,1]+0.5*heightswx,wy,ww,wh=weightsdx=deltas[:,0::4]/wxdy=deltas[:,1::4]/wydw=deltas[:,2::4]/wwdh=deltas[:,3::4]/wh#Preventsendingtoolargevaluesintonp.exp()dw=np.minimum(dw,cfg.BBOX_XFORM_CLIP)dh=np.minimum(dh,cfg.BBOX_XFORM_CLIP)pred_ctr_x=dx*widths[:,np.newaxis]+ctr_x[:,np.newaxis]pred_ctr_y=dy*heights[:,np.newaxis]+ctr_y[:,np.newaxis]pred_w=np.exp(dw)*widths[:,np.newaxis]pred_h=np.exp(dh)*heights[:,np.newaxis]pred_boxes=np.zeros(deltas.shape,dtype=deltas.dtype)#x1pred_boxes[:,0::4]=pred_ctr_x-0.5*pred_w#y1pred_boxes[:,1::4]=pred_ctr_y-0.5*pred_h#x2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,2::4]=pred_ctr_x+0.5*pred_w-1#y2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,3::4]=pred_ctr_y+0.5*pred_h-1returnpred_boxesdefbbox_transform_inv(boxes,gt_boxes,weights=(1.0,1.0,1.0,1.0)):\"\"\"Inversetransformthatcomputestargetbounding-boxregressiondeltasgivenproposalboxesandground-truthboxes.Theweightsargumentshouldbea4-tupleofmultiplicativeweightsthatareappliedtotheregressiontarget.Inolderversionsofthiscode(andinpy-faster-rcnn),theweightsweresetsuchthattheregressiondeltaswouldhaveunitstandarddeviationonthetrainingdataset.Presently,ratherthancomputingthesestatisticsexactly,weuseafixedsetofweights(10.,10.,5.,5.)bydefault.TheseareapproximatelytheweightsonewouldgetfromCOCOusingthepreviousunitstdevheuristic.\"\"\"ex_widths=boxes[:,2]-boxes[:,0]+1.0ex_heights=boxes[:,3]-boxes[:,1]+1.0ex_ctr_x=boxes[:,0]+0.5*ex_widthsex_ctr_y=boxes[:,1]+0.5*ex_heightsgt_widths=gt_boxes[:,2]-gt_boxes[:,0]+1.0gt_heights=gt_boxes[:,3]-gt_boxes[:,1]+1.0gt_ctr_x=gt_boxes[:,0]+0.5*gt_widthsgt_ctr_y=gt_boxes[:,1]+0.5*gt_heightswx,wy,ww,wh=weightstargets_dx=wx*(gt_ctr_x-ex_ctr_x)/ex_widthstargets_dy=wy*(gt_ctr_y-ex_ctr_y)/ex_heightstargets_dw=ww*np.log(gt_widths/ex_widths)targets_dh=wh*np.log(gt_heights/ex_heights)targets=np.vstack((targets_dx,targets_dy,targets_dw,targets_dh)).transpose()returntargetsdefexpand_boxes(boxes,scale):\"\"\"Expandanarrayofboxesbyagivenscale.\"\"\"w_half=(boxes[:,2]-boxes[:,0])*.5h_half=(boxes[:,3]-boxes[:,1])*.5x_c=(boxes[:,2]+boxes[:,0])*.5y_c=(boxes[:,3]+boxes[:,1])*.5w_half*=scaleh_half*=scaleboxes_exp=np.zeros(boxes.shape)boxes_exp[:,0]=x_c-w_halfboxes_exp[:,2]=x_c+w_halfboxes_exp[:,1]=y_c-h_halfboxes_exp[:,3]=y_c+h_halfreturnboxes_expdefflip_boxes(boxes,im_width):\"\"\"Flipboxeshorizontally.\"\"\"boxes_flipped=boxes.copy()boxes_flipped[:,0::4]=im_width-boxes[:,2::4]-1boxes_flipped[:,2::4]=im_width-boxes[:,0::4]-1returnboxes_flippeddefaspect_ratio(boxes,aspect_ratio):\"\"\"Performwidth-relativeaspectratiotransformation.\"\"\"boxes_ar=boxes.copy()boxes_ar[:,0::4]=aspect_ratio*boxes[:,0::4]boxes_ar[:,2::4]=aspect_ratio*boxes[:,2::4]returnboxes_ardefbox_voting(top_dets,all_dets,thresh,scoring_method=\\'ID\\',beta=1.0):\"\"\"Applybounding-boxvotingtorefine`top_dets`byvotingwith`all_dets`.See:Optionalscoreaveraging(notinthereferencedpaper)canbeappliedbysetting`scoring_method`appropriately.\"\"\"#top_detsis[N,5]eachrowis[x1y1x2y2,sore]#all_detsis[N,5]eachrowis[x1y1x2y2,sore]top_dets_out=top_dets.copy()top_boxes=top_dets[:,:4]all_boxes=all_dets[:,:4]all_scores=all_dets[:,4]top_to_all_overlaps=bbox_overlaps(top_boxes,all_boxes)forkinrange(top_dets_out.shape[0]):inds_to_vote=np.where(top_to_all_overlaps[k]>=thresh)[0]boxes_to_vote=all_boxes[inds_to_vote,:]ws=all_scores[inds_to_vote]top_dets_out[k,:4]=np.average(boxes_to_vote,axis=0,weights=ws)ifscoring_method==\\'ID\\':#Identity,nothingtodopasselifscoring_method==\\'TEMP_AVG\\':#Averageprobabilities(consideredasP(detectedclass)vs.#P(notthedetectedclass))aftersmoothingwithatemperature#hyperparameter.P=np.vstack((ws,1.0-ws))P_max=np.max(P,axis=0)X=np.log(P/P_max)X_exp=np.exp(X/beta)P_temp=X_exp/np.sum(X_exp,axis=0)P_avg=P_temp[0].mean()top_dets_out[k,4]=P_avgelifscoring_method==\\'AVG\\':#Combinenewprobsfromoverlappingboxestop_dets_out[k,4]=ws.mean()elifscoring_method==\\'IOU_AVG\\':P=wsws=top_to_all_overlaps[k,inds_to_vote]P_avg=np.average(P,weights=ws)top_dets_out[k,4]=P_avgelifscoring_method==\\'GENERALIZED_AVG\\':P_avg=np.mean(ws**beta)**(1.0/beta)top_dets_out[k,4]=P_avgelifscoring_method==\\'QUASI_SUM\\':top_dets_out[k,4]=ws.sum()/float(len(ws))**betaelse:raiseNotImplementedError(\\'Unknownscoringmethod{}\\'.format(scoring_method))returntop_dets_outdefnms(dets,thresh):\"\"\"ApplyclassicDPM-stylegreedyNMS.\"\"\"ifdets.shape[0]==0:return[]returncython_nms.nms(dets,thresh)defsoft_nms(dets,sigma=0.5,overlap_thresh=0.3,score_thresh=0.001,method=\\'linear\\'):\"\"\"ApplythesoftNMSalgorithmfrom\"\"\"ifdets.shape[0]==0:returndets,[]methods={\\'hard\\':0,\\'linear\\':1,\\'gaussian\\':2}assertmethodinmethods,\\'Unknownsoft_nmsmethod:{}\\'.format(method)dets,keep=cython_nms.soft_nms(np.ascontiguousarray(dets,dtype=np.float32),np.float32(sigma),np.float32(overlap_thresh),np.float32(score_thresh),np.uint8(methods[method]))returndets,keep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesforlogging.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromemail.mime.textimportMIMETextimportjsonimportloggingimportnumpyasnpimportsmtplibimportsysdeflog_json_stats(stats,sort_keys=True):#hacktocontrolprecisionoftop-levelfloatsstats={k:\\'{:.6f}\\'.format(v)ifisinstance(v,float)elsevfork,vinstats.items()}print(\\'json_stats:{:s}\\'.format(json.dumps(stats,sort_keys=sort_keys)))classSmoothedValue:\"\"\"Trackaseriesofvaluesandprovideaccesstosmoothedvaluesoverawindowortheglobalseriesaverage.\"\"\"def__init__(self,window_size):self.deque=deque(maxlen=window_size)self.series=[]self.total=0.0self.count=0defAddValue(self,value):self.deque.append(value)self.series.append(value)self.count+=1self.total+=valuedefGetMedianValue(self):returnnp.median(self.deque)defGetAverageValue(self):returnnp.mean(self.deque)defGetGlobalAverageValue(self):returnself.total/self.countdefsend_email(subject,body,to):s=smtplib.SMTP(\\'localhost\\')mime=MIMEText(body)mime[\\'Subject\\']=subjectmime[\\'To\\']=tos.sendmail(\\'detectron\\',to,mime.as_string())defsetup_logging(name):FORMAT=\\'%(levelname)s%(filename)s:%(lineno)4d:%(message)s\\'#Manuallyclearrootloggerstopreventanymodulethatmayhavecalled#logging.basicConfig()fromblockingourloggingsetuplogging.root.handlers=[]logging.basicConfig(level=logging.INFO,format=FORMAT,stream=sys.stdout)logger=logging.getLogger(name)returnlogger#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Imagehelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpdefaspect_ratio_rel(im,aspect_ratio):\"\"\"Performswidth-relativeaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_ar_w=int(round(aspect_ratio*im_w))im_ar=cv2.resize(im,dsize=(im_ar_w,im_h))returnim_ardefaspect_ratio_abs(im,aspect_ratio):\"\"\"Performsabsoluteaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_area=im_h*im_wim_ar_w=np.sqrt(im_area*aspect_ratio)im_ar_h=np.sqrt(im_area/aspect_ratio)assertnp.isclose(im_ar_w/im_ar_h,aspect_ratio)im_ar=cv2.resize(im,dsize=(int(im_ar_w),int(im_ar_h)))returnim_ar#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Learningratepolicies.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgdefget_lr_at_iter(it):\"\"\"Getthelearningrateatiterationitaccordingtothecfg.SOLVERsettings.\"\"\"lr=get_lr_func()(it)ifit<cfg.SOLVER.WARM_UP_ITERS:method=cfg.SOLVER.WARM_UP_METHODifmethod==\\'constant\\':warmup_factor=cfg.SOLVER.WARM_UP_FACTORelifmethod==\\'linear\\':alpha=it/cfg.SOLVER.WARM_UP_ITERSwarmup_factor=cfg.SOLVER.WARM_UP_FACTOR*(1-alpha)+alphaelse:raiseKeyError(\\'UnknownSOLVER.WARM_UP_METHOD:{}\\'.format(method))lr*=warmup_factorreturnnp.float32(lr)#----------------------------------------------------------------------------##Learningratepolicyfunctions#----------------------------------------------------------------------------#deflr_func_steps_with_lrs(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_lrs\\'Changethelearningratetospecifiedvaluesatspecifiediterations.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.LRS:[0.02,0.002,0.0002]forcur_iterin[0,59]use0.02in[60,79]use0.002in[80,inf]use0.0002\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.LRS[ind]deflr_func_steps_with_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_decay\\'Changethelearningratespecifiediterationsbasedontheformulalr=base_lr*gamma**lr_step_count.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.BASE_LR:0.02cfg.SOLVER.GAMMA:0.1forcur_iterin[0,59]use0.02=0.02*0.1**0in[60,79]use0.002=0.02*0.1**1in[80,inf]use0.0002=0.02*0.1**2\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**inddeflr_func_step(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'step\\'\"\"\"return(cfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**(cur_iter//cfg.SOLVER.STEP_SIZE))deflr_func_cosine_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'cosine_decay\\'\"\"\"iter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERcos_frac=0.5*(np.cos(np.pi*iter_frac)+1)returncfg.SOLVER.BASE_LR*cos_fracdeflr_func_exp_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'exp_decay\\'\"\"\"#GAMMAisfinal/initiallearningrateratioiter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERexp_frac=np.exp(iter_frac*np.log(cfg.SOLVER.GAMMA))returncfg.SOLVER.BASE_LR*exp_frac#----------------------------------------------------------------------------##Helpers#----------------------------------------------------------------------------#defget_step_index(cur_iter):\"\"\"Givenaniteration,findwhichlearningratestepwe\\'reat.\"\"\"assertcfg.SOLVER.STEPS[0]==0,\\'Thefirststepshouldalwaysstartat0.\\'steps=cfg.SOLVER.STEPS+[cfg.SOLVER.MAX_ITER]forind,stepinenumerate(steps):#NoQAifcur_iter<step:breakreturnind-1defget_lr_func():policy=\\'lr_func_\\'+cfg.SOLVER.LR_POLICYifpolicynotinglobals():raiseNotImplementedError(\\'UnknownLRpolicy:{}\\'.format(cfg.SOLVER.LR_POLICY))else:returnglobals()[policy]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Timingrelatedfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporttimeclassTimer:\"\"\"Asimpletimer.\"\"\"def__init__(self):self.reset()deftic(self):#usingtime.timeinsteadoftime.clockbecausetimetime.clock#doesnotnormalizeformultithreadingself.start_time=time.time()deftoc(self,average=True):self.diff=time.time()-self.start_timeself.total_time+=self.diffself.calls+=1self.average_time=self.total_time/self.callsifaverage:returnself.average_timeelse:returnself.diffdefreset(self):self.total_time=0.self.calls=0self.start_time=0.self.diff=0.self.average_time=0.#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Coordinatedaccesstoasharedmultithreading/processingqueue.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcontextlibimportloggingimportthreadingimporttracebackfromsix.movesimportqueueasQueuelog=logging.getLogger(__name__)classCoordinator:def__init__(self):self._event=threading.Event()defrequest_stop(self):log.debug(\\'Coordinatorstopping\\')self._event.set()defshould_stop(self):returnself._event.is_set()defwait_for_stop(self):returnself._event.wait()@contextlib.contextmanagerdefstop_on_exception(self):try:yieldexceptException:ifnotself.should_stop():traceback.print_exc()self.request_stop()defcoordinated_get(coordinator,queue):whilenotcoordinator.should_stop():try:returnqueue.get(block=True,timeout=1.0)exceptQueue.Empty:continueraiseException(\\'Coordinatorstoppedduringget()\\')defcoordinated_put(coordinator,queue,element):whilenotcoordinator.should_stop():try:queue.put(element,block=True,timeout=1.0)returnexceptQueue.Full:continueraiseException(\\'Coordinatorstoppedduringput()\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Utilitiesdrivingthetrain_netbinary\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromshutilimportcopyfileimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportosimportrefromcaffe2.pythonimportmemongerfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utilsimportlr_policyfromdetectron.utils.training_statsimportTrainingStatsimportdetectron.utils.envasenvuimportdetectron.utils.netasnudeftrain_model():\"\"\"Modeltrainingloop.\"\"\"model,weights_file,start_iter,checkpoints,output_dir=create_model()if\\'final\\'incheckpoints:#Thefinalmodelwasfoundintheoutputdirectory,sonothingtodoreturncheckpointssetup_model_for_training(model,weights_file,output_dir)training_stats=TrainingStats(model)CHECKPOINT_PERIOD=int(cfg.TRAIN.SNAPSHOT_ITERS/cfg.NUM_GPUS)forcur_iterinrange(start_iter,cfg.SOLVER.MAX_ITER):ifmodel.roi_data_loader.has_stopped():handle_critical_error(model,\\'roi_data_loaderfailed\\')training_stats.IterTic()lr=model.UpdateWorkspaceLr(cur_iter,lr_policy.get_lr_at_iter(cur_iter))workspace.RunNet(model.net.Proto().name)ifcur_iter==start_iter:nu.print_net(model)training_stats.IterToc()training_stats.UpdateIterStats()training_stats.LogIterStats(cur_iter,lr)if(cur_iter+1)%CHECKPOINT_PERIOD==0andcur_iter>start_iter:checkpoints[cur_iter]=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(cur_iter))nu.save_model_to_weights_file(checkpoints[cur_iter],model)ifcur_iter==start_iter+training_stats.LOG_PERIOD:#Resettheiterationtimertoremoveoutliersfromthefirstfew#SGDiterationstraining_stats.ResetIterTimer()ifnp.isnan(training_stats.iter_total_loss):handle_critical_error(model,\\'LossisNaN\\')#Savethefinalmodelcheckpoints[\\'final\\']=os.path.join(output_dir,\\'model_final.pkl\\')nu.save_model_to_weights_file(checkpoints[\\'final\\'],model)#Shutdowndataloadingthreadsmodel.roi_data_loader.shutdown()returncheckpointsdefhandle_critical_error(model,msg):logger=logging.getLogger(__name__)logger.critical(msg)model.roi_data_loader.shutdown()raiseException(msg)defcreate_model():\"\"\"Buildthemodelandlookforsavedmodelcheckpointsincasewecanresumefromone.\"\"\"logger=logging.getLogger(__name__)start_iter=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)weights_file=cfg.TRAIN.WEIGHTSifcfg.TRAIN.AUTO_RESUME:#Checkforthefinalmodel(indicatestrainingalreadyfinished)final_path=os.path.join(output_dir,\\'model_final.pkl\\')ifos.path.exists(final_path):logger.info(\\'model_final.pklexists;noneedtotrain!\\')returnNone,None,None,{\\'final\\':final_path},output_dirifcfg.TRAIN.COPY_WEIGHTS:copyfile(weights_file,os.path.join(output_dir,os.path.basename(weights_file)))logger.info(\\'Copy{}to{}\\'.format(weights_file,output_dir))#Findthemostrecentcheckpoint(highestiterationnumber)files=os.listdir(output_dir)forfinfiles:iter_string=re.findall(r\\'(?<=model_iter)\\\\d+(?=\\\\.pkl)\\',f)iflen(iter_string)>0:checkpoint_iter=int(iter_string[0])ifcheckpoint_iter>start_iter:#Startoneiterationimmediatelyafterthecheckpointiterstart_iter=checkpoint_iter+1resume_weights_file=fifstart_iter>0:#Overridetheinitializationweightswiththefoundcheckpointweights_file=os.path.join(output_dir,resume_weights_file)logger.info(\\'========>Resumingfromcheckpoint{}atstartiter{}\\'.format(weights_file,start_iter))logger.info(\\'Buildingmodel:{}\\'.format(cfg.MODEL.TYPE))model=model_builder.create(cfg.MODEL.TYPE,train=True)ifcfg.MEMONGER:optimize_memory(model)#Performsrandomweightinitializationasdefinedbythemodelworkspace.RunNetOnce(model.param_init_net)returnmodel,weights_file,start_iter,checkpoints,output_dirdefoptimize_memory(model):\"\"\"SaveGPUmemorythroughblobsharing.\"\"\"fordeviceinrange(cfg.NUM_GPUS):namescope=\\'gpu_{}/\\'.format(device)losses=[namescope+lforlinmodel.losses]model.net._net=memonger.share_grad_blobs(model.net,losses,set(model.param_to_grad.values()),namescope,share_activations=cfg.MEMONGER_SHARE_ACTIVATIONS)defsetup_model_for_training(model,weights_file,output_dir):\"\"\"LoadedsavedweightsandcreatethenetworkintheC2workspace.\"\"\"logger=logging.getLogger(__name__)add_model_training_inputs(model)ifweights_file:#Overriderandomweightinitializationwithweightsfromasavedmodelnu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)#Evenifwe\\'rerandomlyinitializingwestillneedtosynchronize#parametersacrossGPUsnu.broadcast_parameters(model)workspace.CreateNet(model.net)logger.info(\\'Outputssavedto:{:s}\\'.format(os.path.abspath(output_dir)))dump_proto_files(model,output_dir)#Startloadingmini-batchesandenqueuingblobsmodel.roi_data_loader.register_sigint_handler()model.roi_data_loader.start(prefill=True)returnoutput_dirdefadd_model_training_inputs(model):\"\"\"Loadthetrainingdatasetandattachthetraininginputstothemodel.\"\"\"logger=logging.getLogger(__name__)logger.info(\\'Loadingdataset:{}\\'.format(cfg.TRAIN.DATASETS))roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))model_builder.add_training_inputs(model,roidb=roidb)defdump_proto_files(model,output_dir):\"\"\"Saveprototxtdescriptionsofthetrainingnetworkandparameterinitializationnetwork.\"\"\"withopen(os.path.join(output_dir,\\'net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.net.Proto()))withopen(os.path.join(output_dir,\\'param_init_net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.param_init_net.Proto()))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"IOutilities.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporterrnoimporthashlibimportloggingimportosimportreimportsiximportsysfromsix.movesimportcPickleaspicklefromsix.movesimporturllibfromuuidimportuuid4logger=logging.getLogger(__name__)_DETECTRON_S3_BASE_URL=\\'defsave_object(obj,file_name,pickle_format=2):\"\"\"SaveaPythonobjectbypicklingit.Unlessspecificallyoverridden,wewanttosaveitinPickleformat=2sincethiswillallowotherPython2executablestoloadtheresultingPickle.WhenwewanttocompletelyremovePython2backward-compatibility,wecanbumpitupto3.Weshouldneverusepickle.HIGHEST_PROTOCOLasfaraspossibleiftheresultingfileismanifestedorused,externaltothesystem.\"\"\"file_name=os.path.abspath(file_name)#Avoidfilesystemraceconditions(particularlyonnetworkfilesystems)#bysavingtoarandomtmpfileonthesamefilesystem,andthen#atomicallyrenametothetargetfilename.tmp_file_name=file_name+\".tmp.\"+uuid4().hextry:withopen(tmp_file_name,\\'wb\\')asf:pickle.dump(obj,f,pickle_format)f.flush()#makesureit\\'swrittentodiskos.fsync(f.fileno())os.rename(tmp_file_name,file_name)finally:#Cleanupthetempfileonfailure.Ratherthanusingos.path.exists(),#whichcanbeunreliableonnetworkfilesystems,attempttodeleteand#ignoreoserrors.try:os.remove(tmp_file_name)exceptEnvironmentErrorase:#parentclassofIOError,OSErrorifgetattr(e,\\'errno\\',None)!=errno.ENOENT:#WeexpectENOENTlogger.info(\"Couldnotdeletetempfile%r\",tmp_file_name,exc_info=True)#passthroughsincewedon\\'twantthejobtocrashdefload_object(file_name):withopen(file_name,\\'rb\\')asf:#Thedefaultencodingusedwhileunpicklingis7-bit(ASCII.)However,#theblobsarearbitrary8-bitbyteswhichdon\\'tagree.Theabsolute#correctwaytodothisistouse`encoding=\"bytes\"`andtheninterpret#theblobnameseitherasASCII,orbetter,asunicodeutf-8.A#reasonablefix,however,istotreatittheencodingas8-bitlatin1#(whichagreeswiththefirst256charactersofUnicodeanyway.)ifsix.PY2:returnpickle.load(f)else:returnpickle.load(f,encoding=\\'latin1\\')defcache_url(url_or_file,cache_dir):\"\"\"DownloadthefilespecifiedbytheURLtothecache_dirandreturnthepathtothecachedfile.IftheargumentisnotaURL,simplyreturnitasis.\"\"\"is_url=re.match(r\\'^(?:http)s?://\\',url_or_file,re.IGNORECASE)isnotNoneifnotis_url:returnurl_or_fileurl=url_or_fileasserturl.startswith(_DETECTRON_S3_BASE_URL),\\\\(\\'DetectrononlyautomaticallycachesURLsintheDetectronS3\\'\\'bucket:{}\\').format(_DETECTRON_S3_BASE_URL)cache_file_path=url.replace(_DETECTRON_S3_BASE_URL,cache_dir)ifos.path.exists(cache_file_path):assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathcache_file_dir=os.path.dirname(cache_file_path)ifnotos.path.exists(cache_file_dir):os.makedirs(cache_file_dir)logger.info(\\'Downloadingremotefile{}to{}\\'.format(url,cache_file_path))download_url(url,cache_file_path)assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathdefassert_cache_file_is_ok(url,file_path):\"\"\"Checkthatcachefilehasthecorrecthash.\"\"\"#Fileisalreadyinthecache,verifythatthemd5summatchesand#returnlocalpathcache_file_md5sum=_get_file_md5sum(file_path)ref_md5sum=_get_reference_md5sum(url)assertcache_file_md5sum==ref_md5sum,\\\\(\\'TargetURL{}appearstobedownloadedtothelocalcachefile\\'\\'{},butthemd5hashofthelocalfiledoesnotmatchthe\\'\\'reference(actual:{}vs.expected:{}).Youmaywishtodelete\\'\\'thecachedfileandtryagaintotriggerautomatic\\'\\'download.\\').format(url,file_path,cache_file_md5sum,ref_md5sum)def_progress_bar(count,total):\"\"\"Reportdownloadprogress.Credit:\"\"\"bar_len=60filled_len=int(round(bar_len*count/float(total)))percents=round(100.0*count/float(total),1)bar=\\'=\\'*filled_len+\\'-\\'*(bar_len-filled_len)sys.stdout.write(\\'[{}]{}%of{:.1f}MBfile\\\\r\\'.format(bar,percents,total/1024/1024))sys.stdout.flush()ifcount>=total:sys.stdout.write(\\'\\\\n\\')defdownload_url(url,dst_file_path,chunk_size=8192,progress_hook=_progress_bar):\"\"\"Downloadurlandwriteittodst_file_path.Credit:\"\"\"response=urllib.request.urlopen(url)ifsix.PY2:total_size=response.info().getheader(\\'Content-Length\\').strip()else:total_size=response.info().get(\\'Content-Length\\').strip()total_size=int(total_size)bytes_so_far=0withopen(dst_file_path,\\'wb\\')asf:while1:chunk=response.read(chunk_size)bytes_so_far+=len(chunk)ifnotchunk:breakifprogress_hook:progress_hook(bytes_so_far,total_size)f.write(chunk)returnbytes_so_fardef_get_file_md5sum(file_name):\"\"\"Computethemd5hashofafile.\"\"\"hash_obj=hashlib.md5()withopen(file_name,\\'rb\\')asf:hash_obj.update(f.read())returnhash_obj.hexdigest().encode(\\'utf-8\\')def_get_reference_md5sum(url):\"\"\"Byconventionthemd5hashforurlisstoredinurl+\\'.md5sum\\'.\"\"\"url_md5sum=url+\\'.md5sum\\'md5sum=urllib.request.urlopen(url_md5sum).read().strip()returnmd5sum#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Keypointutilities(somewhatspecifictoCOCOkeypoints).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_keypoints():\"\"\"GettheCOCOkeypointsandtheirleft/rightflipcoorespondencemap.\"\"\"#KeypointsarenotavailableintheCOCOjsonforthetestsplit,sowe#providethemhere.keypoints=[\\'nose\\',\\'left_eye\\',\\'right_eye\\',\\'left_ear\\',\\'right_ear\\',\\'left_shoulder\\',\\'right_shoulder\\',\\'left_elbow\\',\\'right_elbow\\',\\'left_wrist\\',\\'right_wrist\\',\\'left_hip\\',\\'right_hip\\',\\'left_knee\\',\\'right_knee\\',\\'left_ankle\\',\\'right_ankle\\']keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}returnkeypoints,keypoint_flip_mapdefget_person_class_index():\"\"\"IndexofthepersonclassinCOCO.\"\"\"return1defflip_keypoints(keypoints,keypoint_flip_map,keypoint_coords,width):\"\"\"Left/rightflipkeypoint_coords.keypointsandkeypoint_flip_mapareaccessiblefromget_keypoints().\"\"\"flipped_kps=keypoint_coords.copy()forlkp,rkpinkeypoint_flip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)flipped_kps[:,:,lid]=keypoint_coords[:,:,rid]flipped_kps[:,:,rid]=keypoint_coords[:,:,lid]#Flipxcoordinatesflipped_kps[:,0,:]=width-flipped_kps[:,0,:]-1#MaintainCOCOconventionthatifvisibility==0,thenx,y=0inds=np.where(flipped_kps[:,2,:]==0)flipped_kps[inds[0],0,inds[1]]=0returnflipped_kpsdefflip_heatmaps(heatmaps):\"\"\"Flipheatmapshorizontally.\"\"\"keypoints,flip_map=get_keypoints()heatmaps_flipped=heatmaps.copy()forlkp,rkpinflip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)heatmaps_flipped[:,rid,:,:]=heatmaps[:,lid,:,:]heatmaps_flipped[:,lid,:,:]=heatmaps[:,rid,:,:]heatmaps_flipped=heatmaps_flipped[:,:,:,::-1]returnheatmaps_flippeddefheatmaps_to_keypoints(maps,rois):\"\"\"Extractpredictedkeypointlocationsfromheatmaps.Outputhasshape(#rois,4,#keypoints)withthe4rowscorrespondingto(x,y,logit,prob)foreachkeypoint.\"\"\"#ThisfunctionconvertsadiscreteimagecoordinateinaHEATMAP_SIZEx#HEATMAP_SIZEimagetoacontinuouskeypointcoordinate.Wemaintain#consistencywithkeypoints_to_heatmap_labelsbyusingtheconversionfrom#Heckbert1990:c=d+0.5,wheredisadiscretecoordinateandcisa#continuouscoordinate.offset_x=rois[:,0]offset_y=rois[:,1]widths=rois[:,2]-rois[:,0]heights=rois[:,3]-rois[:,1]widths=np.maximum(widths,1)heights=np.maximum(heights,1)widths_ceil=np.ceil(widths)heights_ceil=np.ceil(heights)#NCHWtoNHWCforusewithOpenCVmaps=np.transpose(maps,[0,2,3,1])min_size=cfg.KRCNN.INFERENCE_MIN_SIZExy_preds=np.zeros((len(rois),4,cfg.KRCNN.NUM_KEYPOINTS),dtype=np.float32)foriinrange(len(rois)):ifmin_size>0:roi_map_width=int(np.maximum(widths_ceil[i],min_size))roi_map_height=int(np.maximum(heights_ceil[i],min_size))else:roi_map_width=widths_ceil[i]roi_map_height=heights_ceil[i]width_correction=widths[i]/roi_map_widthheight_correction=heights[i]/roi_map_heightroi_map=cv2.resize(maps[i],(roi_map_width,roi_map_height),interpolation=cv2.INTER_CUBIC)#BringbacktoCHWroi_map=np.transpose(roi_map,[2,0,1])roi_map_probs=scores_to_probs(roi_map.copy())w=roi_map.shape[2]forkinrange(cfg.KRCNN.NUM_KEYPOINTS):pos=roi_map[k,:,:].argmax()x_int=pos%wy_int=(pos-x_int)//wassert(roi_map_probs[k,y_int,x_int]==roi_map_probs[k,:,:].max())x=(x_int+0.5)*width_correctiony=(y_int+0.5)*height_correctionxy_preds[i,0,k]=x+offset_x[i]xy_preds[i,1,k]=y+offset_y[i]xy_preds[i,2,k]=roi_map[k,y_int,x_int]xy_preds[i,3,k]=roi_map_probs[k,y_int,x_int]returnxy_predsdefkeypoints_to_heatmap_labels(keypoints,rois):\"\"\"EncodekeypointlocationinthetargetheatmapforuseinSoftmaxWithLoss.\"\"\"#Mapskeypointsfromthehalf-openinterval[x1,x2)oncontinuousimage#coordinatestotheclosedinterval[0,HEATMAP_SIZE-1]ondiscreteimage#coordinates.WeusethecontinuousdiscreteconversionfromHeckbert#1990(\"Whatisthecoordinateofapixel?\"):d=floor(c)andc=d+0.5,#wheredisadiscretecoordinateandcisacontinuouscoordinate.assertkeypoints.shape[2]==cfg.KRCNN.NUM_KEYPOINTSshape=(len(rois),cfg.KRCNN.NUM_KEYPOINTS)heatmaps=blob_utils.zeros(shape)weights=blob_utils.zeros(shape)offset_x=rois[:,0]offset_y=rois[:,1]scale_x=cfg.KRCNN.HEATMAP_SIZE/(rois[:,2]-rois[:,0])scale_y=cfg.KRCNN.HEATMAP_SIZE/(rois[:,3]-rois[:,1])forkpinrange(keypoints.shape[2]):vis=keypoints[:,2,kp]>0x=keypoints[:,0,kp].astype(np.float32)y=keypoints[:,1,kp].astype(np.float32)#Sinceweusefloorbelow,ifakeypointisexactlyontheroi\\'sright#orbottomboundary,weshiftitinbyeps(conceptually)tokeepitin#thegroundtruthheatmap.x_boundary_inds=np.where(x==rois[:,2])[0]y_boundary_inds=np.where(y==rois[:,3])[0]x=(x-offset_x)*scale_xx=np.floor(x)iflen(x_boundary_inds)>0:x[x_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1y=(y-offset_y)*scale_yy=np.floor(y)iflen(y_boundary_inds)>0:y[y_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1valid_loc=np.logical_and(np.logical_and(x>=0,y>=0),np.logical_and(x<cfg.KRCNN.HEATMAP_SIZE,y<cfg.KRCNN.HEATMAP_SIZE))valid=np.logical_and(valid_loc,vis)valid=valid.astype(np.int32)lin_ind=y*cfg.KRCNN.HEATMAP_SIZE+xheatmaps[:,kp]=lin_ind*validweights[:,kp]=validreturnheatmaps,weightsdefscores_to_probs(scores):\"\"\"TransformsCxHxWofscorestoprobabilitiesspatially.\"\"\"channels=scores.shape[0]forcinrange(channels):temp=scores[c,:,:]max_score=temp.max()temp=np.exp(temp-max_score)/np.sum(np.exp(temp-max_score))scores[c,:,:]=tempreturnscoresdefnms_oks(kp_predictions,rois,thresh):\"\"\"Nmsbasedonkppredictions.\"\"\"scores=np.mean(kp_predictions[:,2,:],axis=1)order=scores.argsort()[::-1]keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=compute_oks(kp_predictions[i],rois[i],kp_predictions[order[1:]],rois[order[1:]])inds=np.where(ovr<=thresh)[0]order=order[inds+1]returnkeepdefcompute_oks(src_keypoints,src_roi,dst_keypoints,dst_roi):\"\"\"ComputeOKSforpredictedkeypointswrtgt_keypoints.src_keypoints:4xKsrc_roi:4x1dst_keypoints:Nx4xKdst_roi:Nx4\"\"\"sigmas=np.array([.26,.25,.25,.35,.35,.79,.79,.72,.72,.62,.62,1.07,1.07,.87,.87,.89,.89])/10.0vars=(sigmas*2)**2#areasrc_area=(src_roi[2]-src_roi[0]+1)*(src_roi[3]-src_roi[1]+1)#measuretheper-keypointdistanceifkeypointsvisibledx=dst_keypoints[:,0,:]-src_keypoints[0,:]dy=dst_keypoints[:,1,:]-src_keypoints[1,:]e=(dx**2+dy**2)/vars/(src_area+np.spacing(1))/2e=np.sum(np.exp(-e),axis=1)/e.shape[1]returne#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fill#----------------------------------------------------------------------------##R-FCNoutputsandlosses#----------------------------------------------------------------------------#defadd_rfcn_outputs(model,blob_in,dim_in,dim_reduce,spatial_scale):ifdim_reduceisnotNone:#Optionaldimreductionblob_in=model.Conv(blob_in,\\'conv_dim_reduce\\',dim_in,dim_reduce,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))blob_in=model.Relu(blob_in,blob_in)dim_in=dim_reduce#Classificationconvmodel.Conv(blob_in,\\'conv_cls\\',dim_in,model.num_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Bounding-boxregressionconvnum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.Conv(blob_in,\\'conv_bbox_pred\\',dim_in,4*num_bbox_reg_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#ClassificationPSRoIpoolingmodel.net.PSRoIPool([\\'conv_cls\\',\\'rois\\'],[\\'psroipooled_cls\\',\\'_mapping_channel_cls\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=model.num_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_cls\\',\\'cls_score_4d\\',kernel=cfg.RFCN.PS_GRID_SIZE)model.net.Reshape(\\'cls_score_4d\\',[\\'cls_score\\',\\'_cls_scores_shape\\'],shape=(-1,cfg.MODEL.NUM_CLASSES))ifnotmodel.train:model.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#BboxregressionPSRoIpoolingmodel.net.PSRoIPool([\\'conv_bbox_pred\\',\\'rois\\'],[\\'psroipooled_bbox\\',\\'_mapping_channel_bbox\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=4*num_bbox_reg_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_bbox\\',\\'bbox_pred\\',kernel=cfg.RFCN.PS_GRID_SIZE)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ImplementsResNetandResNeXt.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.netimportget_group_gn#----------------------------------------------------------------------------##Bitsforspecificarchitectures(ResNet50,ResNet101,...)#----------------------------------------------------------------------------#defadd_ResNet50_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,6))defadd_ResNet50_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,6,3))defadd_ResNet101_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,23))defadd_ResNet101_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,23,3))defadd_ResNet152_conv5_body(model):returnadd_ResNet_convX_body(model,(3,8,36,3))#----------------------------------------------------------------------------##GenericResNetcomponents#----------------------------------------------------------------------------#defadd_stage(model,prefix,blob_in,n,dim_in,dim_out,dim_inner,dilation,stride_init=2):\"\"\"AddaResNetstagetothemodelbystackingnresidualblocks.\"\"\"#e.g.,prefix=res2foriinrange(n):blob_in=add_residual_block(model,\\'{}_{}\\'.format(prefix,i),blob_in,dim_in,dim_out,dim_inner,dilation,stride_init,#Notusinginplaceforthelastblock;#itmaybefetchedexternallyorusedbyFPNinplace_sum=i<n-1)dim_in=dim_outreturnblob_in,dim_indefadd_ResNet_convX_body(model,block_counts):\"\"\"AddaResNetbodyfrominputdataupthroughtheres5(akaconv5)stage.Thefinalres5/conv5stagemaybeoptionallyexcluded(henceconvX,whereX=4or5).\"\"\"freeze_at=cfg.TRAIN.FREEZE_ATassertfreeze_atin[0,2,3,4,5]#addthestem(bydefault,conv1andpool1withbn;cansupportgn)p,dim_in=globals()[cfg.RESNETS.STEM_FUNC](model,\\'data\\')dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUP(n1,n2,n3)=block_counts[:3]s,dim_in=add_stage(model,\\'res2\\',p,n1,dim_in,256,dim_bottleneck,1)iffreeze_at==2:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res3\\',s,n2,dim_in,512,dim_bottleneck*2,1)iffreeze_at==3:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res4\\',s,n3,dim_in,1024,dim_bottleneck*4,1)iffreeze_at==4:model.StopGradient(s,s)iflen(block_counts)==4:n4=block_counts[3]s,dim_in=add_stage(model,\\'res5\\',s,n4,dim_in,2048,dim_bottleneck*8,cfg.RESNETS.RES5_DILATION)iffreeze_at==5:model.StopGradient(s,s)returns,dim_in,1./32.*cfg.RESNETS.RES5_DILATIONelse:returns,dim_in,1./16.defadd_ResNet_roi_conv5_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddsanRoIfeaturetransformation(e.g.,RoIpooling)followedbyares5/conv5headappliedtoeachRoI.\"\"\"#TODO(rbg):ThiscontainsFastR-CNNspecificconfigoptionsmakingitnon-#reusable;makethismoregenericwithmodel-specificwrappersmodel.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=cfg.FAST_RCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUPstride_init=int(cfg.FAST_RCNN.ROI_XFORM_RESOLUTION/7)s,dim_in=add_stage(model,\\'res5\\',\\'pool5\\',3,dim_in,2048,dim_bottleneck*8,1,stride_init)s=model.AveragePool(s,\\'res5_pool\\',kernel=7)returns,2048defadd_residual_block(model,prefix,blob_in,dim_in,dim_out,dim_inner,dilation,stride_init=2,inplace_sum=False):\"\"\"Addaresidualblocktothemodel.\"\"\"#prefix=res_,e.g.,res2_3#Maxpoolingisperformedpriortothefirststage(whichisuniquely#distinguishedbydim_in=64),thuswekeepstride=1forthefirststagestride=stride_initif(dim_in!=dim_outanddim_in!=64anddilation==1)else1#transformationblobtr=globals()[cfg.RESNETS.TRANS_FUNC](model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,group=cfg.RESNETS.NUM_GROUPS,dilation=dilation)#sum->ReLU#shortcutfunction:bydefaultusingbn;supportgnadd_shortcut=globals()[cfg.RESNETS.SHORTCUT_FUNC]sc=add_shortcut(model,prefix,blob_in,dim_in,dim_out,stride)ifinplace_sum:s=model.net.Sum([tr,sc],tr)else:s=model.net.Sum([tr,sc],prefix+\\'_sum\\')returnmodel.Relu(s,s)#------------------------------------------------------------------------------#variousshortcuts(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):\"\"\"Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"ifdim_in==dim_out:returnblob_inc=model.Conv(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,stride=stride,no_bias=1)returnmodel.AffineChannel(c,prefix+\\'_branch1_bn\\',dim=dim_out)defbasic_gn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):ifdim_in==dim_out:returnblob_in#outputnameisprefix+\\'_branch1_gn\\'returnmodel.ConvGN(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=stride,pad=0,group=1,)#------------------------------------------------------------------------------#variousstems(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem.Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"dim=64p=model.Conv(data,\\'conv1\\',3,dim,7,pad=3,stride=2,no_bias=1)p=model.AffineChannel(p,\\'res_conv1_bn\\',dim=dim,inplace=True)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dimdefbasic_gn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem(usingGN)\"\"\"dim=64p=model.ConvGN(data,\\'conv1\\',3,dim,7,group_gn=get_group_gn(dim),pad=3,stride=2)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dim#------------------------------------------------------------------------------#varioustransformations(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbottleneck_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"Addabottlenecktransformationtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->BN->ReLUcur=model.ConvAffine(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,stride=str1x1,pad=0,inplace=True)cur=model.Relu(cur,cur)#conv3x3->BN->ReLUcur=model.ConvAffine(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,stride=str3x3,pad=1*dilation,dilation=dilation,group=group,inplace=True)cur=model.Relu(cur,cur)#conv1x1->BN(noReLU)#NB:fornowthisAffineChannelopcannotbein-placeduetoabuginC2#gradientcomputationforgraphslikethiscur=model.ConvAffine(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,stride=1,pad=0,inplace=False)returncurdefbottleneck_gn_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"AddabottlenecktransformationwithGroupNormtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->GN->ReLUcur=model.ConvGN(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,group_gn=get_group_gn(dim_inner),stride=str1x1,pad=0,)cur=model.Relu(cur,cur)#conv3x3->GN->ReLUcur=model.ConvGN(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,group_gn=get_group_gn(dim_inner),stride=str3x3,pad=1*dilation,dilation=dilation,group=group,)cur=model.Relu(cur,cur)#conv1x1->GN(noReLU)cur=model.ConvGN(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=1,pad=0,)returncur#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingkeypointsinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->keypointhead->keypointoutput->loss...->Feature/MapThekeypointheadproducesafeaturerepresentationoftheRoIforthepurposeofkeypointprediction.Thekeypointoutputmoduleconvertsthefeaturerepresentationintokeypointheatmaps.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##KeypointR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_keypoint_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNkeypointspecificoutputs:keypointheatmaps.\"\"\"#NxKxHxWupsample_heatmap=(cfg.KRCNN.UP_SCALE>1)ifcfg.KRCNN.USE_DECONV:#ApplyConvTransposetothefeaturerepresentation;resultsin2x#upsamplingblob_in=model.ConvTranspose(blob_in,\\'kps_deconv\\',dim,cfg.KRCNN.DECONV_DIM,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'kps_deconv\\',\\'kps_deconv\\')dim=cfg.KRCNN.DECONV_DIMifupsample_heatmap:blob_name=\\'kps_score_lowres\\'else:blob_name=\\'kps_score\\'ifcfg.KRCNN.USE_DECONV_OUTPUT:#UseConvTransposetopredictheatmaps;resultsin2xupsamplingblob_out=model.ConvTranspose(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))else:#UseConvtopredictheatmaps;doesnoupsamplingblob_out=model.Conv(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=1,pad=0,stride=1,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifupsample_heatmap:#Increaseheatmapoutputsizeviabilinearupsamplingblob_out=model.BilinearInterpolation(blob_out,\\'kps_score\\',cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.UP_SCALE)returnblob_outdefadd_keypoint_losses(model):\"\"\"AddMaskR-CNNkeypointspecificlosses.\"\"\"#Reshapeinputfrom(N,K,H,W)to(NK,HW)model.net.Reshape([\\'kps_score\\'],[\\'kps_score_reshaped\\',\\'_kps_score_old_shape\\'],shape=(-1,cfg.KRCNN.HEATMAP_SIZE*cfg.KRCNN.HEATMAP_SIZE))#Softmaxacross**space**(woahh....space!)#Note:thisisnotwhatiscommonlycalled\"spatialsoftmax\"#(i.e.,softmaxappliedalongthechanneldimensionateachspatial#location);Thisissoftmaxappliedoverasetofspatiallocations(i.e.,#eachspatiallocationisa\"class\").kps_prob,loss_kps=model.net.SoftmaxWithLoss([\\'kps_score_reshaped\\',\\'keypoint_locations_int32\\',\\'keypoint_weights\\'],[\\'kps_prob\\',\\'loss_kps\\'],scale=cfg.KRCNN.LOSS_WEIGHT/cfg.NUM_GPUS,spatial=0)ifnotcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS:#Discussion:thesoftmaxlossabovewillaveragethelossbythesumof#keypoint_weights,i.e.thetotalnumberofvisiblekeypoints.Since#thenumberofvisiblekeypointscanvarysignificantlybetween#minibatches,thishastheeffectofup-weightingtheimportanceof#minibatcheswithfewvisiblekeypoints.(Imaginetheextremecaseof#onlyonevisiblekeypointversusN:inthecaseofN,eachone#contributes1/Ntothegradientcomparedtothesinglekeypoint#determiningthegradientdirection).Instead,wecannormalizethe#lossbythetotalnumberofkeypoints,ifitwerethecasethatall#keypointswerevisibleinafullminibatch.(Returningtotheexample,#thismeansthattheonevisiblekeypointcontributesasmuchaseach#oftheNkeypoints.)model.StopGradient(\\'keypoint_loss_normalizer\\',\\'keypoint_loss_normalizer\\')loss_kps=model.net.Mul([\\'loss_kps\\',\\'keypoint_loss_normalizer\\'],\\'loss_kps_normalized\\')loss_gradients=blob_utils.get_loss_gradients(model,[loss_kps])model.AddLosses(loss_kps)returnloss_gradients#----------------------------------------------------------------------------##Keypointheads#----------------------------------------------------------------------------#defadd_ResNet_roi_conv5_head_for_keypoints(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforMaskR-CNNkeypointprediction.\"\"\"model.RoIFeatureTransform(blob_in,\\'_[pose]_pool5\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)#Usingtheprefix\\'_[pose]_\\'to\\'res5\\'enablesinitializingthehead\\'s#parametersusingpretrained\\'res5\\'parametersifgiven(see#utils.net.initialize_from_weights_file)s,dim_in=ResNet.add_stage(model,\\'_[pose]_res5\\',\\'_[pose]_pool5\\',3,dim_in,2048,512,cfg.KRCNN.DILATION,stride_init=int(cfg.KRCNN.ROI_XFORM_RESOLUTION/7))returns,2048defadd_roi_pose_head_v1convX(model,blob_in,dim_in,spatial_scale):\"\"\"AddaMaskR-CNNkeypointhead.v1convXdesign:X*(conv).\"\"\"hidden_dim=cfg.KRCNN.CONV_HEAD_DIMkernel_size=cfg.KRCNN.CONV_HEAD_KERNELpad_size=kernel_size//2current=model.RoIFeatureTransform(blob_in,\\'_[pose]_roi_feat\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)foriinrange(cfg.KRCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'conv_fcn\\'+str(i+1),dim_in,hidden_dim,kernel_size,stride=1,pad=pad_size,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimreturncurrent,hidden_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectronmodelconstructionfunctions.Detectronsupportsalargenumberofmodeltypes.Theconfigurationspaceislarge.Togetasense,agivenmodelisinelementinthecartesianproductof:-backbone(e.g.,VGG16,ResNet,ResNeXt)-FPN(onoroff)-RPNonly(justproposals)-FixedproposalsforFastR-CNN,RFCN,MaskR-CNN(withorwithoutkeypoints)-End-to-endmodelwithRPN+FastR-CNN(i.e.,FasterR-CNN),MaskR-CNN,...-Different\"head\"choicesforthemodel-...manyconfigurationoptions...Agivenmodelismadebycombiningmanybasiccomponents.Theresultisflexiblethoughsomewhatcomplextounderstandatfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportimportlibimportloggingfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.modeling.detectorimportDetectionModelHelperfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.modeling.fast_rcnn_headsasfast_rcnn_headsimportdetectron.modeling.keypoint_rcnn_headsaskeypoint_rcnn_headsimportdetectron.modeling.mask_rcnn_headsasmask_rcnn_headsimportdetectron.modeling.name_compatasname_compatimportdetectron.modeling.optimizerasoptimimportdetectron.modeling.retinanet_headsasretinanet_headsimportdetectron.modeling.rfcn_headsasrfcn_headsimportdetectron.modeling.rpn_headsasrpn_headsimportdetectron.roi_data.minibatchasroi_data_minibatchimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)#----------------------------------------------------------------------------##Genericrecomposablemodelbuilders##Forexample,youcancreateaFastR-CNNmodelwiththeResNet-50-C4backbone#withtheconfiguration:##MODEL:#TYPE:generalized_rcnn#CONV_BODY:ResNet.add_ResNet50_conv4_body#ROI_HEAD:ResNet.add_ResNet_roi_conv5_head#----------------------------------------------------------------------------#defgeneralized_rcnn(model):\"\"\"Thismodeltypehandles:-FastR-CNN-RPNonly(notintegratedwithFastR-CNN)-FasterR-CNN(stagewisetrainingfromNIPSpaper)-FasterR-CNN(end-to-endjointtraining)-MaskR-CNN(stagewisetrainingfromNIPSpaper)-MaskR-CNN(end-to-endjointtraining)\"\"\"returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=cfg.TRAIN.FREEZE_CONV_BODY)defrfcn(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_rfcn_model(model,get_func(cfg.MODEL.CONV_BODY))defretinanet(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_retinanet_model(model,get_func(cfg.MODEL.CONV_BODY))#----------------------------------------------------------------------------##Helperfunctionsforbuildingvariousre-usablenetworkbits#----------------------------------------------------------------------------#defcreate(model_type_func,train=False,gpu_id=0):\"\"\"Genericmodelcreationfunctionthatdispatchestospecificmodelbuildingfunctions.Bydefault,thisfunctionwillgenerateadataparallelmodelconfiguredtorunoncfg.NUM_GPUSdevices.However,youcanrestrictittobuildamodeltargetedtoaspecificGPUbyspecifyinggpu_id.Thisisusedbyoptimizer.build_data_parallel_model()duringtesttime.\"\"\"model=DetectionModelHelper(name=model_type_func,train=train,num_classes=cfg.MODEL.NUM_CLASSES,init_params=train)model.only_build_forward_pass=Falsemodel.target_gpu_id=gpu_idreturnget_func(model_type_func)(model)defget_func(func_name):\"\"\"Helpertoreturnafunctionobjectbyname.func_namemustidentifyafunctioninthismoduleorthepathtoafunctionrelativetothebase\\'modeling\\'module.\"\"\"iffunc_name==\\'\\':returnNonenew_func_name=name_compat.get_new_name(func_name)ifnew_func_name!=func_name:logger.warn(\\'Remappingoldfunctionname:{}->{}\\'.format(func_name,new_func_name))func_name=new_func_nametry:parts=func_name.split(\\'.\\')#Referstoafunctioninthismoduleiflen(parts)==1:returnglobals()[parts[0]]#Otherwise,assumewe\\'rereferencingamoduleundermodelingmodule_name=\\'detectron.modeling.\\'+\\'.\\'.join(parts[:-1])module=importlib.import_module(module_name)returngetattr(module,parts[-1])exceptException:logger.error(\\'Failedtofindfunction:{}\\'.format(func_name))raisedefbuild_generic_detection_model(model,add_conv_body_func,add_roi_box_head_func=None,add_roi_mask_head_func=None,add_roi_keypoint_head_func=None,freeze_conv_body=False):def_single_gpu_build_func(model):\"\"\"BuildthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"#Addtheconvbody(called\"backbonearchitecture\"inpapers)#E.g.,ResNet-50,ResNet-50-FPN,ResNeXt-101-FPN,etc.blob_conv,dim_conv,spatial_scale_conv=add_conv_body_func(model)iffreeze_conv_body:forbinc2_utils.BlobReferenceList(blob_conv):model.StopGradient(b,b)ifnotmodel.train:#==inference#Createanetthatcanbeusedtoexecutetheconvbodyonanimage#(withoutalsoexecutingRPNoranyothernetworkheads)model.conv_body_net=model.net.Clone(\\'conv_body_net\\')head_loss_gradients={\\'rpn\\':None,\\'box\\':None,\\'mask\\':None,\\'keypoints\\':None,}ifcfg.RPN.RPN_ON:#AddtheRPNheadhead_loss_gradients[\\'rpn\\']=rpn_heads.add_generic_rpn_outputs(model,blob_conv,dim_conv,spatial_scale_conv)ifcfg.FPN.FPN_ON:#AfteraddingtheRPNhead,restrictFPNblobsandscalesto#thoseusedintheRoIheadsblob_conv,spatial_scale_conv=_narrow_to_fpn_roi_levels(blob_conv,spatial_scale_conv)ifnotcfg.MODEL.RPN_ONLY:#AddtheFastR-CNNheadhead_loss_gradients[\\'box\\']=_add_fast_rcnn_head(model,add_roi_box_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.MASK_ON:#Addthemaskheadhead_loss_gradients[\\'mask\\']=_add_roi_mask_head(model,add_roi_mask_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.KEYPOINTS_ON:#Addthekeypointheadhead_loss_gradients[\\'keypoint\\']=_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_conv,dim_conv,spatial_scale_conv)ifmodel.train:loss_gradients={}forlginhead_loss_gradients.values():iflgisnotNone:loss_gradients.update(lg)returnloss_gradientselse:returnNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldef_narrow_to_fpn_roi_levels(blobs,spatial_scales):\"\"\"ReturnonlytheblobsandspatialscalesthatwillbeusedforRoIheads.Inputs`blobs`and`spatial_scales`mayincludeextrablobsandscalesthatareusedforRPNproposals,butnotforRoIheads.\"\"\"#CodeonlysupportscasewhenRPNandROIminlevelsarethesameassertcfg.FPN.RPN_MIN_LEVEL==cfg.FPN.ROI_MIN_LEVEL#RPNmaxlevelcanbe>=toROImaxlevelassertcfg.FPN.RPN_MAX_LEVEL>=cfg.FPN.ROI_MAX_LEVEL#FPNRPNmaxlevelmightbe>FPNROImaxlevelinwhichcasewe#needtodiscardsomeleadingconvblobs(blobsareorderedfrom#max/coarsestleveltomin/finestlevel)num_roi_levels=cfg.FPN.ROI_MAX_LEVEL-cfg.FPN.ROI_MIN_LEVEL+1returnblobs[-num_roi_levels:],spatial_scales[-num_roi_levels:]def_add_fast_rcnn_head(model,add_roi_box_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"AddaFastR-CNNheadtothemodel.\"\"\"blob_frcn,dim_frcn=add_roi_box_head_func(model,blob_in,dim_in,spatial_scale_in)fast_rcnn_heads.add_fast_rcnn_outputs(model,blob_frcn,dim_frcn)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)else:loss_gradients=Nonereturnloss_gradientsdef_add_roi_mask_head(model,add_roi_mask_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addamaskpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthemaskheadblob_mask_head,dim_mask_head=add_roi_mask_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthemaskoutputblob_mask=mask_rcnn_heads.add_mask_rcnn_outputs(model,blob_mask_head,dim_mask_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenmaskpredictions.#Thisrequiresseparatenetsforboxandmaskprediction.#Soweextractthemaskpredictionnet,storeitasitsownnetwork,#thenrestoremodel.nettobethebbox-onlynetworkmodel.mask_net,blob_mask=c2_utils.SuffixNet(\\'mask_net\\',model.net,len(bbox_net.op),blob_mask)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=mask_rcnn_heads.add_mask_rcnn_losses(model,blob_mask)returnloss_gradientsdef_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addakeypointpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthekeypointheadblob_keypoint_head,dim_keypoint_head=add_roi_keypoint_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthekeypointoutputblob_keypoint=keypoint_rcnn_heads.add_keypoint_outputs(model,blob_keypoint_head,dim_keypoint_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenkeypointpredictions#Thisrequiresseparatenetsforboxandkeypointprediction.#Soweextractthekeypointpredictionnet,storeitasitsown#network,thenrestoremodel.nettobethebbox-onlynetworkmodel.keypoint_net,keypoint_blob_out=c2_utils.SuffixNet(\\'keypoint_net\\',model.net,len(bbox_net.op),blob_keypoint)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=keypoint_rcnn_heads.add_keypoint_losses(model)returnloss_gradientsdefbuild_generic_rfcn_model(model,add_conv_body_func,dim_reduce=None):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blob,dim,spatial_scale=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')rfcn_heads.add_rfcn_outputs(model,blob,dim,dim_reduce,spatial_scale)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldefbuild_generic_retinanet_model(model,add_conv_body_func,freeze_conv_body=False):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blobs,dim,spatial_scales=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')retinanet_heads.add_fpn_retinanet_outputs(model,blobs,dim,spatial_scales)ifmodel.train:loss_gradients=retinanet_heads.add_fpn_retinanet_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodel#----------------------------------------------------------------------------##Networkinputs#----------------------------------------------------------------------------#defadd_training_inputs(model,roidb=None):\"\"\"Createnetworkinputopsandblobsusedfortraining.Tobecalled*after*model_builder.create().\"\"\"#Implementationnotes:#Typically,onewouldcreatetheinputopsandthentherestofthenet.#However,creatingtheinputopsdependsonloadingthedataset,which#cantakeafewminutesforCOCO.#Weprefertoavoidwaitingsodebuggingcanfailfast.#Thus,wecreatethenet*withoutinputops*priortoloadingthe#dataset,andthenaddtheinputopsafterloadingthedataset.#Sincewedeferinputopcreation,weneedtodoalittlebitofsurgery#toplacetheinputopsatthestartofthenetworkoplist.assertmodel.train,\\'Traininginputscanonlybeaddedtoatrainablemodel\\'ifroidbisnotNone:#Tomakedebuggingeasieryoucansetcfg.DATA_LOADER.NUM_THREADS=1model.roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)orig_num_op=len(model.net._net.op)blob_names=roi_data_minibatch.get_minibatch_blob_names(is_training=True)forgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):forblob_nameinblob_names:workspace.CreateBlob(core.ScopedName(blob_name))model.net.DequeueBlobs(model.roi_data_loader._blobs_queue_name,blob_names)#Alittleopsurgerytomoveinputopstothestartofthenetdiff=len(model.net._net.op)-orig_num_opnew_op=model.net._net.op[-diff:]+model.net._net.op[:-diff]delmodel.net._net.op[:]model.net._net.op.extend(new_op)defadd_inference_inputs(model):\"\"\"Createnetworkinputblobsusedforinference.\"\"\"defcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)create_input_blobs_for_net(model.net.Proto())ifcfg.MODEL.MASK_ON:create_input_blobs_for_net(model.mask_net.Proto())ifcfg.MODEL.KEYPOINTS_ON:create_input_blobs_for_net(model.keypoint_net.Proto())#----------------------------------------------------------------------------##**********************DEPRECATEDFUNCTIONALITYBELOW**********************##----------------------------------------------------------------------------##----------------------------------------------------------------------------##Hardcodedfunctionstocreatevarioustypesofcommonmodels##***Thistypeofmodeldefinitionisdeprecated***#***Usethegenericcomposableversionsinstead***##----------------------------------------------------------------------------#importdetectron.modeling.ResNetasResNetimportdetectron.modeling.VGG16asVGG16importdetectron.modeling.VGG_CNN_M_1024asVGG_CNN_M_1024deffast_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`.\\')returngeneralized_rcnn(model)defmask_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:True`\\')returngeneralized_rcnn(model)defkeypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defmask_and_keypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:Trueand``MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defrpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`\\')returngeneralized_rcnn(model)deffpn_rpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`andFPNenabledviaconfigs\\')returngeneralized_rcnn(model)deffaster_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.FASTER_RCNN:True`\\')returngeneralized_rcnn(model)deffast_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),freeze_conv_body=True)defrpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)deffpn_rpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)defmask_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),freeze_conv_body=True)defkeypoint_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=True)#----------------------------------------------------------------------------##FastR-CNNmodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,VGG_CNN_M_1024.add_VGG_CNN_M_1024_roi_fc_head)defVGG16_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet50_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)defResNet101_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)#----------------------------------------------------------------------------##RPN-onlymodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_rpn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body)defVGG16_rpn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body)defResNet50_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body)defResNet101_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body)defVGG_CNN_M_1024_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,freeze_conv_body=True)defVGG16_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,freeze_conv_body=True)defResNet50_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,freeze_conv_body=True)defResNet101_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,freeze_conv_body=True)#----------------------------------------------------------------------------##FasterR-CNNmodels#----------------------------------------------------------------------------#defVGG16_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)#----------------------------------------------------------------------------##R-FCNmodels#----------------------------------------------------------------------------#defResNet50_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet50_conv5_body,dim_reduce=1024)defResNet101_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet101_conv5_body,dim_reduce=1024)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforusingaFeaturePyramidNetwork(FPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcollectionsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utils#Lowestandhighestpyramidlevelsinthebackbonenetwork.ForFPN,weassume#thatallnetworkshave5spatialreductions,eachbyafactorof2.Level1#wouldcorrespondtotheinputimage,henceitdoesnotmakesensetouseit.LOWEST_BACKBONE_LVL=2#E.g.,\"conv2\"-likelevelHIGHEST_BACKBONE_LVL=5#E.g.,\"conv5\"-likelevel#----------------------------------------------------------------------------##FPNwithResNet#----------------------------------------------------------------------------#defadd_fpn_ResNet50_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5)defadd_fpn_ResNet50_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5,P2only=True)defadd_fpn_ResNet101_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5)defadd_fpn_ResNet101_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5,P2only=True)defadd_fpn_ResNet152_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5)defadd_fpn_ResNet152_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5,P2only=True)#----------------------------------------------------------------------------##FunctionsforboltingFPNontoabackbonearchitectures#----------------------------------------------------------------------------#defadd_fpn_onto_conv_body(model,conv_body_func,fpn_level_info_func,P2only=False):\"\"\"AddthespecifiedconvbodytothemodelandthenaddFPNlevelstoit.\"\"\"#Note:blobs_convisinrevsersedorder:[fpn5,fpn4,fpn3,fpn2]#similarlyfordims_conv:[2048,1024,512,256]#similarlyforspatial_scales_fpn:[1/32,1/16,1/8,1/4]conv_body_func(model)blobs_fpn,dim_fpn,spatial_scales_fpn=add_fpn(model,fpn_level_info_func())ifP2only:#useonlythefinestlevelreturnblobs_fpn[-1],dim_fpn,spatial_scales_fpn[-1]else:#usealllevelsreturnblobs_fpn,dim_fpn,spatial_scales_fpndefadd_fpn(model,fpn_level_info):\"\"\"AddFPNconnectionsbasedonthemodeldescribedintheFPNpaper.\"\"\"#FPNlevelsarebuiltstartingfromthehighest/coarestlevelofthe#backbone(usually\"conv5\").Firstwebuilddown,recursivelyconstructing#lower/finerresolutionFPNlevels.Thenwebuildup,constructinglevels#thatareevenhigher/coarserthanthestartinglevel.fpn_dim=cfg.FPN.DIMmin_level,max_level=get_min_max_levels()#CountthenumberofbackbonestagesthatwewillgenerateFPNlevelsfor#startingfromthecoarestbackbonestage(usuallythe\"conv5\"-likelevel)#E.g.,ifthebackbonelevelinfodefinesstages4stages:\"conv5\",#\"conv4\",...\"conv2\"andmin_level=2,thenweendupwith4-(2-2)=4#backbonestagestoaddFPNto.num_backbone_stages=(len(fpn_level_info.blobs)-(min_level-LOWEST_BACKBONE_LVL))lateral_input_blobs=fpn_level_info.blobs[:num_backbone_stages]output_blobs=[\\'fpn_inner_{}\\'.format(s)forsinfpn_level_info.blobs[:num_backbone_stages]]fpn_dim_lateral=fpn_level_info.dimsxavier_fill=(\\'XavierFill\\',{})#Forthecoarsestbackbonelevel:1x1convonlyseedsrecursionifcfg.FPN.USE_GN:#useGroupNormc=model.ConvGN(lateral_input_blobs[0],output_blobs[0],#note:thisisaprefixdim_in=fpn_dim_lateral[0],dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))output_blobs[0]=c#renameitelse:model.Conv(lateral_input_blobs[0],output_blobs[0],dim_in=fpn_dim_lateral[0],dim_out=fpn_dim,kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))##Step1:recursivelybuilddownstartingfromthecoarsestbackbonelevel##Forotherlevelsaddtop-downandlateralconnectionsforiinrange(num_backbone_stages-1):add_topdown_lateral_module(model,output_blobs[i],#top-downbloblateral_input_blobs[i+1],#lateralbloboutput_blobs[i+1],#nextoutputblobfpn_dim,#outputdimensionfpn_dim_lateral[i+1]#lateralinputdimension)#Post-hocscale-specific3x3convsblobs_fpn=[]spatial_scales=[]foriinrange(num_backbone_stages):ifcfg.FPN.USE_GN:#useGroupNormfpn_blob=model.ConvGN(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))else:fpn_blob=model.Conv(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))blobs_fpn+=[fpn_blob]spatial_scales+=[fpn_level_info.spatial_scales[i]]##Step2:buildupstartingfromthecoarsestbackbonelevel##CheckifweneedtheP6featuremapifnotcfg.FPN.EXTRA_CONV_LEVELSandmax_level==HIGHEST_BACKBONE_LVL+1:#OriginalFPNP6levelimplementationfromourCVPR\\'17FPNpaperP6_blob_in=blobs_fpn[0]P6_name=P6_blob_in+\\'_subsampled_2x\\'#Usemaxpoolingtosimulatestride2subsamplingP6_blob=model.MaxPool(P6_blob_in,P6_name,kernel=1,pad=0,stride=2)blobs_fpn.insert(0,P6_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)#CoarserFPNlevelsintroducedforRetinaNetifcfg.FPN.EXTRA_CONV_LEVELSandmax_level>HIGHEST_BACKBONE_LVL:fpn_blob=fpn_level_info.blobs[0]dim_in=fpn_level_info.dims[0]foriinrange(HIGHEST_BACKBONE_LVL+1,max_level+1):fpn_blob_in=fpn_blobifi>HIGHEST_BACKBONE_LVL+1:fpn_blob_in=model.Relu(fpn_blob,fpn_blob+\\'_relu\\')fpn_blob=model.Conv(fpn_blob_in,\\'fpn_\\'+str(i),dim_in=dim_in,dim_out=fpn_dim,kernel=3,pad=1,stride=2,weight_init=xavier_fill,bias_init=const_fill(0.0))dim_in=fpn_dimblobs_fpn.insert(0,fpn_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)returnblobs_fpn,fpn_dim,spatial_scalesdefadd_topdown_lateral_module(model,fpn_top,fpn_lateral,fpn_bottom,dim_top,dim_lateral):\"\"\"Addatop-downlateralmodule.\"\"\"#Lateral1x1convifcfg.FPN.USE_GN:#useGroupNormlat=model.ConvGN(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,group_gn=get_group_gn(dim_top),kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))else:lat=model.Conv(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))#Top-down2xupsamplingtd=model.net.UpsampleNearest(fpn_top,fpn_bottom+\\'_topdown\\',scale=2)#Sumlateralandtop-downmodel.net.Sum([lat,td],fpn_bottom)defget_min_max_levels():\"\"\"TheminandmaxFPNlevelsrequiredforsupportingRPNand/orRoItransformoperationsonmultipleFPNlevels.\"\"\"min_level=LOWEST_BACKBONE_LVLmax_level=HIGHEST_BACKBONE_LVLifcfg.FPN.MULTILEVEL_RPNandnotcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.RPN_MAX_LEVELmin_level=cfg.FPN.RPN_MIN_LEVELifnotcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.ROI_MAX_LEVELmin_level=cfg.FPN.ROI_MIN_LEVELifcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=max(cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.ROI_MAX_LEVEL)min_level=min(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.ROI_MIN_LEVEL)returnmin_level,max_level#----------------------------------------------------------------------------##RPNwithanFPNbackbone#----------------------------------------------------------------------------#defadd_fpn_rpn_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"AddRPNonFPNspecificoutputs.\"\"\"num_anchors=len(cfg.FPN.RPN_ASPECT_RATIOS)dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scales[k_max-lvl]#inreversedorderslvl=str(lvl)iflvl==k_min:#Createconvopswithrandomlyinitializedweightsand#zeroedbiasesforthefirstFPNlevel;thesewillbesharedby#allotherFPNlevels#RPNhiddenrepresentationconv_rpn_fpn=model.Conv(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.Conv(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.Conv(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))else:#Shareweightsandbiasessk_min=str(k_min)#RPNhiddenrepresentationconv_rpn_fpn=model.ConvShared(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight=\\'conv_rpn_fpn\\'+sk_min+\\'_w\\',bias=\\'conv_rpn_fpn\\'+sk_min+\\'_b\\')model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_b\\')#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_b\\')ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededlvl_anchors=generate_anchors(stride=2.**lvl,sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),),aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOS)rpn_cls_probs_fpn=model.net.Sigmoid(rpn_cls_logits_fpn,\\'rpn_cls_probs_fpn\\'+slvl)model.GenerateProposals([rpn_cls_probs_fpn,rpn_bbox_pred_fpn,\\'im_info\\'],[\\'rpn_rois_fpn\\'+slvl,\\'rpn_roi_probs_fpn\\'+slvl],anchors=lvl_anchors,spatial_scale=sc)defadd_fpn_rpn_losses(model):\"\"\"AddRPNonFPNspecificlosses.\"\"\"loss_gradients={}forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):slvl=str(lvl)#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide_fpn\\'+slvl,\\'rpn_cls_logits_fpn\\'+slvl],\\'rpn_labels_int32_fpn\\'+slvl)forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide_fpn\\'+slvl,\\'rpn_bbox_pred_fpn\\'+slvl],\\'rpn_bbox_\\'+key+\\'_fpn\\'+slvl)loss_rpn_cls_fpn=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits_fpn\\'+slvl,\\'rpn_labels_int32_fpn\\'+slvl],\\'loss_rpn_cls_fpn\\'+slvl,normalize=0,scale=(model.GetLossScale()/cfg.TRAIN.RPN_BATCH_SIZE_PER_IM/cfg.TRAIN.IMS_PER_BATCH))#Normalizationby(1)RPN_BATCH_SIZE_PER_IMand(2)IMS_PER_BATCHis#handledby(1)settingbboxoutsideweightsand(2)SmoothL1Loss#normalizesbyIMS_PER_BATCHloss_rpn_bbox_fpn=model.net.SmoothL1Loss([\\'rpn_bbox_pred_fpn\\'+slvl,\\'rpn_bbox_targets_fpn\\'+slvl,\\'rpn_bbox_inside_weights_fpn\\'+slvl,\\'rpn_bbox_outside_weights_fpn\\'+slvl],\\'loss_rpn_bbox_fpn\\'+slvl,beta=1./9.,scale=model.GetLossScale(),)loss_gradients.update(blob_utils.get_loss_gradients(model,[loss_rpn_cls_fpn,loss_rpn_bbox_fpn]))model.AddLosses([\\'loss_rpn_cls_fpn\\'+slvl,\\'loss_rpn_bbox_fpn\\'+slvl])returnloss_gradients#----------------------------------------------------------------------------##HelperfunctionsforworkingwithmultilevelFPNRoIs#----------------------------------------------------------------------------#defmap_rois_to_fpn_levels(rois,k_min,k_max):\"\"\"DeterminewhichFPNleveleachRoIinasetofRoIsshouldmaptobasedontheheuristicintheFPNpaper.\"\"\"#Computelevelidss=np.sqrt(box_utils.boxes_area(rois))s0=cfg.FPN.ROI_CANONICAL_SCALE#default:224lvl0=cfg.FPN.ROI_CANONICAL_LEVEL#default:4#Eqn.(1)inFPNpapertarget_lvls=np.floor(lvl0+np.log2(s/s0+1e-6))target_lvls=np.clip(target_lvls,k_min,k_max)returntarget_lvlsdefadd_multilevel_roi_blobs(blobs,blob_prefix,rois,target_lvls,lvl_min,lvl_max):\"\"\"AddRoIblobsformultipleFPNlevelstotheblobsdict.blobs:adictmappingfromblobnametonumpyndarrayblob_prefix:nameprefixtousefortheFPNblobsrois:thesourceroisasa2Dnumpyarrayofshape(N,5)whereeachrowisanroiandthecolumnsencode(batch_idx,x1,y1,x2,y2)target_lvls:numpyarrayofshape(N,)indicatingwhichFPNleveleachroiinroisshouldbeassignedtolvl_min:thefinest(highestresolution)FPNlevel(e.g.,2)lvl_max:thecoarest(lowestresolution)FPNlevel(e.g.,6)\"\"\"rois_idx_order=np.empty((0,))rois_stacked=np.zeros((0,5),dtype=np.float32)#forassertforlvlinrange(lvl_min,lvl_max+1):idx_lvl=np.where(target_lvls==lvl)[0]blobs[blob_prefix+\\'_fpn\\'+str(lvl)]=rois[idx_lvl,:]rois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_stacked=np.vstack([rois_stacked,blobs[blob_prefix+\\'_fpn\\'+str(lvl)]])rois_idx_restore=np.argsort(rois_idx_order).astype(np.int32,copy=False)blobs[blob_prefix+\\'_idx_restore_int32\\']=rois_idx_restore#Sanitycheckthatrestoreorderiscorrectassert(rois_stacked[rois_idx_restore]==rois).all()#----------------------------------------------------------------------------##FPNlevelinfoforstages5,4,3,2forselectmodels(morecanbeadded)#----------------------------------------------------------------------------#FpnLevelInfo=collections.namedtuple(\\'FpnLevelInfo\\',[\\'blobs\\',\\'dims\\',\\'spatial_scales\\'])deffpn_level_info_ResNet50_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_5_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet101_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_22_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet152_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_35_sum\\',\\'res3_7_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forclassificationandboundingboxprediction.Thedesignisasfollows:...->RoI----\\\\/->boxclsoutput->clsloss->RoIFeatureXform->boxhead...->Feature/\\\\->boxregoutput->reglossMapTheFastR-CNNheadproducesafeaturerepresentationoftheRoIforthepurposeofboundingboxclassificationandregression.Theboxoutputmoduleconvertsthefeaturerepresentationintoclassificationandregressionpredictions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##FastR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_fast_rcnn_outputs(model,blob_in,dim):\"\"\"AddRoIclassificationandboundingboxregressionoutputops.\"\"\"#Boxclassificationlayermodel.FC(blob_in,\\'cls_score\\',dim,model.num_classes,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.train:#==iftest#Onlyaddsoftmaxwhentesting;duringtrainingthesoftmaxiscombined#withthelabelcrossentropylossfornumericalstabilitymodel.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#Boxregressionlayernum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.FC(blob_in,\\'bbox_pred\\',dim,num_bbox_reg_classes*4,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))defadd_fast_rcnn_losses(model):\"\"\"AddlossesforRoIclassificationandboundingboxregression.\"\"\"cls_prob,loss_cls=model.net.SoftmaxWithLoss([\\'cls_score\\',\\'labels_int32\\'],[\\'cls_prob\\',\\'loss_cls\\'],scale=model.GetLossScale())loss_bbox=model.net.SmoothL1Loss([\\'bbox_pred\\',\\'bbox_targets\\',\\'bbox_inside_weights\\',\\'bbox_outside_weights\\'],\\'loss_bbox\\',scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_cls,loss_bbox])model.Accuracy([\\'cls_prob\\',\\'labels_int32\\'],\\'accuracy_cls\\')model.AddLosses([\\'loss_cls\\',\\'loss_bbox\\'])model.AddMetrics(\\'accuracy_cls\\')returnloss_gradients#----------------------------------------------------------------------------##Boxheads#----------------------------------------------------------------------------#defadd_roi_2mlp_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaReLUMLPwithtwohiddenlayers.\"\"\"hidden_dim=cfg.FAST_RCNN.MLP_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(roi_feat,\\'fc6\\',dim_in*roi_size*roi_size,hidden_dim)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',hidden_dim,hidden_dim)model.Relu(\\'fc7\\',\\'fc7\\')return\\'fc7\\',hidden_dimdefadd_roi_Xconv1fc_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,asareferenceifnotusingGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}),no_bias=0)current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dimdefadd_roi_Xconv1fc_gn_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,withGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.ConvGN(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,group_gn=get_group_gn(hidden_dim),stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingmasksinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->maskhead->maskoutput->loss...->Feature/MapThemaskheadproducesafeaturerepresentationoftheRoIforthepurposeofmaskprediction.Themaskoutputmoduleconvertsthefeaturerepresentationintoreal-valued(soft)masks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##MaskR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_mask_rcnn_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNspecificoutputs:eithermasklogitsorprobs.\"\"\"num_cls=cfg.MODEL.NUM_CLASSESifcfg.MRCNN.CLS_SPECIFIC_MASKelse1ifcfg.MRCNN.USE_FC_OUTPUT:#Predictmaskswithafullyconnectedlayer(ignore\\'fcn\\'intheblob#name)dim_fc=int(dim*(cfg.MRCNN.RESOLUTION/cfg.MRCNN.UPSAMPLE_RATIO)**2)blob_out=model.FC(blob_in,\\'mask_fcn_logits\\',dim_fc,num_cls*cfg.MRCNN.RESOLUTION**2,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))else:#PredictmaskusingConv#UseGaussianFillforclass-agnosticmaskprediction;fillsbasedon#fan-incanbetoolargeinthiscaseandcausedivergencefill=(cfg.MRCNN.CONV_INITifcfg.MRCNN.CLS_SPECIFIC_MASKelse\\'GaussianFill\\')blob_out=model.Conv(blob_in,\\'mask_fcn_logits\\',dim,num_cls,kernel=1,pad=0,stride=1,weight_init=(fill,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifcfg.MRCNN.UPSAMPLE_RATIO>1:blob_out=model.BilinearInterpolation(\\'mask_fcn_logits\\',\\'mask_fcn_logits_up\\',num_cls,num_cls,cfg.MRCNN.UPSAMPLE_RATIO)ifnotmodel.train:#==iftestblob_out=model.net.Sigmoid(blob_out,\\'mask_fcn_probs\\')returnblob_outdefadd_mask_rcnn_losses(model,blob_mask):\"\"\"AddMaskR-CNNspecificlosses.\"\"\"loss_mask=model.net.SigmoidCrossEntropyLoss([blob_mask,\\'masks_int32\\'],\\'loss_mask\\',scale=model.GetLossScale()*cfg.MRCNN.WEIGHT_LOSS_MASK)loss_gradients=blob_utils.get_loss_gradients(model,[loss_mask])model.AddLosses(\\'loss_mask\\')returnloss_gradients#----------------------------------------------------------------------------##Maskheads#----------------------------------------------------------------------------#defmask_rcnn_fcn_head_v1up4convs(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up4convs_gn(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2,withGroupNorm\"\"\"returnmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:2*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,2)defmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2.\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.Conv(current,\\'_[mask]_fcn\\'+str(i+1),dim_in,dim_inner,kernel=3,dilation=dilation,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2,withGroupNorm\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_mask_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.ConvGN(current,\\'_mask_fcn\\'+str(i+1),dim_in,dim_inner,group_gn=get_group_gn(dim_inner),kernel=3,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v0upshare(model,blob_in,dim_in,spatial_scale):\"\"\"UseaResNet\"conv5\"/\"stage5\"headformaskprediction.Weightsandcomputationaresharedwiththeconv5boxhead.Computationcanonlybesharedduringtraining,sinceinferenceiscascaded.v0upsharedesign:conv5,convT2x2.\"\"\"#Sinceboxandmaskheadareshared,thesemustmatchassertcfg.MRCNN.ROI_XFORM_RESOLUTION==cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONifmodel.train:#sharecomputationwithbboxheadattrainingtimedim_conv5=2048blob_conv5=model.net.SampleAs([\\'res5_2_sum\\',\\'roi_has_mask_int32\\'],[\\'_[mask]_res5_2_sum_sliced\\'])else:#re-computeattesttimeblob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDblob_mask=model.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),#stdonlyforgaussbias_init=const_fill(0.0))model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefmask_rcnn_fcn_head_v0up(model,blob_in,dim_in,spatial_scale):\"\"\"v0updesign:conv5,deconv2x2(noweightsharingwiththeboxhead).\"\"\"blob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDmodel.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(\\'GaussianFill\\',{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefadd_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforpredictingmasks.\"\"\"model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_pool5\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONstride_init=int(cfg.MRCNN.ROI_XFORM_RESOLUTION/7)#bydefault:2s,dim_in=ResNet.add_stage(model,\\'_[mask]_res5\\',\\'_[mask]_pool5\\',3,dim_in,2048,512,dilation,stride_init=stride_init)returns,2048#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG_CNN_M_1024from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG_CNN_M_1024_conv5_body(model):model.Conv(\\'data\\',\\'conv1\\',3,96,7,pad=0,stride=2)model.Relu(\\'conv1\\',\\'conv1\\')model.LRN(\\'conv1\\',\\'norm1\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm1\\',\\'pool1\\',kernel=3,pad=0,stride=2)model.StopGradient(\\'pool1\\',\\'pool1\\')#Noupdatesatconv1andbelow(norm1andpool1havenoparams,#sowecanstopgradientsbeforethem,too)model.Conv(\\'pool1\\',\\'conv2\\',96,256,5,pad=0,stride=2)model.Relu(\\'conv2\\',\\'conv2\\')model.LRN(\\'conv2\\',\\'norm2\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm2\\',\\'pool2\\',kernel=3,pad=0,stride=2)model.Conv(\\'pool2\\',\\'conv3\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv3\\',\\'conv3\\')model.Conv(\\'conv3\\',\\'conv4\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4\\',\\'conv4\\')model.Conv(\\'conv4\\',\\'conv5\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5\\',\\'conv5\\')returnblob_out,512,1./16.defadd_VGG_CNN_M_1024_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=6,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*6*6,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,1024)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,1024#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Optimizationoperatorgraphconstruction.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromcaffe2.pythonimportmujifromdetectron.core.configimportcfgimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)defbuild_data_parallel_model(model,single_gpu_build_func):\"\"\"BuildadataparallelmodelgivenafunctionthatbuildsthemodelonasingleGPU.\"\"\"ifmodel.only_build_forward_pass:single_gpu_build_func(model)elifmodel.train:all_loss_gradients=_build_forward_graph(model,single_gpu_build_func)#AddbackwardpassonallGPUsmodel.AddGradientOperators(all_loss_gradients)ifcfg.NUM_GPUS>1:_add_allreduce_graph(model)forgpu_idinrange(cfg.NUM_GPUS):#Afterallreduce,allGPUsperformSGDupdatesontheiridentical#paramsandgradientsinparallelwithc2_utils.NamedCudaScope(gpu_id):add_single_gpu_param_update_ops(model,gpu_id)else:#Test-timenetworkoperatesonsingleGPU#Test-timeparallelismisimplementedthroughmultiprocessingwithc2_utils.NamedCudaScope(model.target_gpu_id):single_gpu_build_func(model)def_build_forward_graph(model,single_gpu_build_func):\"\"\"ConstructtheforwardgraphoneachGPU.\"\"\"all_loss_gradients={}#WillincludelossgradientsfromallGPUs#BuildthemodeloneachGPUwithcorrectnameanddevicescopingforgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):all_loss_gradients.update(single_gpu_build_func(model))returnall_loss_gradientsdef_add_allreduce_graph(model):\"\"\"ConstructthegraphthatperformsAllreduceonthegradients.\"\"\"#Needtoall-reducetheper-GPUgradientsiftrainingwithmorethan1GPUall_params=model.TrainableParams()assertlen(all_params)%cfg.NUM_GPUS==0#ThemodelparametersarereplicatedoneachGPU,getthenumber#distinctparameterblobs(i.e.,thenumberofparameterblobson#eachGPU)params_per_gpu=int(len(all_params)/cfg.NUM_GPUS)withc2_utils.CudaScope(0):#Iterateoverdistinctparameterblobsforiinrange(params_per_gpu):#GradientsfromallGPUsforthisparameterblobgradients=[model.param_to_grad[p]forpinall_params[i::params_per_gpu]]iflen(gradients)>0:ifcfg.USE_NCCL:model.net.NCCLAllreduce(gradients,gradients)else:muji.Allreduce(model.net,gradients,reduced_affix=\\'\\')defadd_single_gpu_param_update_ops(model,gpu_id):#Learningrateof0isadummyvaluetobesetproperlyatthe#startoftraininglr=model.param_init_net.ConstantFill([],\\'lr\\',shape=[1],value=0.0)one=model.param_init_net.ConstantFill([],\\'one\\',shape=[1],value=1.0)wd=model.param_init_net.ConstantFill([],\\'wd\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY)#weightdecayofGroupNorm\\'sparameterswd_gn=model.param_init_net.ConstantFill([],\\'wd_gn\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY_GN)forparaminmodel.TrainableParams(gpu_id=gpu_id):logger.debug(\\'param\\'+str(param)+\\'willbeupdated\\')param_grad=model.param_to_grad[param]#Initializemomentumvectorparam_momentum=model.param_init_net.ConstantFill([param],param+\\'_momentum\\',value=0.0)ifparaminmodel.biases:#Specialtreatmentforbiases(mainlytomatchhistoricalimpl.#details):#(1)Donotapplyweightdecay#(2)Usea2xhigherlearningratemodel.Scale(param_grad,param_grad,scale=2.0)elifparaminmodel.gn_params:#SpecialtreatmentforGroupNorm\\'sparametersmodel.WeightedSum([param_grad,one,param,wd_gn],param_grad)elifcfg.SOLVER.WEIGHT_DECAY>0:#Applyweightdecaytonon-biasweightsmodel.WeightedSum([param_grad,one,param,wd],param_grad)#Updateparam_gradandparam_momentuminplacemodel.net.MomentumSGDUpdate([param_grad,param_momentum,lr,param],[param_grad,param_momentum,param],momentum=cfg.SOLVER.MOMENTUM)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"DefinesDetectionModelHelper,theclassthatrepresentsaDetectronmodel.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcaffe2.pythonimportcnnfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromcaffe2.python.modelingimportinitializersfromcaffe2.python.modeling.parameter_infoimportParameterTagsfromdetectron.core.configimportcfgfromdetectron.ops.collect_and_distribute_fpn_rpn_proposals\\\\importCollectAndDistributeFpnRpnProposalsOpfromdetectron.ops.generate_proposal_labelsimportGenerateProposalLabelsOpfromdetectron.ops.generate_proposalsimportGenerateProposalsOpimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classDetectionModelHelper(cnn.CNNModelHelper):def__init__(self,**kwargs):#HandleargsspecifictotheDetectionModelHelper,otherspassthrough#toCNNModelHelperself.train=kwargs.get(\\'train\\',False)self.num_classes=kwargs.get(\\'num_classes\\',-1)assertself.num_classes>0,\\'num_classesmustbe>0\\'forkin(\\'train\\',\\'num_classes\\'):ifkinkwargs:delkwargs[k]kwargs[\\'order\\']=\\'NCHW\\'#Defensivelysetcudnn_exhaustive_searchtoFalseincasethedefault#changesinCNNModelHelper.Thedetectioncodeusesvariablesize#inputsthatmightnotplaynicelywithcudnn_exhaustive_search.kwargs[\\'cudnn_exhaustive_search\\']=Falsesuper(DetectionModelHelper,self).__init__(**kwargs)self.roi_data_loader=Noneself.losses=[]self.metrics=[]self.do_not_update_params=[]#Paramonthislistarenotupdatedself.net.Proto().type=cfg.MODEL.EXECUTION_TYPEself.net.Proto().num_workers=cfg.NUM_GPUS*4self.prev_use_cudnn=self.use_cudnnself.gn_params=[]#ParamonthislistareGroupNormparametersdefTrainableParams(self,gpu_id=-1):\"\"\"Gettheblobnamesforalltrainableparameters,possiblyfilteredbyGPUid.\"\"\"return[pforpinself.paramsif(pinself.param_to_gradand#phasagradientpnotinself.do_not_update_paramsand#notontheblacklist(gpu_id==-1or#filterforgpuassignment,ifgpu_idsetstr(p).find(\\'gpu_{}\\'.format(gpu_id))==0))]defAffineChannel(self,blob_in,blob_out,dim,inplace=False):\"\"\"AffinetransformationtoreplaceBNinnetworkswhereBNcannotbeused(e.g.,becausetheminibatchsizeistoosmall).Theoperationscanbedoneinplacetosavememory.\"\"\"blob_out=blob_outorself.net.NextName()param_prefix=blob_outscale=self.create_param(param_name=param_prefix+\\'_s\\',initializer=initializers.Initializer(\"ConstantFill\",value=1.),tags=ParameterTags.WEIGHT,shape=[dim,],)bias=self.create_param(param_name=param_prefix+\\'_b\\',initializer=initializers.Initializer(\"ConstantFill\",value=0.),tags=ParameterTags.BIAS,shape=[dim,],)ifinplace:returnself.net.AffineChannel([blob_in,scale,bias],blob_in)else:returnself.net.AffineChannel([blob_in,scale,bias],blob_out)defGenerateProposals(self,blobs_in,blobs_out,anchors,spatial_scale):\"\"\"OpforgeneratingRPNporposals.blobs_in:-\\'rpn_cls_probs\\':4Dtensorofshape(N,A,H,W),whereNisthenumberofminibatchimages,Aisthenumberofanchorsperlocations,and(H,W)isthespatialsizeofthepredictiongrid.Eachvaluerepresentsa\"probabilityofobject\"ratingin[0,1].-\\'rpn_bbox_pred\\':4Dtensorofshape(N,4*A,H,W)ofpredicteddeltasfortransformationanchorboxesintoRPNproposals.-\\'im_info\\':2Dtensorofshape(N,3)wherethethreecolumnsencodetheinputimage\\'s[height,width,scale].Heightandwidtharefortheinputtothenetwork,nottheoriginalimage;scaleisthescalefactorusedtoscaletheoriginalimagetothenetworkinputsize.blobs_out:-\\'rpn_rois\\':2Dtensorofshape(R,5),forRRPNproposalswherethefivecolumnsencode[batchind,x1,y1,x2,y2].Theboxesarew.r.t.thenetworkinput,whichisa*scaled*versionoftheoriginalimage;theseproposalsmustbescaledby1/scale(wherescalecomesfromim_info;seeabove)totransformitbacktotheoriginalinputimagecoordinatesystem.-\\'rpn_roi_probs\\':1Dtensorofobjectnessprobabilityscores(extractedfromrpn_cls_probs;seeabove).\"\"\"cfg_key=\\'TRAIN\\'ifself.trainelse\\'TEST\\'ifcfg[cfg_key].GENERATE_PROPOSALS_ON_GPU:rpn_pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Nrpn_post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nrpn_nms_thresh=cfg[cfg_key].RPN_NMS_THRESHrpn_min_size=float(cfg[cfg_key].RPN_MIN_SIZE)input_name=str(blobs_in[0])lvl=int(input_name[-1])ifinput_name[-1].isdigit()elseNoneanchors_name=\\'anchors{}\\'.format(lvl)iflvlelse\\'anchors\\'foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/{}\\'.format(i,anchors_name),anchors.astype(np.float32))self.net.GenerateProposals(blobs_in+[anchors_name],blobs_out,spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,)else:name=\\'GenerateProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#spatial_scalepassedtothePythonopisonlyusedin#convert_pkl_to_pbself.net.Python(GenerateProposalsOp(anchors,spatial_scale,self.train).forward)(blobs_in,blobs_out,name=name,spatial_scale=spatial_scale)returnblobs_outdefGenerateProposalLabels(self,blobs_in):\"\"\"OpforgeneratingtraininglabelsforRPNproposals.ThisisusedwhentrainingRPNjointlywithFast/MaskR-CNN(asinend-to-endFasterR-CNNtraining).blobs_in:-\\'rpn_rois\\':2DtensorofRPNproposalsoutputbyGenerateProposals-\\'roidb\\':roidbentriesthatwillbelabeled-\\'im_info\\':SeeGenerateProposalsdoc.blobs_out:-(variablesetofblobs):returnswhateverblobsarerequiredfortrainingthemodel.Itdoesthisbyqueryingthedataloaderforthelistofblobsthatareneeded.\"\"\"name=\\'GenerateProposalLabelsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Thelistofblobsisnotknownbeforerun-timebecauseitdependson#thespecificmodelbeingtrained.Querythedataloadertogetthe#listofoutputblobnames.blobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]self.net.Python(GenerateProposalLabelsOp().forward)(blobs_in,blobs_out,name=name)returnblobs_outdefCollectAndDistributeFpnRpnProposals(self):\"\"\"MergeRPNproposalsgeneratedatmultipleFPNlevelsandthendistributethoseproposalstotheirappropriateFPNlevels.AnanchoratoneFPNlevelmaypredictanRoIthatwillmaptoanotherlevel,hencetheneedtoredistributetheproposals.Thisfunctionassumesstandardblobnamesforinputandoutputblobs.Inputblobs:[rpn_rois_fpn,...,rpn_rois_fpn,rpn_roi_probs_fpn,...,rpn_roi_probs_fpn]-rpn_rois_fpnaretheRPNproposalsforFPNleveli;seerpn_roisdocumentationfromGenerateProposals.-rpn_roi_probs_fpnaretheRPNobjectnessprobabilitiesforFPNleveli;seerpn_roi_probsdocumentationfromGenerateProposals.Ifusedduringtraining,thentheinputblobswillalsoinclude:[roidb,im_info](seeGenerateProposalLabels).Outputblobs:[rois_fpn,...,rois_rpn,rois,rois_idx_restore]-rois_fpnaretheRPNproposalsforFPNleveli-rois_idx_restoreisapermutationontheconcatenationofallrois_fpn,i=min...max,suchthatwhenappliedtheRPNRoIsarerestoredtotheiroriginalorderintheinputblobs.Ifusedduringtraining,thentheoutputblobswillalsoinclude:[labels,bbox_targets,bbox_inside_weights,bbox_outside_weights].\"\"\"k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVEL#Prepareinputblobsrois_names=[\\'rpn_rois_fpn\\'+str(l)forlinrange(k_min,k_max+1)]score_names=[\\'rpn_roi_probs_fpn\\'+str(l)forlinrange(k_min,k_max+1)]blobs_in=rois_names+score_namesifself.train:blobs_in+=[\\'roidb\\',\\'im_info\\']blobs_in=[core.ScopedBlobReference(b)forbinblobs_in]name=\\'CollectAndDistributeFpnRpnProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Prepareoutputblobsblobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]outputs=self.net.Python(CollectAndDistributeFpnRpnProposalsOp(self.train).forward)(blobs_in,blobs_out,name=name)returnoutputsdefDropoutIfTraining(self,blob_in,dropout_rate):\"\"\"Adddropouttoblob_inifthemodelisintrainingmodeanddropout_rateis>0.\"\"\"blob_out=blob_inifself.trainanddropout_rate>0:blob_out=self.Dropout(blob_in,blob_in,ratio=dropout_rate,is_test=False)returnblob_outdefRoIFeatureTransform(self,blobs_in,blob_out,blob_rois=\\'rois\\',method=\\'RoIPoolF\\',resolution=7,spatial_scale=1./16.,sampling_ratio=0):\"\"\"AddthespecifiedRoIpoolingmethod.Thesampling_ratioargumentissupportedforsome,butnotall,RoItransformmethods.RoIFeatureTransformabstractsaway:-UseofFPNornot-Specificsofthetransformmethod\"\"\"assertmethodin{\\'RoIPoolF\\',\\'RoIAlign\\'},\\\\\\'Unknownpoolingmethod:{}\\'.format(method)has_argmax=(method==\\'RoIPoolF\\')ifisinstance(blobs_in,list):#FPNcase:addRoIFeatureTransformtoeachFPNlevelk_max=cfg.FPN.ROI_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.ROI_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1bl_out_list=[]forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scale[k_max-lvl]#inreversedorderbl_rois=blob_rois+\\'_fpn\\'+str(lvl)bl_out=blob_out+\\'_fpn\\'+str(lvl)bl_out_list.append(bl_out)bl_argmax=[\\'_argmax_\\'+bl_out]ifhas_argmaxelse[]self.net.__getattr__(method)([bl_in,bl_rois],[bl_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=sc,sampling_ratio=sampling_ratio)#Thepooledfeaturesfromalllevelsareconcatenatedalongthe#batchdimensionintoasingle4Dtensor.xform_shuffled,_=self.net.Concat(bl_out_list,[blob_out+\\'_shuffled\\',\\'_concat_\\'+blob_out],axis=0)#Unshuffletomatchroisfromdataloaderrestore_bl=blob_rois+\\'_idx_restore_int32\\'xform_out=self.net.BatchPermutation([xform_shuffled,restore_bl],blob_out)else:#Singlefeaturelevelbl_argmax=[\\'_argmax_\\'+blob_out]ifhas_argmaxelse[]#sampling_ratioisignoredforRoIPoolFxform_out=self.net.__getattr__(method)([blobs_in,blob_rois],[blob_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=spatial_scale,sampling_ratio=sampling_ratio)#Onlyreturnthefirstblob(thetransformedfeatures)returnxform_out[0]ifisinstance(xform_out,tuple)elsexform_outdefConvShared(self,blob_in,blob_out,dim_in,dim_out,kernel,weight=None,bias=None,**kwargs):\"\"\"Addconvopthatsharesweightsand/orbiaseswithanotherconvop.\"\"\"use_bias=(Falseif(\\'no_bias\\'inkwargsandkwargs[\\'no_bias\\'])elseTrue)ifself.use_cudnn:kwargs[\\'engine\\']=\\'CUDNN\\'kwargs[\\'exhaustive_search\\']=self.cudnn_exhaustive_searchifself.ws_nbytes_limit:kwargs[\\'ws_nbytes_limit\\']=self.ws_nbytes_limitifuse_bias:blobs_in=[blob_in,weight,bias]else:blobs_in=[blob_in,weight]if\\'no_bias\\'inkwargs:delkwargs[\\'no_bias\\']returnself.net.Conv(blobs_in,blob_out,kernel=kernel,order=self.order,**kwargs)defBilinearInterpolation(self,blob_in,blob_out,dim_in,dim_out,up_scale):\"\"\"Bilinearinterpolationinspaceofscale.TakesinputofNxKxHxWandoutputsNxKx(sH)x(sW),wheres:=up_scaleAdaptedfromtheCVPR\\'15FCNcode.See:\"\"\"assertdim_in==dim_outassertup_scale%2==0,\\'Scaleshouldbeeven\\'defupsample_filt(size):factor=(size+1)//2ifsize%2==1:center=factor-1else:center=factor-0.5og=np.ogrid[:size,:size]return((1-abs(og[0]-center)/factor)*(1-abs(og[1]-center)/factor))kernel_size=up_scale*2bil_filt=upsample_filt(kernel_size)kernel=np.zeros((dim_in,dim_out,kernel_size,kernel_size),dtype=np.float32)kernel[range(dim_out),range(dim_in),:,:]=bil_filtblob=self.ConvTranspose(blob_in,blob_out,dim_in,dim_out,kernel_size,stride=int(up_scale),pad=int(up_scale/2),weight_init=(\\'GivenTensorFill\\',{\\'values\\':kernel}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))self.do_not_update_params.append(self.weights[-1])self.do_not_update_params.append(self.biases[-1])returnblobdefConvAffine(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_bn\\',inplace=False):\"\"\"ConvAffineaddsaConvopfollowedbyaAffineChannelop(whichreplacesBNduringfinetuning).\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=1)blob_out=self.AffineChannel(conv_blob,prefix+suffix,dim=dim_out,inplace=inplace)returnblob_outdefConvGN(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group_gn,#numofgroupsingngroup=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_gn\\',no_conv_bias=1,):\"\"\"ConvGNaddsaConvopfollowedbyaGroupNormop,includinglearnablescale/bias(gamma/beta)\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=no_conv_bias)ifgroup_gn<1:logger.warning(\\'Layer:{}(dim{}):\\'\\'group_gn<1;resetto1.\\'.format(prefix,dim_in))group_gn=1blob_out=self.SpatialGN(conv_blob,prefix+suffix,dim_out,group=group_gn,#op\\'sargnameis\"group\"epsilon=cfg.GROUP_NORM.EPSILON,)self.gn_params.append(self.params[-1])#addgn\\'sbiastolistself.gn_params.append(self.params[-2])#addgn\\'sscaletolistreturnblob_outdefDisableCudnn(self):self.prev_use_cudnn=self.use_cudnnself.use_cudnn=FalsedefRestorePreviousUseCudnn(self):prev_use_cudnn=self.use_cudnnself.use_cudnn=self.prev_use_cudnnself.prev_use_cudnn=prev_use_cudnndefUpdateWorkspaceLr(self,cur_iter,new_lr):\"\"\"Updatesthemodel\\'scurrentlearningrateandtheworkspace(learningrateandupdatehistory/momentumblobs).\"\"\"#Theworkspaceistheonesourceoftruthforthelr#ThelrisalwaysthesameonallGPUscur_lr=workspace.FetchBlob(\\'gpu_0/lr\\')[0]#TherearenotypeconversionsbetweenthelrinPythonandthelrin#theGPU(botharefloat32),soexactcomparisionisokifcur_lr!=new_lr:ratio=_get_lr_change_ratio(cur_lr,new_lr)ifratio>cfg.SOLVER.LOG_LR_CHANGE_THRESHOLD:logger.info(\\'Changinglearningrate{:.6f}->{:.6f}atiter{:d}\\'.format(cur_lr,new_lr,cur_iter))self._SetNewLr(cur_lr,new_lr)returnnew_lrdef_SetNewLr(self,cur_lr,new_lr):\"\"\"Dotheactualworkofupdatingthemodelandworkspaceblobs.\"\"\"foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/lr\\'.format(i),np.array([new_lr],dtype=np.float32))ratio=_get_lr_change_ratio(cur_lr,new_lr)ifcfg.SOLVER.SCALE_MOMENTUMandcur_lr>1e-7and\\\\ratio>cfg.SOLVER.SCALE_MOMENTUM_THRESHOLD:self._CorrectMomentum(new_lr/cur_lr)def_CorrectMomentum(self,correction):\"\"\"TheMomentumSGDUpdateopimplementstheupdateVasV:=mu*V+lr*grad,wheremuisthemomentumfactor,lristhelearningrate,andgradisthestochasticgradient.SinceVisnotdefinedindependentlyofthelearningrate(asitshouldideallybe),whenthelearningrateischangedweshouldscaletheupdatehistoryVinordertomakeitcompatibleinscalewithlr*grad.\"\"\"logger.info(\\'Scalingupdatehistoryby{:.6f}(newlr/oldlr)\\'.format(correction))foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):forparaminself.TrainableParams(gpu_id=i):op=core.CreateOperator(\\'Scale\\',[param+\\'_momentum\\'],[param+\\'_momentum\\'],scale=correction)workspace.RunOperatorOnce(op)defGetLossScale(self):\"\"\"Allowawaytoconfigurethelossscaledynamically.Thismaybeusedinadistributeddataparallelsetting.\"\"\"return1.0/cfg.NUM_GPUSdefAddLosses(self,losses):ifnotisinstance(losses,list):losses=[losses]#ConversiontostrallowslossestoincludeBlobReferenceslosses=[c2_utils.UnscopeName(str(l))forlinlosses]self.losses=list(set(self.losses+losses))defAddMetrics(self,metrics):ifnotisinstance(metrics,list):metrics=[metrics]self.metrics=list(set(self.metrics+metrics))def_get_lr_change_ratio(cur_lr,new_lr):eps=1e-10ratio=np.max((new_lr/np.max((cur_lr,eps)),cur_lr/np.max((new_lr,eps))))returnratio#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Handlemappingfromoldnetworkbuildingfunctionnamestonewnames.Flexiblenetworkconfigurationisachievedbyspecifyingthefunctionnamethatbuildsanetworkmodule(e.g.,thenameoftheconvbackboneorthemaskroihead).Howeverwemaywishtochangenamesovertimewithoutbreakingpreviousconfigfiles.Thismoduleprovidesbackwardsnamingcompatibilitybyprovidingamappingfromtheoldnametothenewname.Whenrenamingfunctions,it\\'sgenerallyagoodideatocodemodexistingyamlconfigfiles.Aneasywaytobatchedit,byexample,isashellcommandlike$find.-name\"*.yaml\"-execsed-i-e\\\\\\'s/head_builder\\\\.add_roi_2mlp_head/fast_rcnn_heads.add_roi_2mlp_head/g\\'{}\\\\;toperformtherenaming:head_builder.add_roi_2mlp_head=>fast_rcnn_heads.add_roi_2mlp_head\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literals_RENAME={#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up\\':\\'mask_rcnn_heads.mask_rc',\n",
       " 'nn_fcn_head_v1up\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0upshare\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0upshare\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0up\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0up\\',#Removedhead_buildermoduleinfavorofthemorespecificfast_rcnnname\\'head_builder.add_roi_2mlp_head\\':\\'fast_rcnn_heads.add_roi_2mlp_head\\',}defget_new_name(func_name):iffunc_namein_RENAME:func_name=_RENAME[func_name]returnfunc_name#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.FPNasFPNimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##RPNandFasterR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_generic_rpn_outputs(model,blob_in,dim_in,spatial_scale_in):\"\"\"AddRPNoutputs(objectnessclassificationandboundingboxregression)toanRPNmodel.AbstractsawaytheuseofFPN.\"\"\"loss_gradients=Noneifcfg.FPN.FPN_ON:#DelegatetotheFPNmoduleFPN.add_fpn_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifcfg.MODEL.FASTER_RCNN:#CollectAndDistributeFpnRpnProposalsalsolabelsproposalswhenin#trainingmodemodel.CollectAndDistributeFpnRpnProposals()ifmodel.train:loss_gradients=FPN.add_fpn_rpn_losses(model)else:#NotusingFPN,addRPNtoasinglescaleadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifmodel.train:loss_gradients=add_single_scale_rpn_losses(model)returnloss_gradientsdefadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale):\"\"\"AddRPNoutputstoasinglescalemodel(i.e.,noFPN).\"\"\"anchors=generate_anchors(stride=1./spatial_scale,sizes=cfg.RPN.SIZES,aspect_ratios=cfg.RPN.ASPECT_RATIOS)num_anchors=anchors.shape[0]dim_out=dim_in#RPNhiddenrepresentationmodel.Conv(blob_in,\\'conv_rpn\\',dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'conv_rpn\\',\\'conv_rpn\\')#Proposalclassificationscoresmodel.Conv(\\'conv_rpn\\',\\'rpn_cls_logits\\',dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasmodel.Conv(\\'conv_rpn\\',\\'rpn_bbox_pred\\',dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededmodel.net.Sigmoid(\\'rpn_cls_logits\\',\\'rpn_cls_probs\\')model.GenerateProposals([\\'rpn_cls_probs\\',\\'rpn_bbox_pred\\',\\'im_info\\'],[\\'rpn_rois\\',\\'rpn_roi_probs\\'],anchors=anchors,spatial_scale=spatial_scale)ifcfg.MODEL.FASTER_RCNN:ifmodel.train:#Addopthatgeneratestraininglabelsforin-networkRPNproposalsmodel.GenerateProposalLabels([\\'rpn_rois\\',\\'roidb\\',\\'im_info\\'])else:#Aliasroistorpn_roisforinferencemodel.net.Alias(\\'rpn_rois\\',\\'rois\\')defadd_single_scale_rpn_losses(model):\"\"\"AddlossesforasinglescaleRPNmodel(i.e.,noFPN).\"\"\"#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide\\',\\'rpn_cls_logits\\'],\\'rpn_labels_int32\\')forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide\\',\\'rpn_bbox_pred\\'],\\'rpn_bbox_\\'+key)loss_rpn_cls=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits\\',\\'rpn_labels_int32\\'],\\'loss_rpn_cls\\',scale=model.GetLossScale())loss_rpn_bbox=model.net.SmoothL1Loss([\\'rpn_bbox_pred\\',\\'rpn_bbox_targets\\',\\'rpn_bbox_inside_weights\\',\\'rpn_bbox_outside_weights\\'],\\'loss_rpn_bbox\\',beta=1./9.,scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_rpn_cls,loss_rpn_bbox])model.AddLosses([\\'loss_rpn_cls\\',\\'loss_rpn_bbox\\'])returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG16from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG16_conv5_body(model):model.Conv(\\'data\\',\\'conv1_1\\',3,64,3,pad=1,stride=1)model.Relu(\\'conv1_1\\',\\'conv1_1\\')model.Conv(\\'conv1_1\\',\\'conv1_2\\',64,64,3,pad=1,stride=1)model.Relu(\\'conv1_2\\',\\'conv1_2\\')model.MaxPool(\\'conv1_2\\',\\'pool1\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool1\\',\\'conv2_1\\',64,128,3,pad=1,stride=1)model.Relu(\\'conv2_1\\',\\'conv2_1\\')model.Conv(\\'conv2_1\\',\\'conv2_2\\',128,128,3,pad=1,stride=1)model.Relu(\\'conv2_2\\',\\'conv2_2\\')model.MaxPool(\\'conv2_2\\',\\'pool2\\',kernel=2,pad=0,stride=2)model.StopGradient(\\'pool2\\',\\'pool2\\')model.Conv(\\'pool2\\',\\'conv3_1\\',128,256,3,pad=1,stride=1)model.Relu(\\'conv3_1\\',\\'conv3_1\\')model.Conv(\\'conv3_1\\',\\'conv3_2\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_2\\',\\'conv3_2\\')model.Conv(\\'conv3_2\\',\\'conv3_3\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_3\\',\\'conv3_3\\')model.MaxPool(\\'conv3_3\\',\\'pool3\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool3\\',\\'conv4_1\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv4_1\\',\\'conv4_1\\')model.Conv(\\'conv4_1\\',\\'conv4_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_2\\',\\'conv4_2\\')model.Conv(\\'conv4_2\\',\\'conv4_3\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_3\\',\\'conv4_3\\')model.MaxPool(\\'conv4_3\\',\\'pool4\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool4\\',\\'conv5_1\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_1\\',\\'conv5_1\\')model.Conv(\\'conv5_1\\',\\'conv5_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_2\\',\\'conv5_2\\')model.Conv(\\'conv5_2\\',\\'conv5_3\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5_3\\',\\'conv5_3\\')returnblob_out,512,1./16.defadd_VGG16_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=7,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*7*7,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,4096)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,4096#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RetinaNetmodelheadsandlosses.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_retinanet_bias_init(model):\"\"\"Initializethebiasesfortheconvopsthatpredictclassprobabilities.Initializationisperformedsuchthatatthestartoftraining,alllocationsarepredictedtobebackgroundwithhighprobability(e.g.,~0.99=1-cfg.RETINANET.PRIOR_PROB).SeetheFocalLosspaperfordetails.\"\"\"prior_prob=cfg.RETINANET.PRIOR_PROBscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)ifcfg.RETINANET.SOFTMAX:#Multiclasssoftmaxcasebias=np.zeros((model.num_classes,1),dtype=np.float32)bias[0]=np.log((model.num_classes-1)*(1-prior_prob)/(prior_prob))bias=np.vstack([biasfor_inrange(scales_per_octave*aspect_ratios)])bias_init=(\\'GivenTensorFill\\',{\\'values\\':bias.astype(dtype=np.float32)})else:#Per-classsigmoid(binaryclassification)casebias_init=(\\'ConstantFill\\',{\\'value\\':-np.log((1-prior_prob)/prior_prob)})returnbias_initdefadd_fpn_retinanet_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"RetinaNethead.Forclassificationandboxregression,wecanchosetohavethesameconvtoweroraseparatetower.\"bl_feat_list\"storesthelistoffeatureblobsforbboxprediction.Theseblobscanbesharedclsfeatureblobsifwesharethetowerorelseareindependentblobs.\"\"\"dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidA=len(cfg.RETINANET.ASPECT_RATIOS)*cfg.RETINANET.SCALES_PER_OCTAVE#computeinitforbiasbias_init=get_retinanet_bias_init(model)assertlen(blobs_in)==k_max-k_min+1bbox_feat_list=[]cls_pred_dim=(model.num_classesifcfg.RETINANET.SOFTMAXelse(model.num_classes-1))#unpackedbboxfeatureandaddpredictionlayersbbox_regr_dim=(4*(model.num_classes-1)ifcfg.RETINANET.CLASS_SPECIFIC_BBOXelse4)#==========================================================================#classificationtowerwithlogitsandprobprediction#==========================================================================forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorder#classificationtowerstackconvolutionstartsfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_cls_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_cls_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)bl_feat=bl_in#clstowerstackconvolutionends.Addthelogitslayernowiflvl==k_min:retnet_cls_pred=model.Conv(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=bias_init)else:retnet_cls_pred=model.ConvShared(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight=\\'retnet_cls_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_cls_pred_fpn{}_b\\'.format(k_min))ifnotmodel.train:ifcfg.RETINANET.SOFTMAX:model.net.GroupSpatialSoftmax(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl),num_classes=cls_pred_dim)else:model.net.Sigmoid(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl))ifcfg.RETINANET.SHARE_CLS_BBOX_TOWER:bbox_feat_list.append(bl_feat)#==========================================================================#bboxtowerifnotsharingfeatureswiththeclassificationtowerwith#logitsandprobprediction#==========================================================================ifnotcfg.RETINANET.SHARE_CLS_BBOX_TOWER:forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorderfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_bbox_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_bbox_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)#Addoctavescalesandaspectratio#Atleast1convolutionfordealingdifferentaspectratiosbl_feat=bl_inbbox_feat_list.append(bl_feat)#Dependingonthefeatures[shared/separate]forbbox,addpredictionlayerfori,lvlinenumerate(range(k_min,k_max+1)):bbox_pred=\\'retnet_bbox_pred_fpn{}\\'.format(lvl)bl_feat=bbox_feat_list[i]iflvl==k_min:model.Conv(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:model.ConvShared(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight=\\'retnet_bbox_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_bbox_pred_fpn{}_b\\'.format(k_min))defadd_fpn_retinanet_losses(model):loss_gradients={}gradients,losses=[],[]k_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidmodel.AddMetrics([\\'retnet_fg_num\\',\\'retnet_bg_num\\'])#==========================================================================#bboxregressionloss-SelectSmoothL1Lossformultipleanchorsatalocation#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)bbox_loss=model.net.SelectSmoothL1Loss([\\'retnet_bbox_pred_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,\\'retnet_fg_num\\'],\\'retnet_loss_bbox_\\'+suffix,beta=cfg.RETINANET.BBOX_REG_BETA,scale=model.GetLossScale()*cfg.RETINANET.BBOX_REG_WEIGHT)gradients.append(bbox_loss)losses.append(\\'retnet_loss_bbox_\\'+suffix)#==========================================================================#clsloss-dependsonsoftmax/sigmoidoutputs#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_lvl_logits=\\'retnet_cls_pred_\\'+suffixifnotcfg.RETINANET.SOFTMAX:cls_focal_loss=model.net.SigmoidFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes-1)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))else:cls_focal_loss,gated_prob=model.net.SoftmaxFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix),\\'retnet_prob_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))loss_gradients.update(blob_utils.get_loss_gradients(model,gradients))model.AddLosses(losses)returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnp#VerifythatwecomputethesameanchorsasShaoqing\\'smatlabimplementation:##>>loadoutput/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat#>>anchors##anchors=##-83-3910056#-175-87192104#-359-183376200#-55-557272#-119-119136136#-247-247264264#-35-795296#-79-16796184#-167-343184360#array([[-83.,-39.,100.,56.],#[-175.,-87.,192.,104.],#[-359.,-183.,376.,200.],#[-55.,-55.,72.,72.],#[-119.,-119.,136.,136.],#[-247.,-247.,264.,264.],#[-35.,-79.,52.,96.],#[-79.,-167.,96.,184.],#[-167.,-343.,184.,360.]])defgenerate_anchors(stride=16,sizes=(32,64,128,256,512),aspect_ratios=(0.5,1,2)):\"\"\"Generatesamatrixofanchorboxesin(x1,y1,x2,y2)format.Anchorsarecenteredonstride/2,have(approximate)sqrtareasofthespecifiedsizes,andaspectratiosasgiven.\"\"\"return_generate_anchors(stride,np.array(sizes,dtype=float)/stride,np.array(aspect_ratios,dtype=float))def_generate_anchors(base_size,scales,aspect_ratios):\"\"\"Generateanchor(reference)windowsbyenumeratingaspectratiosXscaleswrtareference(0,0,base_size-1,base_size-1)window.\"\"\"anchor=np.array([1,1,base_size,base_size],dtype=float)-1anchors=_ratio_enum(anchor,aspect_ratios)anchors=np.vstack([_scale_enum(anchors[i,:],scales)foriinrange(anchors.shape[0])])returnanchorsdef_whctrs(anchor):\"\"\"Returnwidth,height,xcenter,andycenterforananchor(window).\"\"\"w=anchor[2]-anchor[0]+1h=anchor[3]-anchor[1]+1x_ctr=anchor[0]+0.5*(w-1)y_ctr=anchor[1]+0.5*(h-1)returnw,h,x_ctr,y_ctrdef_mkanchors(ws,hs,x_ctr,y_ctr):\"\"\"Givenavectorofwidths(ws)andheights(hs)aroundacenter(x_ctr,y_ctr),outputasetofanchors(windows).\"\"\"ws=ws[:,np.newaxis]hs=hs[:,np.newaxis]anchors=np.hstack((x_ctr-0.5*(ws-1),y_ctr-0.5*(hs-1),x_ctr+0.5*(ws-1),y_ctr+0.5*(hs-1)))returnanchorsdef_ratio_enum(anchor,ratios):\"\"\"Enumerateasetofanchorsforeachaspectratiowrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)size=w*hsize_ratios=size/ratiosws=np.round(np.sqrt(size_ratios))hs=np.round(ws*ratios)anchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchorsdef_scale_enum(anchor,scales):\"\"\"Enumerateasetofanchorsforeachscalewrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)ws=w*scaleshs=h*scalesanchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchors#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsclassCollectAndDistributeFpnRpnProposalsOp:def__init__(self,train):self._train=traindefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.CollectAndDistributeFpnRpnProposalsforinputs/outputsdocumentation.\"\"\"#inputsis#[rpn_rois_fpn2,...,rpn_rois_fpn6,#rpn_roi_probs_fpn2,...,rpn_roi_probs_fpn6]#IftrainingwithFasterR-CNN,theninputswilladditionallyinclude#+[roidb,im_info]rois=collect(inputs,self._train)ifself._train:#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]im_info=inputs[-1].dataim_scales=im_info[:,2]roidb=blob_utils.deserialize(inputs[-2].data)#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)#ComputetraininglabelsfortheRPNproposals;alsohandles#distributingtheproposalsoverFPNlevelsoutput_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])else:#Forinferencewehaveaspecialcodepaththatavoidssomedata#loaderoverheaddistribute(rois,None,outputs,self._train)defcollect(inputs,is_training):cfg_key=\\'TRAIN\\'ifis_trainingelse\\'TEST\\'post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELnum_lvls=k_max-k_min+1roi_inputs=inputs[:num_lvls]score_inputs=inputs[num_lvls:]ifis_training:score_inputs=score_inputs[:-2]#roisarein[[batch_idx,x0,y0,x1,y2],...]format#Combinepredictionsacrossalllevelsandretainthetopscoringrois=np.concatenate([blob.dataforblobinroi_inputs])scores=np.concatenate([blob.dataforblobinscore_inputs]).squeeze()inds=np.argsort(-scores)[:post_nms_topN]rois=rois[inds,:]returnroisdefdistribute(rois,label_blobs,outputs,train):\"\"\"Tounderstandtheoutputbloborderseereturnvalueofdetectron.roi_data.fast_rcnn.get_fast_rcnn_blob_names(is_training=False)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(rois[:,1:5],lvl_min,lvl_max)outputs[0].reshape(rois.shape)outputs[0].data[...]=rois#CreatenewroiblobsforeachFPNlevel#(See:modeling.FPN.add_multilevel_roi_blobswhichissimilarbutannoying#togeneralizetosupportthisparticularcase.)rois_idx_order=np.empty((0,))foroutput_idx,lvlinenumerate(range(lvl_min,lvl_max+1)):idx_lvl=np.where(lvls==lvl)[0]blob_roi_level=rois[idx_lvl,:]outputs[output_idx+1].reshape(blob_roi_level.shape)outputs[output_idx+1].data[...]=blob_roi_levelrois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_idx_restore=np.argsort(rois_idx_order)blob_utils.py_op_copy_blob(rois_idx_restore.astype(np.int32),outputs[-1])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.boxesasbox_utilsclassGenerateProposalsOp:\"\"\"Outputobjectdetectionproposalsbyapplyingestimatedbounding-boxtransformationstoasetofregularboxes(called\"anchors\").Seecommentinutils/boxes:bbox_transform_invfordetailsaboutstheoptional`reg_weights`parameter.\"\"\"def__init__(self,anchors,spatial_scale,train,reg_weights=(1.0,1.0,1.0,1.0)):self._anchors=anchorsself._num_anchors=self._anchors.shape[0]self._feat_stride=1./spatial_scaleself._train=trainself._reg_weights=reg_weightsdefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalsforinputs/outputsdocumentation.\"\"\"#1.foreachlocationiina(H,W)grid:#generateAanchorboxescenteredoncelli#applypredictedbboxdeltastoeachoftheAanchorsatcelli#2.clippredictedboxestoimage#3.removepredictedboxeswitheitherheightorwidth<threshold#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.takethetoppre_nms_topNproposalsbeforeNMS#6.applyNMSwithaloosethreshold(0.7)totheremainingproposals#7.takeafter_nms_topNproposalsafterNMS#8.returnthetopproposals#predictedprobabilityoffgobjectforeachRPNanchorscores=inputs[0].data#predictedachorstransformationsbbox_deltas=inputs[1].data#inputimage(height,width,scale),inwhichscaleisthescalefactor#appliedtotheoriginaldatasetimagetogetthenetworkinputimageim_info=inputs[2].data#1.Generateproposalsfrombboxdeltasandshiftedanchorsheight,width=scores.shape[-2:]#Enumerateallshiftedpositionsonthe(H,W)gridshift_x=np.arange(0,width)*self._feat_strideshift_y=np.arange(0,height)*self._feat_strideshift_x,shift_y=np.meshgrid(shift_x,shift_y,copy=False)#Convertto(K,4),K=H*W,wherethecolumnsare(dx,dy,dx,dy)#shiftpointingtoeachgridlocationshifts=np.vstack((shift_x.ravel(),shift_y.ravel(),shift_x.ravel(),shift_y.ravel())).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsnum_images=inputs[0].shape[0]A=self._num_anchorsK=shifts.shape[0]all_anchors=self._anchors[np.newaxis,:,:]+shifts[:,np.newaxis,:]all_anchors=all_anchors.reshape((K*A,4))rois=np.empty((0,5),dtype=np.float32)roi_probs=np.empty((0,1),dtype=np.float32)forim_iinrange(num_images):im_i_boxes,im_i_probs=self.proposals_for_one_image(im_info[im_i,:],all_anchors,bbox_deltas[im_i,:,:,:],scores[im_i,:,:,:])batch_inds=im_i*np.ones((im_i_boxes.shape[0],1),dtype=np.float32)im_i_rois=np.hstack((batch_inds,im_i_boxes))rois=np.append(rois,im_i_rois,axis=0)roi_probs=np.append(roi_probs,im_i_probs,axis=0)outputs[0].reshape(rois.shape)outputs[0].data[...]=roisiflen(outputs)>1:outputs[1].reshape(roi_probs.shape)outputs[1].data[...]=roi_probsdefproposals_for_one_image(self,im_info,all_anchors,bbox_deltas,scores):#Getmode-dependentconfigurationcfg_key=\\'TRAIN\\'ifself._trainelse\\'TEST\\'pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Npost_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nnms_thresh=cfg[cfg_key].RPN_NMS_THRESHmin_size=cfg[cfg_key].RPN_MIN_SIZE#Transposeandreshapepredictedbboxtransformationstogetthem#intothesameorderastheanchors:#-bboxdeltaswillbe(4*A,H,W)formatfromconvoutput#-transposeto(H,W,4*A)#-reshapeto(H*W*A,4)whererowsareorderedby(H,W,A)#inslowesttofastestordertomatchtheenumeratedanchorsbbox_deltas=bbox_deltas.transpose((1,2,0)).reshape((-1,4))#Samestoryforthescores:#-scoresare(A,H,W)formatfromconvoutput#-transposeto(H,W,A)#-reshapeto(H*W*A,1)whererowsareorderedby(H,W,A)#tomatchtheorderofanchorsandbbox_deltasscores=scores.transpose((1,2,0)).reshape((-1,1))#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.taketoppre_nms_topN(e.g.6000)ifpre_nms_topN=len(scores):order=np.argsort(-scores.squeeze())else:#Avoidsortingpossiblylargearrays;FirstpartitiontogettopK#unsortedandthensortjustthose(~20xfasterfor200kscores)inds=np.argpartition(-scores.squeeze(),pre_nms_topN)[:pre_nms_topN]order=np.argsort(-scores[inds].squeeze())order=inds[order]bbox_deltas=bbox_deltas[order,:]all_anchors=all_anchors[order,:]scores=scores[order]#Transformanchorsintoproposalsviabboxtransformationsproposals=box_utils.bbox_transform(all_anchors,bbox_deltas,self._reg_weights)#2.clipproposalstoimage(mayresultinproposalswithzeroarea#thatwillberemovedinthenextstep)proposals=box_utils.clip_tiled_boxes(proposals,im_info[:2])#3.removepredictedboxeswitheitherheightorwidth<min_sizekeep=_filter_boxes(proposals,min_size,im_info)proposals=proposals[keep,:]scores=scores[keep]#6.applyloosenms(e.g.threshold=0.7)#7.takeafter_nms_topN(e.g.300)#8.returnthetopproposals(->RoIstop)ifnms_thresh>0:keep=box_utils.nms(np.hstack((proposals,scores)),nms_thresh)ifpost_nms_topN>0:keep=keep[:post_nms_topN]proposals=proposals[keep,:]scores=scores[keep]returnproposals,scoresdef_filter_boxes(boxes,min_size,im_info):\"\"\"Onlykeepboxeswithbothsides>=min_sizeandcenterwithintheimage.\"\"\"#Computethewidthandheightoftheproposalboxesasmeasuredintheoriginal#imagecoordinatesystem(thisisrequiredtoavoid\"NegativeAreasFound\"#assertionsinotherpartsofthecodethatmeasure).im_scale=im_info[2]ws_orig_scale=(boxes[:,2]-boxes[:,0])/im_scale+1hs_orig_scale=(boxes[:,3]-boxes[:,1])/im_scale+1#Toavoidnumericalissueswerequirethemin_sizetobeatleast1pixelinthe#originalimagemin_size=np.maximum(min_size,1)#Proposalcenteriscomputedrelativetothescaledinputimagews=boxes[:,2]-boxes[:,0]+1hs=boxes[:,3]-boxes[:,1]+1x_ctr=boxes[:,0]+ws/2.y_ctr=boxes[:,1]+hs/2.keep=np.where((ws_orig_scale>=min_size)&(hs_orig_scale>=min_size)&(x_ctr<im_info[1])&(y_ctr<im_info[0]))[0]returnkeep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsfromdetectron.utilsimportblobasblob_utilsimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_datalogger=logging.getLogger(__name__)classGenerateProposalLabelsOp:defforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalLabelsforinputs/outputsdocumentation.\"\"\"#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]rois=inputs[0].dataroidb=blob_utils.deserialize(inputs[1].data)im_info=inputs[2].dataim_scales=im_info[:,2]output_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaDetectronnetworkonanimdb(imagedatabase).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.core.rpn_generatorimportgenerate_rpn_on_datasetfromdetectron.core.rpn_generatorimportgenerate_rpn_on_rangefromdetectron.core.testimportim_detect_allfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnet_utilsimportdetectron.utils.subprocessassubprocess_utilsimportdetectron.utils.visasvis_utilslogger=logging.getLogger(__name__)defget_eval_functions():#Determinewhichparentorchildfunctionshouldhandleinferenceifcfg.MODEL.RPN_ONLY:child_func=generate_rpn_on_rangeparent_func=generate_rpn_on_datasetelse:#GenericcasethathandlesallnetworktypesotherthanRPN-onlynets#andRetinaNetchild_func=test_netparent_func=test_net_on_datasetreturnparent_func,child_funcdefget_inference_dataset(index,is_parent=True):assertis_parentorlen(cfg.TEST.DATASETS)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingledataset\\'dataset_name=cfg.TEST.DATASETS[index]ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertis_parentorlen(cfg.TEST.PROPOSAL_FILES)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingleproposalfile\\'assertlen(cfg.TEST.PROPOSAL_FILES)==len(cfg.TEST.DATASETS),\\\\\\'Ifproposalsareused,oneproposalfilemustbespecifiedfor\\'\\\\\\'eachdataset\\'proposal_file=cfg.TEST.PROPOSAL_FILES[index]else:proposal_file=Nonereturndataset_name,proposal_filedefrun_inference(weights_file,ind_range=None,multi_gpu_testing=False,gpu_id=0,check_expected_results=False,):parent_func,child_func=get_eval_functions()is_parent=ind_rangeisNonedefresult_getter():ifis_parent:#Parentcase:#Inthiscasewe\\'reeitherrunninginferenceontheentiredatasetina#singleprocessor(ifmulti_gpu_testingisTrue)usingthisprocessto#launchsubprocessesthateachruninferenceonarangeofthedatasetall_results={}foriinrange(len(cfg.TEST.DATASETS)):dataset_name,proposal_file=get_inference_dataset(i)output_dir=get_output_dir(dataset_name,training=False)results=parent_func(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=multi_gpu_testing)all_results.update(results)returnall_resultselse:#Subprocesschildcase:#Inthiscasetest_netwascalledviasubprocess.Popentoexecuteona#rangeofinputsonasingledatasetdataset_name,proposal_file=get_inference_dataset(0,is_parent=False)output_dir=get_output_dir(dataset_name,training=False)returnchild_func(weights_file,dataset_name,proposal_file,output_dir,ind_range=ind_range,gpu_id=gpu_id)all_results=result_getter()ifcheck_expected_resultsandis_parent:task_evaluation.check_expected_results(all_results,atol=cfg.EXPECTED_RESULTS_ATOL,rtol=cfg.EXPECTED_RESULTS_RTOL)task_evaluation.log_copy_paste_friendly_results(all_results)returnall_resultsdeftest_net_on_dataset(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())all_boxes,all_segms,all_keyps=multi_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir)else:all_boxes,all_segms,all_keyps=test_net(weights_file,dataset_name,proposal_file,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))results=task_evaluation.evaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir)returnresultsdefmulti_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"binary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetandproposalfile(ifany)viathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]ifproposal_file:opts+=[\\'TEST.PROPOSAL_FILES\\',\\'(\"{}\",)\\'.format(proposal_file)]#Runinferenceinparallelinsubprocesses#Outputswillbealistofoutputsfromeachsubprocess,wheretheoutput#ofeachsubprocessisthedictionarysavedbytest_net().outputs=subprocess_utils.process_in_parallel(\\'detection\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessall_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_segms=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_keyps=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]fordet_datainoutputs:all_boxes_batch=det_data[\\'all_boxes\\']all_segms_batch=det_data[\\'all_segms\\']all_keyps_batch=det_data[\\'all_keyps\\']forcls_idxinrange(1,cfg.MODEL.NUM_CLASSES):all_boxes[cls_idx]+=all_boxes_batch[cls_idx]all_segms[cls_idx]+=all_segms_batch[cls_idx]all_keyps[cls_idx]+=all_keyps_batch[cls_idx]det_file=os.path.join(output_dir,\\'detections.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdeftest_net(weights_file,dataset_name,proposal_file,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertnotcfg.MODEL.RPN_ONLY,\\\\\\'Userpn_generatetogenerateproposalsfromRPN-onlymodels\\'roidb,dataset,start_ind,end_ind,total_num_images=get_roidb_and_dataset(dataset_name,proposal_file,ind_range)model=initialize_model_from_cfg(weights_file,gpu_id=gpu_id)num_images=len(roidb)num_classes=cfg.MODEL.NUM_CLASSESall_boxes,all_segms,all_keyps=empty_results(num_classes,num_images)timers=defaultdict(Timer)fori,entryinenumerate(roidb):ifcfg.TEST.PRECOMPUTED_PROPOSALS:#Theroidbmaycontainground-truthrois(forexample,iftheroidb#comesfromthetrainingorvalsplit).Weonlywanttoevaluate#detectiononthe*non*-ground-truthrois.Weselectonlytherois#thathavethegt_classesfieldsetto0,whichmeansthere\\'sno#groundtruth.box_proposals=entry[\\'boxes\\'][entry[\\'gt_classes\\']==0]iflen(box_proposals)==0:continueelse:#FasterR-CNNtypemodelsgenerateproposalson-the-flywithan#in-networkRPN;1-stagemodelsdon\\'trequireproposals.box_proposals=Noneim=cv2.imread(entry[\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):cls_boxes_i,cls_segms_i,cls_keyps_i=im_detect_all(model,im,box_proposals,timers)extend_results(i,all_boxes,cls_boxes_i)ifcls_segms_iisnotNone:extend_results(i,all_segms,cls_segms_i)ifcls_keyps_iisnotNone:extend_results(i,all_keyps,cls_keyps_i)ifi%10==0:#Reducelogfilesizeave_total_time=np.sum([t.average_timefortintimers.values()])eta_seconds=ave_total_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))det_time=(timers[\\'im_detect_bbox\\'].average_time+timers[\\'im_detect_mask\\'].average_time+timers[\\'im_detect_keypoints\\'].average_time)misc_time=(timers[\\'misc_bbox\\'].average_time+timers[\\'misc_mask\\'].average_time+timers[\\'misc_keypoints\\'].average_time)logger.info((\\'im_detect:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s+{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,det_time,misc_time,eta))ifcfg.VIS:im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(i,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=cfg.VIS_TH,box_alpha=0.8,dataset=dataset,show_class=True)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:det_name=\\'detection_range_%s_%s.pkl\\'%tuple(ind_range)else:det_name=\\'detections.pkl\\'det_file=os.path.join(output_dir,det_name)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdefinitialize_model_from_cfg(weights_file,gpu_id=0):\"\"\"Initializeamodelfromtheglobalcfg.Loadstest-timeweightsandcreatesthenetworksintheCaffe2workspace.\"\"\"model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)net_utils.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)workspace.CreateNet(model.conv_body_net)ifcfg.MODEL.MASK_ON:workspace.CreateNet(model.mask_net)ifcfg.MODEL.KEYPOINTS_ON:workspace.CreateNet(model.keypoint_net)returnmodeldefget_roidb_and_dataset(dataset_name,proposal_file,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertproposal_file,\\'Noproposalfilegiven\\'roidb=dataset.get_roidb(proposal_file=proposal_file,proposal_limit=cfg.TEST.PROPOSAL_LIMIT)else:roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,dataset,start,end,total_num_imagesdefempty_results(num_classes,num_images):\"\"\"Returnemptyresultslistsforboxes,masks,andkeypoints.Boxdetectionsarecollectedinto:all_boxes[cls][image]=Nx5arraywithcolumns(x1,y1,x2,y2,score)Instancemaskpredictionsarecollectedinto:all_segms[cls][image]=[...]listofCOCORLEencodedmasksthatarein1:1correspondencewiththeboxesinall_boxes[cls][image]Keypointpredictionsarecollectedinto:all_keyps[cls][image]=[...]listofkeypointsresults,eachencodedasa3Darray(#rois,4,#keypoints)withthe4rowscorrespondingto[x,y,logit,prob](See:utils.keypoints.heatmaps_to_keypoints).Keypointsarerecordedforperson(cls=1);theyarein1:1correspondencewiththeboxesinall_boxes[cls][image].\"\"\"#Note:donotbetemptedtouse[[]*N],whichgivesNreferencestothe#*same*emptylist.all_boxes=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_segms=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_keyps=[[[]for_inrange(num_images)]for_inrange(num_classes)]returnall_boxes,all_segms,all_keypsdefextend_results(index,all_res,im_res):\"\"\"Addresultsforanimagetothesetofallresultsatthespecifiedindex.\"\"\"#Skipcls_idx0(__background__)forcls_idxinrange(1,len(im_res)):all_res[cls_idx][index]=im_res[cls_idx]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"FunctionsforRPNproposalgeneration.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnuimportdetectron.utils.subprocessassubprocess_utilslogger=logging.getLogger(__name__)defgenerate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())_boxes,_scores,_ids,rpn_file=multi_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir)else:#Processesentiredatasetrangebydefault_boxes,_scores,_ids,rpn_file=generate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))returnevaluate_proposal_file(dataset,rpn_file,output_dir)defmulti_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"#Retrievethetest_netbinarypathbinary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetviathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]#Runinferenceinparallelinsubprocessesoutputs=subprocess_utils.process_in_parallel(\\'rpn_proposals\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessboxes,scores,ids=[],[],[]forrpn_datainoutputs:boxes+=rpn_data[\\'boxes\\']scores+=rpn_data[\\'scores\\']ids+=rpn_data[\\'ids\\']rpn_file=os.path.join(output_dir,\\'rpn_proposals.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertcfg.MODEL.RPN_ONLYorcfg.MODEL.FASTER_RCNNroidb,start_ind,end_ind,total_num_images=get_roidb(dataset_name,ind_range)logger.info(\\'Outputwillbesavedto:{:s}\\'.format(os.path.abspath(output_dir)))model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)nu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)boxes,scores,ids=generate_proposals_on_roidb(model,roidb,start_ind=start_ind,end_ind=end_ind,total_num_images=total_num_images,gpu_id=gpu_id,)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:rpn_name=\\'rpn_proposals_range_%s_%s.pkl\\'%tuple(ind_range)else:rpn_name=\\'rpn_proposals.pkl\\'rpn_file=os.path.join(output_dir,rpn_name)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_proposals_on_roidb(model,roidb,start_ind=None,end_ind=None,total_num_images=None,gpu_id=0,):\"\"\"GenerateRPNproposalsonallimagesinanimdb.\"\"\"_t=Timer()num_images=len(roidb)roidb_boxes=[[]for_inrange(num_images)]roidb_scores=[[]for_inrange(num_images)]roidb_ids=[[]for_inrange(num_images)]ifstart_indisNone:start_ind=0end_ind=num_imagestotal_num_images=num_imagesforiinrange(num_images):roidb_ids[i]=roidb[i][\\'id\\']im=cv2.imread(roidb[i][\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):_t.tic()roidb_boxes[i],roidb_scores[i]=im_proposals(model,im)_t.toc()ifi%10==0:ave_time=_t.average_timeeta_seconds=ave_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))logger.info((\\'rpn_generate:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,ave_time,eta))returnroidb_boxes,roidb_scores,roidb_idsdefim_proposals(model,im):\"\"\"GenerateRPNproposalsonasingleimage.\"\"\"inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELrois_names=[core.ScopedName(\\'rpn_rois_fpn\\'+str(l))forlinrange(k_min,k_max+1)]score_names=[core.ScopedName(\\'rpn_roi_probs_fpn\\'+str(l))forlinrange(k_min,k_max+1)]blobs=workspace.FetchBlobs(rois_names+score_names)#Combinepredictionsacrossalllevelsandretainthetopscoringboxes=np.concatenate(blobs[:len(rois_names)])scores=np.concatenate(blobs[len(rois_names):]).squeeze()#Discussion:onecoulddoNMSagainaftercombiningpredictionsfrom#thedifferentFPNlevels.Conceptually,it\\'sprobablytherightthing#todo.Forarbitraryreasons,theoriginalFPNRPNimplementationdid#notdoanotherroundofNMS.inds=np.argsort(-scores)[:cfg.TEST.RPN_POST_NMS_TOP_N]scores=scores[inds]boxes=boxes[inds,:]else:boxes,scores=workspace.FetchBlobs([core.ScopedName(\\'rpn_rois\\'),core.ScopedName(\\'rpn_roi_probs\\')])scores=scores.squeeze()#Column0isthebatchindexinthe(batchind,x1,y1,x2,y2)encoding,#soweremoveitsincewejustwanttoreturnboxes#Scaleproposalsbacktotheoriginalinputimagescaleboxes=boxes[:,1:]/im_scalereturnboxes,scoresdefget_roidb(dataset_name,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,start,end,total_num_imagesdefevaluate_proposal_file(dataset,proposal_file,output_dir):\"\"\"Evaluateboxproposalaveragerecall.\"\"\"roidb=dataset.get_roidb(gt=True,proposal_file=proposal_file)results=task_evaluation.evaluate_box_proposals(dataset,roidb)task_evaluation.log_box_proposal_results(results)recall_file=os.path.join(output_dir,\\'rpn_proposal_recall.pkl\\')save_object(results,recall_file)returnresults#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaRetinaNetnetworkonanimagedatabase\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcollectionsimportdefaultdictfromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)def_create_cell_anchors():\"\"\"Generatealltypesofanchorsforallfpnlevels/scales/aspectratios.Thisfunctioniscalledonlyonceatthebeginningofinference.\"\"\"k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALEA=scales_per_octave*len(aspect_ratios)anchors={}forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=np.zeros((A,4))a=0foroctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foraspectinaspect_ratios:anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect,)cell_anchors[a,:]=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)a+=1anchors[lvl]=cell_anchorsreturnanchorsdefim_detect_bbox(model,im,timers=None):\"\"\"GenerateRetinaNetdetectionsonasingleimage.\"\"\"iftimersisNone:timers=defaultdict(Timer)#Althoughanchorsareinputindependentandcouldbeprecomputed,#recomputingthemperimageonlybringsasmalloverheadanchors=_create_cell_anchors()timers[\\'im_detect_bbox\\'].tic()k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELA=cfg.RETINANET.SCALES_PER_OCTAVE*len(cfg.RETINANET.ASPECT_RATIOS)inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)cls_probs,box_preds=[],[]forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_probs.append(core.ScopedName(\\'retnet_cls_prob_{}\\'.format(suffix)))box_preds.append(core.ScopedName(\\'retnet_bbox_pred_{}\\'.format(suffix)))fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)cls_probs=workspace.FetchBlobs(cls_probs)box_preds=workspace.FetchBlobs(box_preds)#heretheboxes_allare[x0,y0,x1,y1,score]boxes_all=defaultdict(list)cnt=0forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=anchors[lvl]#fetchperlevelprobabilitycls_prob=cls_probs[cnt]box_pred=box_preds[cnt]cls_prob=cls_prob.reshape((cls_prob.shape[0],A,int(cls_prob.shape[1]/A),cls_prob.shape[2],cls_prob.shape[3]))box_pred=box_pred.reshape((box_pred.shape[0],A,4,box_pred.shape[2],box_pred.shape[3]))cnt+=1ifcfg.RETINANET.SOFTMAX:cls_prob=cls_prob[:,:,1::,:,:]cls_prob_ravel=cls_prob.ravel()#Insomecases[especiallyforverysmallimgsizes],it\\'spossiblethat#candidate_indisemptyifweimposethreshold0.05atalllevels.This#willleadtoerrorssincenodetectionsarefoundforthisimage.Hence,#forlvl7whichhassmallspatialresolution,wetakethethreshold0.0th=cfg.RETINANET.INFERENCE_THiflvl<k_maxelse0.0candidate_inds=np.where(cls_prob_ravel>th)[0]if(len(candidate_inds)==0):continuepre_nms_topn=min(cfg.RETINANET.PRE_NMS_TOP_N,len(candidate_inds))inds=np.argpartition(cls_prob_ravel[candidate_inds],-pre_nms_topn)[-pre_nms_topn:]inds=candidate_inds[inds]inds_5d=np.array(np.unravel_index(inds,cls_prob.shape)).transpose()classes=inds_5d[:,2]anchor_ids,y,x=inds_5d[:,1],inds_5d[:,3],inds_5d[:,4]scores=cls_prob[:,anchor_ids,classes,y,x]boxes=np.column_stack((x,y,x,y)).astype(dtype=np.float32)boxes*=strideboxes+=cell_anchors[anchor_ids,:]ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:box_deltas=box_pred[0,anchor_ids,:,y,x]else:box_cls_inds=classes*4box_deltas=np.vstack([box_pred[0,ind:ind+4,yi,xi]forind,yi,xiinzip(box_cls_inds,y,x)])pred_boxes=(box_utils.bbox_transform(boxes,box_deltas)ifcfg.TEST.BBOX_REGelseboxes)pred_boxes/=im_scalepred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)box_scores=np.zeros((pred_boxes.shape[0],5))box_scores[:,0:4]=pred_boxesbox_scores[:,4]=scoresforclsinrange(1,cfg.MODEL.NUM_CLASSES):inds=np.where(classes==cls-1)[0]iflen(inds)>0:boxes_all[cls].extend(box_scores[inds,:])timers[\\'im_detect_bbox\\'].toc()#Combinepredictionsacrossalllevelsandretainthetopscoringbyclasstimers[\\'misc_bbox\\'].tic()detections=[]forcls,boxesinboxes_all.items():cls_dets=np.vstack(boxes).astype(dtype=np.float32)#doclassspecificnmshereifcfg.TEST.SOFT_NMS.ENABLED:cls_dets,keep=box_utils.soft_nms(cls_dets,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(cls_dets,cfg.TEST.NMS)cls_dets=cls_dets[keep,:]out=np.zeros((len(keep),6))out[:,0:5]=cls_detsout[:,5].fill(cls)detections.append(out)#detections(N,6)format:#detections[:,:4]-boxes#detections[:,4]-scores#detections[:,5]-classesdetections=np.vstack(detections)#sortallagaininds=np.argsort(-detections[:,4])detections=detections[inds[0:cfg.TEST.DETECTIONS_PER_IM],:]#Convertthedetectionstoimagecls_format(seecore/test_engine.py)num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]forcinrange(1,num_classes):inds=np.where(detections[:,5]==c)[0]cls_boxes[c]=detections[inds,:5]timers[\\'misc_bbox\\'].toc()returncls_boxes#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Detectronconfigsystem.ThisfilespecifiesdefaultconfigoptionsforDetectron.Youshouldnotchangevaluesinthisfile.Instead,youshouldwriteaconfigfile(inyaml)andusemerge_cfg_from_file(yaml_file)toloaditandoverridethedefaultoptions.Mosttoolsinthetoolsdirectorytakea--cfgoptiontospecifyanoverridefileandanoptionallistofoverride(key,value)pairs:-Seetools/{train,test}_net.pyforexamplecodethatusesmerge_cfg_from_file-Seeconfigs/*/*.yamlforexampleconfigfilesDetectronsupportsalotofdifferentmodeltypes,eachofwhichhasalotofdifferentoptions.TheresultisaHUGEsetofconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromastimportliteral_evalfromfuture.utilsimportiteritemsimportcopyimportioimportloggingimportnumpyasnpimportosimportos.pathasospimportsixfromdetectron.utils.collectionsimportAttrDictfromdetectron.utils.ioimportcache_urllogger=logging.getLogger(__name__)__C=AttrDict()#Consumerscangetconfigby:#fromdetectron.core.configimportcfgcfg=__C#Randomnote:avoidusing\\'.ON\\'asaconfigkeysinceyamlconvertsittoTrue;#prefer\\'ENABLED\\'instead#----------------------------------------------------------------------------##Trainingoptions#----------------------------------------------------------------------------#__C.TRAIN=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TRAIN.WEIGHTS=\\'\\'#Datasetstotrainon#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,themodelistrainedontheirunion__C.TRAIN.DATASETS=()#Scalestouseduringtraining#Eachscaleisthepixelsizeofanimage\\'sshortestside#Ifmultiplescalesarelisted,thenoneisselecteduniformlyatrandomfor#eachtrainingimage(i.e.,scalejitterdataaugmentation)__C.TRAIN.SCALES=(600,)#Maxpixelsizeofthelongestsideofascaledinputimage__C.TRAIN.MAX_SIZE=1000#Images*perGPU*inthetrainingminibatch#Totalimagesperminibatch=TRAIN.IMS_PER_BATCH*NUM_GPUS__C.TRAIN.IMS_PER_BATCH=2#RoIminibatchsize*perimage*(numberofregionsofinterest[ROIs])#TotalnumberofRoIspertrainingminibatch=#TRAIN.BATCH_SIZE_PER_IM*TRAIN.IMS_PER_BATCH*NUM_GPUS#E.g.,acommonconfigurationis:512*2*8=8192__C.TRAIN.BATCH_SIZE_PER_IM=64#TargetfractionofRoIminibatchthatislabeledforeground(i.e.class>0)__C.TRAIN.FG_FRACTION=0.25#OverlapthresholdforanRoItobeconsideredforeground(if>=FG_THRESH)__C.TRAIN.FG_THRESH=0.5#OverlapthresholdforanRoItobeconsideredbackground(class=0if#overlapin[LO,HI))__C.TRAIN.BG_THRESH_HI=0.5__C.TRAIN.BG_THRESH_LO=0.0#Usehorizontally-flippedimagesduringtraining?__C.TRAIN.USE_FLIPPED=True#OverlaprequiredbetweenanRoIandaground-truthboxinorderforthat#(RoI,gtbox)pairtobeusedasabounding-boxregressiontrainingexample__C.TRAIN.BBOX_THRESH=0.5#Snapshot(modelcheckpoint)period#DividebyNUM_GPUStodetermineactualperiod(e.g.,80000/8=>10000iters)#toallowforlineartrainingschedulescaling__C.TRAIN.SNAPSHOT_ITERS=80000#Trainusingtheseproposals#Duringtraining,allproposalsspecifiedinthefileareused(nolimitis#applied)#Proposalfilesmustbeincorrespondencewiththedatasetslistedin#TRAIN.DATASETS__C.TRAIN.PROPOSAL_FILES=()#Makeminibatchesfromimagesthathavesimilaraspectratios(i.e.both#tallandthinorbothshortandwide)#Thisfeatureiscriticalforsavingmemory(andmakestrainingslightly#faster)__C.TRAIN.ASPECT_GROUPING=True#----------------------------------------------------------------------------##RPNtrainingoptions#----------------------------------------------------------------------------##RunGenerateProposalsonGPUifsettoTrue__C.TRAIN.GENERATE_PROPOSALS_ON_GPU=False#Minimumoverlaprequiredbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeapositiveexample(IOU>=thresh==>positiveRPN#example)__C.TRAIN.RPN_POSITIVE_OVERLAP=0.7#Maximumoverlapallowedbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeanegativeexamples(IOUnegativeRPN#example)__C.TRAIN.RPN_NEGATIVE_OVERLAP=0.3#Targetfractionofforeground(positive)examplesperRPNminibatch__C.TRAIN.RPN_FG_FRACTION=0.5#TotalnumberofRPNexamplesperimage__C.TRAIN.RPN_BATCH_SIZE_PER_IM=256#NMSthresholdusedonRPNproposals(usedduringend-to-endtrainingwithRPN)__C.TRAIN.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TRAIN.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TRAIN.RPN_POST_NMS_TOP_N=2000#RemoveRPNanchorsthatgooutsidetheimagebyRPN_STRADDLE_THRESHpixels#Setto-1oralargevalue,e.g.100000,todisablepruninganchors__C.TRAIN.RPN_STRADDLE_THRESH=0#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TRAIN.RPN_MIN_SIZE=0#FilterproposalsthatareinsideofcrowdregionsbyCROWD_FILTER_THRESH#\"Inside\"ismeasuredas:proposal-with-crowdintersectionareadividedby#proposalarea__C.TRAIN.CROWD_FILTER_THRESH=0.7#Ignoreground-truthobjectswitharea<thisthreshold__C.TRAIN.GT_MIN_AREA=-1#FreezethebackbonearchitectureduringtrainingifsettoTrue__C.TRAIN.FREEZE_CONV_BODY=False#Trainingwillresumefromthelatestsnapshot(modelcheckpoint)foundinthe#outputdirectory__C.TRAIN.AUTO_RESUME=True#TrainingwillcopyTRAIN.WEIGHTSandtreatitasacandidatecheckpoint__C.TRAIN.COPY_WEIGHTS=False#AddStopGradataspecifiedstagesothebottomlayersarefrozen__C.TRAIN.FREEZE_AT=2#----------------------------------------------------------------------------##Dataloaderoptions(seedetectron/roi_data/loader.pyformoreinfo)#----------------------------------------------------------------------------#__C.DATA_LOADER=AttrDict()#NumberofPythonthreadstouseforthedataloader(warning:usingtoomany#threadscancauseGIL-basedinterferencewithPythonOpsleadingto*slower*#training;4seemstobethesweetspotinourexperience)__C.DATA_LOADER.NUM_THREADS=4#Sizeofthesharedminibatchqueue__C.DATA_LOADER.MINIBATCH_QUEUE_SIZE=64#CapacityoftheperGPUblobsqueue__C.DATA_LOADER.BLOBS_QUEUE_CAPACITY=8#----------------------------------------------------------------------------##Inference(\\'test\\')options#----------------------------------------------------------------------------#__C.TEST=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TEST.WEIGHTS=\\'\\'#Datasetstoteston#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,testingisperformedoneachonesequentially__C.TEST.DATASETS=()#Scaletouseduringtesting__C.TEST.SCALE=600#Maxpixelsizeofthelongestsideofascaledinputimage__C.TEST.MAX_SIZE=1000#Overlapthresholdusedfornon-maximumsuppression(suppressboxeswith#IoU>=thisthreshold)__C.TEST.NMS=0.3#ApplyFastR-CNNstylebounding-boxregressionifTrue__C.TEST.BBOX_REG=True#Testusingtheseproposalfiles(mustcorrespondwithTEST.DATASETS)__C.TEST.PROPOSAL_FILES=()#RunGenerateProposalsonGPUifsettoTrue__C.TEST.GENERATE_PROPOSALS_ON_GPU=False#Limitonthenumberofproposalsperimageusedduringinference__C.TEST.PROPOSAL_LIMIT=2000#NMSthresholdusedonRPNproposals__C.TEST.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TEST.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TEST.RPN_POST_NMS_TOP_N=2000#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TEST.RPN_MIN_SIZE=0#Maximumnumberofdetectionstoreturnperimage(100isbasedonthelimit#establishedfortheCOCOdataset)__C.TEST.DETECTIONS_PER_IM=100#Minimumscorethreshold(assumingscoresina[0,1]range);avaluechosento#balanceobtaininghighrecallwithnothavingtoomanylowprecision#detectionsthatwillslowdowninferencepostprocessingsteps(likeNMS)__C.TEST.SCORE_THRESH=0.05#SavedetectionresultsfilesifTrue#Iffalse,resultsfilesarecleanedup(theycanbelarge)afterlocal#evaluation__C.TEST.COMPETITION_MODE=True#EvaluatedetectionswiththeCOCOjsondatasetevalcodeevenifit\\'snotthe#evaluationcodeforthedataset(e.g.evaluatePASCALVOCresultsusingthe#COCOAPItogetCOCOstyleAPonPASCALVOC)__C.TEST.FORCE_JSON_DATASET_EVAL=False#[Inferredvalue;donotsetdirectlyinaconfig]#Indicatesifprecomputedproposalsareusedattesttime#Notsetfor1-stagemodelsand2-stagemodelswithRPNsubnetworkenabled__C.TEST.PRECOMPUTED_PROPOSALS=True#Evaluateproposalsinclass-specificAverageRecall(AR).#ItmeansthatonefirstcomputesARwithineachcategoryandthenaverages#overthecategories.ItisnotbiasedtowardstheARoffrequentcategories#comparedwithclass-agnosticAR.__C.TEST.CLASS_SPECIFIC_AR=False#----------------------------------------------------------------------------##Test-timeaugmentationsforboundingboxdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.BBOX_AUG=AttrDict()#Enabletest-timeaugmentationforboundingboxdetectionifTrue__C.TEST.BBOX_AUG.ENABLED=False#Heuristicusedtocombinepredictedboxscores#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.SCORE_HEUR=\\'UNION\\'#Heuristicusedtocombinepredictedboxcoordinates#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.COORD_HEUR=\\'UNION\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.BBOX_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.BBOX_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.BBOX_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.BBOX_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.BBOX_AUG.SCALE_SIZE_DEP=False__C.TEST.BBOX_AUG.AREA_TH_LO=50**2__C.TEST.BBOX_AUG.AREA_TH_HI=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.BBOX_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-timeaugmentationsformaskdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.MASK_AUG=AttrDict()#Enabletest-timeaugmentationforinstancemaskdetectionifTrue__C.TEST.MASK_AUG.ENABLED=False#Heuristicusedtocombinemaskpredictions#SOFTprefixindicatesthatthecomputationisperformedonsoftmasks#Validoptions:(\\'SOFT_AVG\\',\\'SOFT_MAX\\',\\'LOGIT_AVG\\')__C.TEST.MASK_AUG.HEUR=\\'SOFT_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.MASK_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.MASK_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.MASK_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.MASK_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.MASK_AUG.SCALE_SIZE_DEP=False__C.TEST.MASK_AUG.AREA_TH=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.MASK_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-augmentationsforkeypointsdetection#configs/test_time_aug/keypoint_rcnn_R-50-FPN_1x.yaml#----------------------------------------------------------------------------#__C.TEST.KPS_AUG=AttrDict()#Enabletest-timeaugmentationforkeypointdetectionifTrue__C.TEST.KPS_AUG.ENABLED=False#Heuristicusedtocombinekeypointpredictions#Validoptions:(\\'HM_AVG\\',\\'HM_MAX\\')__C.TEST.KPS_AUG.HEUR=\\'HM_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.KPS_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.KPS_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.KPS_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.KPS_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.KPS_AUG.SCALE_SIZE_DEP=False__C.TEST.KPS_AUG.AREA_TH=180**2#Eeachaspectratioisrealtivetoimagewidth__C.TEST.KPS_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##SoftNMS#----------------------------------------------------------------------------#__C.TEST.SOFT_NMS=AttrDict()#UsesoftNMSinsteadofstandardNMSifsettoTrue__C.TEST.SOFT_NMS.ENABLED=False#SeesoftNMSpaperfordefinitionoftheseoptions__C.TEST.SOFT_NMS.METHOD=\\'linear\\'__C.TEST.SOFT_NMS.SIGMA=0.5#ForthesoftNMSoverlapthreshold,wesimplyuseTEST.NMS#----------------------------------------------------------------------------##Boundingboxvoting(fromtheMulti-RegionCNNpaper)#----------------------------------------------------------------------------#__C.TEST.BBOX_VOTE=AttrDict()#UseboxvotingifsettoTrue__C.TEST.BBOX_VOTE.ENABLED=False#WeuseTEST.NMSthresholdfortheNMSstep.VOTE_THoverlapthreshold#isusedtoselectvotingboxes(IoU>=VOTE_TH)foreachboxthatsurvivesNMS__C.TEST.BBOX_VOTE.VOTE_TH=0.8#Themethodusedtocombinescoreswhendoingboundingboxvoting#Validoptionsinclude(\\'ID\\',\\'AVG\\',\\'IOU_AVG\\',\\'GENERALIZED_AVG\\',\\'QUASI_SUM\\')__C.TEST.BBOX_VOTE.SCORING_METHOD=\\'ID\\'#Hyperparameterusedbythescoringmethod(ithasdifferentmeaningsfor#differentmethods)__C.TEST.BBOX_VOTE.SCORING_METHOD_BETA=1.0#----------------------------------------------------------------------------##Modeloptions#----------------------------------------------------------------------------#__C.MODEL=AttrDict()#Thetypeofmodeltouse#Thestringmustmatchafunctioninthemodeling.model_buildermodule#(e.g.,\\'generalized_rcnn\\',\\'mask_rcnn\\',...)__C.MODEL.TYPE=\\'\\'#Thebackboneconvbodytouse#Thestringmustmatchafunctionthatisimportedinmodeling.model_builder#(e.g.,\\'FPN.add_fpn_ResNet101_conv5_body\\'tospecifyaResNet-101-FPN#backbone)__C.MODEL.CONV_BODY=\\'\\'#Numberofclassesinthedataset;mustbeset#E.g.,81forCOCO(80foreground+1background)__C.MODEL.NUM_CLASSES=-1#Useaclassagnosticboundingboxregressorinsteadofthedefaultper-class#regressor__C.MODEL.CLS_AGNOSTIC_BBOX_REG=False#Defaultweightson(dx,dy,dw,dh)fornormalizingbboxregressiontargets#Theseareempiricallychosentoapproximatelyleadtounitvariancetargets__C.MODEL.BBOX_REG_WEIGHTS=(10.,10.,5.,5.)#ThemeaningofFASTER_RCNNdependsonthecontext(trainingvs.inference):#1)Duringtraining,FASTER_RCNN=Truemeansthatend-to-endtrainingwillbe#usedtojointlytraintheRPNsubnetworkandtheFastR-CNNsubnetwork#(FasterR-CNN=RPN+FastR-CNN).#2)Duringinference,FASTER_RCNN=Truemeansthatthemodel\\'sRPNsubnetwork#willbeusedtogenerateproposalsratherthanrelyingonprecomputed#proposals.NotethatFASTER_RCNN=Truecanbeusedatinferencetimeeven#iftheFasterR-CNNmodelwastrainedwithstagewisetraining(which#consistsofalternatingbetweenRPNandFastR-CNNtraininginawaythat#finallyleadstoasinglenetwork).__C.MODEL.FASTER_RCNN=False#Indicatesthemodelmakesinstancemaskpredictions(asinMaskR-CNN)__C.MODEL.MASK_ON=False#Indicatesthemodelmakeskeypointpredictions(asinMaskR-CNNfor#keypoints)__C.MODEL.KEYPOINTS_ON=False#Indicatesthemodel\\'scomputationterminateswiththeproductionofRPN#proposals(i.e.,itoutputsproposalsONLY,noactualobjectdetections)__C.MODEL.RPN_ONLY=False#Caffe2netexecutiontype#Use\\'prof_dag\\'togetprofilingstatistics__C.MODEL.EXECUTION_TYPE=\\'dag\\'#----------------------------------------------------------------------------##RetinaNetoptions#----------------------------------------------------------------------------#__C.RETINANET=AttrDict()#RetinaNetisused(insteadofFast/er/MaskR-CNN/R-FCN/RPN)ifTrue__C.RETINANET.RETINANET_ON=False#Anchoraspectratiostouse__C.RETINANET.ASPECT_RATIOS=(0.5,1.0,2.0)#Anchorscalesperoctave__C.RETINANET.SCALES_PER_OCTAVE=3#AteachFPNlevel,wegenerateanchorsbasedontheirscale,aspect_ratio,#strideofthelevel,andwemultiplytheresultinganchorbyANCHOR_SCALE__C.RETINANET.ANCHOR_SCALE=4#Convolutionstouseintheclsandbboxtower#NOTE:thisdoesn\\'tincludethelastconvforlogits__C.RETINANET.NUM_CONVS=4#Weightforbbox_regressionloss__C.RETINANET.BBOX_REG_WEIGHT=1.0#SmoothL1lossbetaforbboxregression__C.RETINANET.BBOX_REG_BETA=0.11#Duringinference,#locstoselectbasedonclsscorebeforeNMSisperformed#perFPNlevel__C.RETINANET.PRE_NMS_TOP_N=1000#IoUoverlapratioforlabelingananchoraspositive#Anchorswith>=iouoverlaparelabeledpositive__C.RETINANET.POSITIVE_OVERLAP=0.5#IoUoverlapratioforlabelingananchorasnegative#Anchorswith<iouoverlaparelabelednegative__C.RETINANET.NEGATIVE_OVERLAP=0.4#Focallossparameter:alpha__C.RETINANET.LOSS_ALPHA=0.25#Focallossparameter:gamma__C.RETINANET.LOSS_GAMMA=2.0#Priorprobforthepositivesatthebeginningoftraining.Thisisusedtoset#thebiasinitforthelogitslayer__C.RETINANET.PRIOR_PROB=0.01#Whetherclassificationandbboxbranchtowershouldbesharedornot__C.RETINANET.SHARE_CLS_BBOX_TOWER=False#Useclassspecificboundingboxregressioninsteadofthedefaultclass#agnosticregression__C.RETINANET.CLASS_SPECIFIC_BBOX=False#Whethersoftmaxshouldbeusedinclassificationbranchtraining__C.RETINANET.SOFTMAX=False#Inferenceclsscorethreshold,anchorswithscore>INFERENCE_THare#consideredforinference__C.RETINANET.INFERENCE_TH=0.05#----------------------------------------------------------------------------##Solveroptions#Note:allsolveroptionsareusedexactlyasspecified;theimplicationis#thatifyouswitchfromtrainingon1GPUtoNGPUs,youMUSTadjustthe#solverconfigurationaccordingly.Wesuggestusinggradualwarmupandthe#linearlearningratescalingruleasdescribedin#\"Accurate,LargeMinibatchSGD:TrainingImageNetin1Hour\"Goyaletal.##----------------------------------------------------------------------------#__C.SOLVER=AttrDict()#Baselearningrateforthespecifiedschedule__C.SOLVER.BASE_LR=0.001#Scheduletype(seefunctionsinutils.lr_policyforoptions)#E.g.,\\'step\\',\\'steps_with_decay\\',...__C.SOLVER.LR_POLICY=\\'step\\'#SomeLRPolicies(byexample):#\\'step\\'#lr=SOLVER.BASE_LR*SOLVER.GAMMA**(cur_iter//SOLVER.STEP_SIZE)#\\'steps_with_decay\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.GAMMA=0.1#lr=SOLVER.BASE_LR*SOLVER.GAMMA**current_step#iters[0,59999]areincurrent_step=0,iters[60000,79999]arein#current_step=1,andsoon#\\'steps_with_lrs\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.LRS=[0.02,0.002,0.0002]#lr=LRS[current_step]#\\'cosine_decay\\'#lr=SOLVER.BASE_LR*(cos(PI*cur_iter/SOLVER.MAX_ITER)*0.5+0.5)#\\'exp_decay\\'#lrsmoothlydecaysfromSOLVER.BASE_LRtoSOLVER.GAMMA*SOLVER.BASE_LR#lr=SOLVER.BASE_LR*exp(np.log(SOLVER.GAMMA)*cur_iter/SOLVER.MAX_ITER)#Hyperparameterusedbythespecifiedpolicy#For\\'step\\',thecurrentLRismultipliedbySOLVER.GAMMAateachstep#For\\'exp_decay\\',SOLVER.GAMMAistheratiobetweenthefinalandinitialLR.__C.SOLVER.GAMMA=0.1#Uniformstepsizefor\\'steps\\'policy__C.SOLVER.STEP_SIZE=30000#Non-uniformstepiterationsfor\\'steps_with_decay\\'or\\'steps_with_lrs\\'#policies__C.SOLVER.STEPS=[]#Learningratestousewith\\'steps_with_lrs\\'policy__C.SOLVER.LRS=[]#MaximumnumberofSGDiterations__C.SOLVER.MAX_ITER=40000#MomentumtousewithSGD__C.SOLVER.MOMENTUM=0.9#L2regularizationhyperparameter__C.SOLVER.WEIGHT_DECAY=0.0005#L2regularizationhyperparameterforGroupNorm\\'sparameters__C.SOLVER.WEIGHT_DECAY_GN=0.0#WarmuptoSOLVER.BASE_LRoverthisnumberofSGDiterations__C.SOLVER.WARM_UP_ITERS=500#StartthewarmupfromSOLVER.BASE_LR*SOLVER.WARM_UP_FACTOR__C.SOLVER.WARM_UP_FACTOR=1.0/3.0#WARM_UP_METHODcanbeeither\\'constant\\'or\\'linear\\'(i.e.,gradual)__C.SOLVER.WARM_UP_METHOD=\\'linear\\'#Scalethemomentumupdatehistorybynew_lr/old_lrwhenupdatingthe#learningrate(thisiscorrectgivenMomentumSGDUpdateOp)__C.SOLVER.SCALE_MOMENTUM=True#OnlyapplythecorrectioniftherelativeLRchangeexceedsthisthreshold#(preventseverchangeinlinearwarmupfromscalingthemomentumbyatiny#amount;momentumscalingisonlyimportantiftheLRchangeislarge)__C.SOLVER.SCALE_MOMENTUM_THRESHOLD=1.1#SuppressloggingofchangestoLRunlesstherelativechangeexceedsthis#threshold(preventslinearwarmupfromspammingthetraininglog)__C.SOLVER.LOG_LR_CHANGE_THRESHOLD=1.1#----------------------------------------------------------------------------##FastR-CNNoptions#----------------------------------------------------------------------------#__C.FAST_RCNN=AttrDict()#ThetypeofRoIheadtouseforboundingboxclassificationandregression#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'head_builder.add_roi_2mlp_head\\'tospecifyatwohiddenlayerMLP)__C.FAST_RCNN.ROI_BOX_HEAD=\\'\\'#HiddenlayerdimensionwhenusinganMLPfortheRoIboxhead__C.FAST_RCNN.MLP_HEAD_DIM=1024#HiddenConvlayerdimensionwhenusingConvsfortheRoIboxhead__C.FAST_RCNN.CONV_HEAD_DIM=256#NumberofstackedConvlayersintheRoIboxhead__C.FAST_RCNN.NUM_STACKED_CONVS=4#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)#(RoIPoolFisthesameasRoIPool;ignorethetrailing\\'F\\')__C.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIPoolF\\'#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO=0#RoItransformoutputresolution#Note:somemodelsmayhaveconstraintsonwhattheycanuse,e.g.theyuse#pretrainedFClayerslikeinVGG16,andwillignorethisoption__C.FAST_RCNN.ROI_XFORM_RESOLUTION=14#----------------------------------------------------------------------------##RPNoptions#----------------------------------------------------------------------------#__C.RPN=AttrDict()#[Inferedvalue;donotsetdirectlyinaconfig]#IndicatesthatthemodelcontainsanRPNsubnetwork__C.RPN.RPN_ON=False#RPNanchorsizesgiveninabsolutepixelsw.r.t.thescalednetworkinput#Note:theseoptionsare*not*usedbyFPNRPN;seeFPN.RPN*options__C.RPN.SIZES=(64,128,256,512)#StrideofthefeaturemapthatRPNisattached__C.RPN.STRIDE=16#RPNanchoraspectratios__C.RPN.ASPECT_RATIOS=(0.5,1,2)#----------------------------------------------------------------------------##FPNoptions#----------------------------------------------------------------------------#__C.FPN=AttrDict()#FPNisenabledifTrue__C.FPN.FPN_ON=False#ChanneldimensionoftheFPNfeaturelevels__C.FPN.DIM=256#InitializethelateralconnectionstooutputzeroifTrue__C.FPN.ZERO_INIT_LATERAL=False#StrideofthecoarsestFPNlevel#Thisisneededsotheinputcanbepaddedproperly__C.FPN.COARSEST_STRIDE=32##FPNmaybeusedforjustRPN,justobjectdetection,orboth##UseFPNforRoItransformforobjectdetectionifTrue__C.FPN.MULTILEVEL_ROIS=False#HyperparametersfortheRoI-to-FPNlevelmappingheuristic__C.FPN.ROI_CANONICAL_SCALE=224#s0__C.FPN.ROI_CANONICAL_LEVEL=4#k0:wheres0mapsto#CoarsestleveloftheFPNpyramid__C.FPN.ROI_MAX_LEVEL=5#FinestleveloftheFPNpyramid__C.FPN.ROI_MIN_LEVEL=2#UseFPNforRPNifTrue__C.FPN.MULTILEVEL_RPN=False#CoarsestleveloftheFPNpyramid__C.FPN.RPN_MAX_LEVEL=6#FinestleveloftheFPNpyramid__C.FPN.RPN_MIN_LEVEL=2#FPNRPNanchoraspectratios__C.FPN.RPN_ASPECT_RATIOS=(0.5,1,2)#RPNanchorsstartatthissizeonRPN_MIN_LEVEL#Theanchorsizedoubledeachlevelafterthat#Withadefaultof32andlevels2to6,wegetanchorsizesof32to512__C.FPN.RPN_ANCHOR_START_SIZE=32#UseextraFPNlevels,asdoneintheRetinaNetpaper__C.FPN.EXTRA_CONV_LEVELS=False#UseGroupNormintheFPN-specificlayers(lateral,etc.)__C.FPN.USE_GN=False#----------------------------------------------------------------------------##MaskR-CNNoptions(\"MRCNN\"meansMaskR-CNN)#----------------------------------------------------------------------------#__C.MRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancemaskprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\')__C.MRCNN.ROI_MASK_HEAD=\\'\\'#Resolutionofmaskpredictions__C.MRCNN.RESOLUTION=14#RoItransformationfunctionandassociatedoptions__C.MRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)__C.MRCNN.ROI_XFORM_RESOLUTION=7#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.MRCNN.ROI_XFORM_SAMPLING_RATIO=0#Numberofchannelsinthemaskhead__C.MRCNN.DIM_REDUCED=256#Usedilatedconvolutioninthemaskhead__C.MRCNN.DILATION=2#Upsamplethepredictedmasksbythisfactor__C.MRCNN.UPSAMPLE_RATIO=1#Useafully-connectedlayertopredictthefinalmasksinsteadofaconvlayer__C.MRCNN.USE_FC_OUTPUT=False#Weightinitializationmethodforthemaskheadandmaskoutputlayers__C.MRCNN.CONV_INIT=\\'GaussianFill\\'#UseclassspecificmaskpredictionsifTrue(otherwiseuseclassagnosticmask#predictions)__C.MRCNN.CLS_SPECIFIC_MASK=True#Multi-tasklossweightformasks__C.MRCNN.WEIGHT_LOSS_MASK=1.0#Binarizationthresholdforconvertingsoftmaskstohardmasks__C.MRCNN.THRESH_BINARIZE=0.5#----------------------------------------------------------------------------##KeypointMaskR-CNNoptions(\"KRCNN\"=MaskR-CNNwithKeypointsupport)#----------------------------------------------------------------------------#__C.KRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancekeypointprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'keypoint_rcnn_heads.add_roi_pose_head_v1convX\\')__C.KRCNN.ROI_KEYPOINTS_HEAD=\\'\\'#Outputsize(andsizelossiscomputedon),e.g.,56x56__C.KRCNN.HEATMAP_SIZE=-1#Usebilinearinterpolationtoupsamplethefinalheatmapbythisfactor__C.KRCNN.UP_SCALE=-1#ApplyaConvTransposelayertothehiddenrepresentationcomputedbythe#keypointheadpriortopredictingtheper-keypointheatmaps__C.KRCNN.USE_DECONV=False#ChanneldimensionofthehiddenrepresentationproducedbytheConvTranspose__C.KRCNN.DECONV_DIM=256#UseaConvTransposelayertopredicttheper-keypointheatmaps__C.KRCNN.USE_DECONV_OUTPUT=False#Usedilationinthekeypointhead__C.KRCNN.DILATION=1#SizeofthekernelstouseinallConvTransposeoperations__C.KRCNN.DECONV_KERNEL=4#Numberofkeypointsinthedataset(e.g.,17forCOCO)__C.KRCNN.NUM_KEYPOINTS=-1#NumberofstackedConvlayersinkeypointhead__C.KRCNN.NUM_STACKED_CONVS=8#Dimensionofthehiddenrepresentationoutputbythekeypointhead__C.KRCNN.CONV_HEAD_DIM=256#Convkernelsizeusedinthekeypointhead__C.KRCNN.CONV_HEAD_KERNEL=3#Convkernelweightfillingfunction__C.KRCNN.CONV_INIT=\\'GaussianFill\\'#UseNMSbasedonOKSifTrue__C.KRCNN.NMS_OKS=False#Sourceofkeypointconfidence#Validoptions:(\\'bbox\\',\\'logit\\',\\'prob\\')__C.KRCNN.KEYPOINT_CONFIDENCE=\\'bbox\\'#StandardROIXFORMoptions(seeFAST_RCNNorMRCNNoptions)__C.KRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'__C.KRCNN.ROI_XFORM_RESOLUTION=7__C.KRCNN.ROI_XFORM_SAMPLING_RATIO=0#Minimumnumberoflabeledkeypointsthatmustexistinaminibatch(otherwise#theminibatchisdiscarded)__C.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH=20#Wheninferingthekeypointlocationsfromtheheatmap,don\\'tscaletheheatmap#belowthisminimumsize__C.KRCNN.INFERENCE_MIN_SIZE=0#Multi-tasklossweighttouseforkeypoints#Recommendedvalues:#-use1.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisTrue#-use4.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse__C.KRCNN.LOSS_WEIGHT=1.0#NormalizebythetotalnumberofvisiblekeypointsintheminibatchifTrue.#Otherwise,normalizebythetotalnumberofkeypointsthatcouldeverexist#intheminibatch.Seecommentsinmodeling.model_builder.add_keypoint_losses#fordetaileddiscussion.__C.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS=True#----------------------------------------------------------------------------##R-FCNoptions#----------------------------------------------------------------------------#__C.RFCN=AttrDict()#Position-sensitiveRoIpoolingoutputgridsize(heightandwidth)__C.RFCN.PS_GRID_SIZE=3#----------------------------------------------------------------------------##ResNetsoptions(\"ResNets\"=ResNetandResNeXt)#----------------------------------------------------------------------------#__C.RESNETS=AttrDict()#Numberofgroupstouse;1==>ResNet;>1==>ResNeXt__C.RESNETS.NUM_GROUPS=1#Baselinewidthofeachgroup__C.RESNETS.WIDTH_PER_GROUP=64#Placethestride2convonthe1x1filter#UseTrueonlyfortheoriginalMSRAResNet;useFalseforC2andTorchmodels__C.RESNETS.STRIDE_1X1=True#Residualtransformationfunction__C.RESNETS.TRANS_FUNC=\\'bottleneck_transformation\\'#ResNet\\'sstemfunction(conv1andpool1)__C.RESNETS.STEM_FUNC=\\'basic_bn_stem\\'#ResNet\\'sshortcutfunction__C.RESNETS.SHORTCUT_FUNC=\\'basic_bn_shortcut\\'#Applydilationinstage\"res5\"__C.RESNETS.RES5_DILATION=1#----------------------------------------------------------------------------##GroupNormoptions#----------------------------------------------------------------------------#__C.GROUP_NORM=AttrDict()#NumberofdimensionspergroupinGroupNorm(-1ifusingNUM_GROUPS)__C.GROUP_NORM.DIM_PER_GP=-1#NumberofgroupsinGroupNorm(-1ifusingDIM_PER_GP)__C.GROUP_NORM.NUM_GROUPS=32#GroupNorm\\'ssmallconstantinthedenominator__C.GROUP_NORM.EPSILON=1e-5#----------------------------------------------------------------------------##Miscoptions#----------------------------------------------------------------------------##NumberofGPUstouse(appliestobothtrainingandtesting)__C.NUM_GPUS=1#UseNCCLforallreduce,otherwiseusemuji#Warning:ifsettoTrue,youmayexperiencedeadlocks__C.USE_NCCL=False#Themappingfromimagecoordinatestofeaturemapcoordinatesmightcause#someboxesthataredistinctinimagespacetobecomeidenticalinfeature#coordinates.IfDEDUP_BOXES>0,thenDEDUP_BOXESisusedasthescalefactor#foridentifyingduplicateboxes.#1/16iscorrectfor{Alex,Caffe}Net,VGG_CNN_M_1024,andVGG16__C.DEDUP_BOXES=1/16.#Clipboundingboxtransformationpredictionstopreventnp.expfrom#overflowing#Heuristicchoicebasedonthatwouldscalea16pixelanchorupto1000pixels__C.BBOX_XFORM_CLIP=np.log(1000./16.)#Pixelmeanvalues(BGRorder)asa(1,1,3)array#Weusethesamepixelmeanforallnetworkseventhoughit\\'snotexactlywhat#theyweretrainedwith#\"Fun\"fact:thehistoryofwherethesevaluescomesfromislost__C.PIXEL_MEANS=np.array([[[102.9801,115.9465,122.7717]]])#Forreproducibility...butnotreallybecausemodernfastGPUlibrariesuse#non-deterministicopimplementations__C.RNG_SEED=3#Asmallnumberthat\\'susedmanytimes__C.EPS=1e-14#Rootdirectoryofproject__C.ROOT_DIR=os.getcwd()#Outputbasedir__C.OUTPUT_DIR=\\'/tmp\\'#Name(orpathto)thematlabexecutable__C.MATLAB=\\'matlab\\'#Reducememoryusagewithmemongergradientblobsharing__C.MEMONGER=True#Futherreducememorybyallowingforwardpassactivationstobesharedwhen#possible.Notethatthiswillcauseactivationblobinspection(values,#shapes,etc.)tobemeaninglesswhenactivationblobsarereused.__C.MEMONGER_SHARE_ACTIVATIONS=False#Dumpdetectionvisualizations__C.VIS=False#Scorethresholdforvisualization__C.VIS_TH=0.9#Expectedresultsshouldtaketheformofalistofexpectations,each#specifiedbyfourelements(dataset,task,metric,expectedvalue).For#example:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387]]__C.EXPECTED_RESULTS=[]#AbsoluteandrelativetolerancetousewhencomparingtoEXPECTED_RESULTS__C.EXPECTED_RESULTS_RTOL=0.1__C.EXPECTED_RESULTS_ATOL=0.005#Whentheexpectedvaluespecifiesameanandstandarddeviation,wecheck#thattheactualvalueiswithinmean+/-SIGMA_TOL*std__C.EXPECTED_RESULTS_SIGMA_TOL=4#SettosendemailincaseofanEXPECTED_RESULTSfailure__C.EXPECTED_RESULTS_EMAIL=\\'\\'#ModelsandproposalsreferredtobyURLaredownloadedtoalocalcache#specifiedbyDOWNLOAD_CACHE__C.DOWNLOAD_CACHE=\\'/tmp/detectron-download-cache\\'#----------------------------------------------------------------------------##Clusteroptions#----------------------------------------------------------------------------#__C.CLUSTER=AttrDict()#Flagtoindicateifthecodeisrunninginaclusterenvironment__C.CLUSTER.ON_CLUSTER=False#----------------------------------------------------------------------------##Deprecatedoptions#Ifanoptionisremovedfromthecodeandyoudon\\'twanttobreakexisting#yamlconfigs,youcanaddthefullconfigkeyasastringtothesetbelow.#----------------------------------------------------------------------------#_DEPRECATED_KEYS=set({\\'FINAL_MSG\\',\\'MODEL.DILATION\\',\\'ROOT_GPU_ID\\',\\'RPN.ON\\',\\'TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED\\',\\'TRAIN.DROPOUT\\',\\'USE_GPU_NMS\\',\\'TEST.NUM_TEST_IMAGES\\',})#----------------------------------------------------------------------------##Renamedoptions#Ifyourenameaconfigoption,recordthemappingfromtheoldnametothenew#nameinthedictionarybelow.Optionally,ifthetypealsochanged,youcan#makethevalueatuplethatspecifiesfirsttherenamedkeyandthen#instructionsforhowtoedittheconfigfile.#----------------------------------------------------------------------------#_RENAMED_KEYS={\\'EXAMPLE.RENAMED.KEY\\':\\'EXAMPLE.KEY\\',#Dummyexampletofollow\\'MODEL.PS_GRID_SIZE\\':\\'RFCN.PS_GRID_SIZE\\',\\'MODEL.ROI_HEAD\\':\\'FAST_RCNN.ROI_BOX_HEAD\\',\\'MRCNN.MASK_HEAD_NAME\\':\\'MRCNN.ROI_MASK_HEAD\\',\\'TRAIN.DATASET\\':(\\'TRAIN.DATASETS\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'coco_2014_train\\'->(\\'coco_2014_train\\',)or\"+\"\\'coco_2014_train:coco_2014_valminusminival\\'->\"+\"(\\'coco_2014_train\\',\\'coco_2014_valminusminival\\')\"),\\'TRAIN.PROPOSAL_FILE\\':(\\'TRAIN.PROPOSAL_FILES\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'path/to/file\\'->(\\'path/to/file\\',)or\"+\"\\'path/to/file1:path/to/file2\\'->\"+\"(\\'path/to/file1\\',\\'path/to/file2\\')\"),\\'TEST.SCALES\\':(\\'TEST.SCALE\\',\"Alsoconvertfromatuple,e.g.(600,),\"+\"toainteger,e.g.600.\"),\\'TEST.DATASET\\':(\\'TEST.DATASETS\\',\"Alsoconvertfromastring,e.g\\'coco_2014_minival\\',\"+\"toatuple,e.g.(\\'coco_2014_minival\\',).\"),\\'TEST.PROPOSAL_FILE\\':(\\'TEST.PROPOSAL_FILES\\',\"Alsoconvertfromastring,e.g.\\'/path/to/props.pkl\\',\"+\"toatuple,e.g.(\\'/path/to/props.pkl\\',).\"),}#----------------------------------------------------------------------------##Renamedmodules#Ifamodulecontainingadatastructureusedintheconfig(e.g.AttrDict)#isrenamed/movedandyoudon\\'twanttobreakloadingofexistingyamlconfigs#(e.g.fromweightsfiles)youcanspecifytherenamedmodulebelow.#----------------------------------------------------------------------------#_RENAMED_MODULES={\\'utils.collections\\':\\'detectron.utils.collections\\',}defassert_and_infer_cfg(cache_urls=True,make_immutable=True):\"\"\"Callthisfunctioninyourscriptafteryouhavefinishedsettingallcfgvaluesthatarenecessary(e.g.,mergingaconfigfromafile,mergingcommandlineconfigoptions,etc.).Bydefault,thisfunctionwillalsomarktheglobalcfgasimmutabletopreventchangingtheglobalcfgsettingsduringscriptexecution(whichcanleadtohardtodebugerrorsorcodethat\\'shardertounderstandthanisnecessary).\"\"\"if__C.MODEL.RPN_ONLYor__C.MODEL.FASTER_RCNN:__C.RPN.RPN_ON=Trueif__C.RPN.RPN_ONor__C.RETINANET.RETINANET_ON:__C.TEST.PRECOMPUTED_PROPOSALS=Falseifcache_urls:cache_cfg_urls()ifmake_immutable:cfg.immutable(True)defcache_cfg_urls():\"\"\"DownloadURLsintheconfig,cachethemlocally,andrewritecfgtomakeuseofthelocallycachedfile.\"\"\"__C.TRAIN.WEIGHTS=cache_url(__C.TRAIN.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TEST.WEIGHTS=cache_url(__C.TEST.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TRAIN.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TRAIN.PROPOSAL_FILES)__C.TEST.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TEST.PROPOSAL_FILES)defget_output_dir(datasets,training=True):\"\"\"Gettheoutputdirectorydeterminedbythecurrentglobalconfig.\"\"\"assertisinstance(datasets,tuple([tuple,list]+list(six.string_types))),\\\\\\'datasetsargumentmustbeoftypetuple,listorstring\\'is_string=isinstance(datasets,six.string_types)dataset_name=datasetsifis_stringelse\\':\\'.join(datasets)tag=\\'train\\'iftrainingelse\\'test\\'#////outdir=osp.join(__C.OUTPUT_DIR,tag,dataset_name,__C.MODEL.TYPE)ifnotosp.exists(outdir):os.makedirs(outdir)returnoutdirdefload_cfg(cfg_to_load):\"\"\"Wrapperaroundyaml.loadusedformaintainingbackwardcompatibility\"\"\"file_types=[file,io.IOBase]ifsix.PY2else[io.IOBase]#noqafalsepositiveexpected_types=tuple(file_types+list(six.string_types))assertisinstance(cfg_to_load,expected_types),\\\\\\'Expectedoneof{},got{}\\'.format(expected_types,type(cfg_to_load))ifisinstance(cfg_to_load,tuple(file_types)):cfg_to_load=\\'\\'.join(cfg_to_load.readlines())forold_module,new_moduleiniteritems(_RENAMED_MODULES):#yamlobjectencoding:!!python/object/new:.old_module,new_module=\\'new:\\'+old_module,\\'new:\\'+new_modulecfg_to_load=cfg_to_load.replace(old_module,new_module)#Importinlineduetoacirculardependencybetweenenv.pyandconfig.pyimportdetectron.utils.envasenvureturnenvu.yaml_load(cfg_to_load)defmerge_cfg_from_file(cfg_filename):\"\"\"Loadayamlconfigfileandmergeitintotheglobalconfig.\"\"\"withopen(cfg_filename,\\'r\\')asf:yaml_cfg=AttrDict(load_cfg(f))_merge_a_into_b(yaml_cfg,__C)defmerge_cfg_from_cfg(cfg_other):\"\"\"Merge`cfg_other`intotheglobalconfig.\"\"\"_merge_a_into_b(cfg_other,__C)defmerge_cfg_from_list(cfg_list):\"\"\"Mergeconfigkeys,valuesinalist(e.g.,fromcommandline)intotheglobalconfig.Forexample,`cfg_list=[\\'TEST.NMS\\',0.5]`.\"\"\"assertlen(cfg_list)%2==0forfull_key,vinzip(cfg_list[0::2],cfg_list[1::2]):if_key_is_deprecated(full_key):continueif_key_is_renamed(full_key):_raise_key_rename_error(full_key)key_list=full_key.split(\\'.\\')d=__Cforsubkeyinkey_list[:-1]:assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)d=d[subkey]subkey=key_list[-1]assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)value=_decode_cfg_value(v)value=_check_and_coerce_cfg_value_type(value,d[subkey],subkey,full_key)d[subkey]=valuedef_merge_a_into_b(a,b,stack=None):\"\"\"Mergeconfigdictionaryaintoconfigdictionaryb,clobberingtheoptionsinbwhenevertheyarealsospecifiedina.\"\"\"assertisinstance(a,AttrDict),\\\\\\'`a`(curtype{})mustbeaninstanceof{}\\'.format(type(a),AttrDict)assertisinstance(b,AttrDict),\\\\\\'`b`(curtype{})mustbeaninstanceof{}\\'.format(type(b),AttrDict)fork,v_ina.items():full_key=\\'.\\'.join(stack)+\\'.\\'+kifstackisnotNoneelsek#amustspecifykeysthatareinbifknotinb:if_key_is_deprecated(full_key):continueelif_key_is_renamed(full_key):_raise_key_rename_error(full_key)else:raiseKeyError(\\'Non-existentconfigkey:{}\\'.format(full_key))v=copy.deepcopy(v_)v=_decode_cfg_value(v)v=_check_and_coerce_cfg_value_type(v,b[k],k,full_key)#Recursivelymergedictsifisinstance(v,AttrDict):try:stack_push=[k]ifstackisNoneelsestack+[k]_merge_a_into_b(v,b[k],stack=stack_push)exceptBaseException:raiseelse:b[k]=vdef_key_is_deprecated(full_key):iffull_keyin_DEPRECATED_KEYS:logger.warn(\\'Deprecatedconfigkey(ignoring):{}\\'.format(full_key))returnTruereturnFalsedef_key_is_renamed(full_key):returnfull_keyin_RENAMED_KEYSdef_raise_key_rename_error(full_key):new_key=_RENAMED_KEYS[full_key]ifisinstance(new_key,tuple):msg=\\'Note:\\'+new_key[1]new_key=new_key[0]else:msg=\\'\\'raiseKeyError(\\'Key{}wasrenamedto{};pleaseupdateyourconfig.{}\\'.format(full_key,new_key,msg))def_decode_cfg_value(v):\"\"\"Decodesarawconfigvalue(e.g.,fromayamlconfigfilesorcommandlineargument)intoaPythonobject.\"\"\"#Configsparsedfromrawyamlwillcontaindictionarykeysthatneedtobe#convertedtoAttrDictobjectsifisinstance(v,dict):returnAttrDict(v)#Allremainingprocessingisonlyappliedtostringsifnotisinstance(v,six.string_types):returnv#Trytointerpret`v`asa:#string,number,tuple,list,dict,boolean,orNonetry:v=literal_eval(v)#Thefollowingtwoexceptsallowvtopassthroughwhenitrepresentsa#string.##Longerexplanation:#Thetypeofvisalwaysastring(beforecallingliteral_eval),but#sometimesit*represents*astringandothertimesadatastructure,like#alist.Inthecasethatvrepresentsastring,whatwegotbackfromthe#yamlparseris\\'foo\\'*withoutquotes*(so,not\\'\"foo\"\\').literal_evalis#okwith\\'\"foo\"\\',butwillraiseaValueErrorifgiven\\'foo\\'.Inother#cases,likepaths(v=\\'foo/bar\\'andnotv=\\'\"foo/bar\"\\'),literal_eval#willraiseaSyntaxError.exceptValueError:passexceptSyntaxError:passreturnvdef_check_and_coerce_cfg_value_type(value_a,value_b,key,full_key):\"\"\"Checksthat`value_a`,whichisintendedtoreplace`value_b`isoftherighttype.Thetypeiscorrectifitmatchesexactlyorisoneofafewcasesinwhichthetypecanbeeasilycoerced.\"\"\"#Thetypesmustmatch(withsomeexceptions)type_b=type(value_b)type_a=type(value_a)iftype_aistype_b:returnvalue_a#Exceptions:numpyarrays,strings,tuplelistifisinstance(value_b,np.ndarray):value_a=np.array(value_a,dtype=value_b.dtype)elifisinstance(value_b,six.string_types):value_a=str(value_a)elifisinstance(value_a,tuple)andisinstance(value_b,list):value_a=list(value_a)elifisinstance(value_a,list)andisinstance(value_b,tuple):value_a=tuple(value_a)else:raiseValueError(\\'Typemismatch({}vs.{})withvalues({}vs.{})forconfig\\'\\'key:{}\\'.format(type_b,type_a,value_b,value_a,full_key))returnvalue_a#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"InferencefunctionalityformostDetectronmodels.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importloggingimportnumpyasnpfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.core.test_retinanetastest_retinanetimportdetectron.modeling.FPNasfpnimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.imageasimage_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defim_detect_all(model,im,box_proposals,timers=None):iftimersisNone:timers=defaultdict(Timer)#HandleRetinaNettestingseparatelyfornowifcfg.RETINANET.RETINANET_ON:cls_boxes=test_retinanet.im_detect_bbox(model,im,timers)returncls_boxes,None,Nonetimers[\\'im_detect_bbox\\'].tic()ifcfg.TEST.BBOX_AUG.ENABLED:scores,boxes,im_scale=im_detect_bbox_aug(model,im,box_proposals)else:scores,boxes,im_scale=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)timers[\\'im_detect_bbox\\'].toc()#scoreandboxesarefromthewholeimageafterscorethresholdingandnms#(theyarenotseparatedbyclass)#cls_boxesboxesandscoresareseparatedbyclassandintheformatused#forevaluatingresultstimers[\\'misc_bbox\\'].tic()scores,boxes,cls_boxes=box_results_with_nms_and_limit(scores,boxes)timers[\\'misc_bbox\\'].toc()ifcfg.MODEL.MASK_ONandboxes.shape[0]>0:timers[\\'im_detect_mask\\'].tic()ifcfg.TEST.MASK_AUG.ENABLED:masks=im_detect_mask_aug(model,im,boxes)else:masks=im_detect_mask(model,im_scale,boxes)timers[\\'im_detect_mask\\'].toc()timers[\\'misc_mask\\'].tic()cls_segms=segm_results(cls_boxes,masks,boxes,im.shape[0],im.shape[1])timers[\\'misc_mask\\'].toc()else:cls_segms=Noneifcfg.MODEL.KEYPOINTS_ONandboxes.shape[0]>0:timers[\\'im_detect_keypoints\\'].tic()ifcfg.TEST.KPS_AUG.ENABLED:heatmaps=im_detect_keypoints_aug(model,im,boxes)else:heatmaps=im_detect_keypoints(model,im_scale,boxes)timers[\\'im_detect_keypoints\\'].toc()timers[\\'misc_keypoints\\'].tic()cls_keyps=keypoint_results(cls_boxes,heatmaps,boxes)timers[\\'misc_keypoints\\'].toc()else:cls_keyps=Nonereturncls_boxes,cls_segms,cls_keypsdefim_conv_body_only(model,im,target_scale,target_max_size):\"\"\"Runs`model.conv_body_net`onthegivenimage`im`.\"\"\"im_blob,im_scale,_im_info=blob_utils.get_image_blob(im,target_scale,target_max_size)workspace.FeedBlob(core.ScopedName(\\'data\\'),im_blob)workspace.RunNet(model.conv_body_net.Proto().name)returnim_scaledefim_detect_bbox(model,im,target_scale,target_max_size,boxes=None):\"\"\"Boundingboxobjectdetectionforanimagewithgivenboxproposals.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):colorimagetotest(inBGRorder)boxes(ndarray):Rx4arrayofobjectproposalsin0-indexed[x1,y1,x2,y2]format,orNoneifusingRPNReturns:scores(ndarray):RxKarrayofobjectclassscoresforKclasses(Kincludesbackgroundasobjectcategory0)boxes(ndarray):Rx4*Karrayofpredictedboundingboxesim_scales(list):listofimagescalesusedintheinputblob(asreturnedby_get_blobsandforusewithim_detect_mask,etc.)\"\"\"inputs,im_scale=_get_blobs(im,boxes,target_scale,target_max_size)#WhenmappingfromimageROIstofeaturemapROIs,there\\'ssomealiasing#(somedistinctimageROIsgetmappedtothesamefeatureROI).#Here,weidentifyduplicatefeatureROIs,soweonlycomputefeatures#ontheuniquesubset.ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:v=np.array([1,1e3,1e6,1e9,1e12])hashes=np.round(inputs[\\'rois\\']*cfg.DEDUP_BOXES).dot(v)_,index,inv_index=np.unique(hashes,return_index=True,return_inverse=True)inputs[\\'rois\\']=inputs[\\'rois\\'][index,:]boxes=boxes[index,:]#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROISandnotcfg.MODEL.FASTER_RCNN:_add_multilevel_rois_for_test(inputs,\\'rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.net.Proto().name)#Readoutblobsifcfg.MODEL.FASTER_RCNN:rois=workspace.FetchBlob(core.ScopedName(\\'rois\\'))#unscalebacktorawimagespaceboxes=rois[:,1:5]/im_scale#Softmaxclassprobabilitiesscores=workspace.FetchBlob(core.ScopedName(\\'cls_prob\\')).squeeze()#Incasethereis1proposalscores=scores.reshape([-1,scores.shape[-1]])ifcfg.TEST.BBOX_REG:#Applybounding-boxregressiondeltasbox_deltas=workspace.FetchBlob(core.ScopedName(\\'bbox_pred\\')).squeeze()#Incasethereis1proposalbox_deltas=box_deltas.reshape([-1,box_deltas.shape[-1]])ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:#Removepredictionsforbgclass(compatwithMSRAcode)box_deltas=box_deltas[:,-4:]pred_boxes=box_utils.bbox_transform(boxes,box_deltas,cfg.MODEL.BBOX_REG_WEIGHTS)pred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:pred_boxes=np.tile(pred_boxes,(1,scores.shape[1]))else:#Simplyrepeattheboxes,onceforeachclasspred_boxes=np.tile(boxes,(1,scores.shape[1]))ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:#Mapscoresandpredictionsbacktotheoriginalsetofboxesscores=scores[inv_index,:]pred_boxes=pred_boxes[inv_index,:]returnscores,pred_boxes,im_scaledefim_detect_bbox_aug(model,im,box_proposals=None):\"\"\"Performsbboxdetectionwithtest-timeaugmentations.Functionsignatureisthesameasforim_detect_bbox.\"\"\"assertnotcfg.TEST.BBOX_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'assertnotcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\',\\\\\\'Coordheuristicmustbeunionwheneverscoreheuristicisunion\\'assertnotcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'Scoreheuristicmustbeunionwhenevercoordheuristicisunion\\'assertnotcfg.MODEL.FASTER_RCNNor\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'UnionheuristicmustbeusedtocombineFasterRCNNpredictions\\'#Collectdetectionscomputedunderdifferenttransformationsscores_ts=[]boxes_ts=[]defadd_preds_t(scores_t,boxes_t):scores_ts.append(scores_t)boxes_ts.append(boxes_t)#Performdetectiononthehorizontallyflippedimageifcfg.TEST.BBOX_AUG.H_FLIP:scores_hf,boxes_hf,_=im_detect_bbox_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals)add_preds_t(scores_hf,boxes_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.BBOX_AUG.SCALES:max_size=cfg.TEST.BBOX_AUG.MAX_SIZEscores_scl,boxes_scl=im_detect_bbox_scale(model,im,scale,max_size,box_proposals)add_preds_t(scores_scl,boxes_scl)ifcfg.TEST.BBOX_AUG.SCALE_H_FLIP:scores_scl_hf,boxes_scl_hf=im_detect_bbox_scale(model,im,scale,max_size,box_proposals,hflip=True)add_preds_t(scores_scl_hf,boxes_scl_hf)#Performdetectionatdifferentaspectratiosforaspect_ratioincfg.TEST.BBOX_AUG.ASPECT_RATIOS:scores_ar,boxes_ar=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals)add_preds_t(scores_ar,boxes_ar)ifcfg.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP:scores_ar_hf,boxes_ar_hf=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals,hflip=True)add_preds_t(scores_ar_hf,boxes_ar_hf)#Computedetectionsfortheoriginalimage(identitytransform)lastto#ensurethattheCaffe2workspaceispopulatedwithblobscorresponding#totheoriginalimageonreturn(postconditionofim_detect_bbox)scores_i,boxes_i,im_scale_i=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)add_preds_t(scores_i,boxes_i)#Combinethepredictedscoresifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'ID\\':scores_c=scores_ielifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'AVG\\':scores_c=np.mean(scores_ts,axis=0)elifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\':scores_c=np.vstack(scores_ts)else:raiseNotImplementedError(\\'Scoreheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.SCORE_HEUR))#Combinethepredictedboxesifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'ID\\':boxes_c=boxes_ielifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'AVG\\':boxes_c=np.mean(boxes_ts,axis=0)elifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\':boxes_c=np.vstack(boxes_ts)else:raiseNotImplementedError(\\'Coordheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.COORD_HEUR))returnscores_c,boxes_c,im_scale_idefim_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=None):\"\"\"Performsbboxdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_bbox.\"\"\"#Computepredictionsontheflippedimageim_hf=im[:,::-1,:]im_width=im.shape[1]ifnotcfg.MODEL.FASTER_RCNN:box_proposals_hf=box_utils.flip_boxes(box_proposals,im_width)else:box_proposals_hf=Nonescores_hf,boxes_hf,im_scale=im_detect_bbox(model,im_hf,target_scale,target_max_size,boxes=box_proposals_hf)#Invertthedetectionscomputedontheflippedimageboxes_inv=box_utils.flip_boxes(boxes_hf,im_width)returnscores_hf,boxes_inv,im_scaledefim_detect_bbox_scale(model,im,target_scale,target_max_size,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenscale.Returnspredictionsintheoriginalimagespace.\"\"\"ifhflip:scores_scl,boxes_scl,_=im_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=box_proposals)else:scores_scl,boxes_scl,_=im_detect_bbox(model,im,target_scale,target_max_size,boxes=box_proposals)returnscores_scl,boxes_scldefim_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenwidth-relativeaspectratio.Returnspredictionsintheoriginalimagespace.\"\"\"#Computepredictionsonthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)ifnotcfg.MODEL.FASTER_RCNN:box_proposals_ar=box_utils.aspect_ratio(box_proposals,aspect_ratio)else:box_proposals_ar=Noneifhflip:scores_ar,boxes_ar,_=im_detect_bbox_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals_ar)else:scores_ar,boxes_ar,_=im_detect_bbox(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals_ar)#Invertthedetectedboxesboxes_inv=box_utils.aspect_ratio(boxes_ar,1.0/aspect_ratio)returnscores_ar,boxes_invdefim_detect_mask(model,im_scale,boxes):\"\"\"Inferinstancesegmentationmasks.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_masks(ndarray):RxKxMxMarrayofclassspecificsoftmasksoutputbythenetwork(mustbeprocessedbysegm_resultstoconvertintohardmasksintheoriginalimagecoordinatespace)\"\"\"M=cfg.MRCNN.RESOLUTIONifboxes.shape[0]==0:pred_masks=np.zeros((0,M,M),np.float32)returnpred_masksinputs={\\'mask_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'mask_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.mask_net.Proto().name)#Fetchmaskspred_masks=workspace.FetchBlob(core.ScopedName(\\'mask_fcn_probs\\')).squeeze()ifcfg.MRCNN.CLS_SPECIFIC_MASK:pred_masks=pred_masks.reshape([-1,cfg.MODEL.NUM_CLASSES,M,M])else:pred_masks=pred_masks.reshape([-1,1,M,M])returnpred_masksdefim_detect_mask_aug(model,im,boxes):\"\"\"Performsmaskdetectionwithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:masks(ndarray):RxKxMxMarrayofclassspecificsoftmasks\"\"\"assertnotcfg.TEST.MASK_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'#Collectmaskscomputedunderdifferenttransformationsmasks_ts=[]#Computemasksfortheoriginalimage(identitytransform)im_scale_i=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_i=im_detect_mask(model,im_scale_i,boxes)masks_ts.append(masks_i)#Performmaskdetectiononthehorizontallyflippedimageifcfg.TEST.MASK_AUG.H_FLIP:masks_hf=im_detect_mask_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)masks_ts.append(masks_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.MASK_AUG.SCALES:max_size=cfg.TEST.MASK_AUG.MAX_SIZEmasks_scl=im_detect_mask_scale(model,im,scale,max_size,boxes)masks_ts.append(masks_scl)ifcfg.TEST.MASK_AUG.SCALE_H_FLIP:masks_scl_hf=im_detect_mask_scale(model,im,scale,max_size,boxes,hflip=True)masks_ts.append(masks_scl_hf)#Computemasksatdifferentaspectratiosforaspect_ratioincfg.TEST.MASK_AUG.ASPECT_RATIOS:masks_ar=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes)masks_ts.append(masks_ar)ifcfg.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP:masks_ar_hf=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)masks_ts.append(masks_ar_hf)#Combinethepredictedsoftmasksifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_AVG\\':masks_c=np.mean(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_MAX\\':masks_c=np.amax(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'LOGIT_AVG\\':deflogit(y):return-1.0*np.log((1.0-y)/np.maximum(y,1e-20))logit_masks=[logit(y)foryinmasks_ts]logit_masks=np.mean(logit_masks,axis=0)masks_c=1.0/(1.0+np.exp(-logit_masks))else:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.MASK_AUG.HEUR))returnmasks_cdefim_detect_mask_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Performsmaskdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_mask_aug.\"\"\"#Computethemasksfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)masks_hf=im_detect_mask(model,im_scale,boxes_hf)#Invertthepredictedsoftmasksmasks_inv=masks_hf[:,:,:,::-1]returnmasks_invdefim_detect_mask_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computesmasksatthegivenscale.\"\"\"ifhflip:masks_scl=im_detect_mask_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)masks_scl=im_detect_mask(model,im_scale,boxes)returnmasks_scldefim_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Computesmaskdetectionsatthegivenwidth-relativeaspectratio.\"\"\"#Performmaskdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:masks_ar=im_detect_mask_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_ar=im_detect_mask(model,im_scale,boxes_ar)returnmasks_ardefim_detect_keypoints(model,im_scale,boxes):\"\"\"Inferinstancekeypointposes.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits(softmaxinputs)foreachoftheJkeypointtypesoutputbythenetwork(mustbeprocessedbykeypoint_resultstoconvertintopointpredictionsintheoriginalimagecoordinatespace)\"\"\"M=cfg.KRCNN.HEATMAP_SIZEifboxes.shape[0]==0:pred_heatmaps=np.zeros((0,cfg.KRCNN.NUM_KEYPOINTS,M,M),np.float32)returnpred_heatmapsinputs={\\'keypoint_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'keypoint_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.keypoint_net.Proto().name)pred_heatmaps=workspace.FetchBlob(core.ScopedName(\\'kps_score\\')).squeeze()#Incaseof1ifpred_heatmaps.ndim==3:pred_heatmaps=np.expand_dims(pred_heatmaps,axis=0)returnpred_heatmapsdefim_detect_keypoints_aug(model,im,boxes):\"\"\"Computeskeypointpredictionswithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits\"\"\"#Collectheatmapspredictedunderdifferenttransformationsheatmaps_ts=[]#Tagpredictionscomputedunderdownscalingandupscalingtransformationsds_ts=[]us_ts=[]defadd_heatmaps_t(heatmaps_t,ds_t=False,us_t=False):heatmaps_ts.append(heatmaps_t)ds_ts.append(ds_t)us_ts.append(us_t)#Computetheheatmapsfortheoriginalimage(identitytransform)im_scale=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_i=im_detect_keypoints(model,im_scale,boxes)add_heatmaps_t(heatmaps_i)#Performkeypointsdetectiononthehorizontallyflippedimageifcfg.TEST.KPS_AUG.H_FLIP:heatmaps_hf=im_detect_keypoints_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.KPS_AUG.SCALES:ds_scl=scale<cfg.TEST.SCALEus_scl=scale>cfg.TEST.SCALEheatmaps_scl=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_scl,ds_scl,us_scl)ifcfg.TEST.KPS_AUG.SCALE_H_FLIP:heatmaps_scl_hf=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes,hflip=True)add_heatmaps_t(heatmaps_scl_hf,ds_scl,us_scl)#Computekeypointsatdifferentaspectratiosforaspect_ratioincfg.TEST.KPS_AUG.ASPECT_RATIOS:heatmaps_ar=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes)add_heatmaps_t(heatmaps_ar)ifcfg.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP:heatmaps_ar_hf=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)add_heatmaps_t(heatmaps_ar_hf)#Selecttheheuristicfunctionforcombiningtheheatmapsifcfg.TEST.KPS_AUG.HEUR==\\'HM_AVG\\':np_f=np.meanelifcfg.TEST.KPS_AUG.HEUR==\\'HM_MAX\\':np_f=np.amaxelse:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.KPS_AUG.HEUR))defheur_f(hms_ts):returnnp_f(hms_ts,axis=0)#Combinetheheatmapsifcfg.TEST.KPS_AUG.SCALE_SIZE_DEP:heatmaps_c=combine_heatmaps_size_dep(heatmaps_ts,ds_ts,us_ts,boxes,heur_f)else:heatmaps_c=heur_f(heatmaps_ts)returnheatmaps_cdefim_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Computeskeypointpredictionsonthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_keypoints_aug.\"\"\"#Computekeypointsfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)heatmaps_hf=im_detect_keypoints(model,im_scale,boxes_hf)#Invertthepredictedkeypointsheatmaps_inv=keypoint_utils.flip_heatmaps(heatmaps_hf)returnheatmaps_invdefim_detect_keypoints_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computeskeypointpredictionsatthegivenscale.\"\"\"ifhflip:heatmaps_scl=im_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)heatmaps_scl=im_detect_keypoints(model,im_scale,boxes)returnheatmaps_scldefim_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Detectskeypointsatthegivenwidth-relativeaspectratio.\"\"\"#Performkeypointdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:heatmaps_ar=im_detect_keypoints_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_ar=im_detect_keypoints(model,im_scale,boxes_ar)returnheatmaps_ardefcombine_heatmaps_size_dep(hms_ts,ds_ts,us_ts,boxes,heur_f):\"\"\"Combinesheatmapswhiletakingobjectsizesintoaccount.\"\"\"assertlen(hms_ts)==len(ds_ts)andlen(ds_ts)==len(us_ts),\\\\\\'Allsetsofhmsmustbetaggedwithdownscalingandupscalingflags\\'#Classifyobjectsintosmall+mediumandlargebasedontheirboxareasareas=box_utils.boxes_area(boxes)sm_objs=areas<cfg.TEST.KPS_AUG.AREA_THl_objs=areas>=cfg.TEST.KPS_AUG.AREA_TH#Combineheatmapscomputedunderdifferenttransformationsforeachobjecthms_c=np.zeros_like(hms_ts[0])foriinrange(hms_c.shape[0]):hms_to_combine=[]forhms_t,ds_t,us_tinzip(hms_ts,ds_ts,us_ts):#Discarddownscalingpredictionsforsmallandmediumobjectsifsm_objs[i]andds_t:continue#Discardupscalingpredictionsforlargeobjectsifl_objs[i]andus_t:continuehms_to_combine.append(hms_t[i])hms_c[i]=heur_f(hms_to_combine)returnhms_cdefbox_results_with_nms_and_limit(scores,boxes):\"\"\"Returnsbounding-boxdetectionresultsbythresholdingonscoresandapplyingnon-maximumsuppression(NMS).`boxes`hasshape(#detections,4*#classes),whereeachrowrepresentsalistofpredictedboundingboxesforeachoftheobjectclassesinthedataset(includingthebackgroundclass).Thedetectionsineachroworiginatefromthesameobjectproposal.`scores`hasshape(#detection,#classes),whereeachrowrepresentsalistofobjectdetectionconfidencescoresforeachoftheobjectclassesinthedataset(includingthebackgroundclass).`scores[i,j]``correspondstotheboxat`boxes[i,j*4:(j+1)*4]`.\"\"\"num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(num_classes)]#ApplythresholdondetectionprobabilitiesandapplyNMS#Skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):inds=np.where(scores[:,j]>cfg.TEST.SCORE_THRESH)[0]scores_j=scores[inds,j]boxes_j=boxes[inds,j*4:(j+1)*4]dets_j=np.hstack((boxes_j,scores_j[:,np.newaxis])).astype(np.float32,copy=False)ifcfg.TEST.SOFT_NMS.ENABLED:nms_dets,_=box_utils.soft_nms(dets_j,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(dets_j,cfg.TEST.NMS)nms_dets=dets_j[keep,:]#Refinethepost-NMSboxesusingbounding-boxvotingifcfg.TEST.BBOX_VOTE.ENABLED:nms_dets=box_utils.box_voting(nms_dets,dets_j,cfg.TEST.BBOX_VOTE.VOTE_TH,scoring_method=cfg.TEST.BBOX_VOTE.SCORING_METHOD)cls_boxes[j]=nms_dets#Limittomax_per_imagedetections**overallclasses**ifcfg.TEST.DETECTIONS_PER_IM>0:image_scores=np.hstack([cls_boxes[j][:,-1]forjinrange(1,num_classes)])iflen(image_scores)>cfg.TEST.DETECTIONS_PER_IM:image_thresh=np.sort(image_scores)[-cfg.TEST.DETECTIONS_PER_IM]forjinrange(1,num_classes):keep=np.where(cls_boxes[j][:,-1]>=image_thresh)[0]cls_boxes[j]=cls_boxes[j][keep,:]im_results=np.vstack([cls_boxes[j]forjinrange(1,num_classes)])boxes=im_results[:,:-1]scores=im_results[:,-1]returnscores,boxes,cls_boxesdefsegm_results(cls_boxes,masks,ref_boxes,im_h,im_w):num_classes=cfg.MODEL.NUM_CLASSEScls_segms=[[]for_inrange(num_classes)]mask_ind=0#Toworkaroundanissuewithcv2.resize(itseemstoautomaticallypad#withrepeatedbordervalues),wemanuallyzero-padthemasksby1pixel#priortoresizingbacktotheoriginalimageresolution.Thisprevents#\"tophat\"artifacts.Wethereforeneedtoexpandthereferenceboxesbyan#appropriatefactor.M=cfg.MRCNN.RESOLUTIONscale=(M+2.0)/Mref_boxes=box_utils.expand_boxes(ref_boxes,scale)ref_boxes=ref_boxes.astype(np.int32)padded_mask=np.zeros((M+2,M+2),dtype=np.float32)#skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):segms=[]for_inrange(cls_boxes[j].shape[0]):ifcfg.MRCNN.CLS_SPECIFIC_MASK:padded_mask[1:-1,1:-1]=masks[mask_ind,j,:,:]else:padded_mask[1:-1,1:-1]=masks[mask_ind,0,:,:]ref_box=ref_boxes[mask_ind,:]w=ref_box[2]-ref_box[0]+1h=ref_box[3]-ref_box[1]+1w=np.maximum(w,1)h=np.maximum(h,1)mask=cv2.resize(padded_mask,(w,h))mask=np.array(mask>cfg.MRCNN.THRESH_BINARIZE,dtype=np.uint8)im_mask=np.zeros((im_h,im_w),dtype=np.uint8)x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,im_w)y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,im_h)im_mask[y_0:y_1,x_0:x_1]=mask[(y_0-ref_box[1]):(y_1-ref_box[1]),(x_0-ref_box[0]):(x_1-ref_box[0])]#GetRLEencodingusedbytheCOCOevaluationAPIrle=mask_util.encode(np.array(im_mask[:,:,np.newaxis],order=\\'F\\'))[0]segms.append(rle)mask_ind+=1cls_segms[j]=segmsassertmask_ind==masks.shape[0]returncls_segmsdefkeypoint_results(cls_boxes,pred_heatmaps,ref_boxes):num_classes=cfg.MODEL.NUM_CLASSEScls_keyps=[[]for_inrange(num_classes)]person_idx=keypoint_utils.get_person_class_index()xy_preds=keypoint_utils.heatmaps_to_keypoints(pred_heatmaps,ref_boxes)#NMSOKSifcfg.KRCNN.NMS_OKS:keep=keypoint_utils.nms_oks(xy_preds,ref_boxes,0.3)xy_preds=xy_preds[keep,:,:]ref_boxes=ref_boxes[keep,:]pred_heatmaps=pred_heatmaps[keep,:,:,:]cls_boxes[person_idx]=cls_boxes[person_idx][keep,:]kps=[xy_preds[i]foriinrange(xy_preds.shape[0])]cls_keyps[person_idx]=kpsreturncls_keypsdef_get_rois_blob(im_rois,im_scale):\"\"\"ConvertsRoIsintonetworkinputs.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesim_scale_factors(list):scalefactorsasreturnedby_get_image_blobReturns:blob(ndarray):Rx5matrixofRoIsintheimagepyramidwithcolumns[level,x1,y1,x2,y2]\"\"\"rois,levels=_project_im_rois(im_rois,im_scale)rois_blob=np.hstack((levels,rois))returnrois_blob.astype(np.float32,copy=False)def_project_im_rois(im_rois,scales):\"\"\"ProjectimageRoIsintotheimagepyramidbuiltby_get_image_blob.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesscales(list):scalefactorsasreturnedby_get_image_blobReturns:rois(ndarray):Rx4matrixofprojectedRoIcoordinateslevels(ndarray):imagepyramidlevelsusedbyeachprojectedRoI\"\"\"rois=im_rois.astype(float,copy=False)*scaleslevels=np.zeros((im_rois.shape[0],1),dtype=int)returnrois,levelsdef_add_multilevel_rois_for_test(blobs,name):\"\"\"DistributesasetofRoIsacrossFPNpyramidlevelsbycreatingnewlevelspecificRoIblobs.Arguments:blobs(dict):dictionaryofblobsname(str):akeyin\\'blobs\\'identifyingthesourceRoIblobReturns:[byref]blobs(dict):newkeysnamedby`name+\\'fpn\\'+level`areaddedtodicteachwithavaluethat\\'sanR_levelx5ndarrayofRoIs(see_get_rois_blobforformat)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(blobs[name][:,1:5],lvl_min,lvl_max)fpn.add_multilevel_roi_blobs(blobs,name,blobs[name],lvls,lvl_min,lvl_max)def_get_blobs(im,rois,target_scale,target_max_size):\"\"\"ConvertanimageandRoIswithinthatimageintonetworkinputs.\"\"\"blobs={}blobs[\\'data\\'],im_scale,blobs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,target_scale,target_max_size)ifroisisnotNone:blobs[\\'rois\\']=_get_rois_blob(rois,im_scale)returnblobs,im_scale#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyBharathHariharan#--------------------------------------------------------\"\"\"PythonimplementationofthePASCALVOCdevkit\\'sAPevaluationcode.\"\"\"importloggingimportnumpyasnpimportosimportxml.etree.ElementTreeasETfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defparse_rec(filename):\"\"\"ParseaPASCALVOCxmlfile.\"\"\"tree=ET.parse(filename)objects=[]forobjintree.findall(\\'object\\'):obj_struct={}obj_struct[\\'name\\']=obj.find(\\'name\\').textobj_struct[\\'pose\\']=obj.find(\\'pose\\').textobj_struct[\\'truncated\\']=int(obj.find(\\'truncated\\').text)obj_struct[\\'difficult\\']=int(obj.find(\\'difficult\\').text)bbox=obj.find(\\'bndbox\\')obj_struct[\\'bbox\\']=[int(bbox.find(\\'xmin\\').text),int(bbox.find(\\'ymin\\').text),int(bbox.find(\\'xmax\\').text),int(bbox.find(\\'ymax\\').text)]objects.append(obj_struct)returnobjectsdefvoc_ap(rec,prec,use_07_metric=False):\"\"\"ComputeVOCAPgivenprecisionandrecall.Ifuse_07_metricistrue,usestheVOC0711-pointmethod(default:False).\"\"\"ifuse_07_metric:#11pointmetricap=0.fortinnp.arange(0.,1.1,0.1):ifnp.sum(rec>=t)==0:p=0else:p=np.max(prec[rec>=t])ap=ap+p/11.else:#correctAPcalculation#firstappendsentinelvaluesattheendmrec=np.concatenate(([0.],rec,[1.]))mpre=np.concatenate(([0.],prec,[0.]))#computetheprecisionenvelopeforiinrange(mpre.size-1,0,-1):mpre[i-1]=np.maximum(mpre[i-1],mpre[i])#tocalculateareaunderPRcurve,lookforpoints#whereXaxis(recall)changesvaluei=np.where(mrec[1:]!=mrec[:-1])[0]#andsum(\\\\Deltarecall)*precap=np.sum((mrec[i+1]-mrec[i])*mpre[i+1])returnapdefvoc_eval(detpath,annopath,imagesetfile,classname,cachedir,ovthresh=0.5,use_07_metric=False):\"\"\"rec,prec,ap=voc_eval(detpath,annopath,imagesetfile,classname,[ovthresh],[use_07_metric])ToplevelfunctionthatdoesthePASCALVOCevaluation.detpath:Pathtodetectionsdetpath.format(classname)shouldproducethedetectionresultsfile.annopath:Pathtoannotationsannopath.format(imagename)shouldbethexmlannotationsfile.imagesetfile:Textfilecontainingthelistofimages,oneimageperline.classname:Categoryname(duh)cachedir:Directoryforcachingtheannotations[ovthresh]:Overlapthreshold(default=0.5)[use_07_metric]:WhethertouseVOC07\\'s11pointAPcomputation(defaultFalse)\"\"\"#assumesdetectionsareindetpath.format(classname)#assumesannotationsareinannopath.format(imagename)#assumesimagesetfileisatextfilewitheachlineanimagename#cachedircachestheannotationsinapicklefile#firstloadgtifnotos.path.isdir(cachedir):os.mkdir(cachedir)imageset=os.path.splitext(os.path.basename(imagesetfile))[0]cachefile=os.path.join(cachedir,imageset+\\'_annots.pkl\\')#readlistofimageswithopen(imagesetfile,\\'r\\')asf:lines=f.readlines()imagenames=[x.strip()forxinlines]ifnotos.path.isfile(cachefile):#loadannotsrecs={}fori,imagenameinenumerate(imagenames):recs[imagename]=parse_rec(annopath.format(imagename))ifi%100==0:logger.info(\\'Readingannotationfor{:d}/{:d}\\'.format(i+1,len(imagenames)))#savelogger.info(\\'Savingcachedannotationsto{:s}\\'.format(cachefile))save_object(recs,cachefile)else:recs=load_object(cachefile)#extractgtobjectsforthisclassclass_recs={}npos=0forimagenameinimagenames:R=[objforobjinrecs[imagename]ifobj[\\'name\\']==classname]bbox=np.array([x[\\'bbox\\']forxinR])difficult=np.array([x[\\'difficult\\']forxinR]).astype(bool)det=[False]*len(R)npos=npos+sum(~difficult)class_recs[imagename]={\\'bbox\\':bbox,\\'difficult\\':difficult,\\'det\\':det}#readdetsdetfile=detpath.format(classname)withopen(detfile,\\'r\\')asf:lines=f.readlines()splitlines=[x.strip().split(\\'\\')forxinlines]image_ids=[x[0]forxinsplitlines]confidence=np.array([float(x[1])forxinsplitlines])BB=np.array([[float(z)forzinx[2:]]forxinsplitlines])#sortbyconfidencesorted_ind=np.argsort(-confidence)BB=BB[sorted_ind,:]image_ids=[image_ids[x]forxinsorted_ind]#godowndetsandmarkTPsandFPsnd=len(image_ids)tp=np.zeros(nd)fp=np.zeros(nd)fordinrange(nd):R=class_recs[image_ids[d]]bb=BB[d,:].astype(float)ovmax=-np.infBBGT=R[\\'bbox\\'].astype(float)ifBBGT.size>0:#computeoverlaps#intersectionixmin=np.maximum(BBGT[:,0],bb[0])iymin=np.maximum(BBGT[:,1],bb[1])ixmax=np.minimum(BBGT[:,2],bb[2])iymax=np.minimum(BBGT[:,3],bb[3])iw=np.maximum(ixmax-ixmin+1.,0.)ih=np.maximum(iymax-iymin+1.,0.)inters=iw*ih#unionuni=((bb[2]-bb[0]+1.)*(bb[3]-bb[1]+1.)+(BBGT[:,2]-BBGT[:,0]+1.)*(BBGT[:,3]-BBGT[:,1]+1.)-inters)overlaps=inters/uniovmax=np.max(overlaps)jmax=np.argmax(overlaps)ifovmax>ovthresh:ifnotR[\\'difficult\\'][jmax]:ifnotR[\\'det\\'][jmax]:tp[d]=1.R[\\'det\\'][jmax]=1else:fp[d]=1.else:fp[d]=1.#computeprecisionrecallfp=np.cumsum(fp)tp=np.cumsum(tp)rec=tp/float(npos)#avoiddividebyzeroincasethefirstdetectionmatchesadifficult#groundtruthprec=tp/np.maximum(tp+fp,np.finfo(np.float64).eps)ap=voc_ap(rec,prec,use_07_metric)returnrec,prec,ap#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforevaluatingresultscomputedforajsondataset.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportjsonimportloggingimportnumpyasnpimportosimportsiximportuuidfrompycocotools.cocoevalimportCOCOevalfromdetectron.core.configimportcfgfromdetectron.utils.ioimportsave_objectimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_segmentation_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Segmentation\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"segmentation\":[...],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_segms_results_one_category(json_dataset,all_boxes[cls_ind],all_segms[cls_ind],cat_id))logger.info(\\'Writingsegmentationresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:#\"counts\"isanarrayencodedbymask_utilasabyte-stream.Python3\\'s#jsonwriterwhich/alwaysproducesstrings/cannotserializeabytestream#unlessyoudecodeit.Thankfully,utf-8worksout(whichisalsowhat#thepycocotools/_mask.pyxdoes.ifsix.PY3:forrinresults:rle=r[\\'segmentation\\']if\\'counts\\'inrle:rle[\\'counts\\']=rle[\\'counts\\'].decode(\"utf8\")json.dump(results,fid)def_coco_segms_results_one_category(json_dataset,boxes,segms,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)assertlen(segms)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]rles=segms[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'segmentation\\':rles[k],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_segmentation_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'segm\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'segmentation_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldefevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'bbox_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_bbox_results_file(json_dataset,all_boxes,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_detection_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Bbox\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_bbox_results_file(json_dataset,all_boxes,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"bbox\":[258.15,41.29,348.26,243.78],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_bbox_results_one_category(json_dataset,all_boxes[cls_ind],cat_id))logger.info(\\'Writingbboxresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_bbox_results_one_category(json_dataset,boxes,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]xywh_dets=box_utils.xyxy_to_xywh(dets[:,0:4])xs=xywh_dets[:,0]ys=xywh_dets[:,1]ws=xywh_dets[:,2]hs=xywh_dets[:,3]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'bbox\\':[xs[k],ys[k],ws[k],hs[k]],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_detection_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'bbox\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'detection_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldef_log_detection_eval_metrics(json_dataset,coco_eval):def_get_thr_ind(coco_eval,thr):ind=np.where((coco_eval.params.iouThrs>thr-1e-5)&(coco_eval.params.iouThrs<thr+1e-5))[0][0]iou_thr=coco_eval.params.iouThrs[ind]assertnp.isclose(iou_thr,thr)returnindIoU_lo_thresh=0.5IoU_hi_thresh=0.95ind_lo=_get_thr_ind(coco_eval,IoU_lo_thresh)ind_hi=_get_thr_ind(coco_eval,IoU_hi_thresh)#precisionhasdims(iou,recall,cls,arearange,maxdets)#arearangeindex0:allarearanges#maxdetsindex2:100perimageprecision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,:,0,2]ap_default=np.mean(precision[precision>-1])logger.info(\\'~~~~Meanandper-categoryAP@IoU=[{:.2f},{:.2f}]~~~~\\'.format(IoU_lo_thresh,IoU_hi_thresh))logger.info(\\'{:.1f}\\'.format(100*ap_default))forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continue#minus1becauseof__background__precision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,cls_ind-1,0,2]ap=np.mean(precision[precision>-1])logger.info(\\'{:.1f}\\'.format(100*ap))logger.info(\\'~~~~Summarymetrics~~~~\\')coco_eval.summarize()defevaluate_box_proposals(json_dataset,roidb,thresholds=None,area=\\'all\\',l',\n",
       " 'imit=None,class_specific=False):\"\"\"Evaluatedetectionproposalrecallmetrics.ThisfunctionisamuchfasteralternativetotheofficialCOCOAPIrecallevaluationcode.However,itproducesslightlydifferentresults.\"\"\"#Recordmaxoverlapvalueforeachgtbox#Returnvectorofoverlapvaluesareas={\\'all\\':0,\\'small\\':1,\\'medium\\':2,\\'large\\':3,\\'96-128\\':4,\\'128-256\\':5,\\'256-512\\':6,\\'512-inf\\':7}area_ranges=[[0**2,1e5**2],#all[0**2,32**2],#small[32**2,96**2],#medium[96**2,1e5**2],#large[96**2,128**2],#96-128[128**2,256**2],#128-256[256**2,512**2],#256-512[512**2,1e5**2]]#512-infassertareainareas,\\'Unknownarearange:{}\\'.format(area)area_range=area_ranges[areas[area]]gt_overlaps=np.zeros(0)gt_classes=np.zeros(0)num_pos=0forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_areas=entry[\\'seg_areas\\'][gt_inds]valid_gt_inds=np.where((gt_areas>=area_range[0])&(gt_areas<=area_range[1]))[0]gt_boxes=gt_boxes[valid_gt_inds,:]_gt_classes=entry[\"gt_classes\"][valid_gt_inds]assertgt_boxes.shape[0]==_gt_classes.shape[0]gt_classes=np.hstack((gt_classes,_gt_classes))num_pos+=len(valid_gt_inds)non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]boxes=entry[\\'boxes\\'][non_gt_inds,:]ifboxes.shape[0]==0:continueiflimitisnotNoneandboxes.shape[0]>limit:boxes=boxes[:limit,:]overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))_gt_overlaps=np.zeros((gt_boxes.shape[0]))forjinrange(min(boxes.shape[0],gt_boxes.shape[0])):#findwhichproposalboxmaximallycoverseachgtboxargmax_overlaps=overlaps.argmax(axis=0)#andgettheiouamountofcoverageforeachgtboxmax_overlaps=overlaps.max(axis=0)#findwhichgtboxis\\'best\\'covered(i.e.\\'best\\'=mostiou)gt_ind=max_overlaps.argmax()gt_ovr=max_overlaps.max()assertgt_ovr>=0#findtheproposalboxthatcoversthebestcoveredgtboxbox_ind=argmax_overlaps[gt_ind]#recordtheioucoverageofthisgtbox_gt_overlaps[j]=overlaps[box_ind,gt_ind]assert_gt_overlaps[j]==gt_ovr#marktheproposalboxandthegtboxasusedoverlaps[box_ind,:]=-1overlaps[:,gt_ind]=-1#appendrecordedioucoveragelevelgt_overlaps=np.hstack((gt_overlaps,_gt_overlaps))ifthresholdsisNone:step=0.05thresholds=np.arange(0.5,0.95+1e-5,step)ifnotclass_specific:gt_overlaps=np.sort(gt_overlaps)recalls=np.zeros_like(thresholds)#computerecallforeachiouthresholdfori,tinenumerate(thresholds):recalls[i]=(gt_overlaps>=t).sum()/float(num_pos)ar=recalls.mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}else:gt_classes_unique=np.unique(gt_classes)recalls=np.zeros((gt_classes_unique.shape[0],thresholds.shape[0]))#computerecallforeachcategoryandeachiouthresholdfori,category_idinenumerate(gt_classes_unique):inds=(gt_classes==category_id)num_pos_per_category=float(inds.sum())forj,threshinenumerate(thresholds):recalls[i][j]=(gt_overlaps[inds]>=thresh).sum()/num_pos_per_categoryar=recalls.mean(axis=1).mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}defevaluate_keypoints(json_dataset,all_boxes,all_keypoints,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'keypoints_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_keypoint_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Keypoints\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file):results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_keypoints):breaklogger.info(\\'Collecting{}results({:d}/{:d})\\'.format(cls,cls_ind,len(all_keypoints)-1))cat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_kp_results_one_category(json_dataset,all_boxes[cls_ind],all_keypoints[cls_ind],cat_id))logger.info(\\'Writingkeypointresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_kp_results_one_category(json_dataset,boxes,kps,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(kps)==len(image_ids)assertlen(boxes)==len(image_ids)use_box_score=Falseifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'logit\\':#Thisisugly;seeutils.keypoints.heatmap_to_keypointsforthemagic#indexesscore_index=2elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'prob\\':score_index=3elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'bbox\\':use_box_score=Trueelse:raiseValueError(\\'KRCNN.KEYPOINT_CONFIDENCEmustbe\"logit\",\"prob\",or\"bbox\"\\')fori,image_idinenumerate(image_ids):iflen(boxes[i])==0:continuekps_dets=kps[i]scores=boxes[i][:,-1].astype(float)iflen(kps_dets)==0:continueforjinrange(len(kps_dets)):xy=[]kps_score=0forkinrange(kps_dets[j].shape[1]):xy.append(float(kps_dets[j][0,k]))xy.append(float(kps_dets[j][1,k]))xy.append(1)ifnotuse_box_score:kps_score+=kps_dets[j][score_index,k]ifuse_box_score:kps_score=scores[j]else:kps_score/=kps_dets[j].shape[1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'keypoints\\':xy,\\'score\\':kps_score}])returnresultsdef_do_keypoint_eval(json_dataset,res_file,output_dir):ann_type=\\'keypoints\\'imgIds=json_dataset.COCO.getImgIds()imgIds.sort()coco_dt=json_dataset.COCO.loadRes(res_file)coco_eval=COCOeval(json_dataset.COCO,coco_dt,ann_type)coco_eval.params.imgIds=imgIdscoco_eval.evaluate()coco_eval.accumulate()eval_file=os.path.join(output_dir,\\'keypoint_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))coco_eval.summarize()returncoco_eval#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Collectionofavailabledatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportos#Pathtodatadir_DATA_DIR=os.path.join(os.path.dirname(__file__),\\'data\\')#Requireddatasetentrykeys_IM_DIR=\\'image_directory\\'_ANN_FN=\\'annotation_file\\'#Optionaldatasetentrykeys_IM_PREFIX=\\'image_prefix\\'_DEVKIT_DIR=\\'devkit_directory\\'_RAW_DIR=\\'raw_dir\\'#Availabledatasets_DATASETS={\\'cityscapes_fine_instanceonly_seg_train\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_train.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_val\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',#usefilteredvalidationasthereisanissueconvertingcontours_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_filtered_gtFine_val.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_test\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_test.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_train2014.json\\'},\\'coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_val2014.json\\'},\\'coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_minival2014.json\\'},\\'coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_valminusminival2014.json\\'},\\'coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'coco_2017_test\\':{#2017testuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_2017_test-dev\\':{#2017test-devuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_stuff_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_train.json\\'},\\'coco_stuff_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_val.json\\'},\\'keypoints_coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_train2014.json\\'},\\'keypoints_coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_val2014.json\\'},\\'keypoints_coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_minival2014.json\\'},\\'keypoints_coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_valminusminival2014.json\\'},\\'keypoints_coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'keypoints_coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'voc_2007_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_test\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_test.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2012_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'},\\'voc_2012_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'}}defdatasets():\"\"\"Retrievethelistofavailabledatasetnames.\"\"\"return_DATASETS.keys()defcontains(name):\"\"\"Determineifthedatasetisinthecatalog.\"\"\"returnnamein_DATASETS.keys()defget_im_dir(name):\"\"\"Retrievetheimagedirectoryforthedataset.\"\"\"return_DATASETS[name][_IM_DIR]defget_ann_fn(name):\"\"\"Retrievetheannotationfileforthedataset.\"\"\"return_DATASETS[name][_ANN_FN]defget_im_prefix(name):\"\"\"Retrievetheimageprefixforthedataset.\"\"\"return_DATASETS[name][_IM_PREFIX]if_IM_PREFIXin_DATASETS[name]else\\'\\'defget_devkit_dir(name):\"\"\"Retrievethedevkitdirforthedataset.\"\"\"return_DATASETS[name][_DEVKIT_DIR]defget_raw_dir(name):\"\"\"Retrievetherawdirforthedataset.\"\"\"return_DATASETS[name][_RAW_DIR]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"PASCALVOCdatasetevaluationinterface.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimportuuidfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_devkit_dirfromdetectron.datasets.voc_evalimportvoc_evalfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=True,use_matlab=False):salt=\\'_{}\\'.format(str(uuid.uuid4()))ifuse_saltelse\\'\\'filenames=_write_voc_results_files(json_dataset,all_boxes,salt)_do_python_eval(json_dataset,salt,output_dir)ifuse_matlab:_do_matlab_eval(json_dataset,salt,output_dir)ifcleanup:forfilenameinfilenames:shutil.copy(filename,output_dir)os.remove(filename)returnNonedef_write_voc_results_files(json_dataset,all_boxes,salt):filenames=[]image_set_path=voc_info(json_dataset)[\\'image_set_path\\']assertos.path.exists(image_set_path),\\\\\\'Imagesetpathdoesnotexist:{}\\'.format(image_set_path)withopen(image_set_path,\\'r\\')asf:image_index=[x.strip()forxinf.readlines()]#Sanitycheckthatorderofimagesinjsondatasetmatchesorderinthe#imagesetroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):index=os.path.splitext(os.path.split(entry[\\'image\\'])[1])[0]assertindex==image_index[i]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuelogger.info(\\'WritingVOCresultsfor:{}\\'.format(cls))filename=_get_voc_results_file_template(json_dataset,salt).format(cls)filenames.append(filename)assertlen(all_boxes[cls_ind])==len(image_index)withopen(filename,\\'wt\\')asf:forim_ind,indexinenumerate(image_index):dets=all_boxes[cls_ind][im_ind]iftype(dets)==list:assertlen(dets)==0,\\\\\\'detsshouldbenumpy.ndarrayoremptylist\\'continue#theVOCdevkitexpects1-basedindicesforkinrange(dets.shape[0]):f.write(\\'{:s}{:.3f}{:.1f}{:.1f}{:.1f}{:.1f}\\\\n\\'.format(index,dets[k,-1],dets[k,0]+1,dets[k,1]+1,dets[k,2]+1,dets[k,3]+1))returnfilenamesdef_get_voc_results_file_template(json_dataset,salt):info=voc_info(json_dataset)year=info[\\'year\\']image_set=info[\\'image_set\\']devkit_path=info[\\'devkit_path\\']#VOCdevkit/results/VOC2007/Main/_det_test_aeroplane.txtfilename=\\'comp4\\'+salt+\\'_det_\\'+image_set+\\'_{:s}.txt\\'returnos.path.join(devkit_path,\\'results\\',\\'VOC\\'+year,\\'Main\\',filename)def_do_python_eval(json_dataset,salt,output_dir=\\'output\\'):info=voc_info(json_dataset)year=info[\\'year\\']anno_path=info[\\'anno_path\\']image_set_path=info[\\'image_set_path\\']devkit_path=info[\\'devkit_path\\']cachedir=os.path.join(devkit_path,\\'annotations_cache\\')aps=[]#ThePASCALVOCmetricchangedin2010use_07_metric=Trueifint(year)<2010elseFalselogger.info(\\'VOC07metric?\\'+(\\'Yes\\'ifuse_07_metricelse\\'No\\'))ifnotos.path.isdir(output_dir):os.mkdir(output_dir)for_,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuefilename=_get_voc_results_file_template(json_dataset,salt).format(cls)rec,prec,ap=voc_eval(filename,anno_path,image_set_path,cls,cachedir,ovthresh=0.5,use_07_metric=use_07_metric)aps+=[ap]logger.info(\\'APfor{}={:.4f}\\'.format(cls,ap))res_file=os.path.join(output_dir,cls+\\'_pr.pkl\\')save_object({\\'rec\\':rec,\\'prec\\':prec,\\'ap\\':ap},res_file)logger.info(\\'MeanAP={:.4f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'Results:\\')forapinaps:logger.info(\\'{:.3f}\\'.format(ap))logger.info(\\'{:.3f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'\\')logger.info(\\'----------------------------------------------------------\\')logger.info(\\'Resultscomputedwiththe**unofficial**Pythonevalcode.\\')logger.info(\\'ResultsshouldbeveryclosetotheofficialMATLABcode.\\')logger.info(\\'Use`./tools/reval.py--matlab...`foryourpaper.\\')logger.info(\\'--Thanks,TheManagement\\')logger.info(\\'----------------------------------------------------------\\')def_do_matlab_eval(json_dataset,salt,output_dir=\\'output\\'):importsubprocesslogger.info(\\'-----------------------------------------------------\\')logger.info(\\'ComputingresultswiththeofficialMATLABevalcode.\\')logger.info(\\'-----------------------------------------------------\\')info=voc_info(json_dataset)path=os.path.join(cfg.ROOT_DIR,\\'detectron\\',\\'datasets\\',\\'VOCdevkit-matlab-wrapper\\')cmd=\\'cd{}&&\\'.format(path)cmd+=\\'{:s}-nodisplay-nodesktop\\'.format(cfg.MATLAB)cmd+=\\'-r\"dbstopiferror;\\'cmd+=\\'voc_eval(\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\');quit;\"\\'\\\\.format(info[\\'devkit_path\\'],\\'comp4\\'+salt,info[\\'image_set\\'],output_dir)logger.info(\\'Running:\\\\n{}\\'.format(cmd))subprocess.call(cmd,shell=True)defvoc_info(json_dataset):year=json_dataset.name[4:8]image_set=json_dataset.name[9:]devkit_path=get_devkit_dir(json_dataset.name)assertos.path.exists(devkit_path),\\\\\\'Devkitdirectory{}notfound\\'.format(devkit_path)anno_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'Annotations\\',\\'{:s}.xml\\')image_set_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'ImageSets\\',\\'Main\\',image_set+\\'.txt\\')returndict(year=year,image_set=image_set,devkit_path=devkit_path,anno_path=anno_path,image_set_path=image_set_path)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################mappingcococategoriestocityscapes(ourconvertedjson)id#cityscapes#INFOroidb.py:220:1bicycle:7286#INFOroidb.py:220:2car:53684#INFOroidb.py:220:3person:35704#INFOroidb.py:220:4train:336#INFOroidb.py:220:5truck:964#INFOroidb.py:220:6motorcycle:1468#INFOroidb.py:220:7bus:758#INFOroidb.py:220:8rider:3504#coco(val5k)#INFOroidb.py:220:1person:21296#INFOroidb.py:220:2bicycle:628#INFOroidb.py:220:3car:3818#INFOroidb.py:220:4motorcycle:732#INFOroidb.py:220:5airplane:286<------irrelevant#INFOroidb.py:220:6bus:564#INFOroidb.py:220:7train:380#INFOroidb.py:220:8truck:828defcityscapes_to_coco(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(-1meansrandinit)}returnlookup[cityscapes_id]defcityscapes_to_coco_with_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:1,#rider(\"person\",*riderhashumanright!*)}returnlookup[cityscapes_id]defcityscapes_to_coco_without_person_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:-1,#person(ignore)4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]defcityscapes_to_coco_all_random(cityscapes_id):lookup={0:-1,#...background1:-1,#bicycle2:-1,#car3:-1,#person(ignore)4:-1,#train5:-1,#truck6:-1,#motorcycle7:-1,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforcommonroidbmanipulations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfrompast.builtinsimportbasestringimportloggingimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasets.json_datasetimportJsonDatasetimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.keypointsaskeypoint_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defcombined_roidb_for_training(dataset_names,proposal_files):\"\"\"Loadandconcatenateroidbsforoneormoredatasets,alongwithoptionalobjectproposals.Theroidbentriesarethenpreparedforuseintraining,whichinvolvescachingcertaintypesofmetadataforeachroidbentry.\"\"\"defget_roidb(dataset_name,proposal_file):ds=JsonDataset(dataset_name)roidb=ds.get_roidb(gt=True,proposal_file=proposal_file,crowd_filter_thresh=cfg.TRAIN.CROWD_FILTER_THRESH)ifcfg.TRAIN.USE_FLIPPED:logger.info(\\'Appendinghorizontally-flippedtrainingexamples...\\')extend_with_flipped_entries(roidb,ds)logger.info(\\'Loadeddataset:{:s}\\'.format(ds.name))returnroidbifisinstance(dataset_names,basestring):dataset_names=(dataset_names,)ifisinstance(proposal_files,basestring):proposal_files=(proposal_files,)iflen(proposal_files)==0:proposal_files=(None,)*len(dataset_names)assertlen(dataset_names)==len(proposal_files)roidbs=[get_roidb(*args)forargsinzip(dataset_names,proposal_files)]roidb=roidbs[0]forrinroidbs[1:]:roidb.extend(r)roidb=filter_for_training(roidb)logger.info(\\'Computingbounding-boxregressiontargets...\\')add_bbox_regression_targets(roidb)logger.info(\\'done\\')_compute_and_log_stats(roidb)returnroidbdefextend_with_flipped_entries(roidb,dataset):\"\"\"Flipeachentryinthegivenroidbandreturnanewroidbthatistheconcatenationoftheoriginalroidbandtheflippedentries.\"Flipping\"anentrymeansthatthatimageandassociatedmetadata(e.g.,groundtruthboxesandobjectproposals)arehorizontallyflipped.\"\"\"flipped_roidb=[]forentryinroidb:width=entry[\\'width\\']boxes=entry[\\'boxes\\'].copy()oldx1=boxes[:,0].copy()oldx2=boxes[:,2].copy()boxes[:,0]=width-oldx2-1boxes[:,2]=width-oldx1-1assert(boxes[:,2]>=boxes[:,0]).all()flipped_entry={}dont_copy=(\\'boxes\\',\\'segms\\',\\'gt_keypoints\\',\\'flipped\\')fork,vinentry.items():ifknotindont_copy:flipped_entry[k]=vflipped_entry[\\'boxes\\']=boxesflipped_entry[\\'segms\\']=segm_utils.flip_segms(entry[\\'segms\\'],entry[\\'height\\'],entry[\\'width\\'])ifdataset.keypointsisnotNone:flipped_entry[\\'gt_keypoints\\']=keypoint_utils.flip_keypoints(dataset.keypoints,dataset.keypoint_flip_map,entry[\\'gt_keypoints\\'],entry[\\'width\\'])flipped_entry[\\'flipped\\']=Trueflipped_roidb.append(flipped_entry)roidb.extend(flipped_roidb)deffilter_for_training(roidb):\"\"\"RemoveroidbentriesthathavenousableRoIsbasedonconfigsettings.\"\"\"defis_valid(entry):#Validimageshave:#(1)AtleastoneforegroundRoIOR#(2)AtleastonebackgroundRoIoverlaps=entry[\\'max_overlaps\\']#findboxeswithsufficientoverlapfg_inds=np.where(overlaps>=cfg.TRAIN.FG_THRESH)[0]#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((overlaps<cfg.TRAIN.BG_THRESH_HI)&(overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#imageisonlyvalidifsuchboxesexistvalid=len(fg_inds)>0orlen(bg_inds)>0ifcfg.MODEL.KEYPOINTS_ON:#Ifwe\\'retrainingforkeypoints,excludeimageswithnokeypointsvalid=validandentry[\\'has_visible_keypoints\\']returnvalidnum=len(roidb)filtered_roidb=[entryforentryinroidbifis_valid(entry)]num_after=len(filtered_roidb)logger.info(\\'Filtered{}roidbentries:{}->{}\\'.format(num-num_after,num,num_after))returnfiltered_roidbdefadd_bbox_regression_targets(roidb):\"\"\"Addinformationneededtotrainbounding-boxregressors.\"\"\"forentryinroidb:entry[\\'bbox_targets\\']=compute_bbox_regression_targets(entry)defcompute_bbox_regression_targets(entry):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"#Indicesofground-truthROIsrois=entry[\\'boxes\\']overlaps=entry[\\'max_overlaps\\']labels=entry[\\'max_classes\\']gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]#Targetshasformat(class,tx,ty,tw,th)targets=np.zeros((rois.shape[0],5),dtype=np.float32)iflen(gt_inds)==0:#Bailiftheimagehasnoground-truthROIsreturntargets#Indicesofexamplesforwhichwetrytomakepredictionsex_inds=np.where(overlaps>=cfg.TRAIN.BBOX_THRESH)[0]#GetIoUoverlapbetweeneachexROIandgtROIex_gt_overlaps=box_utils.bbox_overlaps(rois[ex_inds,:].astype(dtype=np.float32,copy=False),rois[gt_inds,:].astype(dtype=np.float32,copy=False))#FindwhichgtROIeachexROIhasmaxoverlapwith:#thiswillbetheexROI\\'sgttargetgt_assignment=ex_gt_overlaps.argmax(axis=1)gt_rois=rois[gt_inds[gt_assignment],:]ex_rois=rois[ex_inds,:]#Useclass\"1\"forallboxesifusingclass_agnostic_bbox_regtargets[ex_inds,0]=(1ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelselabels[ex_inds])targets[ex_inds,1:]=box_utils.bbox_transform_inv(ex_rois,gt_rois,cfg.MODEL.BBOX_REG_WEIGHTS)returntargetsdef_compute_and_log_stats(roidb):classes=roidb[0][\\'dataset\\'].classeschar_len=np.max([len(c)forcinclasses])hist_bins=np.arange(len(classes)+1)#Histogramofground-truthobjectsgt_hist=np.zeros((len(classes)),dtype=int)forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_classes=entry[\\'gt_classes\\'][gt_inds]gt_hist+=np.histogram(gt_classes,bins=hist_bins)[0]logger.debug(\\'Ground-truthclasshistogram:\\')fori,vinenumerate(gt_hist):logger.debug(\\'{:d}{:s}:{:d}\\'.format(i,classes[i].rjust(char_len),v))logger.debug(\\'-\\'*char_len)logger.debug(\\'{:s}:{:d}\\'.format(\\'total\\'.rjust(char_len),np.sum(gt_hist)))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Evaluationinterfaceforsupportedtasks(boxdetection,instancesegmentation,keypointdetection,...).ResultsarestoredinanOrderedDictwiththefollowingnestedstructure::::isanyvaliddataset(e.g.,\\'coco_2014_minival\\')isin[\\'box\\',\\'mask\\',\\'keypoint\\',\\'box_proposal\\']canbe[\\'AP\\',\\'AP50\\',\\'AP75\\',\\'APs\\',\\'APm\\',\\'APl\\',\\'\\',\\'\\',\\'\\',\\'\\',...]isafloatingpointnumber\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportosimportpprintfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportsend_emailimportdetectron.datasets.cityscapes_json_dataset_evaluator\\\\ascs_json_dataset_evaluatorimportdetectron.datasets.json_dataset_evaluatorasjson_dataset_evaluatorimportdetectron.datasets.voc_dataset_evaluatorasvoc_dataset_evaluatorlogger=logging.getLogger(__name__)defevaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir,use_matlab=False):\"\"\"Evaluate\"all\"tasks,where\"all\"includesboxdetection,instancesegmentation,andkeypointdetection.\"\"\"all_results=evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)logger.info(\\'Evaluatingboundingboxesisdone!\\')ifcfg.MODEL.MASK_ON:results=evaluate_masks(dataset,all_boxes,all_segms,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingsegmentationsisdone!\\')ifcfg.MODEL.KEYPOINTS_ON:results=evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingkeypointsisdone!\\')returnall_resultsdefevaluate_boxes(dataset,all_boxes,output_dir,use_matlab=False):\"\"\"Evaluateboundingboxdetection.\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_cityscapes_evaluator(dataset):logger.warn(\\'CityscapesbboxevaluatedusingCOCOmetrics/conversions\\')coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_voc_evaluator(dataset):#ForVOC,alwaysusesaltandalwayscleanupbecauseresultsare#writtentothesharedVOCdevkitresultsdirectoryvoc_eval=voc_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)box_results=_voc_eval_to_box_results(voc_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,box_results)])defevaluate_masks(dataset,all_boxes,all_segms,output_dir):\"\"\"Evaluateinstancesegmentation.\"\"\"logger.info(\\'Evaluatingsegmentations\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_coco_eval_to_mask_results(coco_eval)elif_use_cityscapes_evaluator(dataset):cs_eval=cs_json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_cs_eval_to_mask_results(cs_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,mask_results)])defevaluate_keypoints(dataset,all_boxes,all_keyps,output_dir):\"\"\"Evaluatehumankeypointdetection(i.e.,2Dposeestimation).\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEassertdataset.name.startswith(\\'keypoints_coco_\\'),\\\\\\'OnlyCOCOkeypointsarecurrentlysupported\\'coco_eval=json_dataset_evaluator.evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir,use_salt=not_comp,cleanup=not_comp)keypoint_results=_coco_eval_to_keypoint_results(coco_eval)returnOrderedDict([(dataset.name,keypoint_results)])defevaluate_box_proposals(dataset,roidb):\"\"\"Evaluateboundingboxobjectproposals.\"\"\"res=_empty_box_proposal_results()areas={\\'all\\':\\'\\',\\'small\\':\\'s\\',\\'medium\\':\\'m\\',\\'large\\':\\'l\\'}forlimitin[100,1000]:forarea,suffixinareas.items():stats=json_dataset_evaluator.evaluate_box_proposals(dataset,roidb,area=area,limit=limit,class_specific=cfg.TEST.CLASS_SPECIFIC_AR)key=\\'AR{}@{:d}\\'.format(suffix,limit)res[\\'box_proposal\\'][key]=stats[\\'ar\\']returnOrderedDict([(dataset.name,res)])deflog_box_proposal_results(results):\"\"\"Logboundingboxproposalresults.\"\"\"fordatasetinresults.keys():keys=results[dataset][\\'box_proposal\\'].keys()pad=max([len(k)forkinkeys])logger.info(dataset)fork,vinresults[dataset][\\'box_proposal\\'].items():logger.info(\\'{}:{:.3f}\\'.format(k.ljust(pad),v))deflog_copy_paste_friendly_results(results):\"\"\"Logresultsinaformatthatmakesiteasytocopy-and-pasteinaspreadsheet.Linesareprefixedwith\\'copypaste:\\'tomakegreppingeasy.\"\"\"fordatasetinresults.keys():logger.info(\\'copypaste:Dataset:{}\\'.format(dataset))fortask,metricsinresults[dataset].items():logger.info(\\'copypaste:Task:{}\\'.format(task))metric_names=metrics.keys()metric_vals=[\\'{:.4f}\\'.format(v)forvinmetrics.values()]logger.info(\\'copypaste:\\'+\\',\\'.join(metric_names))logger.info(\\'copypaste:\\'+\\',\\'.join(metric_vals))defcheck_expected_results(results,atol=0.005,rtol=0.1):\"\"\"Checkactualresultsagainstexpectedresultsstoredincfg.EXPECTED_RESULTS.Optionallyemailifthematchexceedsthespecifiedtolerance.Expectedresultsshouldtaketheformofalistofexpectations,eachspecifiedbyfourelements:[dataset,task,metric,expectedvalue].Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387],...].Theexpectedvaluemayalsobeformattedasalist[mean,std]providinganempiricalmeanandstandarddeviationfromwhichavalidrangeiscomputedusingcfg.EXPECTED_RESULTS_SIGMA_TOL.Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',[0.387,0.001]],...]\"\"\"#cfgcontainsareferencesetofresultsthatwewanttocheckagainstiflen(cfg.EXPECTED_RESULTS)==0:returnfordataset,task,metric,expected_valincfg.EXPECTED_RESULTS:assertdatasetinresults,\\'Dataset{}notinresults\\'.format(dataset)asserttaskinresults[dataset],\\'Task{}notinresults\\'.format(task)assertmetricinresults[dataset][task],\\\\\\'Metric{}notinresults\\'.format(metric)actual_val=results[dataset][task][metric]ok=Falseifisinstance(expected_val,list):assertlen(expected_val)==2,(\\'Expectedresultmustbein(mean,std)format\\')mean,std=expected_vallo=mean-cfg.EXPECTED_RESULTS_SIGMA_TOL*stdhi=mean+cfg.EXPECTED_RESULTS_SIGMA_TOL*stdok=(lo<actual_val)and(actual_val<hi)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.mean={:.4f},std={:.4},range=({:.4f},{:.4f})\\').format(dataset,task,metric,actual_val,mean,std,lo,hi)else:err=abs(actual_val-expected_val)tol=atol+rtol*abs(expected_val)ok=(err>tol)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.{:.3f},err={:.3f},tol={:.3f}\\').format(dataset,task,metric,actual_val,expected_val,err,tol)ifnotok:msg=\\'FAIL:\\'+msglogger.error(msg)ifcfg.EXPECTED_RESULTS_EMAIL!=\\'\\':subject=\\'Detectronend-to-endtestfailure\\'job_name=os.environ[\\'DETECTRON_JOB_NAME\\']if\\'DETECTRON_JOB_NAME\\'inos.environelse\\'\\'job_id=os.environ[\\'WORKFLOW_RUN_ID\\']if\\'WORKFLOW_RUN_ID\\'inos.environelse\\'\\'body=[\\'Name:\\',job_name,\\'RunID:\\',job_id,\\'Failure:\\',msg,\\'Config:\\',pprint.pformat(cfg),\\'Env:\\',pprint.pformat(dict(os.environ)),]send_email(subject,\\'\\\\n\\\\n\\'.join(body),cfg.EXPECTED_RESULTS_EMAIL)else:msg=\\'PASS:\\'+msglogger.info(msg)def_use_json_dataset_evaluator(dataset):\"\"\"Checkifthedatasetusesthegeneraljsondatasetevaluator.\"\"\"returndataset.name.find(\\'coco_\\')>-1orcfg.TEST.FORCE_JSON_DATASET_EVALdef_use_cityscapes_evaluator(dataset):\"\"\"CheckifthedatasetusestheCityscapesdatasetevaluator.\"\"\"returndataset.name.find(\\'cityscapes_\\')>-1def_use_voc_evaluator(dataset):\"\"\"CheckifthedatasetusesthePASCALVOCdatasetevaluator.\"\"\"returndataset.name[:4]==\\'voc_\\'#IndicesinthestatsarrayforCOCOboxesandmasksCOCO_AP=0COCO_AP50=1COCO_AP75=2COCO_APS=3COCO_APM=4COCO_APL=5#SlightdifferenceforkeypointsCOCO_KPS_APM=3COCO_KPS_APL=4#----------------------------------------------------------------------------##Helperfunctionsforproducingproperlyformattedresults.#----------------------------------------------------------------------------#def_coco_eval_to_box_results(coco_eval):res=_empty_box_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'box\\'][\\'AP\\']=s[COCO_AP]res[\\'box\\'][\\'AP50\\']=s[COCO_AP50]res[\\'box\\'][\\'AP75\\']=s[COCO_AP75]res[\\'box\\'][\\'APs\\']=s[COCO_APS]res[\\'box\\'][\\'APm\\']=s[COCO_APM]res[\\'box\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_mask_results(coco_eval):res=_empty_mask_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'mask\\'][\\'AP\\']=s[COCO_AP]res[\\'mask\\'][\\'AP50\\']=s[COCO_AP50]res[\\'mask\\'][\\'AP75\\']=s[COCO_AP75]res[\\'mask\\'][\\'APs\\']=s[COCO_APS]res[\\'mask\\'][\\'APm\\']=s[COCO_APM]res[\\'mask\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_keypoint_results(coco_eval):res=_empty_keypoint_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'keypoint\\'][\\'AP\\']=s[COCO_AP]res[\\'keypoint\\'][\\'AP50\\']=s[COCO_AP50]res[\\'keypoint\\'][\\'AP75\\']=s[COCO_AP75]res[\\'keypoint\\'][\\'APm\\']=s[COCO_KPS_APM]res[\\'keypoint\\'][\\'APl\\']=s[COCO_KPS_APL]returnresdef_voc_eval_to_box_results(voc_eval):#Notsupported(returnemptyresults)return_empty_box_results()def_cs_eval_to_mask_results(cs_eval):#Notsupported(returnemptyresults)return_empty_mask_results()def_empty_box_results():returnOrderedDict({\\'box\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_mask_results():returnOrderedDict({\\'mask\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_keypoint_results():returnOrderedDict({\\'keypoint\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_box_proposal_results():returnOrderedDict({\\'box_proposal\\':OrderedDict([(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),])})#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforevaluatingresultsonCityscapes.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportosimportuuidimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_raw_dirlogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):ifcfg.CLUSTER.ON_CLUSTER:#Ontheclusteravoidsavingthesefilesinthejobdirectoryoutput_dir=\\'/tmp\\'res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'results_dir=os.path.join(output_dir,\\'results\\')ifnotos.path.exists(results_dir):os.mkdir(results_dir)os.environ[\\'CITYSCAPES_DATASET\\']=get_raw_dir(json_dataset.name)os.environ[\\'CITYSCAPES_RESULTS\\']=output_dir#LoadtheCityscapesevalscript*after*settingtherequiredenvvars,#sincethescriptreadstheirvaluesintoglobalvariables(atloadtime).importcityscapesscripts.evaluation.evalInstanceLevelSemanticLabeling\\\\ascityscapes_evalroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):im_name=entry[\\'image\\']basename=os.path.splitext(os.path.basename(im_name))[0]txtname=os.path.join(output_dir,basename+\\'pred.txt\\')withopen(txtname,\\'w\\')asfid_txt:ifi%10==0:logger.info(\\'i:{}:{}\\'.format(i,basename))forjinrange(1,len(all_segms)):clss=json_dataset.classes[j]clss_id=cityscapes_eval.name2label[clss].idsegms=all_segms[j][i]boxes=all_boxes[j][i]ifsegms==[]:continuemasks=mask_util.decode(segms)forkinrange(boxes.shape[0]):score=boxes[k,-1]mask=masks[:,:,k]pngname=os.path.join(\\'results\\',basename+\\'_\\'+clss+\\'_{}.png\\'.format(k))#writetxtfid_txt.write(\\'{}{}{}\\\\n\\'.format(pngname,clss_id,score))#savemaskcv2.imwrite(os.path.join(output_dir,pngname),mask*255)logger.info(\\'Evaluating...\\')cityscapes_eval.main([])returnNone#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Providestubobjectsthatcanactasstand-in\"dummy\"datasetsforsimpleusecases,likegettingallclassesinadataset.Thisexistssothatdemoscanberunwithoutrequiringuserstodownload/installdatasetsfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.utils.collectionsimportAttrDictdefget_coco_dataset():\"\"\"AdummyCOCOdatasetthatincludesonlythe\\'classes\\'field.\"\"\"ds=AttrDict()classes=[\\'__background__\\',\\'person\\',\\'bicycle\\',\\'car\\',\\'motorcycle\\',\\'airplane\\',\\'bus\\',\\'train\\',\\'truck\\',\\'boat\\',\\'trafficlight\\',\\'firehydrant\\',\\'stopsign\\',\\'parkingmeter\\',\\'bench\\',\\'bird\\',\\'cat\\',\\'dog\\',\\'horse\\',\\'sheep\\',\\'cow\\',\\'elephant\\',\\'bear\\',\\'zebra\\',\\'giraffe\\',\\'backpack\\',\\'umbrella\\',\\'handbag\\',\\'tie\\',\\'suitcase\\',\\'frisbee\\',\\'skis\\',\\'snowboard\\',\\'sportsball\\',\\'kite\\',\\'baseballbat\\',\\'baseballglove\\',\\'skateboard\\',\\'surfboard\\',\\'tennisracket\\',\\'bottle\\',\\'wineglass\\',\\'cup\\',\\'fork\\',\\'knife\\',\\'spoon\\',\\'bowl\\',\\'banana\\',\\'apple\\',\\'sandwich\\',\\'orange\\',\\'broccoli\\',\\'carrot\\',\\'hotdog\\',\\'pizza\\',\\'donut\\',\\'cake\\',\\'chair\\',\\'couch\\',\\'pottedplant\\',\\'bed\\',\\'diningtable\\',\\'toilet\\',\\'tv\\',\\'laptop\\',\\'mouse\\',\\'remote\\',\\'keyboard\\',\\'cellphone\\',\\'microwave\\',\\'oven\\',\\'toaster\\',\\'sink\\',\\'refrigerator\\',\\'book\\',\\'clock\\',\\'vase\\',\\'scissors\\',\\'teddybear\\',\\'hairdrier\\',\\'toothbrush\\']ds.classes={i:namefori,nameinenumerate(classes)}returnds#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RepresentationofthestandardCOCOjsondatasetformat.Whenworkingwithanewdataset,westronglysuggesttoconvertthedatasetintotheCOCOjsonformatandusetheexistingcode;itisnotrecommendedtowritecodetosupportnewdatasetformats.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportloggingimportnumpyasnpimportosimportscipy.sparse#MusthappenbeforeimportingCOCOAPI(whichimportsmatplotlib)importdetectron.utils.envasenvuenvu.set_up_matplotlib()#COCOAPIfrompycocotoolsimportmaskasCOCOmaskfrompycocotools.cocoimportCOCOfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.datasets.dataset_catalogasdataset_catalogimportdetectron.utils.boxesasbox_utilsfromdetectron.utils.ioimportload_objectimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)classJsonDataset:\"\"\"AclassrepresentingaCOCOjsondataset.\"\"\"def__init__(self,name):assertdataset_catalog.contains(name),\\\\\\'Unknowndatasetname:{}\\'.format(name)assertos.path.exists(dataset_catalog.get_im_dir(name)),\\\\\\'Imdir\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_im_dir(name))assertos.path.exists(dataset_catalog.get_ann_fn(name)),\\\\\\'Annfn\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_ann_fn(name))logger.debug(\\'Creating:{}\\'.format(name))self.name=nameself.image_directory=dataset_catalog.get_im_dir(name)self.image_prefix=dataset_catalog.get_im_prefix(name)self.COCO=COCO(dataset_catalog.get_ann_fn(name))self.debug_timer=Timer()#Setupdatasetclassescategory_ids=self.COCO.getCatIds()categories=[c[\\'name\\']forcinself.COCO.loadCats(category_ids)]self.category_to_id_map=dict(zip(categories,category_ids))self.classes=[\\'__background__\\']+categoriesself.num_classes=len(self.classes)self.json_category_id_to_contiguous_id={v:i+1fori,vinenumerate(self.COCO.getCatIds())}self.contiguous_category_id_to_json_id={v:kfork,vinself.json_category_id_to_contiguous_id.items()}self._init_keypoints()defget_roidb(self,gt=False,proposal_file=None,min_proposal_size=2,proposal_limit=-1,crowd_filter_thresh=0):\"\"\"Returnanroidbcorrespondingtothejsondataset.Optionally:-includegroundtruthboxesintheroidb-addproposalsspecifiedinaproposalsfile-filterproposalsbasedonaminimumsidelength-filterproposalsthatintersectwithcrowdregions\"\"\"assertgtisTrueorcrowd_filter_thresh==0,\\\\\\'Crowdfilterthresholdmustbe0ifground-truthannotations\\'\\\\\\'arenotincluded.\\'image_ids=self.COCO.getImgIds()image_ids.sort()roidb=copy.deepcopy(self.COCO.loadImgs(image_ids))forentryinroidb:self._prep_roidb_entry(entry)ifgt:#Includeground-truthobjectannotationsself.debug_timer.tic()forentryinroidb:self._add_gt_annotations(entry)logger.debug(\\'_add_gt_annotationstook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))ifproposal_fileisnotNone:#Includeproposalsfromafileself.debug_timer.tic()self._add_proposals_from_file(roidb,proposal_file,min_proposal_size,proposal_limit,crowd_filter_thresh)logger.debug(\\'_add_proposals_from_filetook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))_add_class_assignments(roidb)returnroidbdef_prep_roidb_entry(self,entry):\"\"\"Addsemptymetadatafieldstoanroidbentry.\"\"\"#Referencebacktotheparentdatasetentry[\\'dataset\\']=self#Makefile_nameanabspathim_path=os.path.join(self.image_directory,self.image_prefix+entry[\\'file_name\\'])assertos.path.exists(im_path),\\'Image\\\\\\'{}\\\\\\'notfound\\'.format(im_path)entry[\\'image\\']=im_pathentry[\\'flipped\\']=Falseentry[\\'has_visible_keypoints\\']=False#Emptyplaceholdersentry[\\'boxes\\']=np.empty((0,4),dtype=np.float32)entry[\\'segms\\']=[]entry[\\'gt_classes\\']=np.empty((0),dtype=np.int32)entry[\\'seg_areas\\']=np.empty((0),dtype=np.float32)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(np.empty((0,self.num_classes),dtype=np.float32))entry[\\'is_crowd\\']=np.empty((0),dtype=bool)#\\'box_to_gt_ind_map\\':Shapeis(#rois).Mapsfromeachroitotheindex#inthelistofroisthatsatisfynp.where(entry[\\'gt_classes\\']>0)entry[\\'box_to_gt_ind_map\\']=np.empty((0),dtype=np.int32)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.empty((0,3,self.num_keypoints),dtype=np.int32)#Removeunwantedfieldsthatcomefromthejsonfile(iftheyexist)forkin[\\'date_captured\\',\\'url\\',\\'license\\',\\'file_name\\']:ifkinentry:delentry[k]def_add_gt_annotations(self,entry):\"\"\"Addgroundtruthannotationmetadatatoanroidbentry.\"\"\"ann_ids=self.COCO.getAnnIds(imgIds=entry[\\'id\\'],iscrowd=None)objs=self.COCO.loadAnns(ann_ids)#Sanitizebboxes--someareinvalidvalid_objs=[]valid_segms=[]width=entry[\\'width\\']height=entry[\\'height\\']forobjinobjs:#crowdregionsareRLEencodedifsegm_utils.is_poly(obj[\\'segmentation\\']):#Validpolygonshave>=3points,sorequire>=6coordinatesobj[\\'segmentation\\']=[pforpinobj[\\'segmentation\\']iflen(p)>=6]ifobj[\\'area\\']<cfg.TRAIN.GT_MIN_AREA:continueif\\'ignore\\'inobjandobj[\\'ignore\\']==1:continue#Convertform(x1,y1,w,h)to(x1,y1,x2,y2)x1,y1,x2,y2=box_utils.xywh_to_xyxy(obj[\\'bbox\\'])x1,y1,x2,y2=box_utils.clip_xyxy_to_image(x1,y1,x2,y2,height,width)#Requirenon-zerosegareaandmorethan1x1boxsizeifobj[\\'area\\']>0andx2>x1andy2>y1:obj[\\'clean_bbox\\']=[x1,y1,x2,y2]valid_objs.append(obj)valid_segms.append(obj[\\'segmentation\\'])num_valid_objs=len(valid_objs)boxes=np.zeros((num_valid_objs,4),dtype=entry[\\'boxes\\'].dtype)gt_classes=np.zeros((num_valid_objs),dtype=entry[\\'gt_classes\\'].dtype)gt_overlaps=np.zeros((num_valid_objs,self.num_classes),dtype=entry[\\'gt_overlaps\\'].dtype)seg_areas=np.zeros((num_valid_objs),dtype=entry[\\'seg_areas\\'].dtype)is_crowd=np.zeros((num_valid_objs),dtype=entry[\\'is_crowd\\'].dtype)box_to_gt_ind_map=np.zeros((num_valid_objs),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)ifself.keypointsisnotNone:gt_keypoints=np.zeros((num_valid_objs,3,self.num_keypoints),dtype=entry[\\'gt_keypoints\\'].dtype)im_has_visible_keypoints=Falseforix,objinenumerate(valid_objs):cls=self.json_category_id_to_contiguous_id[obj[\\'category_id\\']]boxes[ix,:]=obj[\\'clean_bbox\\']gt_classes[ix]=clsseg_areas[ix]=obj[\\'area\\']is_crowd[ix]=obj[\\'iscrowd\\']box_to_gt_ind_map[ix]=ixifself.keypointsisnotNone:gt_keypoints[ix,:,:]=self._get_gt_keypoints(obj)ifnp.sum(gt_keypoints[ix,2,:])>0:im_has_visible_keypoints=Trueifobj[\\'iscrowd\\']:#Setoverlapto-1forallclassesforcrowdobjects#sotheywillbeexcludedduringtraininggt_overlaps[ix,:]=-1.0else:gt_overlaps[ix,cls]=1.0entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes,axis=0)entry[\\'segms\\'].extend(valid_segms)#Tomatchtheoriginalimplementation:#entry[\\'boxes\\']=np.append(#entry[\\'boxes\\'],boxes.astype(int).astype(float),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],gt_classes)entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],seg_areas)entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],is_crowd)entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.append(entry[\\'gt_keypoints\\'],gt_keypoints,axis=0)entry[\\'has_visible_keypoints\\']=im_has_visible_keypointsdef_add_proposals_from_file(self,roidb,proposal_file,min_proposal_size,top_k,crowd_thresh):\"\"\"Addproposalsfromaproposalsfiletoanroidb.\"\"\"logger.info(\\'Loadingproposalsfrom:{}\\'.format(proposal_file))proposals=load_object(proposal_file)id_field=\\'indexes\\'if\\'indexes\\'inproposalselse\\'ids\\'#compatfix_remove_proposals_not_in_roidb(proposals,roidb,id_field)_sort_proposals(proposals,id_field)box_list=[]fori,entryinenumerate(roidb):ifi%2500==0:logger.info(\\'{:d}/{:d}\\'.format(i+1,len(roidb)))boxes=proposals[\\'boxes\\'][i]#Sanitycheckthattheseboxesareforthecorrectimageidassertentry[\\'id\\']==proposals[id_field][i]#Removeduplicateboxesandverysmallboxesandthentaketopkboxes=box_utils.clip_boxes_to_image(boxes,entry[\\'height\\'],entry[\\'width\\'])keep=box_utils.unique_boxes(boxes)boxes=boxes[keep,:]keep=box_utils.filter_small_boxes(boxes,min_proposal_size)boxes=boxes[keep,:]iftop_k>0:boxes=boxes[:top_k,:]box_list.append(boxes)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)def_init_keypoints(self):\"\"\"InitializeCOCOkeypointinformation.\"\"\"self.keypoints=Noneself.keypoint_flip_map=Noneself.keypoints_to_id_map=Noneself.num_keypoints=0#Thusfaronlythe\\'person\\'categoryhaskeypointsif\\'person\\'inself.category_to_id_map:cat_info=self.COCO.loadCats([self.category_to_id_map[\\'person\\']])else:return#Checkiftheannotationscontainkeypointdataornotif\\'keypoints\\'incat_info[0]:keypoints=cat_info[0][\\'keypoints\\']self.keypoints_to_id_map=dict(zip(keypoints,range(len(keypoints))))self.keypoints=keypointsself.num_keypoints=len(keypoints)self.keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}def_get_gt_keypoints(self,obj):\"\"\"Returngroundtruthkeypoints.\"\"\"if\\'keypoints\\'notinobj:returnNonekp=np.array(obj[\\'keypoints\\'])x=kp[0::3]#0-indexedxcoordinatesy=kp[1::3]#0-indexedycoordinates#0:notlabeled;1:labeled,notinsidemask;#2:labeledandinsidemaskv=kp[2::3]num_keypoints=len(obj[\\'keypoints\\'])/3assertnum_keypoints==self.num_keypointsgt_kps=np.ones((3,self.num_keypoints),dtype=np.int32)foriinrange(self.num_keypoints):gt_kps[0,i]=x[i]gt_kps[1,i]=y[i]gt_kps[2,i]=v[i]returngt_kpsdefadd_proposals(roidb,rois,scales,crowd_thresh):\"\"\"Addproposalboxes(rois)toanroidbthathasground-truthannotationsbutnoproposals.Iftheproposalsarenotattheoriginalimagescale,specifythescalefactorthatseparatetheminscales.\"\"\"box_list=[]foriinrange(len(roidb)):inv_im_scale=1./scales[i]idx=np.where(rois[:,0]==i)[0]box_list.append(rois[idx,1:]*inv_im_scale)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)_add_class_assignments(roidb)def_merge_proposal_boxes_into_roidb(roidb,box_list):\"\"\"Addproposalboxestoeachroidbentry.\"\"\"assertlen(box_list)==len(roidb)fori,entryinenumerate(roidb):boxes=box_list[i]num_boxes=boxes.shape[0]gt_overlaps=np.zeros((num_boxes,entry[\\'gt_overlaps\\'].shape[1]),dtype=entry[\\'gt_overlaps\\'].dtype)box_to_gt_ind_map=-np.ones((num_boxes),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)#Note:unlikeinotherplaces,hereweintentionallyincludeallgt#rois,evenonesmarkedascrowd.Boxesthatoverlapwithcrowdswill#befilteredoutlater(see:_filter_crowd_proposals).gt_inds=np.where(entry[\\'gt_classes\\']>0)[0]iflen(gt_inds)>0:gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_classes=entry[\\'gt_classes\\'][gt_inds]proposal_to_gt_overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))#Gtboxthatoverlapseachinputboxthemost#(tiesarebrokenarbitrarilybyclassorder)argmaxes=proposal_to_gt_overlaps.argmax(axis=1)#Amountofthatoverlapmaxes=proposal_to_gt_overlaps.max(axis=1)#Thoseboxeswithnon-zerooverlapwithgtboxesI=np.where(maxes>0)[0]#Recordmaxoverlapswiththeclassoftheappropriategtboxgt_overlaps[I,gt_classes[argmaxes[I]]]=maxes[I]box_to_gt_ind_map[I]=gt_inds[argmaxes[I]]entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes.astype(entry[\\'boxes\\'].dtype,copy=False),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],np.zeros((num_boxes),dtype=entry[\\'gt_classes\\'].dtype))entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],np.zeros((num_boxes),dtype=entry[\\'seg_areas\\'].dtype))entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],np.zeros((num_boxes),dtype=entry[\\'is_crowd\\'].dtype))entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map.astype(entry[\\'box_to_gt_ind_map\\'].dtype,copy=False))def_filter_crowd_proposals(roidb,crowd_thresh):\"\"\"Findsproposalsthatareinsidecrowdregionsandmarksthemasoverlap=-1witheachground-truthrois,whichmeanstheywillbeexcludedfromtraining.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()crowd_inds=np.where(entry[\\'is_crowd\\']==1)[0]non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]iflen(crowd_inds)==0orlen(non_gt_inds)==0:continuecrowd_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][crowd_inds,:])non_gt_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][non_gt_inds,:])iscrowd_flags=[int(True)]*len(crowd_inds)ious=COCOmask.iou(non_gt_boxes,crowd_boxes,iscrowd_flags)bad_inds=np.where(ious.max(axis=1)>crowd_thresh)[0]gt_overlaps[non_gt_inds[bad_inds],:]=-1entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(gt_overlaps)def_add_class_assignments(roidb):\"\"\"Computeobjectcategoryassignmentforeachboxassociatedwitheachroidbentry.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()#maxoverlapwithgtoverclasses(columns)max_overlaps=gt_overlaps.max(axis=1)#gtclassthathadthemaxoverlapmax_classes=gt_overlaps.argmax(axis=1)entry[\\'max_classes\\']=max_classesentry[\\'max_overlaps\\']=max_overlaps#sanitychecks#ifmaxoverlapis0,theclassmustbebackground(class0)zero_inds=np.where(max_overlaps==0)[0]assertall(max_classes[zero_inds]==0)#ifmaxoverlap>0,theclassmustbeafgclass(notclass0)nonzero_inds=np.where(max_overlaps>0)[0]assertall(max_classes[nonzero_inds]!=0)def_sort_proposals(proposals,id_field):\"\"\"Sortproposalsbythespecifiedidfield.\"\"\"order=np.argsort(proposals[id_field])fields_to_sort=[\\'boxes\\',id_field,\\'scores\\']forkinfields_to_sort:proposals[k]=[proposals[k][i]foriinorder]def_remove_proposals_not_in_roidb(proposals,roidb,id_field):#fixproposalssotheydon\\'tcontainentriesforimagesnotintheroidbroidb_ids=set({entry[\"id\"]forentryinroidb})keep=[ifori,idinenumerate(proposals[id_field])ifidinroidb_ids]forfin[\\'boxes\\',id_field,\\'scores\\']:proposals[f]=[proposals[f][i]foriinkeep]#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.Allowsforusingacombinationofmultiplemodels.Forexample,onemodelmaybeusedforRPN,anothermodelforFastR-CNNstyleboxdetection,yetanothermodeltopredictmasks,andyetanothermodeltopredictkeypoints.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportosimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.core.configimportmerge_cfg_from_cfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.rpn_generatorasrpn_engineimportdetectron.core.test_engineasmodel_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)#infer.py#--im[path/to/image.jpg]\\\\#--rpn-model[path/to/rpn/model.pkl]\\\\#--rpn-cfg[path/to/rpn/config.yaml]\\\\#--output-dir[path/to/output/dir]\\\\#[model1][config1][model2][config2]...defparse_args():parser=argparse.ArgumentParser(description=\\'Inferenceonanimage\\')parser.add_argument(\\'--im\\',dest=\\'im_file\\',help=\\'inputimage\\',default=None,type=str)parser.add_argument(\\'--rpn-pkl\\',dest=\\'rpn_pkl\\',help=\\'rpnmodelfile(pkl)\\',default=None,type=str)parser.add_argument(\\'--rpn-cfg\\',dest=\\'rpn_cfg\\',help=\\'cfgmodelfile(yaml)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer)\\',default=\\'/tmp/infer\\',type=str)parser.add_argument(\\'models_to_run\\',help=\\'pairsofmodels&configs,listedlikeso:[pkl1][yaml1][pkl2][yaml2]...\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defget_rpn_box_proposals(im,args):cfg.immutable(False)merge_cfg_from_file(args.rpn_cfg)cfg.NUM_GPUS=1cfg.MODEL.RPN_ONLY=Truecfg.TEST.RPN_PRE_NMS_TOP_N=10000cfg.TEST.RPN_POST_NMS_TOP_N=2000assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(args.rpn_pkl)withc2_utils.NamedCudaScope(0):boxes,scores=rpn_engine.im_proposals(model,im)returnboxes,scoresdefmain(args):logger=logging.getLogger(__name__)dummy_coco_dataset=dummy_datasets.get_coco_dataset()cfg_orig=load_cfg(envu.yaml_dump(cfg))im=cv2.imread(args.im_file)ifargs.rpn_pklisnotNone:proposal_boxes,_proposal_scores=get_rpn_box_proposals(im,args)workspace.ResetWorkspace()else:proposal_boxes=Nonecls_boxes,cls_segms,cls_keyps=None,None,Noneforiinrange(0,len(args.models_to_run),2):pkl=args.models_to_run[i]yml=args.models_to_run[i+1]cfg.immutable(False)merge_cfg_from_cfg(cfg_orig)merge_cfg_from_file(yml)iflen(pkl)>0:weights_file=pklelse:weights_file=cfg.TEST.WEIGHTScfg.NUM_GPUS=1assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(weights_file)withc2_utils.NamedCudaScope(0):cls_boxes_,cls_segms_,cls_keyps_=\\\\model_engine.im_detect_all(model,im,proposal_boxes)cls_boxes=cls_boxes_ifcls_boxes_isnotNoneelsecls_boxescls_segms=cls_segms_ifcls_segms_isnotNoneelsecls_segmscls_keyps=cls_keyps_ifcls_keyps_isnotNoneelsecls_keypsworkspace.ResetWorkspace()out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(args.im_file)+\\'.pdf\\'))logger.info(\\'Processing{}->{}\\'.format(args.im_file,out_name))vis_utils.vis_one_image(im[:,:,::-1],args.im_file,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=0.7,kp_thresh=2)defcheck_args(args):assert((args.rpn_pklisnotNoneandargs.rpn_cfgisnotNone)or(args.rpn_pklisNoneandargs.rpn_cfgisNone))ifargs.rpn_pklisnotNone:args.rpn_pkl=cache_url(args.rpn_pkl,cfg.DOWNLOAD_CACHE)assertos.path.exists(args.rpn_pkl)assertos.path.exists(args.rpn_cfg)ifargs.models_to_runisnotNone:assertlen(args.models_to_run)%2==0fori,model_fileinenumerate(args.models_to_run):iflen(model_file)>0:ifi%2==0:model_file=cache_url(model_file,cfg.DOWNLOAD_CACHE)args.models_to_run[i]=model_fileassertos.path.exists(model_file),\\\\\\'\\\\\\'{}\\\\\\'doesnotexist\\'.format(model_file)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()check_args(args)main(args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceononeormoredatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importosimportpprintimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TestaFastR-CNNnetwork\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--wait\\',dest=\\'wait\\',help=\\'waituntilnetfileexists\\',default=True,type=bool)parser.add_argument(\\'--vis\\',dest=\\'vis\\',help=\\'visualizedetections\\',action=\\'store_true\\')parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'usingcfg.NUM_GPUSforinference\\',action=\\'store_true\\')parser.add_argument(\\'--range\\',dest=\\'range\\',help=\\'start(inclusive)andend(exclusive)indices\\',default=None,type=int,nargs=2)parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Testingwithconfig:\\')logger.info(pprint.pformat(cfg))whilenotos.path.exists(cfg.TEST.WEIGHTS)andargs.wait:logger.info(\\'Waitingfor\\\\\\'{}\\\\\\'toexist...\\'.format(cfg.TEST.WEIGHTS))time.sleep(10)run_inference(cfg.TEST.WEIGHTS,ind_range=args.range,multi_gpu_testing=args.multi_gpu_testing,check_expected_results=True,)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scriptforvisualizingresultssavedinadetections.pklfile.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2importosimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectimportdetectron.utils.visasvis_utils#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--dataset\\',dest=\\'dataset\\',help=\\'dataset\\',default=\\'coco_2014_minival\\',type=str)parser.add_argument(\\'--detections\\',dest=\\'detections\\',help=\\'detectionspklfile\\',default=\\'\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'detectionprobthreshold\\',default=0.9,type=float)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'./tmp/vis-output\\',type=str)parser.add_argument(\\'--first\\',dest=\\'first\\',help=\\'onlyvisualizethefirstkimages\\',default=0,type=int)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefvis(dataset,detections_pkl,thresh,output_dir,limit=0):ds=JsonDataset(dataset)roidb=ds.get_roidb()dets=load_object(detections_pkl)assertall(kindetsforkin[\\'all_boxes\\',\\'all_segms\\',\\'all_keyps\\']),\\\\\\'Expecteddetectionspklfileintheformatusedbytest_engine.py\\'all_boxes=dets[\\'all_boxes\\']all_segms=dets[\\'all_segms\\']all_keyps=dets[\\'all_keyps\\']defid_or_index(ix,val):iflen(val)==0:returnvalelse:returnval[ix]forix,entryinenumerate(roidb):iflimit>0andix>=limit:breakifix%10==0:print(\\'{:d}/{:d}\\'.format(ix+1,len(roidb)))im=cv2.imread(entry[\\'image\\'])im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]cls_boxes_i=[id_or_index(ix,cls_k_boxes)forcls_k_boxesinall_boxes]cls_segms_i=[id_or_index(ix,cls_k_segms)forcls_k_segmsinall_segms]cls_keyps_i=[id_or_index(ix,cls_k_keyps)forcls_k_keypsinall_keyps]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(ix,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=thresh,box_alpha=0.8,dataset=ds,show_class=True)if__name__==\\'__main__\\':opts=parse_args()vis(opts.dataset,opts.detections,opts.thresh,opts.output_dir,limit=opts.first)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TrainanetworkwithDetectron.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportpprintimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.trainc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TrainanetworkwithDetectron\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'Configfilefortraining(andoptionallytesting)\\',default=None,type=str)parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'Usecfg.NUM_GPUSGPUsforinference\\',action=\\'store_true\\')parser.add_argument(\\'--skip-test\\',dest=\\'skip_test\\',help=\\'Donottestthefinalmodel\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain():#InitializeC2workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\',\\'--caffe2_gpu_memory_tracking=1\\'])#Setuploggingandloadconfigoptionslogger=setup_logging(__name__)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()smi_output,cuda_ver,cudnn_ver=c2_utils.get_nvidia_info()logger.info(\"cudaversion:{}\".format(cuda_ver))logger.info(\"cudnnversion:{}\".format(cudnn_ver))logger.info(\"nvidia-smioutput:\\\\n{}\".format(smi_output))logger.info(\\'Trainingwithconfig:\\')logger.info(pprint.pformat(cfg))#Notethatwhilewesetthenumpyrandomseednetworktrainingwillnotbe#deterministicingeneral.Therearesourcesofnon-determinismthatcannot#beremovedwithareasonbleexecution-speedtradeoff(suchascertain#non-deterministiccudnnfunctions).np.random.seed(cfg.RNG_SEED)#Executethetrainingruncheckpoints=detectron.utils.train.train_model()#Testthetrainedmodelifnotargs.skip_test:test_model(checkpoints[\\'final\\'],args.multi_gpu_testing,args.opts)deftest_model(model_file,multi_gpu_testing,opts=None):\"\"\"Testamodel.\"\"\"#Clearmemorybeforeinferenceworkspace.ResetWorkspace()#Runinferencerun_inference(model_file,multi_gpu_testing=multi_gpu_testing,check_expected_results=True,)if__name__==\\'__main__\\':main()#!/usr/bin/envpython3#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scripttoconvertthemodel(.yamland.pkl)trainedbytrain_nettoastandardCaffe2modelinpbformat(model.pbandmodel_init.pb).Theconvertedmodelisgoodforproductionusage,asitcouldrunindependentlyandefficientlyonCPU,GPUandmobilewithoutdependingonthedetectroncodebase.PleaseseeCaffe2tutorial(forloadingtheconvertedmodel,andrun_model_pb()forrunningthemodelforinference.\"\"\"from__future__importabsolute_import,division,print_function,unicode_literalsimportargparseimportcopyimportosimportpprintimportsysimportcaffe2.python.utilsasputilsimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importdetectron.core.test_engineastest_engineimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.model_convert_utilsasmutilsimportdetectron.utils.visasvis_utilsimportnumpyasnpfromcaffe2.caffe2.fb.predictorimportpredictor_exporter,predictor_py_utilsfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcore,workspacefromcaffe2.python.predictor_constantsimportpredictor_constantsfromdetectron.core.configimport(assert_and_infer_cfg,cfg,merge_cfg_from_file,merge_cfg_from_list,)fromdetectron.modelingimportgenerate_anchorsfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.model_convert_utilsimportconvert_op_in_proto,op_filterc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)logger=setup_logging(__name__)defparse_args():parser=argparse.ArgumentParser(description=\"Convertatrainednetworktopbformat\")parser.add_argument(\"--cfg\",dest=\"cfg_file\",help=\"optionalconfigfile\",default=None,type=str)parser.add_argument(\"--net_name\",dest=\"net_name\",help=\"optionalnameforthenet\",default=\"detectron\",type=str,)parser.add_argument(\"--out_dir\",dest=\"out_dir\",help=\"outputdir\",default=None,type=str)parser.add_argument(\"--test_img\",dest=\"test_img\",help=\"optionaltestimage,usedtoverifythemodelconversion\",default=None,type=str,)parser.add_argument(\"--fuse_af\",dest=\"fuse_af\",help=\"1tofuse_af\",default=1,type=int)parser.add_argument(\"--device\",dest=\"device\",help=\"Devicetorunthemodelon\",choices=[\"cpu\",\"gpu\"],default=\"cpu\",type=str,)parser.add_argument(\"--net_execution_type\",dest=\"net_execution_type\",help=\"caffe2netexecutiontype\",choices=[\"simple\",\"dag\"],default=\"simple\",type=str,)parser.add_argument(\"--use_nnpack\",dest=\"use_nnpack\",help=\"Usennpackforconv\",default=1,type=int,)parser.add_argument(\"--logdb\",dest=\"logdb\",help=\"outputtologfiledbinsteadofpbfiles\",default=0,type=int,)parser.add_argument(\"opts\",help=\"Seedetectron/core/config.pyforalloptions\",default=None,nargs=argparse.REMAINDER,)iflen(sys.argv)==1:parser.print_help()sys.exit(1)ret=parser.parse_args()ret.out_dir=os.path.abspath(ret.out_dir)ifret.device==\"gpu\"andret.use_nnpack:logger.warn(\"Shouldnotusemobileengineforgpumodel.\")ret.use_nnpack=0returnretdefunscope_name(name):returnc2_utils.UnscopeName(name)defreset_names(names):foriinrange(len(names)):names[i]=unscope_name(names[i])defconvert_collect_and_distribute(op,blobs,roi_canonical_scale,roi_canonical_level,roi_max_level,roi_min_level,rpn_max_level,rpn_min_level,rpn_post_nms_topN,):print(\"ConvertingCollectAndDistributeFpnRpnProposals\"\"Python->C++:\\\\n{}\".format(op))assertop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"),\"NotvalidCollectAndDistributeFpnRpnProposalsOp\"inputs=[xforxinop.input]ret=core.CreateOperator(\"CollectAndDistributeFpnRpnProposals\",inputs,list(op.output),roi_canonical_scale=roi_canonical_scale,roi_canonical_level=roi_canonical_level,roi_max_level=roi_max_level,roi_min_level=roi_min_level,rpn_max_level=rpn_max_level,rpn_min_level=rpn_min_level,rpn_post_nms_topN=rpn_post_nms_topN,)returnretdefconvert_gen_proposals(op,blobs,rpn_pre_nms_topN,rpn_post_nms_topN,rpn_nms_thresh,rpn_min_size):print(\"ConvertingGenerateProposalsPython->C++:\\\\n{}\".format(op))assertop.name.startswith(\"GenerateProposalsOp\"),\"NotvalidGenerateProposalsOp\"spatial_scale=mutils.get_op_arg_valf(op,\"spatial_scale\",None)assertspatial_scaleisnotNonelvl=int(op.input[0][-1])ifop.input[0][-1].isdigit()elseNoneinputs=[xforxinop.input]anchor_name=\"anchor{}\".format(lvl)iflvlelse\"anchor\"inputs.append(anchor_name)anchor_sizes=((cfg.FPN.RPN_ANCHOR_START_SIZE*2.0**(lvl-cfg.FPN.RPN_MIN_LEVEL),)iflvlelsecfg.RPN.SIZES)blobs[anchor_name]=get_anchors(spatial_scale,anchor_sizes)print(\"anchors{}\".format(blobs[anchor_name]))ret=core.CreateOperator(\"GenerateProposals\",inputs,list(op.output),spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,correct_transform_coords=True,)returnret,anchor_namedefget_anchors(spatial_scale,anchor_sizes):anchors=generate_anchors.generate_anchors(stride=1.0/spatial_scale,sizes=anchor_sizes,aspect_ratios=cfg.RPN.ASPECT_RATIOS,).astype(np.float32)returnanchorsdefreset_blob_names(blobs):ret={unscope_name(x):blobs[x]forxinblobs}blobs.clear()blobs.update(ret)defconvert_net(args,net,blobs):@op_filter()defconvert_op_name(op):ifargs.device!=\"gpu\":ifop.engine!=\"DEPTHWISE_3x3\":op.engine=\"\"op.device_option.CopyFrom(caffe2_pb2.DeviceOption())reset_names(op.input)reset_names(op.output)return[op]@op_filter(type=\"Python\")defconvert_python(op):ifop.name.startswith(\"GenerateProposalsOp\"):gen_proposals_op,ext_input=convert_gen_proposals(op,blobs,rpn_min_size=float(cfg.TEST.RPN_MIN_SIZE),rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,rpn_pre_nms_topN=cfg.TEST.RPN_PRE_NMS_TOP_N,rpn_nms_thresh=cfg.TEST.RPN_NMS_THRESH,)net.external_input.extend([ext_input])return[gen_proposals_op]elifop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"):collect_dist_op=convert_collect_and_distribute(op,blobs,roi_canonical_scale=cfg.FPN.ROI_CANONICAL_SCALE,roi_canonical_level=cfg.FPN.ROI_CANONICAL_LEVEL,roi_max_level=cfg.FPN.ROI_MAX_LEVEL,roi_min_level=cfg.FPN.ROI_MIN_LEVEL,rpn_max_level=cfg.FPN.RPN_MAX_LEVEL,rpn_min_level=cfg.FPN.RPN_MIN_LEVEL,rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,)return[collect_dist_op]else:raiseValueError(\"FailedtoconvertPythonop{}\".format(op.name))#OnlyconvertUpsampleNearesttoResizeNearestwhenconvertingtopbsothattheexistingmodelsisunchanged##issuecomment-410248561@op_filter(type=\"UpsampleNearest\")defconvert_upsample_nearest(op):forarginop.arg:ifarg.name==\"scale\":scale=arg.ibreakelse:raiseKeyError(\\'Noattribute\"scale\"inUpsampleNearestop\\')resize_nearest_op=core.CreateOperator(\"ResizeNearest\",list(op.input),list(op.output),name=op.name,width_scale=float(scale),height_scale=float(scale),)returnresize_nearest_op@op_filter()defconvert_rpn_rois(op):forjinrange(len(op.input)):ifop.input[j]==\"rois\":print(\"Convertingop{}inputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.input[j]=\"rpn_rois\"forjinrange(len(op.output)):ifop.output[j]==\"rois\":print(\"Convertingop{}outputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.output[j]=\"rpn_rois\"return[op]@op_filter(type_in=[\"StopGradient\",\"Alias\"])defconvert_remove_op(op):print(\"Removingop{}:\\\\n{}\".format(op.type,op))return[]#Wewanttoapplytoalloperators,includingconverted#sorunseparatelyconvert_op_in_proto(net,convert_remove_op)convert_op_in_proto(net,convert_upsample_nearest)convert_op_in_proto(net,convert_python)convert_op_in_proto(net,convert_op_name)convert_op_in_proto(net,convert_rpn_rois)reset_names(net.external_input)reset_names(net.external_output)reset_blob_names(blobs)defadd_bbox_ops(args,net,blobs):new_ops=[]new_external_outputs=[]#Operatorsforbboxesop_box=core.CreateOperator(\"BBoxTransform\",[\"rpn_rois\",\"bbox_pred\",\"im_info\"],[\"pred_bbox\"],weights=cfg.MODEL.BBOX_REG_WEIGHTS,apply_scale=False,correct_transform_coords=True,)new_ops.extend([op_box])blob_prob=\"cls_prob\"blob_box=\"pred_bbox\"op_nms=core.CreateOperator(\"BoxWithNMSLimit\",[blob_prob,blob_box],[\"score_nms\",\"bbox_nms\",\"class_nms\"],arg=[putils.MakeArgument(\"score_thresh\",cfg.TEST.SCORE_THRESH),putils.MakeArgument(\"nms\",cfg.TEST.NMS),putils.MakeArgument(\"detections_per_im\",cfg.TEST.DETECTIONS_PER_IM),putils.MakeArgument(\"soft_nms_enabled\",cfg.TEST.SOFT_NMS.ENABLED),putils.MakeArgument(\"soft_nms_method\",cfg.TEST.SOFT_NMS.METHOD),putils.MakeArgument(\"soft_nms_sigma\",cfg.TEST.SOFT_NMS.SIGMA),],)new_ops.extend([op_nms])new_external_outputs.extend([\"score_nms\",\"bbox_nms\",\"class_nms\"])net.Proto().op.extend(new_ops)net.Proto().external_output.extend(new_external_outputs)defconvert_model_gpu(args,net,init_net):assertargs.device==\"gpu\"ret_net=copy.deepcopy(net)ret_init_net=copy.deepcopy(init_net)cdo_cuda=mutils.get_device_option_cuda()cdo_cpu=mutils.get_device_option_cpu()CPU_OPS=[[\"CollectAndDistributeFpnRpnProposals\",None],[\"GenerateProposals\",None],[\"BBoxTransform\",None],[\"BoxWithNMSLimit\",None],]CPU_BLOBS=[\"im_info\",\"anchor\"]@op_filter()defconvert_op_gpu(op):forxinCPU_OPS:ifmutils.filter_op(op,type=x[0],inputs=x[1]):returnNoneop.device_option.CopyFrom(cdo_cuda)return[op]@op_filter()defconvert_init_op_gpu(op):ifop.output[0]inCPU_BLOBS:op.device_option.CopyFrom(cdo_cpu)else:op.device_option.CopyFrom(cdo_cuda)return[op]convert_op_in_proto(ret_init_net.Proto(),convert_init_op_gpu)convert_op_in_proto(ret_net.Proto(),convert_op_gpu)ret=core.InjectDeviceCopiesAmongNets([ret_init_net,ret_net])return[ret[0][1],ret[0][0]]defgen_init_net(net,blobs,empty_blobs):blobs=copy.deepcopy(blobs)forxinempty_blobs:blobs[x]=np.array([],dtype=np.float32)init_net=mutils.gen_init_net_from_blobs(blobs,net.external_inputs)init_net=core.Net(init_net)returninit_netdef_save_image_graphs(args,all_net,all_init_net):print(\"Savingmodelgraph...\")mutils.save_graph(all_net.Proto(),os.path.join(args.out_dir,\"model_def.png\"),op_only=False)print(\"Modeldefimagesavedto{}.\".format(args.out_dir))def_save_models(all_net,all_init_net,args):print(\"Writingconvertedmodelto{}...\".format(args.out_dir))fname=\"model\"ifnotos.path.exists(args.out_dir):os.makedirs(args.out_dir)withopen(os.path.join(args.out_dir,fname+\".pb\"),\"wb\")asf:f.write(all_net.Proto().SerializeToString())withopen(os.path.join(args.out_dir,fname+\".pbtxt\"),\"wb\")asf:f.write(str(all_net.Proto()))withopen(os.path.join(args.out_dir,fname+\"_init.pb\"),\"wb\")asf:f.write(all_init_net.Proto().SerializeToString())_save_image_graphs(args,all_net,all_init_net)defload_model(args):model=test_engine.initialize_model_from_cfg(cfg.TEST.WEIGHTS)blobs=mutils.get_ws_blobs()returnmodel,blobsdef_get_result_blobs(check_blobs):ret={}forxincheck_blobs:sn=core.ScopedName(x)ifworkspace.HasBlob(sn):ret[x]=workspace.FetchBlob(sn)else:ret[x]=Nonereturnretdef_sort_results(boxes,segms,keypoints,classes):indices=np.argsort(boxes[:,-1])[::-1]ifboxesisnotNone:boxes=boxes[indices,:]ifsegmsisnotNone:segms=[segms[x]forxinindices]ifkeypointsisnotNone:keypoints=[keypoints[x]forxinindices]ifclassesisnotNone:ifisinstance(classes,list):classes=[classes[x]forxinindices]else:classes=classes[indices]returnboxes,segms,keypoints,classesdefrun_model_cfg(args,im,check_blobs):workspace.ResetWorkspace()model,_=load_model(args)withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=test_engine.im_detect_all(model,im,None,None)boxes,segms,keypoints,classes=vis_utils.convert_from_cls_format(cls_boxes,cls_segms,cls_keyps)#sorttheresultsbasedonscoreforcomparisionboxes,segms,keypoints,classes=_sort_results(boxes,segms,keypoints,classes)#writefinalresultsbacktoworkspacedef_ornone(res):returnnp.array(res)ifresisnotNoneelsenp.array([],dtype=np.float32)withc2_utils.NamedCudaScope(0):workspace.FeedBlob(core.ScopedName(\"result_boxes\"),_ornone(boxes))workspace.FeedBlob(core.ScopedName(\"result_segms\"),_ornone(segms))workspace.FeedBlob(core.ScopedName(\"result_keypoints\"),_ornone(keypoints))workspace.FeedBlob(core.ScopedName(\"result_classids\"),_ornone(classes))#getresultblobswithc2_utils.NamedCudaScope(0):ret=_get_result_blobs(check_blobs)returnretdef_prepare_blobs(im,pixel_means,target_size,max_size):\"\"\"Reference:blob.prep_im_for_blob()\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)ifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)#Reusecodeinblob_utilsandfitFPNblob=blob_utils.im_list_to_blob([im])blobs={}blobs[\"data\"]=blobblobs[\"im_info\"]=np.array([[blob.shape[2],blob.shape[3],im_scale]],dtype=np.float32)returnblobsdefrun_model_pb(args,net,init_net,im,check_blobs):workspace.ResetWorkspace()workspace.RunNetOnce(init_net)mutils.create_input_blobs_for_net(net.Proto())workspace.CreateNet(net)#input_blobs,_=core_test._get_blobs(im,None)input_blobs=_prepare_blobs(im,cfg.PIXEL_MEANS,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)gpu_blobs=[]ifargs.device==\"gpu\":gpu_blobs=[\"data\"]fork,vininput_blobs.items():workspace.FeedBlob(core.ScopedName(k),v,mutils.get_device_option_cuda()ifkingpu_blobselsemutils.get_device_option_cpu(),)try:workspace.RunNet(net)scores=workspace.FetchBlob(\"score_nms\")classids=workspace.FetchBlob(\"class_nms\")boxes=workspace.FetchBlob(\"bbox_nms\")exceptExceptionase:print(\"Runningpbmodelfailed.\\\\n{}\".format(e))#maynotdetectanythingatallR=0scores=np.zeros((R,),dtype=np.float32)boxes=np.zeros((R,4),dtype=np.float32)classids=np.zeros((R,),dtype=np.float32)boxes=np.column_stack((boxes,scores))#sorttheresultsbasedonscoreforcomparisionboxes,_,_,classids=_sort_results(boxes,None,None,classids)#writefinalresultbacktoworkspaceworkspace.FeedBlob(\"result_boxes\",boxes)workspace.FeedBlob(\"result_classids\",classids)ret=_get_result_blobs(check_blobs)returnretdefverify_model(args,model_pb,test_img_file):check_blobs=[\"result_boxes\",\"result_classids\"]#resultprint(\"Loadingtestfile{}...\".format(test_img_file))test_img=cv2.imread(test_img_file)asserttest_imgisnotNonedef_run_cfg_func(im,blobs):returnrun_model_cfg(args,im,check_blobs)def_run_pb_func(im,blobs):returnrun_model_pb(args,model_pb[0],model_pb[1],im,check_blobs)print(\"Checkingmodels...\")assertmutils.compare_model(_run_cfg_func,_run_pb_func,test_img,check_blobs)def_export_to_logfiledb(args,net,init_net,inputs,out_file,extra_out_tensors=None):out_tensors=list(net.Proto().external_output)ifextra_out_tensorsisnotNone:out_tensors+=extra_out_tensorsparams=list(set(net.Proto().external_input)-set(inputs))net_type=Nonepredictor_export_meta=predictor_exporter.PredictorExportMeta(predict_net=net,parameters=params,inputs=inputs,outputs=out_tensors,net_type=net_type,)logger.info(\"ExportingCaffe2modelto{}\".format(out_file))predictor_exporter.save_to_db(db_type=\"log_file_db\",db_destination=out_file,predictor_export_meta=predictor_export_meta,)defmain():workspace.GlobalInit([\"caffe2\",\"--caffe2_log_level=0\"])args=parse_args()logger.info(\"Calledwithargs:\")logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)cfg.NUM_GPUS=1assert_and_infer_cfg()logger.info(\"Convertingmodelwithconfig:\")logger.info(pprint.pformat(cfg))#scriptwillstopwhenitcan\\'tfindanoperatorrather#thanstoppingbasedontheseflags##assertnotcfg.MODEL.KEYPOINTS_ON,\"Keypointmodelnotsupported.\"#assertnotcfg.MODEL.MASK_ON,\"Maskmodelnotsupported.\"#assertnotcfg.FPN.FPN_ON,\"FPNnotsupported.\"#assertnotcfg.RETINANET.RETINANET_ON,\"RetinaNetmodelnotsupported.\"#loadmodelfromcfgmodel,blobs=load_model(args)net=core.Net(\"\")net.Proto().op.extend(copy.deepcopy(model.net.Proto().op))net.Proto().external_input.extend(copy.deepcopy(model.net.Proto().external_input))net.Proto().external_output.extend(copy.deepcopy(model.net.Proto().external_output))net.Proto().type=args.net_execution_typenet.Proto().num_workers=1ifargs.net_execution_type==\"simple\"else4#Resetthedevice_option,changetounscopenameandreplacepythonoperatorsconvert_net(args,net.Proto(),blobs)#addoperatorsforbboxadd_bbox_ops(args,net,blobs)ifargs.fuse_af:print(\"Fusingaffinechannel...\")net,blobs=mutils.fuse_net_affine(net,blobs)ifargs.use_nnpack:mutils.update_mobile_engines(net.Proto())#generateinitnetempty_blobs=[\"data\",\"im_info\"]init_net=gen_init_net(net,blobs,empty_blobs)ifargs.device==\"gpu\":[net,init_net]=convert_model_gpu(args,net,init_net)net.Proto().name=args.net_nameinit_net.Proto().name=args.net_name+\"_init\"ifargs.test_imgisnotNone:verify_model(args,[net,init_net],args.test_img)ifargs.logdb==1:output_file=os.path.join(args.out_dir,\"model.logfiledb\")_export_to_logfiledb(args,net,init_net,empty_blobs,output_file)else:_save_models(net,init_net,args)if__name__==\"__main__\":main()#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScriptforconvertingCaffe(<=1.0)modelsintothethesimplestatedictformatusedbyDetectron.Forexample,thisscriptcanconverttheorignalResNetmodelsreleasedbyMSRA.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysfromcaffe.protoimportcaffe_pb2fromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcaffe_translatorfromcaffe2.pythonimportutilsfromgoogle.protobufimporttext_formatfromdetectron.utils.ioimportsave_objectdefparse_args():parser=argparse.ArgumentParser(description=\\'DumpweightsfromaCaffemodel\\')parser.add_argument(\\'--prototxt\\',dest=\\'prototxt_file_name\\',help=\\'Networkdefinitionprototxtfilepath\\',default=None,type=str)parser.add_argument(\\'--caffemodel\\',dest=\\'caffemodel_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefnormalize_resnet_name(name):ifname.find(\\'res\\')==0andname.find(\\'res_\\')==-1:#E.g.,#res4b11_branch2c->res4_11_branch2c#res2a_branch1->res2_0_branch1chunk=name[len(\\'res\\'):name.find(\\'_\\')]name=(\\'res\\'+chunk[0]+\\'_\\'+str(int(chunk[2:])iflen(chunk)>2#e.g.,\"b1\"->1elseord(chunk[1])-ord(\\'a\\'))+#e.g.,\"a\"->0name[name.find(\\'_\\'):])returnnamedefpickle_weights(out_file_name,weights):blobs={normalize_resnet_name(blob.name):utils.Caffe2TensorToNumpyArray(blob)forblobinweights.protos}save_object(blobs,out_file_name)print(\\'Wroteblobs:\\')print(sorted(blobs.keys()))defadd_missing_biases(caffenet_weights):forlayerincaffenet_weights.layer:iflayer.type==\\'Convolution\\'andlen(layer.blobs)==1:num_filters=layer.blobs[0].shape.dim[0]bias_blob=caffe_pb2.BlobProto()bias_blob.data.extend(np.zeros(num_filters))bias_blob.num,bias_blob.channels,bias_blob.height=1,1,1bias_blob.width=num_filterslayer.blobs.extend([bias_blob])defremove_spatial_bn_layers(caffenet,caffenet_weights):#Layertypesassociatedwithspatialbatchnormremove_types=[\\'BatchNorm\\',\\'Scale\\']def_remove_layers(net):foriinreversed(range(len(net.layer))):ifnet.layer[i].typeinremove_types:net.layer.pop(i)#Firstremovelayersfromcaffenetproto_remove_layers(caffenet)#We\\'llreturnthesesowecansavethebatchnormparametersbn_layers=[layerforlayerincaffenet_weights.layeriflayer.typeinremove_types]_remove_layers(caffenet_weights)def_create_tensor(arr,shape,name):t=caffe2_pb2.TensorProto()t.name=namet.data_type=caffe2_pb2.TensorProto.FLOATt.dims.extend(shape.dim)t.float_data.extend(arr)assertlen(t.float_data)==np.prod(t.dims),\\'Datasize,shapemismatch\\'returntbn_tensors=[]for(bn,scl)inzip(bn_layers[0::2],bn_layers[1::2]):assertbn.name[len(\\'bn\\'):]==scl.name[len(\\'scale\\'):],\\'Pairmismatch\\'blob_out=\\'res\\'+bn.name[len(\\'bn\\'):]+\\'_bn\\'bn_mean=np.asarray(bn.blobs[0].data)bn_var=np.asarray(bn.blobs[1].data)scale=np.asarray(scl.blobs[0].data)bias=np.asarray(scl.blobs[1].data)std=np.sqrt(bn_var+1e-5)new_scale=scale/stdnew_bias=bias-bn_mean*scale/stdnew_scale_tensor=_create_tensor(new_scale,bn.blobs[0].shape,blob_out+\\'_s\\')new_bias_tensor=_create_tensor(new_bias,bn.blobs[0].shape,blob_out+\\'_b\\')bn_tensors.extend([new_scale_tensor,new_bias_tensor])returnbn_tensorsdefremove_layers_without_parameters(caffenet,caffenet_weights):foriinreversed(range(len(caffenet_weights.layer))):iflen(caffenet_weights.layer[i].blobs)==0:#Searchforthecorrespondinglayerincaffenetandremoveitname=caffenet_weights.layer[i].namefound=Falseforjinrange(len(caffenet.layer)):ifcaffenet.layer[j].name==name:caffenet.layer.pop(j)found=Truebreakifnotfoundandname[-len(\\'_split\\'):]!=\\'_split\\':print(\\'Warning:layer{}notfoundincaffenet\\'.format(name))caffenet_weights.layer.pop(i)defnormalize_shape(caffenet_weights):forlayerincaffenet_weights.layer:forblobinlayer.blobs:shape=(blob.num,blob.channels,blob.height,blob.width)iflen(blob.data)!=np.prod(shape):shape=tuple(blob.shape.dim)iflen(shape)==1:#Handlebiasesshape=(1,1,1,shape[0])iflen(shape)==2:#HandleInnerProductlayersshape=(1,1,shape[0],shape[1])assertlen(shape)==4blob.num,blob.channels,blob.height,blob.width=shapedefload_and_convert_caffe_model(prototxt_file_name,caffemodel_file_name):caffenet=caffe_pb2.NetParameter()caffenet_weights=caffe_pb2.NetParameter()text_format.Merge(open(prototxt_file_name).read(),caffenet)caffenet_weights.ParseFromString(open(caffemodel_file_name).read())#C2convlayerscurrentrequirebiases,buttheyareoptionalinC1#Addzerosasbiasesistheyaremissingadd_missing_biases(caffenet_weights)#Weonlycareaboutgettingparameters,soremovelayersw/oparametersremove_layers_without_parameters(caffenet,caffenet_weights)#BatchNormisnotimplementedinthetranslator*and*weneedtofoldScale#layersintothenewC2SpatialBNop,henceweremovethebatchnormlayers#andapplycustomtranslationscodebn_weights=remove_spatial_bn_layers(caffenet,caffenet_weights)#Setnum,channel,heightandwidthforblobsthatuseshape.diminsteadnormalize_shape(caffenet_weights)#Translatetherestofthemodelnet,pretrained_weights=caffe_translator.TranslateModel(caffenet,caffenet_weights)pretrained_weights.protos.extend(bn_weights)returnnet,pretrained_weightsif__name__==\\'__main__\\':args=parse_args()assertos.path.exists(args.prototxt_file_name),\\\\\\'Prototxtfiledoesnotexist\\'assertos.path.exists(args.caffemodel_file_name),\\\\\\'Weightsfiledoesnotexist\\'net,weights=load_and_convert_caffe_model(args.prototxt_file_name,args.caffemodel_file_name)pickle_weights(args.out_file_name,weights)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################ConvertadetectionmodeltrainedforCOCOintoamodelthatcanbefine-tuned#oncityscapes##cityscapes_to_cocofrom__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysimportdetectron.datasets.coco_to_cityscapes_idascsfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectNUM_CS_CLS=9NUM_COCO_CLS=81defparse_args():parser=argparse.ArgumentParser(description=\\'ConvertaCOCOpre-trainedmodelforusewithCityscapes\\')parser.add_argument(\\'--coco_model\\',dest=\\'coco_model_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--convert_func\\',dest=\\'convert_func\\',help=\\'Blobconversionfunction\\',default=\\'cityscapes_to_coco\\',type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert_coco_blobs_to_cityscape_blobs(model_dict):fork,vinmodel_dict[\\'blobs\\'].items():ifv.shape[0]==NUM_COCO_CLSorv.shape[0]==4*NUM_COCO_CLS:coco_blob=model_dict[\\'blobs\\'][k]print(\\'ConvertingCOCOblob{}withshape{}\\'.format(k,coco_blob.shape))cs_blob=convert_coco_blob_to_cityscapes_blob(coco_blob,args.convert_func)print(\\'->convertedshape{}\\'.format(cs_blob.shape))model_dict[\\'blobs\\'][k]=cs_blobdefconvert_coco_blob_to_cityscapes_blob(coco_blob,convert_func):#cocoblob(81,...)or(81*4,...)coco_shape=coco_blob.shapeleading_factor=int(coco_shape[0]/NUM_COCO_CLS)tail_shape=list(coco_shape[1:])assertleading_factor==1orleading_factor==4#Reshapein[num_classes,...]formforeasiermanipulationscoco_blob=coco_blob.reshape([NUM_COCO_CLS,-1]+tail_shape)#DefaultinitializationusesGaussianwithmeanandstdtomatchthe#existingparametersstd=coco_blob.std()mean=coco_blob.mean()cs_shape=[NUM_CS_CLS]+list(coco_blob.shape[1:])cs_blob=(np.random.randn(*cs_shape)*std+mean).astype(np.float32)#ReplacerandomparameterswithCOCOparametersifclassmappingexistsforiinrange(NUM_CS_CLS):coco_cls_id=getattr(cs,convert_func)(i)ifcoco_cls_id>=0:#otherwiseignore(randinit)cs_blob[i]=coco_blob[coco_cls_id]cs_shape=[NUM_CS_CLS*leading_factor]+tail_shapereturncs_blob.reshape(cs_shape)defremove_momentum(model_dict):forkinmodel_dict[\\'blobs\\'].keys():ifk.endswith(\\'_momentum\\'):delmodel_dict[\\'blobs\\'][k]defload_and_convert_coco_model(args):model_dict=load_object(args.coco_model_file_name)remove_momentum(model_dict)convert_coco_blobs_to_cityscape_blobs(model_dict)returnmodel_dictif__name__==\\'__main__\\':args=parse_args()print(args)assertos.path.exists(args.coco_model_file_name),\\\\\\'Weightsfiledoesnotexist\\'weights=load_and_convert_coco_model(args)save_object(weights,args.out_file_name)print(\\'Wroteblobsto{}:\\'.format(args.out_file_name))print(sorted(weights[\\'blobs\\'].keys()))#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimporth5pyimportjsonimportosimportimageioimportsysimportcityscapesscripts.evaluation.instances2dict_with_polygonsascsimportdetectron.utils.segmsassegms_utilimportdetectron.utils.boxesasbboxs_utildefparse_args():parser=argparse.ArgumentParser(description=\\'Convertdataset\\')parser.add_argument(\\'--dataset\\',help=\"cocostuff,cityscapes\",default=None,type=str)parser.add_argument(\\'--outdir\\',help=\"outputdirforjsonfiles\",default=None,type=str)parser.add_argument(\\'--datadir\\',help=\"datadirforannotationstobeconverted\",default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defconvert_coco_stuff_mat(data_dir,out_dir):\"\"\"Converttopngandsavejsonwithpath.Thiscurrentlyonlycontainsthesegmentationlabelsforobjects+stuffincocostuff-ifweneedtocombinewithotherlabelsfromoriginalCOCOthatwillbeaTODO.\"\"\"sets=[\\'train\\',\\'val\\']categories=[]json_name=\\'coco_stuff_%s.json\\'ann_dict={}fordata_setinsets:file_list=os.path.join(data_dir,\\'%s.txt\\')images=[]withopen(file_list%data_set)asf:forimg_id,img_nameinenumerate(f):img_name=img_name.replace(\\'coco\\',\\'COCO\\').strip(\\'\\\\n\\')image={}mat_file=os.path.join(data_dir,\\'annotations/%s.mat\\'%img_name)data=h5py.File(mat_file,\\'r\\')labelMap=data.get(\\'S\\')iflen(categories)==0:labelNames=data.get(\\'names\\')foridx,ninenumerate(labelNames):categories.append({\"id\":idx,\"name\":\\'\\'.join(chr(i)foriindata[n[0]])})ann_dict[\\'categories\\']=categoriesimageio.imsave(os.path.join(data_dir,img_name+\\'.png\\'),labelMap)image[\\'width\\']=labelMap.shape[0]image[\\'height\\']=labelMap.shape[1]image[\\'file_name\\']=img_nameimage[\\'seg_file_name\\']=img_nameimage[\\'id\\']=img_idimages.append(image)ann_dict[\\'images\\']=imagesprint(\"Numimages:%s\"%len(images))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))#forCityscapesdefgetLabelID(self,instID):if(instID<1000):returninstIDelse:returnint(instID/1000)defconvert_cityscapes_instance_only(data_dir,out_dir):\"\"\"ConvertfromcityscapesformattoCOCOinstancesegformat-polygons\"\"\"sets=[\\'gtFine_val\\',#\\'gtFine_train\\',#\\'gtFine_test\\',#\\'gtCoarse_train\\',#\\'gtCoarse_val\\',#\\'gtCoarse_train_extra\\']ann_dirs=[\\'gtFine_trainvaltest/gtFine/val\\',#\\'gtFine_trainvaltest/gtFine/train\\',#\\'gtFine_trainvaltest/gtFine/test\\',#\\'gtCoarse/train\\',#\\'gtCoarse/train_extra\\',#\\'gtCoarse/val\\']json_name=\\'instancesonly_filtered_%s.json\\'ends_in=\\'%s_polygons.json\\'img_id=0ann_id=0cat_id=1category_dict={}category_instancesonly=[\\'person\\',\\'rider\\',\\'car\\',\\'truck\\',\\'bus\\',\\'train\\',\\'motorcycle\\',\\'bicycle\\',]fordata_set,ann_dirinzip(sets,ann_dirs):print(\\'Starting%s\\'%data_set)ann_dict={}images=[]annotations=[]ann_dir=os.path.join(data_dir,ann_dir)forroot,_,filesinos.walk(ann_dir):forfilenameinfiles:iffilename.endswith(ends_in%data_set.split(\\'_\\')[0]):iflen(images)%50==0:print(\"Processed%simages,%sannotations\"%(len(images),len(annotations)))json_ann=json.load(open(os.path.join(root,filename)))image={}image[\\'id\\']=img_idimg_id+=1image[\\'width\\']=json_ann[\\'imgWidth\\']image[\\'height\\']=json_ann[\\'imgHeight\\']image[\\'file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\'leftImg8bit.png\\'image[\\'seg_file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\\\\\'%s_instanceIds.png\\'%data_set.split(\\'_\\')[0]images.append(image)fullname=os.path.join(root,image[\\'seg_file_name\\'])objects=cs.instances2dict_with_polygons([fullname],verbose=False)[fullname]forobject_clsinobjects:ifobject_clsnotincategory_instancesonly:continue#skipnon-instancecategoriesforobjinobjects[object_cls]:ifobj[\\'contours\\']==[]:print(\\'Warning:emptycontours.\\')continue#skipnon-instancecategorieslen_p=[len(p)forpinobj[\\'contours\\']]ifmin(len_p)<=4:print(\\'Warning:invalidcontours.\\')continue#skipnon-instancecategoriesann={}ann[\\'id\\']=ann_idann_id+=1ann[\\'image_id\\']=image[\\'id\\']ann[\\'segmentation\\']=obj[\\'contours\\']ifobject_clsnotincategory_dict:category_dict[object_cls]=cat_idcat_id+=1ann[\\'category_id\\']=category_dict[object_cls]ann[\\'iscrowd\\']=0ann[\\'area\\']=obj[\\'pixelCount\\']ann[\\'bbox\\']=bboxs_util.xyxy_to_xywh(segms_util.polys_to_boxes([ann[\\'segmentation\\']])).tolist()[0]annotations.append(ann)ann_dict[\\'images\\']=imagescategories=[{\"id\":category_dict[name],\"name\":name}fornameincategory_dict]ann_dict[\\'categories\\']=categoriesann_dict[\\'annotations\\']=annotationsprint(\"Numcategories:%s\"%len(categories))print(\"Numimages:%s\"%len(images))print(\"Numannotations:%s\"%len(annotations))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))if__name__==\\'__main__\\':args=parse_args()ifargs.dataset==\"cityscapes_instance_only\":convert_cityscapes_instance_only(args.datadir,args.outdir)elifargs.dataset==\"cocostuff\":convert_coco_stuff_mat(args.datadir,args.outdir)else:print(\"Datasetnotsupported:%s\"%args.dataset)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Givenafullsetofresults(boxes,masks,orkeypoints)onthe2017COCOtestset,thisscriptextractstheresultssubsetthatcorrespondsto2017test-dev.Thetest-devsubsetcanthenbesubmittedtotheCOCOevaluationserver.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportjsonimportosimportsysfromdetectron.datasets.dataset_catalogimportget_ann_fnfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--json\\',dest=\\'json_file\\',help=\\'detectionsjsonfile\\',default=\\'\\',type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'/tmp\\',type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert(json_file,output_dir):print(\\'Reading:{}\\'.format(json_file))withopen(json_file,\\'r\\')asfid:dt=json.load(fid)print(\\'done!\\')test_image_info=get_ann_fn(\\'coco_2017_test\\')withopen(test_image_info,\\'r\\')asfid:info_test=json.load(fid)image_test=info_test[\\'images\\']image_test_id=[i[\\'id\\']foriinimage_test]print(\\'{}has{}images\\'.format(test_image_info,len(image_test_id)))test_dev_image_info=get_ann_fn(\\'coco_2017_test-dev\\')withopen(test_dev_image_info,\\'r\\')asfid:info_testdev=json.load(fid)image_testdev=info_testdev[\\'images\\']image_testdev_id=[i[\\'id\\']foriinimage_testdev]print(\\'{}has{}images\\'.format(test_dev_image_info,len(image_testdev_id)))dt_testdev=[]print(\\'Filteringtest-devfromtest...\\')t=Timer()t.tic()foriinrange(len(dt)):ifi%1000==0:print(\\'{}/{}\\'.format(i,len(dt)))ifdt[i][\\'image_id\\']inimage_testdev_id:dt_testdev.append(dt[i])print(\\'Donefiltering({:2}s)!\\'.format(t.toc()))filename,file_extension=os.path.splitext(os.path.basename(json_file))filename=filename+\\'_test-dev\\'filename=os.path.join(output_dir,filename+file_extension)withopen(filename,\\'w\\')asfid:info_test=json.dump(dt_testdev,fid)print(\\'Donewriting:{}!\\'.format(filename))if__name__==\\'__main__\\':opts=parse_args()convert(opts.json_file,opts.output_dir)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Reval=re-eval.Re-evaluatesaveddetections.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportosimportsysfromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.configascore_configdefparse_args():parser=argparse.ArgumentParser(description=\\'Re-evaluateresults\\')parser.add_argument(\\'output_dir\\',nargs=1,help=\\'resultsdirectory\\',type=str)parser.add_argument(\\'--dataset\\',dest=\\'dataset_name\\',help=\\'datasettore-evaluate\\',default=\\'voc_2007_test\\',type=str)parser.add_argument(\\'--matlab\\',dest=\\'matlab_eval\\',help=\\'usematlabforevaluation\\',action=\\'store_true\\')parser.add_argument(\\'--comp\\',dest=\\'comp_mode\\',help=\\'competitionmode\\',action=\\'store_true\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefdo_reval(dataset_name,output_dir,args):dataset=JsonDataset(dataset_name)dets=load_object(os.path.join(output_dir,\\'detections.pkl\\'))#Overrideconfigwiththeonesavedinthedetectionsfileifargs.cfg_fileisnotNone:core_config.merge_cfg_from_cfg(core_config.load_cfg(dets[\\'cfg\\']))else:core_config._merge_a_into_b(core_config.load_cfg(dets[\\'cfg\\']),cfg)results=task_evaluation.evaluate_all(dataset,dets[\\'all_boxes\\'],dets[\\'all_segms\\'],dets[\\'all_keyps\\'],output_dir,use_matlab=args.matlab_eval)task_evaluation.log_copy_paste_friendly_results(results)if__name__==\\'__main__\\':setup_logging(__name__)args=parse_args()ifargs.comp_mode:cfg.TEST.COMPETITION_MODE=Trueoutput_dir=os.path.abspath(args.output_dir[0])do_reval(args.dataset_name,output_dir,args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScripttoconvertSelectiveSearchproposalboxesintotheDetectronproposalfileformat.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportscipy.ioassioimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportsave_objectif__name__==\\'__main__\\':dataset_name=sys.argv[1]file_in=sys.argv[2]file_out=sys.argv[3]ds=JsonDataset(dataset_name)roidb=ds.get_roidb()raw_data=sio.loadmat(file_in)[\\'boxes\\'].ravel()assertraw_data.shape[0]==len(roidb)boxes=[]scores=[]ids=[]foriinrange(raw_data.shape[0]):ifi%1000==0:print(\\'{}/{}\\'.format(i+1,len(roidb)))#selectivesearchboxesare1-indexedand(y1,x1,y2,x2)i_boxes=raw_data[i][:,(1,0,3,2)]-1boxes.append(i_boxes.astype(np.float32))scores.append(np.zeros((i_boxes.shape[0]),dtype=np.float32))ids.append(roidb[i][\\'id\\'])save_object(dict(boxes=boxes,scores=scores,indexes=ids),file_out)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importglobimportloggingimportosimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerimportdetectron.core.test_engineasinfer_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'End-to-endinference\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg\\',help=\\'cfgmodelfile(/path/to/model_config.yaml)\\',default=None,type=str)parser.add_argument(\\'--wts\\',dest=\\'weights\\',help=\\'weightsmodelfile(/path/to/model_weights.pkl)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer_simple)\\',default=\\'/tmp/infer_simple\\',type=str)parser.add_argument(\\'--image-ext\\',dest=\\'image_ext\\',help=\\'imagefilenameextension(default:jpg)\\',default=\\'jpg\\',type=str)parser.add_argument(\\'--always-out\\',dest=\\'out_when_no_box\\',help=\\'outputimageevenwhennoobjectisfound\\',action=\\'store_true\\')parser.add_argument(\\'--output-ext\\',dest=\\'output_ext\\',help=\\'outputimagefileformat(default:pdf)\\',default=\\'pdf\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'Thresholdforvisualizingdetections\\',default=0.7,type=float)parser.add_argument(\\'--kp-thresh\\',dest=\\'kp_thresh\\',help=\\'Thresholdforvisualizingkeypoints\\',default=2.0,type=float)parser.add_argument(\\'im_or_folder\\',help=\\'imageorfolderofimages\\',default=None)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain(args):logger=logging.getLogger(__name__)merge_cfg_from_file(args.cfg)cfg.NUM_GPUS=1args.weights=cache_url(args.weights,cfg.DOWNLOAD_CACHE)assert_and_infer_cfg(cache_urls=False)assertnotcfg.MODEL.RPN_ONLY,\\\\\\'RPNmodelsarenotsupported\\'assertnotcfg.TEST.PRECOMPUTED_PROPOSALS,\\\\\\'Modelsthatrequireprecomputedproposalsarenotsupported\\'model=infer_engine.initialize_model_from_cfg(args.weights)dummy_coco_dataset=dummy_datasets.get_coco_dataset()ifos.path.isdir(args.im_or_folder):im_list=glob.iglob(args.im_or_folder+\\'/*.\\'+args.image_ext)else:im_list=[args.im_or_folder]fori,im_nameinenumerate(im_list):out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(im_name)+\\'.\\'+args.output_ext))logger.info(\\'Processing{}->{}\\'.format(im_name,out_name))im=cv2.imread(im_name)timers=defaultdict(Timer)t=time.time()withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=infer_engine.im_detect_all(model,im,None,timers=timers)logger.info(\\'Inferencetime:{:.3f}s\\'.format(time.time()-t))fork,vintimers.items():logger.info(\\'|{}:{:.3f}s\\'.format(k,v.average_time))ifi==0:logger.info(\\'\\\\Note:inferenceonthefirstimagewillbeslowerthanthe\\'\\'rest(cachesandauto-tuningneedtowarmup)\\')vis_utils.vis_one_image(im[:,:,::-1],#BGR->RGBforvisualizationim_name,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=args.thresh,kp_thresh=args.kp_thresh,ext=args.output_ext,out_when_no_box=args.out_when_no_box)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()main(args)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539ee758",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list = []\n",
    "\n",
    "for sequence in input:\n",
    "    sequence_chunks = create_chunks(sequence)\n",
    "    chunk_list.append(sequence_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14ae3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list_cleaned = [''.join(i).replace('<|begin_of_text|>', '') for i in chunk_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09d6522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfromCython.BuildimportcythonizefromsetuptoolsimportExtensionfromsetuptoolsimportsetupimportnumpyasnp_NP_INCLUDE_DIRS=np.get_include()#Extensionmodulesext_modules=[Extension(name=\\'detectron.utils.cython_bbox\\',sources=[\\'detectron/utils/cython_bbox.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS]),Extension(name=\\'detectron.utils.cython_nms\\',sources=[\\'detectron/utils/cython_nms.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS])]setup(name=\\'Detectron\\',packages=[\\'detectron\\'],ext_modules=cythonize(ext_modules))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ComputeminibatchblobsfortrainingaRetinaNetnetwork.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportdetectron.utils.boxesasbox_utilsimportdetectron.roi_data.data_utilsasdata_utilsfromdetectron.core.configimportcfglogger=logging.getLogger(__name__)defget_retinanet_blob_names(is_training=True):\"\"\"Returnsblobnamesintheorderinwhichtheyarereadbythedataloader.N=numberofimagesperminibatchA=numberofanchors=num_scales*num_aspect_ratios(forexample9usedinRetinaNetpaper)H,W=spatialdimensions(differentforeachFPNlevel)M=Outofalltheanchorsgenerated,dependingonthepositive/negativeIoUoverlapthresholds,wewillhaveMpositiveanchors.Thesearetheanchorsthatboundingboxbranchwillregresson.retnet_cls_labels->labelsfortheclsbranchforeachFPNlevelShape:NxAxHxWretnet_roi_bbox_targets->targetsforthebboxregressionbranchShape:Mx4retnet_roi_fg_bbox_locs->forthebboxregression,sinceweareonlyinterestedinregressingonfgbboxeswhichareMinnumberandtheoutputpredictionofthenetworkisofshapeNx(A*4)xHxW(incaseofnonclass-specificbbox),sowestorethelocationsofpositivefgboxesinthisblobretnet_roi_fg_bbox_locsofshapeMx4whereeachrowlookslike:[img_id,anchor_id,x_loc,y_loc]\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']assertcfg.FPN.FPN_ON,\"RetinaNetusesFPNfordensedetection\"#SameformatasRPNblobs,butoneperFPNlevelifis_training:blob_names+=[\\'retnet_fg_num\\',\\'retnet_bg_num\\']forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):suffix=\\'fpn{}\\'.format(lvl)blob_names+=[\\'retnet_cls_labels_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,]returnblob_namesdefadd_retinanet_blobs(blobs,im_scales,roidb,image_width,image_height):\"\"\"AddRetinaNetblobs.\"\"\"#RetinaNetisappliedtomanyfeaturelevels,asintheFPNpaperk_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEnum_aspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)aspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALE#getanchorsfromalllevelsforallscales/aspectratiosfoas=[]forlvlinrange(k_min,k_max+1):stride=2.**lvlforoctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foridxinrange(num_aspect_ratios):anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect_ratios[idx],)foa=data_utils.get_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave,idx)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])blobs[\\'retnet_fg_num\\'],blobs[\\'retnet_bg_num\\']=0.0,0.0forim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]assertlen(gt_inds)>0,\\\\\\'Emptygroundtruthemptyforimageisnotallowed.Pleasecheck.\\'gt_rois=entry[\\'boxes\\'][gt_inds,:]*scalegt_classes=entry[\\'gt_classes\\'][gt_inds]im_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)retinanet_blobs,fg_num,bg_num=_get_retinanet_blobs(foas,all_anchors,gt_rois,gt_classes,image_width,image_height)fori,foainenumerate(foas):fork,vinretinanet_blobs[i].items():#thewayitstacksis:#[[anchorsforimage1]+[anchorsforimages2]]level=int(np.log2(foa.stride))key=\\'{}_fpn{}\\'.format(k,level)ifk==\\'retnet_roi_fg_bbox_locs\\':v[:,0]=im_i#loc_stride:80*4ifcls_specificelse4loc_stride=4#4coordinatecorrespondingtobboxpredictionifcfg.RETINANET.CLASS_SPECIFIC_BBOX:loc_stride*=(cfg.MODEL.NUM_CLASSES-1)anchor_ind=foa.octave*num_aspect_ratios+foa.aspect#v[:,1]istheclasslabel[range0-80]ifwedo#class-specficbboxotherwiseitis0.Incaseofclass#specific,basedonthelabel,thelocationofcurrent#anchorisclass_label*4andthenwetakeintoaccount#theanchor_indiftheanchorsv[:,1]*=4v[:,1]+=loc_stride*anchor_indblobs[key].append(v)blobs[\\'retnet_fg_num\\']+=fg_numblobs[\\'retnet_bg_num\\']+=bg_numblobs[\\'retnet_fg_num\\']=blobs[\\'retnet_fg_num\\'].astype(np.float32)blobs[\\'retnet_bg_num\\']=blobs[\\'retnet_bg_num\\'].astype(np.float32)N=len(roidb)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:#computenumberofanchorsA=int(len(v)/N)#fortheclsbranchlabels[perfpnlevel],#wehaveblobs[\\'retnet_cls_labels_fpn{}\\']asalistuntilthisstep#andlengthofthislistisNxAwhere#N=num_images,A=num_anchorsforexample,N=2,A=9#Eachelementofthelisthastheshape1x1xHxWwhereH,Ware#spatialdimensionofcurretfpnlvl.Leta{i}denotetheelement#correspondingtoanchori[9anchorstotal]inthelist.#Theelementsinthelistareinorder[[a0,...,a9],[a0,...,a9]]#howeverthenetworkwillmakepredictionslike2x(9*80)xHxW#sowefirstconcatenatetheelementsofeachimagetoanumpyarray#andthenconcatenatethetwoimagestogetthe2x9xHxWifk.find(\\'retnet_cls_labels\\')>=0:tmp=[]#concatanchorswithinanimageforiinrange(0,len(v),A):tmp.append(np.concatenate(v[i:i+A],axis=1))#concatimagesblobs[k]=np.concatenate(tmp,axis=0)else:#forthebboxbranchelements[perFPNlevel],#wehavethetargetsandthefgboxeslocations#intheshape:Mx4whereMisthenumberoffglocationsina#givenimageatthecurrentFPNlevel.Forthegivenlevel,#thebboxpredictionswillbe.Theelementsinthelistarein#order[[a0,...,a9],[a0,...,a9]]#ConcatenatethemtoformMx4blobs[k]=np.concatenate(v,axis=0)returnTruedef_get_retinanet_blobs(foas,all_anchors,gt_boxes,gt_classes,im_width,im_height):total_anchors=all_anchors.shape[0]logger.debug(\\'Gettingmadblobs:im_height{}im_width:{}\\'.format(im_height,im_width))inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.float32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)gt_inds=anchor_to_gt_argmax[anchors_with_max_overlap]labels[anchors_with_max_overlap]=gt_classes[gt_inds]#Fglabel:abovethresholdIOUinds=anchor_to_gt_max>=cfg.RETINANET.POSITIVE_OVERLAPgt_inds=anchor_to_gt_argmax[inds]labels[inds]=gt_classes[gt_inds]fg_inds=np.where(labels>=1)[0]bg_inds=np.where(anchor_to_gt_max<cfg.RETINANET.NEGATIVE_OVERLAP)[0]labels[bg_inds]=0num_fg,num_bg=len(fg_inds),len(bg_inds)bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeend_idx=start_idx+H*W_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,height,width)_labels=_labels.reshape((1,1,H,W))#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,4)).transpose(0,3,1,2)stride=foa.stridew=int(im_width/stride)h=int(im_height/stride)#dataforselect_smooth_l1lossnum_classes=cfg.MODEL.NUM_CLASSES-1inds_4d=np.where(_labels>0)M=len(inds_4d)_roi_bbox_targets=np.zeros((0,4))_roi_fg_bbox_locs=np.zeros((0,4))ifM>0:im_inds,y,x=inds_4d[0],inds_4d[2],inds_4d[3]_roi_bbox_targets=np.zeros((len(im_inds),4))_roi_fg_bbox_locs=np.zeros((len(im_inds),4))lbls=_labels[im_inds,:,y,x]fori,lblinenumerate(lbls):l=lbl[0]-1ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:l=0assertl>=0andl<num_classes,\\'labeloutoftherange\\'_roi_bbox_targets[i,:]=_bbox_targets[:,:,y[i],x[i]]_roi_fg_bbox_locs[i,:]=np.array([[0,l,y[i],x[i]]])blobs_out.append(dict(retnet_cls_labels=_labels[:,:,0:h,0:w].astype(np.int32),retnet_roi_bbox_targets=_roi_bbox_targets.astype(np.float32),retnet_roi_fg_bbox_locs=_roi_fg_bbox_locs.astype(np.float32),))out_num_fg=np.array([num_fg+1.0],dtype=np.float32)out_num_bg=(np.array([num_bg+1.0])*(cfg.MODEL.NUM_CLASSES-1)+out_num_fg*(cfg.MODEL.NUM_CLASSES-2))returnblobs_out,out_num_fg,out_num_bg#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"CommonutilityfunctionsforRPNandRetinaNetminibtachblobspreparation.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportnamedtupleimportloggingimportnumpyasnpimportthreadingfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)#octaveandaspectfieldsareonlyusedonRetinaNet.Octavecorrespondstothe#scaleoftheanchorandaspectdenoteswhichaspectratioisusedintherange#ofaspectratiosFieldOfAnchors=namedtuple(\\'FieldOfAnchors\\',[\\'field_of_anchors\\',\\'num_cell_anchors\\',\\'stride\\',\\'field_size\\',\\'octave\\',\\'aspect\\'])#Cacheformemoizing_get_field_of_anchors_threadlocal_foa=threading.local()defget_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave=None,aspect=None):global_threadlocal_foaifnothasattr(_threadlocal_foa,\\'cache\\'):_threadlocal_foa.cache={}cache_key=str(stride)+str(anchor_sizes)+str(anchor_aspect_ratios)ifcache_keyin_threadlocal_foa.cache:return_threadlocal_foa.cache[cache_key]#Anchorsatasinglefeaturecellcell_anchors=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)num_cell_anchors=cell_anchors.shape[0]#Generatecanonicalproposalsfromshiftedanchors#Enumerateallshiftedpositionsonthe(H,W)gridfpn_max_size=cfg.FPN.COARSEST_STRIDE*np.ceil(cfg.TRAIN.MAX_SIZE/float(cfg.FPN.COARSEST_STRIDE))field_size=int(np.ceil(fpn_max_size/float(stride)))shifts=np.arange(0,field_size)*strideshift_x,shift_y=np.meshgrid(shifts,shifts)shift_x=shift_x.ravel()shift_y=shift_y.ravel()shifts=np.vstack((shift_x,shift_y,shift_x,shift_y)).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAcellanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsA=num_cell_anchorsK=shifts.shape[0]field_of_anchors=(cell_anchors.reshape((1,A,4))+shifts.reshape((1,K,4)).transpose((1,0,2)))field_of_anchors=field_of_anchors.reshape((K*A,4))foa=FieldOfAnchors(field_of_anchors=field_of_anchors.astype(np.float32),num_cell_anchors=num_cell_anchors,stride=stride,field_size=field_size,octave=octave,aspect=aspect)_threadlocal_foa.cache[cache_key]=foareturnfoadefunmap(data,count,inds,fill=0):\"\"\"Unmapasubsetofitem(data)backtotheoriginalsetofitems(ofsizecount)\"\"\"ifcount==len(inds):returndataiflen(data.shape)==1:ret=np.empty((count,),dtype=data.dtype)ret.fill(fill)ret[inds]=dataelse:ret=np.empty((count,)+data.shape[1:],dtype=data.dtype)ret.fill(fill)ret[inds,:]=datareturnretdefcompute_targets(ex_rois,gt_rois,weights=(1.0,1.0,1.0,1.0)):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"returnbox_utils.bbox_transform_inv(ex_rois,gt_rois,weights).astype(np.float32,copy=False)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectrondataloader.Thedesignisgenericandabstractedawayfromanydetailsoftheminibatch.Aminibatchisadictionaryofblobnamekeysandtheirassociatednumpy(float32orint32)ndarrayvalues.Outlineofthedataloaderdesign:loaderthread\\\\loaderthread\\\\/GPU1enqueuethread->feed->EnqueueOp...->minibatchqueue->...loaderthread/\\\\GPUNenqueuethread->feed->EnqueueOploaderthread/Apoolofloaderthreadsconstructminibatchesthatareputontothesharedminibatchqueue.EachGPUhasanenqueuethreadthatpullsaminibatchofftheminibatchqueue,feedstheminibatchblobsintotheworkspace,andthenrunsanEnqueueBlobsOptoplacetheminibatchblobsintotheGPU\\'sblobsqueue.DuringeachfpropthefirstthingthenetworkdoesisrunaDequeueBlobsOpinordertopopulatetheworkspacewiththeblobsfromaqueuedminibatch.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportsignalimportthreadingimporttimeimportuuidfromsix.movesimportqueueasQueuefromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.roi_data.minibatchimportget_minibatchfromdetectron.roi_data.minibatchimportget_minibatch_blob_namesfromdetectron.utils.coordinatorimportcoordinated_getfromdetectron.utils.coordinatorimportcoordinated_putfromdetectron.utils.coordinatorimportCoordinatorimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classRoIDataLoader:def__init__(self,roidb,num_loaders=4,minibatch_queue_size=64,blobs_queue_capacity=8):self._roidb=roidbself._lock=threading.Lock()self._perm=deque(range(len(self._roidb)))self._cur=0#_permcursor#Theminibatchqueueholdspreparedtrainingdatainhost(CPU)memory#WhentrainingwithN>1GPUs,eachelementintheminibatchqueue#isactuallyapartialminibatchwhichcontributes1/Nofthe#examplestotheoverallminibatchself._minibatch_queue=Queue.Queue(maxsize=minibatch_queue_size)self._blobs_queue_capacity=blobs_queue_capacity#RandomqueuenameincaseoneinstantiatesmultpleRoIDataLoadersself._loader_id=uuid.uuid4()self._blobs_queue_name=\\'roi_blobs_queue_{}\\'.format(self._loader_id)#Loaderthreadsconstruct(partial)minibatchesandputthemonthe#minibatchqueueself._num_loaders=num_loadersself._num_gpus=cfg.NUM_GPUSself.coordinator=Coordinator()self._output_names=get_minibatch_blob_names()self._shuffle_roidb_inds()self.create_threads()defminibatch_loader_thread(self):\"\"\"Loadmini-batchesandputthemontothemini-batchqueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():blobs=self.get_next_minibatch()#Blobsmustbequeuedintheorderspecifiedby#self.get_output_namesordered_blobs=OrderedDict()forkeyinself.get_output_names():assertblobs[key].dtypein(np.int32,np.float32),\\\\\\'Blob{}ofdtype{}musthavedtypeof\\'\\\\\\'np.int32ornp.float32\\'.format(key,blobs[key].dtype)ordered_blobs[key]=blobs[key]coordinated_put(self.coordinator,self._minibatch_queue,ordered_blobs)logger.info(\\'Stoppingmini-batchloadingthread\\')defenqueue_blobs_thread(self,gpu_id,blob_names):\"\"\"Transfermini-batchesfromamini-batchqueuetoaBlobsQueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():ifself._minibatch_queue.qsize==0:logger.warning(\\'Mini-batchqueueisempty\\')blobs=coordinated_get(self.coordinator,self._minibatch_queue)self.enqueue_blobs(gpu_id,blob_names,blobs.values())logger.debug(\\'batchqueuesize{}\\'.format(self._minibatch_queue.qsize()))logger.info(\\'Stoppingenqueuethread\\')defget_next_minibatch(self):\"\"\"Returntheblobstobeusedforthenextminibatch.Threadsafe.\"\"\"valid=Falsewhilenotvalid:db_inds=self._get_next_minibatch_inds()minibatch_db=[self._roidb[i]foriindb_inds]blobs,valid=get_minibatch(minibatch_db)returnblobsdef_shuffle_roidb_inds(self):\"\"\"Randomlypermutethetrainingroidb.Notthreadsafe.\"\"\"ifcfg.TRAIN.ASPECT_GROUPING:widths=np.array([r[\\'width\\']forrinself._roidb])heights=np.array([r[\\'height\\']forrinself._roidb])horz=(widths>=heights)vert=np.logical_not(horz)horz_inds=np.where(horz)[0]vert_inds=np.where(vert)[0]horz_inds=np.random.permutation(horz_inds)vert_inds=np.random.permutation(vert_inds)mb=cfg.TRAIN.IMS_PER_BATCHhorz_inds=horz_inds[:(len(horz_inds)//mb)*mb]vert_inds=vert_inds[:(len(vert_inds)//mb)*mb]inds=np.hstack((horz_inds,vert_inds))inds=np.reshape(inds,(-1,mb))row_perm=np.random.permutation(np.arange(inds.shape[0]))inds=np.reshape(inds[row_perm,:],(-1,))self._perm=indselse:self._perm=np.random.permutation(np.arange(len(self._roidb)))self._perm=deque(self._perm)self._cur=0def_get_next_minibatch_inds(self):\"\"\"Returntheroidbindicesforthenextminibatch.Threadsafe.\"\"\"withself._lock:#Weuseadequeandalwaystakethe*first*IMS_PER_BATCHitems#followedby*rotating*thedequesothatweseefreshitems#eachtime.Ifthelengthof_permisnotdivisibleby#IMS_PER_BATCH,thenweendupwrappingaroundthepermutation.db_inds=[self._perm[i]foriinrange(cfg.TRAIN.IMS_PER_BATCH)]self._perm.rotate(-cfg.TRAIN.IMS_PER_BATCH)self._cur+=cfg.TRAIN.IMS_PER_BATCHifself._cur>=len(self._perm):self._shuffle_roidb_inds()returndb_indsdefget_output_names(self):returnself._output_namesdefenqueue_blobs(self,gpu_id,blob_names,blobs):\"\"\"Putamini-batchonaBlobsQueue.\"\"\"assertlen(blob_names)==len(blobs)t=time.time()dev=c2_utils.CudaDevice(gpu_id)queue_name=\\'gpu_{}/{}\\'.format(gpu_id,self._blobs_queue_name)blob_names=[\\'gpu_{}/{}\\'.format(gpu_id,b)forbinblob_names]for(blob_name,blob)inzip(blob_names,blobs):workspace.FeedBlob(blob_name,blob,device_option=dev)logger.debug(\\'enqueue_blobs{}:workspace.FeedBlob:{}\\'.format(gpu_id,time.time()-t))t=time.time()op=core.CreateOperator(\\'SafeEnqueueBlobs\\',[queue_name]+blob_names,blob_names+[queue_name+\\'_enqueue_status\\'],device_option=dev)workspace.RunOperatorOnce(op)logger.debug(\\'enqueue_blobs{}:workspace.RunOperatorOnce:{}\\'.format(gpu_id,time.time()-t))defcreate_threads(self):#Createmini-batchloaderthreads,eachofwhichbuildsmini-batches#andplacesthemintoaqueueinCPUmemoryself._workers=[threading.Thread(target=self.minibatch_loader_thread)for_inrange(self._num_loaders)]#CreateoneBlobsQueueperGPU#(enqueue_blob_namesareunscoped)enqueue_blob_names=self.create_blobs_queues()#CreateoneenqueuerthreadperGPUself._enqueuers=[threading.Thread(target=self.enqueue_blobs_thread,args=(gpu_id,enqueue_blob_names))forgpu_idinrange(self._num_gpus)]defstart(self,prefill=False):forwinself._workers+self._enqueuers:w.setDaemon(True)w.start()ifprefill:logger.info(\\'Pre-fillingmini-batchqueue...\\')whilenotself._minibatch_queue.full():logger.info(\\'[{:d}/{:d}]\\'.format(self._minibatch_queue.qsize(),self._minibatch_queue.maxsize))time.sleep(0.1)#Detectfailureandshutdownifself.coordinator.should_stop():self.shutdown()breakdefhas_stopped(self):returnself.coordinator.should_stop()defshutdown(self):self.coordinator.request_stop()self.coordinator.wait_for_stop()self.close_blobs_queues()forwinself._workers+self._enqueuers:w.join()defcreate_blobs_queues(self):\"\"\"CreateoneBlobsQueueforeachGPUtoholdmini-batches.\"\"\"forgpu_idinrange(self._num_gpus):withc2_utils.GpuNameScope(gpu_id):workspace.RunOperatorOnce(core.CreateOperator(\\'CreateBlobsQueue\\',[],[self._blobs_queue_name],num_blobs=len(self.get_output_names()),capacity=self._blobs_queue_capacity))returnself.create_enqueue_blobs()defclose_blobs_queues(self):\"\"\"CloseaBlobsQueue.\"\"\"forgpu_idinrange(self._num_gpus):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):workspace.RunOperatorOnce(core.CreateOperator(\\'CloseBlobsQueue\\',[self._blobs_queue_name],[]))defcreate_enqueue_blobs(self):blob_names=self.get_output_names()enqueue_blob_names=[\\'{}_enqueue_{}\\'.format(b,self._loader_id)forbinblob_names]forgpu_idinrange(self._num_gpus):withc2_utils.NamedCudaScope(gpu_id):forblobinenqueue_blob_names:workspace.CreateBlob(core.ScopedName(blob))returnenqueue_blob_namesdefregister_sigint_handler(self):defsignal_handler(signal,frame):logger.info(\\'SIGINT:ShuttingdownRoIDataLoaderthreadsandexiting...\\')self.shutdown()signal.signal(signal.SIGINT,signal_handler)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"ConstructminibatchesforDetectronnetworks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.roi_data.retinanetasretinanet_roi_dataimportdetectron.roi_data.rpnasrpn_roi_dataimportdetectron.utils.blobasblob_utilslogger=logging.getLogger(__name__)defget_minibatch_blob_names(is_training=True):\"\"\"Returnblobnamesintheorderinwhichtheyarereadbythedataloader.\"\"\"#datablob:holdsabatchofNimages,eachwith3channelsblob_names=[\\'data\\']ifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFasterR-CNNblob_names+=rpn_roi_data.get_rpn_blob_names(is_training=is_training)elifcfg.RETINANET.RETINANET_ON:blob_names+=retinanet_roi_data.get_retinanet_blob_names(is_training=is_training)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsblob_names+=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=is_training)returnblob_namesdefget_minibatch(roidb):\"\"\"Givenaroidb,constructaminibatchsampledfromit.\"\"\"#Wecollectblobsfromeachimageontoalistandthenconcatthemintoa#singletensor,henceweinitializeeachblobtoanemptylistblobs={k:[]forkinget_minibatch_blob_names()}#Gettheinputimageblob,formattedforcaffe2im_blob,im_scales=_get_image_blob(roidb)blobs[\\'data\\']=im_blobifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFaster/MaskR-CNNvalid=rpn_roi_data.add_rpn_blobs(blobs,im_scales,roidb)elifcfg.RETINANET.RETINANET_ON:im_width,im_height=im_blob.shape[3],im_blob.shape[2]#im_width,im_heightcorrespondstothenetworkinput:paddedimage#(ifneeded)widthandheight.Wepassitasinputandslicethedata#accordinglysothatwedon\\'tneedtouseSampleAsOpvalid=retinanet_roi_data.add_retinanet_blobs(blobs,im_scales,roidb,im_width,im_height)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsvalid=fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)returnblobs,validdef_get_image_blob(roidb):\"\"\"Buildsaninputblobfromtheimagesintheroidbatthespecifiedscales.\"\"\"num_images=len(roidb)#Samplerandomscalestouseforeachimageinthisbatchscale_inds=np.random.randint(0,high=len(cfg.TRAIN.SCALES),size=num_images)processed_ims=[]im_scales=[]foriinrange(num_images):im=cv2.imread(roidb[i][\\'image\\'])assertimisnotNone,\\\\\\'Failedtoreadimage\\\\\\'{}\\\\\\'\\'.format(roidb[i][\\'image\\'])ifroidb[i][\\'flipped\\']:im=im[:,::-1,:]target_size=cfg.TRAIN.SCALES[scale_inds[i]]im,im_scale=blob_utils.prep_im_for_blob(im,cfg.PIXEL_MEANS,target_size,cfg.TRAIN.MAX_SIZE)im_scales.append(im_scale)processed_ims.append(im)#Createablobtoholdtheinputimagesblob=blob_utils.im_list_to_blob(processed_ims)returnblob,im_scales#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforFastR-CNNtraining.HandlestheminibatchblobsthatarespecifictoFastR-CNN.OtherblobsthataregenerictoRPN,etc.arehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.keypoint_rcnnaskeypoint_rcnn_roi_dataimportdetectron.roi_data.mask_rcnnasmask_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_fast_rcnn_blob_names(is_training=True):\"\"\"FastR-CNNblobnames.\"\"\"#roisblob:holdsRregionsofinterest,eachisa5-tuple#(batch_idx,x1,y1,x2,y2)specifyinganimagebatchindexanda#rectangle(x1,y1,x2,y2)blob_names=[\\'rois\\']ifis_training:#labels_int32blob:Rcategoricallabelsin[0,...,K]forK#foregroundclassesplusbackgroundblob_names+=[\\'labels_int32\\']ifis_training:#bbox_targetsblob:Rbounding-boxregressiontargetswith4#targetsperclassblob_names+=[\\'bbox_targets\\']#bbox_inside_weightsblob:Atmost4targetsperroiareactive#thisbinaryvectorsepcifiesthesubsetofactivetargetsblob_names+=[\\'bbox_inside_weights\\']blob_names+=[\\'bbox_outside_weights\\']ifis_trainingandcfg.MODEL.MASK_ON:#\\'mask_rois\\':RoIssampledfortrainingthemaskpredictionbranch.#Shapeis(#masks,5)informat(batch_idx,x1,y1,x2,y2).blob_names+=[\\'mask_rois\\']#\\'roi_has_mask\\':binarylabelsfortheRoIsspecifiedin\\'rois\\'#indicatingifeachRoIhasamaskornot.Notethatinsomecases#a*bg*RoIwillhaveanall-1(ignore)maskassociatedwithitin#thecasethatnofgRoIscanbesampled.Shapeis(batchsize).blob_names+=[\\'roi_has_mask_int32\\']#\\'masks_int32\\'holdsbinarymasksfortheRoIsspecifiedin#\\'mask_rois\\'.Shapeis(#fg,M*M)whereMisthegroundtruth#masksize.blob_names+=[\\'masks_int32\\']ifis_trainingandcfg.MODEL.KEYPOINTS_ON:#\\'keypoint_rois\\':RoIssampledfortrainingthekeypointprediction#branch.Shapeis(#instances,5)informat(batch_idx,x1,y1,x2,#y2).blob_names+=[\\'keypoint_rois\\']#\\'keypoint_locations_int32\\':indexofkeypointin#KRCNN.HEATMAP_SIZE**2sizedarray.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_locations_int32\\']#\\'keypoint_weights\\':weightassignedtoeachtargetin#\\'keypoint_locations_int32\\'.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_weights\\']#\\'keypoint_loss_normalizer\\':optionalnormalizationfactortouseif#cfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.blob_names+=[\\'keypoint_loss_normalizer\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:#SupportforFPNmulti-levelroiswithoutbboxregisn\\'t#implemented(...andmayneverbeimplemented)k_max=cfg.FPN.ROI_MAX_LEVELk_min=cfg.FPN.ROI_MIN_LEVEL#Sameformatasroisblob,butoneperFPNlevelforlvlinrange(k_min,k_max+1):blob_names+=[\\'rois_fpn\\'+str(lvl)]blob_names+=[\\'rois_idx_restore_int32\\']ifis_training:ifcfg.MODEL.MASK_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'mask_rois_fpn\\'+str(lvl)]blob_names+=[\\'mask_rois_idx_restore_int32\\']ifcfg.MODEL.KEYPOINTS_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'keypoint_rois_fpn\\'+str(lvl)]blob_names+=[\\'keypoint_rois_idx_restore_int32\\']returnblob_namesdefadd_fast_rcnn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededfortrainingFastR-CNNstylemodels.\"\"\"#SampletrainingRoIsfromeachimageandappendthemtothebloblistsforim_i,entryinenumerate(roidb):frcn_blobs=_sample_rois(entry,im_scales[im_i],im_i)fork,vinfrcn_blobs.items():blobs[k].append(v)#Concatthetrainingbloblistsintotensorsfork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)#AddFPNmultileveltrainingRoIs,ifconfiguredifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois(blobs)#Performanyfinalworkandvaliditychecksafterthecollatingblobsfor#allminibatchimagesvalid=Trueifcfg.MODEL.KEYPOINTS_ON:valid=keypoint_rcnn_roi_data.finalize_keypoint_minibatch(blobs,valid)returnvaliddef_sample_rois(roidb,im_scale,batch_idx):\"\"\"GeneratearandomsampleofRoIscomprisingforegroundandbackgroundexamples.\"\"\"rois_per_image=int(cfg.TRAIN.BATCH_SIZE_PER_IM)fg_rois_per_image=int(np.round(cfg.TRAIN.FG_FRACTION*rois_per_image))max_overlaps=roidb[\\'max_overlaps\\']#SelectforegroundRoIsasthosewith>=FG_THRESHoverlapfg_inds=np.where(max_overlaps>=cfg.TRAIN.FG_THRESH)[0]#Guardagainstthecasewhenanimagehasfewerthanfg_rois_per_image#foregroundRoIsfg_rois_per_this_image=np.minimum(fg_rois_per_image,fg_inds.size)#Sampleforegroundregionswithoutreplacementiffg_inds.size>0:fg_inds=npr.choice(fg_inds,size=fg_rois_per_this_image,replace=False)#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((max_overlaps<cfg.TRAIN.BG_THRESH_HI)&(max_overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#ComputenumberofbackgroundRoIstotakefromthisimage(guarding#againsttherebeingfewerthandesired)bg_rois_per_this_image=rois_per_image-fg_rois_per_this_imagebg_rois_per_this_image=np.minimum(bg_rois_per_this_image,bg_inds.size)#Sampleforegroundregionswithoutreplacementifbg_inds.size>0:bg_inds=npr.choice(bg_inds,size=bg_rois_per_this_image,replace=False)#Theindicesthatwe\\'reselecting(bothfgandbg)keep_inds=np.append(fg_inds,bg_inds)#LabelistheclasseachRoIhasmaxoverlapwithsampled_labels=roidb[\\'max_classes\\'][keep_inds]sampled_labels[fg_rois_per_this_image:]=0#LabelbgRoIswithclass0sampled_boxes=roidb[\\'boxes\\'][keep_inds]bbox_targets,bbox_inside_weights=_expand_bbox_targets(roidb[\\'bbox_targets\\'][keep_inds,:])bbox_outside_weights=np.array(bbox_inside_weights>0,dtype=bbox_inside_weights.dtype)#Scaleroisandformatas(batch_idx,x1,y1,x2,y2)sampled_rois=sampled_boxes*im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_rois.shape[0],1))sampled_rois=np.hstack((repeated_batch_idx,sampled_rois))#BaseFastR-CNNblobsblob_dict=dict(labels_int32=sampled_labels.astype(np.int32,copy=False),rois=sampled_rois,bbox_targets=bbox_targets,bbox_inside_weights=bbox_inside_weights,bbox_outside_weights=bbox_outside_weights)#OptionallyaddMaskR-CNNblobsifcfg.MODEL.MASK_ON:mask_rcnn_roi_data.add_mask_rcnn_blobs(blob_dict,sampled_boxes,roidb,im_scale,batch_idx)#OptionallyaddKeypointR-CNNblobsifcfg.MODEL.KEYPOINTS_ON:keypoint_rcnn_roi_data.add_keypoint_rcnn_blobs(blob_dict,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx)returnblob_dictdef_expand_bbox_targets(bbox_target_data):\"\"\"Bounding-boxregressiontargetsarestoredinacompactformintheroidb.Thisfunctionexpandsthosetargetsintothe4-of-4*Krepresentationusedbythenetwork(i.e.onlyoneclasshasnon-zerotargets).Thelossweightsaresimilarlyexpanded.Returns:bbox_target_data(ndarray):Nx4Kblobofregressiontargetsbbox_inside_weights(ndarray):Nx4Kbloboflossweights\"\"\"num_bbox_reg_classes=cfg.MODEL.NUM_CLASSESifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:num_bbox_reg_classes=2#bgandfgclss=bbox_target_data[:,0]bbox_targets=blob_utils.zeros((clss.size,4*num_bbox_reg_classes))bbox_inside_weights=blob_utils.zeros(bbox_targets.shape)inds=np.where(clss>0)[0]forindininds:cls=int(clss[ind])start=4*clsend=start+4bbox_targets[ind,start:end]=bbox_target_data[ind,1:]bbox_inside_weights[ind,start:end]=(1.0,1.0,1.0,1.0)returnbbox_targets,bbox_inside_weightsdef_add_multilevel_rois(blobs):\"\"\"BydefaulttrainingRoIsareaddedforasinglefeaturemaplevelonly.WhenusingFPN,theRoIsmustbedistributedoverdifferentFPNlevelsaccordingthelevelassignmentheuristic(see:modeling.FPN.map_rois_to_fpn_levels).\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELdef_distribute_rois_over_fpn_levels(rois_blob_name):\"\"\"DistributeroisoverthedifferentFPNlevels.\"\"\"#Gettargetlevelforeachroi#Recallblobroisarein(batch_idx,x1,y1,x2,y2)format,hencetake#theboxcoordinatesfromcolumns1:5target_lvls=fpn.map_rois_to_fpn_levels(blobs[rois_blob_name][:,1:5],lvl_min,lvl_max)#AddperFPNlevelroiblobsnamedlike:_fpnfpn.add_multilevel_roi_blobs(blobs,rois_blob_name,blobs[rois_blob_name],target_lvls,lvl_min,lvl_max)_distribute_rois_over_fpn_levels(\\'rois\\')ifcfg.MODEL.MASK_ON:_distribute_rois_over_fpn_levels(\\'mask_rois\\')ifcfg.MODEL.KEYPOINTS_ON:_distribute_rois_over_fpn_levels(\\'keypoint_rois\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtraining.HandlestheminibatchblobsthatarespecifictoMaskR-CNN.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defadd_mask_rcnn_blobs(blobs,sampled_boxes,roidb,im_scale,batch_idx):\"\"\"AddMaskR-CNNspecificblobstotheinputblobdictionary.\"\"\"#Preparethemasktargetsbyassociatingonegtmasktoeachtrainingroi#thathasafg(non-bg)classlabel.M=cfg.MRCNN.RESOLUTIONpolys_gt_inds=np.where((roidb[\\'gt_classes\\']>0)&(roidb[\\'is_crowd\\']==0))[0]polys_gt=[roidb[\\'segms\\'][i]foriinpolys_gt_inds]boxes_from_polys=segm_utils.polys_to_boxes(polys_gt)fg_inds=np.where(blobs[\\'labels_int32\\']>0)[0]roi_has_mask=blobs[\\'labels_int32\\'].copy()roi_has_mask[roi_has_mask>0]=1iffg_inds.shape[0]>0:#Classlabelsfortheforegroundroismask_class_labels=blobs[\\'labels_int32\\'][fg_inds]masks=blob_utils.zeros((fg_inds.shape[0],M**2),int32=True)#Findoverlapbetweenallforegroundroisandtheboundingboxes#enclosingeachsegmentationrois_fg=sampled_boxes[fg_inds]overlaps_bbfg_bbpolys=box_utils.bbox_overlaps(rois_fg.astype(np.float32,copy=False),boxes_from_polys.astype(np.float32,copy=False))#Mapfromeachfgroistotheindexofthemaskwithhighestoverlap#(measuredbybboxoverlap)fg_polys_inds=np.argmax(overlaps_bbfg_bbpolys,axis=1)#addfgtargetsforiinrange(rois_fg.shape[0]):fg_polys_ind=fg_polys_inds[i]poly_gt=polys_gt[fg_polys_ind]roi_fg=rois_fg[i]#Rasterizetheportionofthepolygonmaskwithinthegivenfgroi#toanMxMbinaryimagemask=segm_utils.polys_to_mask_wrt_box(poly_gt,roi_fg,M)mask=np.array(mask>0,dtype=np.int32)#Ensureit\\'sbinarymasks[i,:]=np.reshape(mask,M**2)else:#Iftherearenofgmasks(itdoeshappen)#Thenetworkcannothandleemptyblobs,sowemustprovideamask#Wesimplytakethefirstbgroi,givenitanall-1\\'smask(ignore#label),andlabelitwithclasszero(bg).bg_inds=np.where(blobs[\\'labels_int32\\']==0)[0]#rois_fgisactuallyonebackgroundroi,butthat\\'sokbecause...rois_fg=sampled_boxes[bg_inds[0]].reshape((1,-1))#Wegiveitan-1\\'sblob(ignorelabel)masks=-blob_utils.ones((1,M**2),int32=True)#Welabelitwithclass=0(background)mask_class_labels=blob_utils.zeros((1,))#Markthatthefirstroihasamaskroi_has_mask[0]=1ifcfg.MRCNN.CLS_SPECIFIC_MASK:masks=_expand_to_class_specific_mask_targets(masks,mask_class_labels)#Scalerois_fgandformatas(batch_idx,x1,y1,x2,y2)rois_fg*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((rois_fg.shape[0],1))rois_fg=np.hstack((repeated_batch_idx,rois_fg))#UpdateblobsdictwithMaskR-CNNblobsblobs[\\'mask_rois\\']=rois_fgblobs[\\'roi_has_mask_int32\\']=roi_has_maskblobs[\\'masks_int32\\']=masksdef_expand_to_class_specific_mask_targets(masks,mask_class_labels):\"\"\"Expandmasksfromshape(#masks,M**2)to(#masks,#classes*M**2)toencodeclassspecificmasktargets.\"\"\"assertmasks.shape[0]==mask_class_labels.shape[0]M=cfg.MRCNN.RESOLUTION#Targetvaluesof-1are\"don\\'tcare\"/ignorelabelsmask_targets=-blob_utils.ones((masks.shape[0],cfg.MODEL.NUM_CLASSES*M**2),int32=True)foriinrange(masks.shape[0]):cls=int(mask_class_labels[i])start=M**2*clsend=start+M**2#Ignorebackgroundinstance#(onlyhappenswhenthereisnofgsamplesinanimage)ifcls>0:mask_targets[i,start:end]=masks[i,:]returnmask_targets#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"MinibatchconstructionforRegionProposalNetworks(RPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.roi_data.data_utilsasdata_utilsimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_rpn_blob_names(is_training=True):\"\"\"BlobnamesusedbyRPN.\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']ifis_training:#gtboxes:(batch_idx,x1,y1,x2,y2,cls)blob_names+=[\\'roidb\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#SameformatasRPNblobs,butoneperFPNlevelforlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):blob_names+=[\\'rpn_labels_int32_wide_fpn\\'+str(lvl),\\'rpn_bbox_targets_wide_fpn\\'+str(lvl),\\'rpn_bbox_inside_weights_wide_fpn\\'+str(lvl),\\'rpn_bbox_outside_weights_wide_fpn\\'+str(lvl)]else:#SinglelevelRPNblobsblob_names+=[\\'rpn_labels_int32_wide\\',\\'rpn_bbox_targets_wide\\',\\'rpn_bbox_inside_weights_wide\\',\\'rpn_bbox_outside_weights_wide\\']returnblob_namesdefadd_rpn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededtrainingRPN-onlyandend-to-endFasterR-CNNmodels.\"\"\"ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELfoas=[]forlvlinrange(k_min,k_max+1):field_stride=2.**lvlanchor_sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),)anchor_aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOSfoa=data_utils.get_field_of_anchors(field_stride,anchor_sizes,anchor_aspect_ratios)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])else:foa=data_utils.get_field_of_anchors(cfg.RPN.STRIDE,cfg.RPN.SIZES,cfg.RPN.ASPECT_RATIOS)all_anchors=foa.field_of_anchorsforim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_rois=entry[\\'boxes\\'][gt_inds,:]*scaleim_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)#AddRPNtargetsifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperrpn_blobs=_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_rois)fori,lvlinenumerate(range(k_min,k_max+1)):fork,vinrpn_blobs[i].items():blobs[k+\\'_fpn\\'+str(lvl)].append(v)else:#ClassicalRPN,appliedtoasinglefeaturelevelrpn_blobs=_get_rpn_blobs(im_height,im_width,[foa],all_anchors,gt_rois)fork,vinrpn_blobs.items():blobs[k].append(v)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)valid_keys=[\\'has_visible_keypoints\\',\\'boxes\\',\\'segms\\',\\'seg_areas\\',\\'gt_classes\\',\\'gt_overlaps\\',\\'is_crowd\\',\\'box_to_gt_ind_map\\',\\'gt_keypoints\\']minimal_roidb=[{}for_inrange(len(roidb))]fori,einenumerate(roidb):forkinvalid_keys:ifkine:minimal_roidb[i][k]=e[k]blobs[\\'roidb\\']=blob_utils.serialize(minimal_roidb)#Alwaysreturnvalid=True,sinceRPNminibatchesarevalidbydesignreturnTruedef_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_boxes):total_anchors=all_anchors.shape[0]straddle_thresh=cfg.TRAIN.RPN_STRADDLE_THRESHifstraddle_thresh>=0:#Onlykeepanchorsinsidetheimagebyamarginofstraddle_thresh#SetTRAIN.RPN_STRADDLE_THRESHto-1(oralargevalue)tokeepall#anchorsinds_inside=np.where((all_anchors[:,0]>=-straddle_thresh)&(all_anchors[:,1]>=-straddle_thresh)&(all_anchors[:,2]<im_width+straddle_thresh)&(all_anchors[:,3]<im_height+straddle_thresh))[0]#keeponlyinsideanchorsanchors=all_anchors[inds_inside,:]else:inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.int32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)labels[anchors_with_max_overlap]=1#Fglabel:abovethresholdIOUlabels[anchor_to_gt_max>=cfg.TRAIN.RPN_POSITIVE_OVERLAP]=1#subsamplepositivelabelsifwehavetoomanynum_fg=int(cfg.TRAIN.RPN_FG_FRACTION*cfg.TRAIN.RPN_BATCH_SIZE_PER_IM)fg_inds=np.where(labels==1)[0]iflen(fg_inds)>num_fg:disable_inds=npr.choice(fg_inds,size=(len(fg_inds)-num_fg),replace=False)labels[disable_inds]=-1fg_inds=np.where(labels==1)[0]#subsamplenegativelabelsifwehavetoomany#(sampleswithreplacement,butsincethesetofbgindsislargemost#sampleswillnothaverepeats)num_bg=cfg.TRAIN.RPN_BATCH_SIZE_PER_IM-np.sum(labels==1)bg_inds=np.where(anchor_to_gt_max<cfg.TRAIN.RPN_NEGATIVE_OVERLAP)[0]iflen(bg_inds)>num_bg:enable_inds=bg_inds[npr.randint(len(bg_inds),size=num_bg)]else:enable_inds=bg_indslabels[enable_inds]=0bg_inds=np.where(labels==0)[0]bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Bboxregressionlosshastheform:#loss(x)=weight_outside*L(weight_inside*x)#Insideweightsallowustosetzerolossonanelement-wisebasis#Bboxregressionisonlytrainedonpositiveexamplessowesettheir#weightsto1.0(orotherwiseifconfigisdifferent)and0otherwisebbox_inside_weights=np.zeros((num_inside,4),dtype=np.float32)bbox_inside_weights[labels==1,:]=(1.0,1.0,1.0,1.0)#Thebboxregressionlossonlyaveragesbythenumberofimagesinthe#mini-batch,whereasweneedtoaveragebythetotalnumberofexample#anchorsselected#Outsideweightsareusedtoscaleeachelement-wiselosssothefinal#averageoverthemini-batchiscorrectbbox_outside_weights=np.zeros((num_inside,4),dtype=np.float32)#uniformweightingofexamples(givennon-uniformsampling)num_examples=np.sum(labels>=0)bbox_outside_weights[labels==1,:]=1.0/num_examplesbbox_outside_weights[labels==0,:]=1.0/num_examples#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)bbox_inside_weights=data_utils.unmap(bbox_inside_weights,total_anchors,inds_inside,fill=0)bbox_outside_weights=data_utils.unmap(bbox_outside_weights,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeA=foa.num_cell_anchorsend_idx=start_idx+H*W*A_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]_bbox_inside_weights=bbox_inside_weights[start_idx:end_idx,:]_bbox_outside_weights=bbox_outside_weights[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,A,height,width)_labels=_labels.reshape((1,H,W,A)).transpose(0,3,1,2)#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_inside_weightsoutputwithshape(1,4*A,height,width)_bbox_inside_weights=_bbox_inside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_outside_weightsoutputwithshape(1,4*A,height,width)_bbox_outside_weights=_bbox_outside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)blobs_out.append(dict(rpn_labels_int32_wide=_labels,rpn_bbox_targets_wide=_bbox_targets,rpn_bbox_inside_weights_wide=_bbox_inside_weights,rpn_bbox_outside_weights_wide=_bbox_outside_weights))returnblobs_out[0]iflen(blobs_out)==1elseblobs_out#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtrainingwhenkeypointsareenabled.HandlestheminibatchblobsthatarespecifictotrainingMaskR-CNNforkeypointdetection.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defadd_keypoint_rcnn_blobs(blobs,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx):\"\"\"AddMaskR-CNNkeypointspecificblobstothegivenblobsdictionary.\"\"\"#Note:gt_indsmustmatchhowthey\\'recomputedin#datasets.json_dataset._merge_proposal_boxes_into_roidbgt_inds=np.where(roidb[\\'gt_classes\\']>0)[0]max_overlaps=roidb[\\'max_overlaps\\']gt_keypoints=roidb[\\'gt_keypoints\\']ind_kp=gt_inds[roidb[\\'box_to_gt_ind_map\\']]within_box=_within_box(gt_keypoints[ind_kp,:,:],roidb[\\'boxes\\'])vis_kp=gt_keypoints[ind_kp,2,:]>0is_visible=np.sum(np.logical_and(vis_kp,within_box),axis=1)>0kp_fg_inds=np.where(np.logical_and(max_overlaps>=cfg.TRAIN.FG_THRESH,is_visible))[0]kp_fg_rois_per_this_image=np.minimum(fg_rois_per_image,kp_fg_inds.size)ifkp_fg_inds.size>kp_fg_rois_per_this_image:kp_fg_inds=np.random.choice(kp_fg_inds,size=kp_fg_rois_per_this_image,replace=False)sampled_fg_rois=roidb[\\'boxes\\'][kp_fg_inds]box_to_gt_ind_map=roidb[\\'box_to_gt_ind_map\\'][kp_fg_inds]num_keypoints=gt_keypoints.shape[2]sampled_keypoints=-np.ones((len(sampled_fg_rois),gt_keypoints.shape[1],num_keypoints),dtype=gt_keypoints.dtype)foriiinrange(len(sampled_fg_rois)):ind=box_to_gt_ind_map[ii]ifind>=0:sampled_keypoints[ii,:,:]=gt_keypoints[gt_inds[ind],:,:]assertnp.sum(sampled_keypoints[ii,2,:])>0heats,weights=keypoint_utils.keypoints_to_heatmap_labels(sampled_keypoints,sampled_fg_rois)shape=(sampled_fg_rois.shape[0]*cfg.KRCNN.NUM_KEYPOINTS,1)heats=heats.reshape(shape)weights=weights.reshape(shape)sampled_fg_rois*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_fg_rois.shape[0],1))sampled_fg_rois=np.hstack((repeated_batch_idx,sampled_fg_rois))blobs[\\'keypoint_rois\\']=sampled_fg_roisblobs[\\'keypoint_locations_int32\\']=heats.astype(np.int32,copy=False)blobs[\\'keypoint_weights\\']=weightsdeffinalize_keypoint_minibatch(blobs,valid):\"\"\"Finalizetheminibatchafterblobsforallminibatchimageshavebeencollated.\"\"\"min_count=cfg.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCHnum_visible_keypoints=np.sum(blobs[\\'keypoint_weights\\'])valid=(validandlen(blobs[\\'keypoint_weights\\'])>0andnum_visible_keypoints>min_count)#Normalizertouseifcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.#Seemodeling.model_builder.add_keypoint_lossesnorm=num_visible_keypoints/(cfg.TRAIN.IMS_PER_BATCH*cfg.TRAIN.BATCH_SIZE_PER_IM*cfg.TRAIN.FG_FRACTION*cfg.KRCNN.NUM_KEYPOINTS)blobs[\\'keypoint_loss_normalizer\\']=np.array(norm,dtype=np.float32)returnvaliddef_within_box(points,boxes):\"\"\"Validatewhichkeypointsarecontainedinsideagivenbox.points:Nx2xKboxes:Nx4output:NxK\"\"\"x_within=np.logical_and(points[:,0,:]>=np.expand_dims(boxes[:,0],axis=1),points[:,0,:]<=np.expand_dims(boxes[:,2],axis=1))y_within=np.logical_and(points[:,1,:]>=np.expand_dims(boxes[:,1],axis=1),points[:,1,:]<=np.expand_dims(boxes[:,3],axis=1))returnnp.logical_and(x_within,y_within)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSmoothL1LossTest(unittest.TestCase):deftest_forward_and_gradient(self):Y=np.random.randn(128,4*21).astype(np.float32)Y_hat=np.random.randn(128,4*21).astype(np.float32)inside_weights=np.random.randn(128,4*21).astype(np.float32)inside_weights[inside_weights<0]=0outside_weights=np.random.randn(128,4*21).astype(np.float32)outside_weights[outside_weights<0]=0scale=np.random.random()beta=np.random.random()op=core.CreateOperator(\\'SmoothL1Loss\\',[\\'Y_hat\\',\\'Y\\',\\'inside_weights\\',\\'outside_weights\\'],[\\'loss\\'],scale=scale,beta=beta)gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[Y_hat,Y,inside_weights,outside_weights],0,[0])self.assertTrue(grad.shape==grad_estimated.shape,\\'Failcheck:grad.shape!=grad_estimated.shape\\')#Toinspectthegradientandestimatedgradient:#np.set_printoptions(precision=3,suppress=True)#print(\\'grad:\\')#print(grad)#print(\\'grad_estimated:\\')#print(grad_estimated)self.assertTrue(res)if__name__==\\'__main__\\':c2_utils.import_detectron_ops()assert\\'SmoothL1Loss\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfrompycocotoolsimportmaskasCOCOmaskimportdetectron.utils.boxesasbox_utilsdefrandom_boxes(mean_box,stdev,N):boxes=np.random.randn(N,4)*stdev+mean_boxreturnboxes.astype(dtype=np.float32)classTestBboxTransform(unittest.TestCase):deftest_bbox_transform_and_inverse(self):weights=(5,5,10,10)src_boxes=random_boxes([10,10,20,20],1,10)dst_boxes=random_boxes([10,10,20,20],1,10)deltas=box_utils.bbox_transform_inv(src_boxes,dst_boxes,weights=weights)dst_boxes_reconstructed=box_utils.bbox_transform(src_boxes,deltas,weights=weights)np.testing.assert_array_almost_equal(dst_boxes,dst_boxes_reconstructed,decimal=5)deftest_bbox_dataset_to_prediction_roundtrip(self):\"\"\"Simulatetheprocessofreadingaground-truthboxfromadataset,makepredictionsfromproposals,convertthepredictionsbacktothedatasetformat,andthenusetheCOCOAPItocomputeIoUoverlapbetweenthegtboxandthepredictions.TheseshouldhaveIoUof1.\"\"\"weights=(5,5,10,10)#1/\"read\"aboxfromadatasetinthedefault(x1,y1,w,h)formatgt_xywh_box=[10,20,100,150]#2/convertittoourinternal(x1,y1,x2,y2)formatgt_xyxy_box=box_utils.xywh_to_xyxy(gt_xywh_box)#3/considernearbyproposalboxesprop_xyxy_boxes=random_boxes(gt_xyxy_box,10,10)#4/computeproposal-to-gttransformationdeltasdeltas=box_utils.bbox_transform_inv(prop_xyxy_boxes,np.array([gt_xyxy_box]),weights=weights)#5/usedeltastotransformproposalstoxyxypredictedboxpred_xyxy_boxes=box_utils.bbox_transform(prop_xyxy_boxes,deltas,weights=weights)#6/convertxyxypredictedboxtoxywhpredictedboxpred_xywh_boxes=box_utils.xyxy_to_xywh(pred_xyxy_boxes)#7/useCOCOAPItocomputeIoUnot_crowd=[int(False)]*pred_xywh_boxes.shape[0]ious=COCOmask.iou(pred_xywh_boxes,np.array([gt_xywh_box]),not_crowd)np.testing.assert_array_almost_equal(ious,np.ones(ious.shape))deftest_cython_bbox_iou_against_coco_api_bbox_iou(self):\"\"\"CheckthatourcythonimplementationofboundingboxIoUoverlapmatchestheCOCOAPIimplementation.\"\"\"def_do_test(b1,b2):#ComputeIoUoverlapwiththecythonimplementationcython_iou=box_utils.bbox_overlaps(b1,b2)#ComputeIoUoverlapwiththeCOCOAPIimplementation#(requiresconvertingboxesfromxyxytoxywhformat)xywh_b1=box_utils.xyxy_to_xywh(b1)xywh_b2=box_utils.xyxy_to_xywh(b2)not_crowd=[int(False)]*b2.shape[0]coco_ious=COCOmask.iou(xywh_b1,xywh_b2,not_crowd)#IoUsshouldbesimilarnp.testing.assert_array_almost_equal(cython_iou,coco_ious,decimal=5)#Testsmallboxesb1=random_boxes([10,10,20,20],5,10)b2=random_boxes([10,10,20,20],5,10)_do_test(b1,b2)#Testbiggerboxesb1=random_boxes([10,10,110,20],20,10)b2=random_boxes([10,10,110,20],20,10)_do_test(b1,b2)if__name__==\\'__main__\\':unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimporttempfilefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.netasnuc2_utils.import_detectron_ops()defget_params(model):blobs={}#gpu_0blobswithunscoped_nameaskeyall_blobs={}#allblobswithscopednameaskey#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)forparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)returnblobs,all_blobsdefadd_momentum_init_ops(model):forparaminmodel.TrainableParams(gpu_id=0):model.param_init_net.GaussianFill([param+\\'_momentum\\'],param+\\'_momentum\\',mean=0.0,std=1.0)definit_weights(model):#initweightsingpu_id=0andthenbroadcastworkspace.RunNetOnce(model.param_init_net)nu.broadcast_parameters(model)deftest_restore_checkpoint():#CreateModelmodel=model_builder.create(cfg.MODEL.TYPE,train=True)add_momentum_init_ops(model)init_weights(model)#Fillinputblobsroidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)model_builder.add_training_inputs(model,roidb=roidb)workspace.CreateNet(model.net)#Bookkeepingforcheckpointcreationiter_num=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)chk_file_path=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(iter_num))checkpoints[iter_num]=chk_file_path#Savemodelweightsnu.save_model_to_weights_file(checkpoints[iter_num],model)orig_gpu_0_params,orig_all_params=get_params(model)#Changethemodelweightsinit_weights(model)#Reloadtheweightsinthemodelnu.initialize_gpu_from_weights_file(model,chk_file_path,gpu_id=0)nu.broadcast_parameters(model)shutil.rmtree(cfg.OUTPUT_DIR)_,restored_all_params=get_params(model)#Checkifallparamsareloadedcorrectlyforscoped_name,blobinorig_all_params.items():np.testing.assert_array_equal(blob,restored_all_params[scoped_name])#Checkifbroadcast_parametersworksforscoped_name,blobinrestored_all_params.items():unscoped_name=c2_utils.UnscopeName(scoped_name)np.testing.assert_array_equal(blob,orig_gpu_0_params[unscoped_name])if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)output_dir=tempfile.mkdtemp()#Generateconfigfortestcfg.MODEL.TYPE=\\'generalized_rcnn\\'cfg.MODEL.CONV_BODY=\\'FPN.add_fpn_ResNet50_conv5_body\\'cfg.MODEL.NUM_CLASSES=81cfg.MODEL.FASTER_RCNN=Truecfg.FPN.FPN_ON=Truecfg.FPN.MULTILEVEL_ROIS=Truecfg.FPN.MULTILEVEL_RPN=Truecfg.FAST_RCNN.ROI_BOX_HEAD=\\'fast_rcnn_heads.add_roi_2mlp_head\\'cfg.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'cfg.OUTPUT_DIR=output_dircfg.TRAIN.DATASETS=(\\'coco_2014_minival\\',)cfg.TRAIN.WEIGHTS=b\\'\\'fornum_gpuinrange(workspace.NumCudaDevices()):cfg.immutable(False)cfg.NUM_GPUS=num_gpu+1assert_and_infer_cfg()test_restore_checkpoint()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsclassZeroEvenOpTest(unittest.TestCase):def_run_zero_even_op(self,X):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdef_run_zero_even_op_gpu(self,X):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdeftest_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op(X)deftest_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op_gpu(X)deftest_gpu_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_gpu_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_gpu_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_custom_ops()assert\\'ZeroEven\\'inworkspace.RegisteredOperators()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.loggingaslogging_utilsimportdetectron.utils.c2asc2_utilsclassBatchPermutationOpTest(unittest.TestCase):def_run_op_test(self,X,I,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'BatchPermutation\\',[\\'X\\',\\'I\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.FeedBlob(\\'I\\',I)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.1,threshold=0.001,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[X,I],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')Y_ref=X[I]np.testing.assert_allclose(Y,Y_ref,rtol=1e-5,atol=1e-08)def_run_speed_test(self,iters=5,N=1024):\"\"\"ThisfunctionprovidesanexampleofhowtobenchmarkcustomoperatorsusingtheCaffe2\\'prof_dag\\'networkexecutiontype.Pleasenotethatfor\\'prof_dag\\'towork,Caffe2mustbecompiledwithprofilingsupportusingthe`-DUSE_PROF=ON`optionpassedto`cmake`whenbuildingCaffe2.\"\"\"net=core.Net(\\'test\\')net.Proto().type=\\'prof_dag\\'net.Proto().num_workers=2Y=net.BatchPermutation([\\'X\\',\\'I\\'],\\'Y\\')Y_flat=net.FlattenToVec([Y],\\'Y_flat\\')loss=net.AveragedLoss([Y_flat],\\'loss\\')net.AddGradientOperators([loss])workspace.CreateNet(net)X=np.random.randn(N,256,14,14)for_iinrange(iters):I=np.random.permutation(N)workspace.FeedBlob(\\'X\\',X.astype(np.float32))workspace.FeedBlob(\\'I\\',I.astype(np.int32))workspace.RunNet(net.Proto().name)np.testing.assert_allclose(workspace.FetchBlob(\\'Y\\'),X[I],rtol=1e-5,atol=1e-08)deftest_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([0,1],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([1,0],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(10,3,5,7).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)self._run_op_test(A,I,check_grad=True)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)withself.assertRaises(RuntimeError):self._run_op_test(A,I)#Seedocstringin_run_speed_test#deftest_perf(self):#withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):#self._run_speed_test()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'BatchPermutation\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportunittestimportunittest.mockasmockfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.utils.loggingaslogging_utilsdefget_roidb_blobs(roidb):blobs={}blobs[\\'data\\']=np.stack([entry[\\'data\\']forentryinroidb])returnblobs,Truedefget_net(data_loader,name):logger=logging.getLogger(__name__)blob_names=data_loader.get_output_names()net=core.Net(name)net.type=\\'dag\\'forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)workspace.CreateBlob(blob)net.DequeueBlobs(data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))returnnetdefget_roidb_sample_data(sample_data):roidb=[]for_inrange(np.random.randint(4,10)):roidb.append({\\'data\\':sample_data})returnroidbdefcreate_loader_and_network(sample_data,name):roidb=get_roidb_sample_data(sample_data)loader=RoIDataLoader(roidb)net=get_net(loader,\\'dequeue_net_train\\')loader.register_sigint_handler()loader.start(prefill=False)returnloader,netdefrun_net(net):workspace.RunNetOnce(net)gpu_dev=core.DeviceOption(caffe2_pb2.CUDA,0)name_scope=\\'gpu_{}\\'.format(0)withcore.NameScope(name_scope):withcore.DeviceScope(gpu_dev):data=workspace.FetchBlob(core.ScopedName(\\'data\\'))returndataclassTestRoIDataLoader(unittest.TestCase):@mock.patch(\\'detectron.roi_data.loader.get_minibatch_blob_names\\',return_value=[u\\'data\\'])@mock.patch(\\'detectron.roi_data.loader.get_minibatch\\',side_effect=get_roidb_blobs)deftest_two_parallel_loaders(self,_1,_2):train_data=np.random.rand(2,3,3).astype(np.float32)train_loader,train_net=create_loader_and_network(train_data,\\'dequeue_net_train\\')test_data=np.random.rand(2,4,4).astype(np.float32)test_loader,test_net=create_loader_and_network(test_data,\\'dequeue_net_test\\')for_inrange(5):data=run_net(train_net)self.assertEqual(data[0].tolist(),train_data.tolist())data=run_net(test_net)self.assertEqual(data[0].tolist(),test_data.tolist())test_loader.shutdown()train_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=logging_utils.setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)cfg.TRAIN.ASPECT_GROUPING=Falsecfg.NUM_GPUS=2assert_and_infer_cfg()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Exampleusage:#data_loader_benchmark.par\\\\#NUM_GPUS2\\\\#TRAIN.DATASETS\"(\\'voc_2007_trainval\\',)\"\\\\#TRAIN.PROPOSAL_FILES/path/to/voc_2007_trainval/proposals.pkl\\\\#DATA_LOADER.NUM_THREADS4\\\\#DATA_LOADER.MINIBATCH_QUEUE_SIZE64\\\\#DATA_LOADER.BLOBS_QUEUE_CAPACITY8from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportloggingimportnumpyasnpimportpprintimportsysimporttimefromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.roi_data.loaderimportRoIDataLoaderfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--num-batches\\',dest=\\'num_batches\\',help=\\'Numberofminibatchestorun\\',default=200,type=int)parser.add_argument(\\'--sleep\\',dest=\\'sleep_time\\',help=\\'Secondssleeptoemulateanetworkrunning\\',default=0.1,type=float)parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--x-factor\\',dest=\\'x_factor\\',help=\\'simulatesx-factormoreGPUs\\',default=1,type=int)parser.add_argument(\\'--profiler\\',dest=\\'profiler\\',help=\\'profileminibatchloadtime\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefloader_loop(roi_data_loader):load_timer=Timer()iters=100foriinrange(iters):load_timer.tic()roi_data_loader.get_next_minibatch()load_timer.toc()print(\\'{:d}/{:d}:Averageget_next_minibatchtime:{:.3f}s\\'.format(i+1,iters,load_timer.average_time))defmain(opts):logger=logging.getLogger(__name__)roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)blob_names=roi_data_loader.get_output_names()net=core.Net(\\'dequeue_net\\')net.type=\\'dag\\'all_blobs=[]forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)all_blobs.append(blob)workspace.CreateBlob(blob)logger.info(\\'Creatingblob:{}\\'.format(blob))net.DequeueBlobs(roi_data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))ifopts.profiler:importcProfilecProfile.runctx(\\'loader_loop(roi_data_loader)\\',globals(),locals(),sort=\\'cumulative\\')else:loader_loop(roi_data_loader)roi_data_loader.register_sigint_handler()roi_data_loader.start(prefill=True)total_time=0foriinrange(opts.num_batches):start_t=time.time()for_inrange(opts.x_factor):workspace.RunNetOnce(net)total_time+=(time.time()-start_t)/opts.x_factorlogger.info(\\'{:d}/{:d}:Avergedequeuetime:{:.3f}s[{:d}/{:d}]\\'.format(i+1,opts.num_batches,total_time/(i+1),roi_data_loader._minibatch_queue.qsize(),cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE))#Sleeptosimulatethetimetakenbyrunningalittlenetworktime.sleep(opts.sleep_time)#Toinspect:#blobs=workspace.FetchBlobs(all_blobs)#fromIPythonimportembed;embed()logger.info(\\'Shuttingdowndataloader...\\')roi_data_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Runningwithconfig:\\')logger.info(pprint.pformat(cfg))main(args)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSpatialNarrowAsOpTest(unittest.TestCase):def_run_test(self,A,B,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'SpatialNarrowAs\\',[\\'A\\',\\'B\\'],[\\'C\\'])workspace.FeedBlob(\\'A\\',A)workspace.FeedBlob(\\'B\\',B)workspace.RunOperatorOnce(op)C=workspace.FetchBlob(\\'C\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[A,B],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')dims=C.shapeC_ref=A[:dims[0],:dims[1],:dims[2],:dims[3]]np.testing.assert_allclose(C,C_ref,rtol=1e-5,atol=1e-08)deftest_small_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,2,2).astype(np.float32)self._run_test(A,B,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,5).astype(np.float32)self._run_test(A,B,check_grad=True)deftest_large_forward(self):A=np.random.randn(2,256,42,100).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)A=np.random.randn(2,256,42,87).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)A=np.random.randn(2,255,42,88).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'SpatialNarrowAs\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimporttempfileimportunittestfromdetectron.core.configimportcfgfromdetectron.utils.collectionsimportAttrDictimportdetectron.core.configascore_configimportdetectron.utils.envasenvuimportdetectron.utils.loggingaslogging_utilsclassTestAttrDict(unittest.TestCase):deftest_immutability(self):#Toplevelimmutablea=AttrDict()a.foo=0a.immutable(True)withself.assertRaises(AttributeError):a.foo=1a.bar=1asserta.is_immutable()asserta.foo==0a.immutable(False)assertnota.is_immutable()a.foo=1asserta.foo==1#Recursivelyimmutablea.level1=AttrDict()a.level1.foo=0a.level1.level2=AttrDict()a.level1.level2.foo=0a.immutable(True)asserta.is_immutable()withself.assertRaises(AttributeError):a.level1.level2.foo=1a.level1.bar=1asserta.level1.level2.foo==0#Serializeimmutabilitystatea.immutable(True)a2=core_config.load_cfg(envu.yaml_dump(a))asserta.is_immutable()asserta2.is_immutable()classTestCfg(unittest.TestCase):deftest_copy_cfg(self):cfg2=copy.deepcopy(cfg)s=cfg.MODEL.TYPEcfg2.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_cfg(self):#Test:mergefromdeepcopys=\\'dummy0\\'cfg2=copy.deepcopy(cfg)cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergefromyamls=\\'dummy1\\'cfg2=core_config.load_cfg(envu.yaml_dump(cfg))cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithavalidkeys=\\'dummy2\\'cfg2=AttrDict()cfg2.MODEL=AttrDict()cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithaninvalidkeys=\\'dummy3\\'cfg2=AttrDict()cfg2.FOO=AttrDict()cfg2.FOO.BAR=swithself.assertRaises(KeyError):core_config.merge_cfg_from_cfg(cfg2)#Test:mergewithconvertedtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=[1]core_config.merge_cfg_from_cfg(cfg2)asserttype(cfg.TRAIN.SCALES)istupleassertcfg.TRAIN.SCALES[0]==1#Test:mergewithinvalidtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=1withself.assertRaises(ValueError):core_config.merge_cfg_from_cfg(cfg2)deftest_merge_cfg_from_file(self):withtempfile.NamedTemporaryFile()asf:envu.yaml_dump(cfg,f)s=cfg.MODEL.TYPEcfg.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE!=score_config.merge_cfg_from_file(f.name)assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_list(self):opts=[\\'TRAIN.SCALES\\',\\'(100,)\\',\\'MODEL.TYPE\\',u\\'foobar\\',\\'NUM_GPUS\\',2]assertlen(cfg.TRAIN.SCALES)>0assertcfg.TRAIN.SCALES[0]!=100assertcfg.MODEL.TYPE!=\\'foobar\\'assertcfg.NUM_GPUS!=2core_config.merge_cfg_from_list(opts)asserttype(cfg.TRAIN.SCALES)istupleassertlen(cfg.TRAIN.SCALES)==1assertcfg.TRAIN.SCALES[0]==100assertcfg.MODEL.TYPE==\\'foobar\\'assertcfg.NUM_GPUS==2deftest_deprecated_key_from_list(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"opts=[\\'FINAL_MSG\\',\\'foobar\\',\\'MODEL.DILATION\\',2]withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_list(opts)withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_deprecated_key_from_file(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.MODEL.DILATION=2envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_file(f.name)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_renamed_key_from_list(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"opts=[\\'EXAMPLE.RENAMED.KEY\\',\\'foobar\\']withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_list(opts)deftest_renamed_key_from_file(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.EXAMPLE=AttrDict()cfg2.EXAMPLE.RENAMED=AttrDict()cfg2.EXAMPLE.RENAMED.KEY=\\'foobar\\'envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_file(f.name)if__name__==\\'__main__\\':logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Primitivesforrunningmultiplesingle-GPUjobsinparalleloversubrangesofdata.Theseareusedforrunningmulti-GPUinference.SubprocessesareusedtoavoidtheGILsinceinferencemayinvolvenon-trivialamountsofPythoncode.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportnumpyasnpimportsubprocessfromsix.movesimportshlex_quotefromdetectron.core.configimportcfgfromdetectron.utils.ioimportload_objectimportdetectron.utils.envasenvuimportlogginglogger=logging.getLogger(__name__)defprocess_in_parallel(tag,total_range_size,binary,output_dir,opts=\\'\\'):\"\"\"Runthespecifiedbinarycfg.NUM_GPUStimesinparallel,eachtimeasasubprocessthatusesoneGPU.Thebinarymustacceptthecommandlinearguments`--range{start}{end}`thatspecifyadataprocessingrange.\"\"\"#Snapshotthecurrentcfgstateinordertopasstotheinference#subprocessescfg_file=os.path.join(output_dir,\\'{}_range_config.yaml\\'.format(tag))withopen(cfg_file,\\'w\\')asf:envu.yaml_dump(cfg,stream=f)subprocess_env=os.environ.copy()processes=[]subinds=np.array_split(range(total_range_size),cfg.NUM_GPUS)#DetermineGPUstousecuda_visible_devices=os.environ.get(\\'CUDA_VISIBLE_DEVICES\\')ifcuda_visible_devices:gpu_inds=map(int,cuda_visible_devices.split(\\',\\'))assert-1notingpu_inds,\\\\\\'HidingGPUindicesusingthe\\\\\\'-1\\\\\\'indexisnotsupported\\'else:gpu_inds=range(cfg.NUM_GPUS)#Runthebinaryincfg.NUM_GPUSsubprocessesfori,gpu_indinenumerate(gpu_inds):start=subinds[i][0]end=subinds[i][-1]+1subprocess_env[\\'CUDA_VISIBLE_DEVICES\\']=str(gpu_ind)cmd=\\'{binary}--range{start}{end}--cfg{cfg_file}NUM_GPUS1{opts}\\'cmd=cmd.format(binary=shlex_quote(binary),start=int(start),end=int(end),cfg_file=shlex_quote(cfg_file),opts=\\'\\'.join([shlex_quote(opt)foroptinopts]))logger.info(\\'{}rangecommand{}:{}\\'.format(tag,i,cmd))ifi==0:subprocess_stdout=subprocess.PIPEelse:filename=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))subprocess_stdout=open(filename,\\'w\\')#NOQA(closebelow)p=subprocess.Popen(cmd,shell=True,env=subprocess_env,stdout=subprocess_stdout,stderr=subprocess.STDOUT,bufsize=1)processes.append((i,p,start,end,subprocess_stdout))#Logoutputfrominferenceprocessesandcollatetheirresultsoutputs=[]fori,p,start,end,subprocess_stdoutinprocesses:log_subprocess_output(i,p,output_dir,tag,start,end)ifi>0:subprocess_stdout.close()range_file=os.path.join(output_dir,\\'%s_range_%s_%s.pkl\\'%(tag,start,end))range_data=load_object(range_file)outputs.append(range_data)returnoutputsdeflog_subprocess_output(i,p,output_dir,tag,start,end):\"\"\"Capturetheoutputofeachsubprocessandlogitintheparentprocess.Thefirstsubprocess\\'soutputisloggedinrealtime.Theoutputfromtheothersubprocessesisbufferedandthenprintedallatonce(inorder)whensubprocessesfinish.\"\"\"outfile=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')logger.info(\\'stdoutofsubprocess%swithrange[%s,%s]\\'%(i,start+1,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')ifi==0:#Streamthepipedstdoutfromthefirstsubprocessinrealtimewithopen(outfile,\\'wb\\')asf:forlineiniter(p.stdout.readline,b\\'\\'):print(line.rstrip().decode(\"utf8\"))f.write(line)p.stdout.close()ret=p.wait()else:#Forsubprocesses>=1,waitanddumptheirlogfileret=p.wait()withopen(outfile,\\'r\\')asf:print(\\'\\'.join(f.readlines()))assertret==0,\\'Rangesubprocessfailed(exitcode:{})\\'.format(ret)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforinteractingwithsegmentationmasksintheCOCOformat.Thefollowingtermsareusedinthismodulemask:abinarymaskencodedasa2Dnumpyarraysegm:asegmentationmaskinoneofthetwoCOCOformats(polygonorRLE)polygon:COCO\\'spolygonformatRLE:COCO\\'srunlengthencodingformat\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportpycocotools.maskasmask_util#Typeusedforstoringmasksinpolygonformat_POLY_TYPE=list#TypeusedforstoringmasksinRLEformat_RLE_TYPE=dictdefis_poly(segm):\"\"\"Determineifsegmisapolygon.Validsegmexpected(polygonorRLE).\"\"\"assertisinstance(segm,(_POLY_TYPE,_RLE_TYPE)),\\\\\\'Invalidsegmtype:{}\\'.format(type(segm))returnisinstance(segm,_POLY_TYPE)defflip_segms(segms,height,width):\"\"\"Left/rightflipeachmaskinalistofmasks.\"\"\"def_flip_poly(poly,width):flipped_poly=np.array(poly)flipped_poly[0::2]=width-np.array(poly[0::2])-1returnflipped_poly.tolist()def_flip_rle(rle,height,width):if\\'counts\\'inrleandtype(rle[\\'counts\\'])==list:#MagicRLEformathandlingpainfullydiscoveredbylookingatthe#COCOAPIshowAnnsfunction.rle=mask_util.frPyObjects([rle],height,width)mask=mask_util.decode(rle)mask=mask[:,::-1,:]rle=mask_util.encode(np.array(mask,order=\\'F\\',dtype=np.uint8))returnrleflipped_segms=[]forsegminsegms:ifis_poly(segm):#Polygonformatflipped_segms.append([_flip_poly(poly,width)forpolyinsegm])else:#RLEformatflipped_segms.append(_flip_rle(segm,height,width))returnflipped_segmsdefpolys_to_mask(polygons,height,width):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.Thepolygonsegmentationisunderstoodtobeenclosedinsideaheightxwidthimage.Theresultingmaskisthereforeofshape(height,width).\"\"\"rle=mask_util.frPyObjects(polygons,height,width)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefmask_to_bbox(mask):\"\"\"Computethetightboundingboxofabinarymask.\"\"\"xs=np.where(np.sum(mask,axis=0)>0)[0]ys=np.where(np.sum(mask,axis=1)>0)[0]iflen(xs)==0orlen(ys)==0:returnNonex0=xs[0]x1=xs[-1]y0=ys[0]y1=ys[-1]returnnp.array((x0,y0,x1,y1),dtype=np.float32)defpolys_to_mask_wrt_box(polygons,box,M):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.ThepolygonsegmentationisunderstoodtobeenclosedinthegivenboxandrasterizedtoanMxMmask.Theresultingmaskisthereforeofshape(M,M).\"\"\"w=box[2]-box[0]h=box[3]-box[1]w=np.maximum(w,1)h=np.maximum(h,1)polygons_norm=[]forpolyinpolygons:p=np.array(poly,dtype=np.float32)p[0::2]=(p[0::2]-box[0])*M/wp[1::2]=(p[1::2]-box[1])*M/hpolygons_norm.append(p)rle=mask_util.frPyObjects(polygons_norm,M,M)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefpolys_to_boxes(polys):\"\"\"Convertalistofpolygonsintoanarrayoftightboundingboxes.\"\"\"boxes_from_polys=np.zeros((len(polys),4),dtype=np.float32)foriinrange(len(polys)):poly=polys[i]x0=min(min(p[::2])forpinpoly)x1=max(max(p[::2])forpinpoly)y0=min(min(p[1::2])forpinpoly)y1=max(max(p[1::2])forpinpoly)boxes_from_polys[i,:]=[x0,y0,x1,y1]returnboxes_from_polysdefrle_mask_voting(top_masks,all_masks,all_dets,iou_thresh,binarize_thresh,method=\\'AVG\\'):\"\"\"Returnsnewmasks(incorrespondencewith`top_masks`)bycombiningmultipleoverlappingmaskscomingfromthepoolof`all_masks`.Twomethodsforcombiningmasksaresupported:\\'AVG\\'usesaweightedaverageofoverlappingmaskpixels;\\'UNION\\'takestheunionofallmaskpixels.\"\"\"iflen(top_masks)==0:returnall_not_crowd=[False]*len(all_masks)top_to_all_overlaps=mask_util.iou(top_masks,all_masks,all_not_crowd)decoded_all_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinall_masks]decoded_top_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleintop_masks]all_boxes=all_dets[:,:4].astype(np.int32)all_scores=all_dets[:,4]#Fillboxsupportwithweightsmask_shape=decoded_all_masks[0].shapemask_weights=np.zeros((len(all_masks),mask_shape[0],mask_shape[1]))forkinrange(len(all_masks)):ref_box=all_boxes[k]x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,mask_shape[1])y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,mask_shape[0])mask_weights[k,y_0:y_1,x_0:x_1]=all_scores[k]mask_weights=np.maximum(mask_weights,1e-5)top_segms_out=[]forkinrange(len(top_masks)):#Cornercaseofemptymaskifdecoded_top_masks[k].sum()==0:top_segms_out.append(top_masks[k])continueinds_to_vote=np.where(top_to_all_overlaps[k]>=iou_thresh)[0]#Onlymatchesitselfiflen(inds_to_vote)==1:top_segms_out.append(top_masks[k])continuemasks_to_vote=[decoded_all_masks[i]foriininds_to_vote]ifmethod==\\'AVG\\':ws=mask_weights[inds_to_vote]soft_mask=np.average(masks_to_vote,axis=0,weights=ws)mask=np.array(soft_mask>binarize_thresh,dtype=np.uint8)elifmethod==\\'UNION\\':#Anypixelthat\\'sonjoinsthemasksoft_mask=np.sum(masks_to_vote,axis=0)mask=np.array(soft_mask>1e-5,dtype=np.uint8)else:raiseNotImplementedError(\\'Method{}isunknown\\'.format(method))rle=mask_util.encode(np.array(mask[:,:,np.newaxis],order=\\'F\\'))[0]top_segms_out.append(rle)returntop_segms_outdefrle_mask_nms(masks,dets,thresh,mode=\\'IOU\\'):\"\"\"Performsgreedynon-maximumsuppressionbasedonanoverlapmeasurementbetweenmasks.Thetypeofmeasurementisdeterminedby`mode`andcanbeeither\\'IOU\\'(standardintersectionoverunion)or\\'IOMA\\'(intersectionovermininumarea).\"\"\"iflen(masks)==0:return[]iflen(masks)==1:return[0]ifmode==\\'IOU\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(union(m1,m2))all_not_crowds=[False]*len(masks)ious=mask_util.iou(masks,masks,all_not_crowds)elifmode==\\'IOMA\\':#Computesious[m1,m2]=area(intersect(m1,m2))/min(area(m1),area(m2))all_crowds=[True]*len(masks)#ious[m1,m2]=area(intersect(m1,m2))/area(m2)ious=mask_util.iou(masks,masks,all_crowds)#...=max(area(intersect(m1,m2))/area(m2),#area(intersect(m2,m1))/area(m1))ious=np.maximum(ious,ious.transpose())elifmode==\\'CONTAINMENT\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(m2)#Whichmeasureshowmuchm2iscontainedinsidem1all_crowds=[True]*len(masks)ious=mask_util.iou(masks,masks,all_crowds)else:raiseNotImplementedError(\\'Mode{}isunknown\\'.format(mode))scores=dets[:,4]order=np.argsort(-scores)keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=ious[i,order[1:]]inds_to_keep=np.where(ovr<=thresh)[0]order=order[inds_to_keep+1]returnkeepdefrle_masks_to_boxes(masks):\"\"\"ComputestheboundingboxofeachmaskinalistofRLEencodedmasks.\"\"\"iflen(masks)==0:return[]decoded_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinmasks]defget_bounds(flat_mask):inds=np.where(flat_mask>0)[0]returninds.min(),inds.max()boxes=np.zeros((len(decoded_masks),4))keep=[True]*len(decoded_masks)fori,maskinenumerate(decoded_masks):ifmask.sum()==0:keep[i]=Falsecontinueflat_mask=mask.sum(axis=0)x0,x1=get_bounds(flat_mask)flat_mask=mask.sum(axis=1)y0,y1=get_bounds(flat_mask)boxes[i,:]=(x0,y0,x1,y1)returnboxes,np.where(keep)[0]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Anawesomecolormapforreallyneatvisualizations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpdefcolormap(rgb=False):color_list=np.array([0.000,0.447,0.741,0.850,0.325,0.098,0.929,0.694,0.125,0.494,0.184,0.556,0.466,0.674,0.188,0.301,0.745,0.933,0.635,0.078,0.184,0.300,0.300,0.300,0.600,0.600,0.600,1.000,0.000,0.000,1.000,0.500,0.000,0.749,0.749,0.000,0.000,1.000,0.000,0.000,0.000,1.000,0.667,0.000,1.000,0.333,0.333,0.000,0.333,0.667,0.000,0.333,1.000,0.000,0.667,0.333,0.000,0.667,0.667,0.000,0.667,1.000,0.000,1.000,0.333,0.000,1.000,0.667,0.000,1.000,1.000,0.000,0.000,0.333,0.500,0.000,0.667,0.500,0.000,1.000,0.500,0.333,0.000,0.500,0.333,0.333,0.500,0.333,0.667,0.500,0.333,1.000,0.500,0.667,0.000,0.500,0.667,0.333,0.500,0.667,0.667,0.500,0.667,1.000,0.500,1.000,0.000,0.500,1.000,0.333,0.500,1.000,0.667,0.500,1.000,1.000,0.500,0.000,0.333,1.000,0.000,0.667,1.000,0.000,1.000,1.000,0.333,0.000,1.000,0.333,0.333,1.000,0.333,0.667,1.000,0.333,1.000,1.000,0.667,0.000,1.000,0.667,0.333,1.000,0.667,0.667,1.000,0.667,1.000,1.000,1.000,0.000,1.000,1.000,0.333,1.000,1.000,0.667,1.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.143,0.143,0.143,0.286,0.286,0.286,0.429,0.429,0.429,0.571,0.571,0.571,0.714,0.714,0.714,0.857,0.857,0.857,1.000,1.000,1.000]).astype(np.float32)color_list=color_list.reshape((-1,3))*255ifnotrgb:color_list=color_list[:,::-1]returncolor_list#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Environmenthelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportsysimportyaml#DefaultvalueoftheCMakeinstallprefix_CMAKE_INSTALL_PREFIX=\\'/usr/local\\'#Detectronopslib_DETECTRON_OPS_LIB=\\'libcaffe2_detectron_ops_gpu.so\\'defget_runtime_dir():\"\"\"Retrievethepathtotheruntimedirectory.\"\"\"returnsys.path[0]defget_py_bin_ext():\"\"\"Retrievepythonbinaryextension.\"\"\"return\\'.py\\'defset_up_matplotlib():\"\"\"Setmatplotlibup.\"\"\"importmatplotlib#Useanon-interactivebackendmatplotlib.use(\\'Agg\\')defexit_on_error():\"\"\"Exitfromadetectrontoolwhenthere\\'sanerror.\"\"\"sys.exit(1)defimport_nccl_ops():\"\"\"ImportNCCLops.\"\"\"#ThereisnoneedtoloadNCCLopssincethe#NCCLdependencyisbuiltintotheCaffe2gpulibpassdefget_detectron_ops_lib():\"\"\"RetrieveDetectronopslibrary.\"\"\"#Candidateprefixesfordetectronopslibpathprefixes=[_CMAKE_INSTALL_PREFIX,sys.prefix,sys.exec_prefix]+sys.path#Candidatesubdirsfordetectronopslibsubdirs=[\\'lib\\',\\'torch/lib\\']#Trytofinddetectronopslibforprefixinprefixes:forsubdirinsubdirs:ops_path=os.path.join(prefix,subdir,_DETECTRON_OPS_LIB)ifos.path.exists(ops_path):print(\\'FoundDetectronopslib:{}\\'.format(ops_path))returnops_pathraiseException(\\'Detectronopslibnotfound\\')defget_custom_ops_lib():\"\"\"Retrievecustomopslibrary.\"\"\"det_dir,_=os.path.split(os.path.dirname(__file__))root_dir,_=os.path.split(det_dir)custom_ops_lib=os.path.join(root_dir,\\'build/libcaffe2_detectron_custom_ops_gpu.so\\')assertos.path.exists(custom_ops_lib),\\\\\\'Customopslibnotfoundat\\\\\\'{}\\\\\\'\\'.format(custom_ops_lib)returncustom_ops_lib#YAMLload/dumpfunctionaliasesyaml_load=yaml.loadyaml_dump=yaml.dump#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectionoutputvisualizationmodule.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpimportosimportpycocotools.maskasmask_utilfromdetectron.utils.colormapimportcolormapimportdetectron.utils.envasenvuimportdetectron.utils.keypointsaskeypoint_utils#Matplotlibrequirescertainadjustmentsinsomeenvironments#Musthappenbeforeimportingmatplotlibenvu.set_up_matplotlib()importmatplotlib.pyplotaspltfrommatplotlib.patchesimportPolygonplt.rcParams[\\'pdf.fonttype\\']=42#ForeditinginAdobeIllustrator_GRAY=(218,227,218)_GREEN=(18,127,15)_WHITE=(255,255,255)defkp_connections(keypoints):kp_lines=[[keypoints.index(\\'left_eye\\'),keypoints.index(\\'right_eye\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'right_ear\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'left_ear\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'right_elbow\\')],[keypoints.index(\\'right_elbow\\'),keypoints.index(\\'right_wrist\\')],[keypoints.index(\\'left_shoulder\\'),keypoints.index(\\'left_elbow\\')],[keypoints.index(\\'left_elbow\\'),keypoints.index(\\'left_wrist\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'right_knee\\')],[keypoints.index(\\'right_knee\\'),keypoints.index(\\'right_ankle\\')],[keypoints.index(\\'left_hip\\'),keypoints.index(\\'left_knee\\')],[keypoints.index(\\'left_knee\\'),keypoints.index(\\'left_ankle\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'left_shoulder\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'left_hip\\')],]returnkp_linesdefconvert_from_cls_format(cls_boxes,cls_segms,cls_keyps):\"\"\"Convertfromtheclassboxes/segms/keypsformatgeneratedbythetestingcode.\"\"\"box_list=[bforbincls_boxesiflen(b)>0]iflen(box_list)>0:boxes=np.concatenate(box_list)else:boxes=Noneifcls_segmsisnotNone:segms=[sforslistincls_segmsforsinslist]else:segms=Noneifcls_keypsisnotNone:keyps=[kforklistincls_keypsforkinklist]else:keyps=Noneclasses=[]forjinrange(len(cls_boxes)):classes+=[j]*len(cls_boxes[j])returnboxes,segms,keyps,classesdefget_class_string(class_index,score,dataset):class_text=dataset.classes[class_index]ifdatasetisnotNoneelse\\\\\\'id{:d}\\'.format(class_index)returnclass_text+\\'{:0.2f}\\'.format(score).lstrip(\\'0\\')defvis_mask(img,mask,col,alpha=0.4,show_border=True,border_thick=1):\"\"\"Visualizesasinglebinarymask.\"\"\"img=img.astype(np.float32)idx=np.nonzero(mask)img[idx[0],idx[1],:]*=1.0-alphaimg[idx[0],idx[1],:]+=alpha*colifshow_border:contours=cv2.findContours(mask.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]cv2.drawContours(img,contours,-1,_WHITE,border_thick,cv2.LINE_AA)returnimg.astype(np.uint8)defvis_class(img,pos,class_str,font_scale=0.35):\"\"\"Visualizestheclass.\"\"\"img=img.astype(np.uint8)x0,y0=int(pos[0]),int(pos[1])#Computetextsize.txt=class_strfont=cv2.FONT_HERSHEY_SIMPLEX((txt_w,txt_h),_)=cv2.getTextSize(txt,font,font_scale,1)#Placetextbackground.back_tl=x0,y0-int(1.3*txt_h)back_br=x0+txt_w,y0cv2.rectangle(img,back_tl,back_br,_GREEN,-1)#Showtext.txt_tl=x0,y0-int(0.3*txt_h)cv2.putText(img,txt,txt_tl,font,font_scale,_GRAY,lineType=cv2.LINE_AA)returnimgdefvis_bbox(img,bbox,thick=1):\"\"\"Visualizesaboundingbox.\"\"\"img=img.astype(np.uint8)(x0,y0,w,h)=bboxx1,y1=int(x0+w),int(y0+h)x0,y0=int(x0),int(y0)cv2.rectangle(img,(x0,y0),(x1,y1),_GREEN,thickness=thick)returnimgdefvis_keypoints(img,kps,kp_thresh=2,alpha=0.7):\"\"\"Visualizeskeypoints(adaptedfromvis_one_image).kpshasshape(4,#keypoints)where4rowsare(x,y,logit,prob).\"\"\"dataset_keypoints,_=keypoint_utils.get_keypoints()kp_lines=kp_connections(dataset_keypoints)#Convertfromplt0-1RGBAcolorsto0-255BGRcolorsforopencv.cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]colors=[(c[2]*255,c[1]*255,c[0]*255)forcincolors]#Performthedrawingonacopyoftheimage,toallowforblending.kp_mask=np.copy(img)#Drawmidshoulder/midhipfirstforbettervisualization.mid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])nose_idx=dataset_keypoints.index(\\'nose\\')ifsc_mid_shoulder>kp_threshandkps[2,nose_idx]>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(kps[:2,nose_idx]),color=colors[len(kp_lines)],thickness=2,lineType=cv2.LINE_AA)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(mid_hip),color=colors[len(kp_lines)+1],thickness=2,lineType=cv2.LINE_AA)#Drawthekeypoints.forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]p1=kps[0,i1],kps[1,i1]p2=kps[0,i2],kps[1,i2]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:cv2.line(kp_mask,p1,p2,color=colors[l],thickness=2,lineType=cv2.LINE_AA)ifkps[2,i1]>kp_thresh:cv2.circle(kp_mask,p1,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)ifkps[2,i2]>kp_thresh:cv2.circle(kp_mask,p2,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)#Blendthekeypoints.returncv2.addWeighted(img,1.0-alpha,kp_mask,alpha,0)defvis_one_image_opencv(im,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,show_box=False,dataset=None,show_class=False):\"\"\"Constructsanumpyarraywiththedetectionsvisualized.\"\"\"ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)ifboxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh:returnimifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap()mask_color_id=0#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ifshow_box:im=vis_bbox(im,(bbox[0],bbox[1],bbox[2]-bbox[0],bbox[3]-bbox[1]))#showclass(offbydefault)ifshow_class:class_str=get_class_string(classes[i],score,dataset)im=vis_class(im,(bbox[0],bbox[1]-2),class_str)#showmaskifsegmsisnotNoneandlen(segms)>i:color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1im=vis_mask(im,masks[...,i],color_mask)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:im=vis_keypoints(im,keypoints[i],kp_thresh)returnimdefvis_one_image(im,im_name,output_dir,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,dpi=200,box_alpha=0.0,dataset=None,show_class=False,ext=\\'pdf\\',out_when_no_box=False):\"\"\"Visualdebuggingofdetections.\"\"\"ifnotos.path.exists(output_dir):os.makedirs(output_dir)ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)if(boxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh)andnotout_when_no_box:returndataset_keypoints,_=keypoint_utils.get_keypoints()ifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap(rgb=True)/255kp_lines=kp_connections(dataset_keypoints)cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]fig=plt.figure(frameon=False)fig.set_size_inches(im.shape[1]/dpi,im.shape[0]/dpi)ax=plt.Axes(fig,[0.,0.,1.,1.])ax.axis(\\'off\\')fig.add_axes(ax)ax.imshow(im)ifboxesisNone:sorted_inds=[]#avoidcrashwhen\\'boxes\\'isNoneelse:#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)mask_color_id=0foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ax.add_patch(plt.Rectangle((bbox[0],bbox[1]),bbox[2]-bbox[0],bbox[3]-bbox[1],fill=False,edgecolor=\\'g\\',linewidth=0.5,alpha=box_alpha))ifshow_class:ax.text(bbox[0],bbox[1]-2,get_class_string(classes[i],score,dataset),fontsize=3,family=\\'serif\\',bbox=dict(facecolor=\\'g\\',alpha=0.4,pad=0,edgecolor=\\'none\\'),color=\\'white\\')#showmaskifsegmsisnotNoneandlen(segms)>i:img=np.ones(im.shape)color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1w_ratio=.4forcinrange(3):color_mask[c]=color_mask[c]*(1-w_ratio)+w_ratioforcinrange(3):img[:,:,c]=color_mask[c]e=masks[:,:,i]contour=cv2.findContours(e.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]forcincontour:polygon=Polygon(c.reshape((-1,2)),fill=True,facecolor=color_mask,edgecolor=\\'w\\',linewidth=1.2,alpha=0.5)ax.add_patch(polygon)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:kps=keypoints[i]plt.autoscale(False)forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:x=[kps[0,i1],kps[0,i2]]y=[kps[1,i1],kps[1,i2]]line=plt.plot(x,y)plt.setp(line,color=colors[l],linewidth=1.0,alpha=0.7)ifkps[2,i1]>kp_thresh:plt.plot(kps[0,i1],kps[1,i1],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)ifkps[2,i2]>kp_thresh:plt.plot(kps[0,i2],kps[1,i2],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)#addmidshoulder/midhipforbettervisualizationmid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])if(sc_mid_shoulder>kp_threshandkps[2,dataset_keypoints.index(\\'nose\\')]>kp_thresh):x=[mid_shoulder[0],kps[0,dataset_keypoints.index(\\'nose\\')]]y=[mid_shoulder[1],kps[1,dataset_keypoints.index(\\'nose\\')]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)],linewidth=1.0,alpha=0.7)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:x=[mid_shoulder[0],mid_hip[0]]y=[mid_shoulder[1],mid_hip[1]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)+1],linewidth=1.0,alpha=0.7)output_name=os.path.basename(im_name)+\\'.\\'+extfig.savefig(os.path.join(output_dir,\\'{}\\'.format(output_name)),dpi=dpi)plt.close(\\'all\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelpfulutilitiesforworkingwithCaffe2.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromsiximportstring_typesimportcontextlibimportsubprocessfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportdyndepfromcaffe2.pythonimportscopefromcaffe2.pythonimportworkspaceimportdetectron.utils.envasenvudefimport_contrib_ops():\"\"\"ImportcontribopsneededbyDetectron.\"\"\"envu.import_nccl_ops()defimport_detectron_ops():\"\"\"ImportDetectronops.\"\"\"detectron_ops_lib=envu.get_detectron_ops_lib()dyndep.InitOpsLibrary(detectron_ops_lib)defimport_custom_ops():\"\"\"Importcustomops.\"\"\"custom_ops_lib=envu.get_custom_ops_lib()dyndep.InitOpsLibrary(custom_ops_lib)defSuffixNet(name,net,prefix_len,outputs):\"\"\"ReturnsanewNetfromthegivenNet(`net`)thatincludesonlytheopsafterremovingthefirst`prefix_len`numberofops.ThenewNetisthusasuffixof`net`.Blobslistedin`outputs`areregisteredasexternaloutputblobs.\"\"\"outputs=BlobReferenceList(outputs)foroutputinoutputs:assertnet.BlobIsDefined(output)new_net=net.Clone(name)delnew_net.Proto().op[:]delnew_net.Proto().external_input[:]delnew_net.Proto().external_output[:]#Addsuffixopsnew_net.Proto().op.extend(net.Proto().op[prefix_len:])#Addexternalinputblobs#Treatanyundefinedblobsasexternalinputsinput_names=[iforopinnew_net.Proto().opforiinop.inputifnotnew_net.BlobIsDefined(i)]new_net.Proto().external_input.extend(input_names)#Addexternaloutputblobsoutput_names=[str(o)foroinoutputs]new_net.Proto().external_output.extend(output_names)returnnew_net,[new_net.GetBlobRef(o)foroinoutput_names]defBlobReferenceList(blob_ref_or_list):\"\"\"EnsurethattheargumentisreturnedasalistofBlobReferences.\"\"\"ifisinstance(blob_ref_or_list,core.BlobReference):return[blob_ref_or_list]eliftype(blob_ref_or_list)in(list,tuple):forbinblob_ref_or_list:assertisinstance(b,core.BlobReference)returnblob_ref_or_listelse:raiseTypeError(\\'blob_ref_or_listmustbeaBlobReferenceoralist/tupleof\\'\\'BlobReferences\\')defUnscopeName(possibly_scoped_name):\"\"\"Removeanynamescopingfroma(possibly)scopedname.Forexample,convertthename\\'gpu_0/foo\\'to\\'foo\\'.\"\"\"assertisinstance(possibly_scoped_name,string_types)returnpossibly_scoped_name[possibly_scoped_name.rfind(scope._NAMESCOPE_SEPARATOR)+1:]@contextlib.contextmanagerdefNamedCudaScope(gpu_id):\"\"\"CreatesaGPUnamescopeandCUDAdevicescope.Thisfunctionisprovidedtoreduce`with...`nestinglevels.\"\"\"withGpuNameScope(gpu_id):withCudaScope(gpu_id):yield@contextlib.contextmanagerdefGpuNameScope(gpu_id):\"\"\"CreateanamescopeforGPUdevice`gpu_id`.\"\"\"withcore.NameScope(\\'gpu_{:d}\\'.format(gpu_id)):yield@contextlib.contextmanagerdefCudaScope(gpu_id):\"\"\"CreateaCUDAdevicescopeforGPUdevice`gpu_id`.\"\"\"gpu_dev=CudaDevice(gpu_id)withcore.DeviceScope(gpu_dev):yield@contextlib.contextmanagerdefCpuScope():\"\"\"CreateaCPUdevicescope.\"\"\"cpu_dev=core.DeviceOption(caffe2_pb2.CPU)withcore.DeviceScope(cpu_dev):yielddefCudaDevice(gpu_id):\"\"\"CreateaCudadevice.\"\"\"returncore.DeviceOption(caffe2_pb2.CUDA,gpu_id)defgauss_fill(std):\"\"\"Gaussianfillhelpertoreduceverbosity.\"\"\"return(\\'GaussianFill\\',{\\'std\\':std})defconst_fill(value):\"\"\"Constantfillhelpertoreduceverbosity.\"\"\"return(\\'ConstantFill\\',{\\'value\\':value})defget_nvidia_info():return(get_nvidia_smi_output(),workspace.GetCUDAVersion(),workspace.GetCuDNNVersion(),)defget_nvidia_smi_output():try:info=subprocess.check_output([\"nvidia-smi\"],stderr=subprocess.STDOUT)info=info.decode(\"utf8\")exceptExceptionase:info=\"Executingnvidia-smifailed:\"+str(e)returninfo.strip()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelperfunctionsforworkingwithCaffe2networks(i.e.,operatorgraphs).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportosimportpprintfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvulogger=logging.getLogger(__name__)logger.setLevel(logging.INFO)definitialize_from_weights_file(model,weights_file,broadcast=True):\"\"\"Initializeamodelfromweightsstoredinapickleddictionary.IfmultipleGPUsareused,theloadedweightsaresynchronizedonallGPUs,unless\\'broadcast\\'isFalse.\"\"\"initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)ifbroadcast:broadcast_parameters(model)definitialize_gpu_from_weights_file(model,weights_file,gpu_id=0):\"\"\"InitializeanetworkwithopsonaspecificGPU.IfyouuseCUDA_VISIBLE_DEVICEStotargetspecificGPUs,Caffe2willautomaticallymaplogicalGPUids(startingfrom0)tothephysicalGPUsspecifiedinCUDA_VISIBLE_DEVICES.\"\"\"logger.info(\\'Loadingweightsfrom:{}\\'.format(weights_file))ws_blobs=workspace.Blobs()src_blobs=load_object(weights_file)if\\'cfg\\'insrc_blobs:saved_cfg=load_cfg(src_blobs[\\'cfg\\'])configure_bbox_reg_weights(model,saved_cfg)if\\'blobs\\'insrc_blobs:#Backwardscompat--dictionaryusedtobeonlyblobs,nowtheyare#storedunderthe\\'blobs\\'keysrc_blobs=src_blobs[\\'blobs\\']#InitializeweightsonGPUgpu_idonlyunscoped_param_names=OrderedDict()#Printtheseoutinmodelorderforblobinmodel.params:unscoped_param_names[c2_utils.UnscopeName(str(blob))]=Truewithc2_utils.NamedCudaScope(gpu_id):forunscoped_param_nameinunscoped_param_names.keys():if(unscoped_param_name.find(\\']_\\')>=0andunscoped_param_namenotinsrc_blobs):#Specialcaseforsharinginitializationfromapretrained#model:#Ifablobnamed\\'_[xyz]_foo\\'isinmodel.paramsandnotin#theinitializationblobdictionary,thenloadsourceblob#\\'foo\\'intodestinationblob\\'_[xyz]_foo\\'src_name=unscoped_param_name[unscoped_param_name.find(\\']_\\')+2:]else:src_name=unscoped_param_nameifsrc_namenotinsrc_blobs:logger.info(\\'{:s}notfound\\'.format(src_name))continuedst_name=core.ScopedName(unscoped_param_name)has_momentum=src_name+\\'_momentum\\'insrc_blobshas_momentum_str=\\'[+momentum]\\'ifhas_momentumelse\\'\\'logger.info(\\'{:s}{:}loadedfromweightsfileinto{:s}:{}\\'.format(src_name,has_momentum_str,dst_name,src_blobs[src_name].shape))ifdst_nameinws_blobs:#Iftheblobisalreadyintheworkspace,makesurethatit#matchestheshapeoftheloadedblobws_blob=workspace.FetchBlob(dst_name)assertws_blob.shape==src_blobs[src_name].shape,\\\\(\\'Workspaceblob{}withshape{}doesnotmatch\\'\\'weightsfileshape{}\\').format(src_name,ws_blob.shape,src_blobs[src_name].shape)workspace.FeedBlob(dst_name,src_blobs[src_name].astype(np.float32,copy=False))ifhas_momentum:workspace.FeedBlob(dst_name+\\'_momentum\\',src_blobs[src_name+\\'_momentum\\'].astype(np.float32,copy=False))#Wepreserveblobsthatareintheweightsfilebutnotusedbythecurrent#model.WeloadtheseintoCPUmemoryunderthe\\'__preserve__/\\'namescope.#Theseblobswillbestoredwhensavingamodeltoaweightsfile.This#featureallowsforalternatingoptimizationofFasterR-CNNinwhichblobs#unusedbyonestepcanstillbepreservedforwardandusedtoinitialize#anotherstep.forsrc_nameinsrc_blobs.keys():if(src_namenotinunscoped_param_namesandnotsrc_name.endswith(\\'_momentum\\')andsrc_blobs[src_name]isnotNone):withc2_utils.CpuScope():workspace.FeedBlob(\\'__preserve__/{:s}\\'.format(src_name),src_blobs[src_name])logger.info(\\'{:s}preservedinworkspace(unused)\\'.format(src_name))defsave_model_to_weights_file(weights_file,model):\"\"\"Stashmodelweightsinadictionaryandpicklethemtoafile.WemapGPUdevicescopednamestounscopednames(e.g.,\\'gpu_0/conv1_w\\'->\\'conv1_w\\').\"\"\"logger.info(\\'Savingparametersandmomentumto{}\\'.format(os.path.abspath(weights_file)))blobs={}#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savemomentumforparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savepreservedblobsforscoped_nameinworkspace.Blobs():ifscoped_name.startswith(\\'__preserve__/\\'):unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}(preserved)\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)cfg_yaml=envu.yaml_dump(cfg)save_object(dict(blobs=blobs,cfg=cfg_yaml),weights_file)defbroadcast_parameters(model):\"\"\"CopyparameterblobsfromGPU0overthecorrespondingparameterblobsonGPUs1throughcfg.NUM_GPUS-1.\"\"\"ifcfg.NUM_GPUS==1:#no-opifonlyrunningonasingleGPUreturndef_do_broadcast(all_blobs):assertlen(all_blobs)%cfg.NUM_GPUS==0,\\\\(\\'UnexpectedvalueforNUM_GPUS.Makesureyouarenot\\'\\'runningsingle-GPUinferencewithNUM_GPUS>1.\\')blobs_per_gpu=int(len(all_blobs)/cfg.NUM_GPUS)foriinrange(blobs_per_gpu):blobs=[pforpinall_blobs[i::blobs_per_gpu]]data=workspace.FetchBlob(blobs[0])logger.debug(\\'Broadcasting{}to\\'.format(str(blobs[0])))fori,pinenumerate(blobs[1:]):logger.debug(\\'|->{}\\'.format(str(p)))withc2_utils.CudaScope(i+1):workspace.FeedBlob(p,data)_do_broadcast(model.params)_do_broadcast([b+\\'_momentum\\'forbinmodel.TrainableParams()])defsum_multi_gpu_blob(blob_name):\"\"\"ReturnthesumofascalarblobheldonmultipleGPUs.\"\"\"val=0foriinrange(cfg.NUM_GPUS):val+=float(workspace.FetchBlob(\\'gpu_{}/{}\\'.format(i,blob_name)))returnvaldefaverage_multi_gpu_blob(blob_name):\"\"\"ReturntheaverageofascalarblobheldonmultipleGPUs.\"\"\"returnsum_multi_gpu_blob(blob_name)/cfg.NUM_GPUSdefprint_net(model,namescope=\\'gpu_0\\'):\"\"\"Printthemodelnetwork.\"\"\"logger.info(\\'Printingmodel:{}\\'.format(model.net.Name()))op_list=model.net.Proto().opforopinop_list:input_name=op.input#Forsimplicity:onlyprintthefirstoutput#Notrecommendediftherearesplitlayersoutput_name=str(op.output[0])op_type=op.typeop_name=op.nameifnamescopeisNoneoroutput_name.startswith(namescope):#Onlyprinttheforwardpassnetworkifoutput_name.find(\\'grad\\')>=0oroutput_name.find(\\'__m\\')>=0:continuetry:#Undersomeconditions(e.g.,dynamicmemoryoptimization)#itispossiblethatthenetworkfreessomeblobswhentheyare#nolongerneeded.Handlethiscase...output_shape=workspace.FetchBlob(output_name).shapeexceptBaseException:output_shape=\\'\\'first_blob=Trueop_label=op_type+(op_nameifop_name==\\'\\'else\\':\\'+op_name)suffix=\\'-------(op:{})\\'.format(op_label)forjinrange(len(input_name)):ifinput_name[j]inmodel.params:continueinput_blob=workspace.FetchBlob(input_name[j])ifisinstance(input_blob,np.ndarray):input_shape=input_blob.shapelogger.info(\\'{:28s}:{:20s}=>{:28s}:{:20s}{}\\'.format(c2_utils.UnscopeName(str(input_name[j])),\\'{}\\'.format(input_shape),c2_utils.UnscopeName(str(output_name)),\\'{}\\'.format(output_shape),suffix))iffirst_blob:first_blob=Falsesuffix=\\'------|\\'logger.info(\\'Endofmodel:{}\\'.format(model.net.Name()))defconfigure_bbox_reg_weights(model,saved_cfg):\"\"\"Compatibilityforoldmodelstrainedwithboundingboxregressionmean/stdnormalization(insteadoffixedweights).\"\"\"if\\'MODEL\\'notinsaved_cfgor\\'BBOX_REG_WEIGHTS\\'notinsaved_cfg.MODEL:logger.warning(\\'Modelfromweightsfilewastrainedbeforeconfigkey\\'\\'MODEL.BBOX_REG_WEIGHTSwasadded.Forcing\\'\\'MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)toensure\\'\\'correct**inference**behavior.\\')#Generallywedon\\'tallowmodifyingtheconfig,butthisisaone-off#hacktosupportsomeveryoldmodelsis_immutable=cfg.is_immutable()cfg.immutable(False)cfg.MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)cfg.immutable(is_immutable)logger.info(\\'Newconfig:\\')logger.info(pprint.pformat(cfg))assertnotmodel.train,(\\'Thismodelwastrainedwithanolderversionofthecodethat\\'\\'usedboundingboxregressionmean/stdnormalization.Itcanno\\'\\'longerbeusedfortraining.Toupgradeittoatrainablemodel\\'\\'pleaseusefb/compat/convert_bbox_reg_normalized_model.py.\\')defget_group_gn(dim):\"\"\"getnumberofgroupsusedbyGroupNorm,basedonnumberofchannels\"\"\"dim_per_gp=cfg.GROUP_NORM.DIM_PER_GPnum_groups=cfg.GROUP_NORM.NUM_GROUPSassertdim_per_gp==-1ornum_groups==-1,\\\\\"GroupNorm:canonlyspecifyGorC/G.\"ifdim_per_gp>0:assertdim%dim_per_gp==0group_gn=dim//dim_per_gpelse:assertdim%num_groups==0group_gn=num_groupsreturngroup_gn#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesfortraining.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportdatetimeimportnumpyasnpfromcaffe2.pythonimportutilsasc2_py_utilsfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportlog_json_statsfromdetectron.utils.loggingimportSmoothedValuefromdetectron.utils.timerimportTimerimportdetectron.utils.netasnuclassTrainingStats:\"\"\"Trackvitaltrainingstatistics.\"\"\"def__init__(self,model):#Windowsizeforsmoothingtrackedvalues(withmedianfiltering)self.WIN_SZ=20#OutputloggingperiodinSGDiterationsself.LOG_PERIOD=20self.smoothed_losses_and_metrics={key:SmoothedValue(self.WIN_SZ)forkeyinmodel.losses+model.metrics}self.losses_and_metrics={key:0forkeyinmodel.losses+model.metrics}self.smoothed_total_loss=SmoothedValue(self.WIN_SZ)self.smoothed_mb_qsize=SmoothedValue(self.WIN_SZ)self.iter_total_loss=np.nanself.iter_timer=Timer()self.model=modeldefIterTic(self):self.iter_timer.tic()defIterToc(self):returnself.iter_timer.toc(average=False)defResetIterTimer(self):self.iter_timer.reset()defUpdateIterStats(self):\"\"\"Updatetrackediterationstatistics.\"\"\"forkinself.losses_and_metrics.keys():ifkinself.model.losses:self.losses_and_metrics[k]=nu.sum_multi_gpu_blob(k)else:self.losses_and_metrics[k]=nu.average_multi_gpu_blob(k)fork,vinself.smoothed_losses_and_metrics.items():v.AddValue(self.losses_and_metrics[k])self.iter_total_loss=np.sum(np.array([self.losses_and_metrics[k]forkinself.model.losses]))self.smoothed_total_loss.AddValue(self.iter_total_loss)self.smoothed_mb_qsize.AddValue(self.model.roi_data_loader._minibatch_queue.qsize())defLogIterStats(self,cur_iter,lr):\"\"\"Logthetrackedstatistics.\"\"\"if(cur_iter%self.LOG_PERIOD==0orcur_iter==cfg.SOLVER.MAX_ITER-1):stats=self.GetStats(cur_iter,lr)log_json_stats(stats)defGetStats(self,cur_iter,lr):eta_seconds=self.iter_timer.average_time*(cfg.SOLVER.MAX_ITER-cur_iter)eta=str(datetime.timedelta(seconds=int(eta_seconds)))mem_stats=c2_py_utils.GetGPUMemoryUsageStats()mem_usage=np.max(mem_stats[\\'max_by_gpu\\'][:cfg.NUM_GPUS])stats=dict(iter=cur_iter,lr=float(lr),time=self.iter_timer.average_time,loss=self.smoothed_total_loss.GetMedianValue(),eta=eta,mb_qsize=int(np.round(self.smoothed_mb_qsize.GetMedianValue())),mem=int(np.ceil(mem_usage/1024/1024)))fork,vinself.smoothed_losses_and_metrics.items():stats[k]=v.GetMedianValue()returnstats#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\\'\\'\\'Helperfunctionsformodelconversiontopb\\'\\'\\'from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromfunctoolsimportwrapsimportcopyimportnumpyasnpfromcaffe2.pythonimportcore,workspacefromcaffe2.protoimportcaffe2_pb2classOpFilter:def__init__(self,**kwargs):self.type=Noneself.type_in=Noneself.inputs=Noneself.outputs=Noneself.input_has=Noneself.output_has=Noneself.cond=Noneself.reverse=Falseassertall([xinself.__dict__forxinkwargs])self.__dict__.update(kwargs)defcheck(self,op):ret=self.reverseifself.typeandop.type!=self.type:returnretifself.type_inandop.typenotinself.type_in:returnretifself.inputsandset(op.input)!=set(self.inputs):returnretifself.outputsandset(op.output)!=set(self.outputs):returnretifself.input_hasandself.input_hasnotinop.input:returnretifself.output_hasandself.output_hasnotinop.output:returnretifself.condisnotNoneandnotself.cond:returnretreturnnotretdeffilter_op(op,**kwargs):\\'\\'\\'Returnstrueifpassedallchecks\\'\\'\\'returnOpFilter(**kwargs).check(op)defop_filter(**filter_args):\\'\\'\\'ReturnsNoneifnoconditionissatisfied\\'\\'\\'defactual_decorator(f):@wraps(f)defwrapper(op,**params):ifnotfilter_op(op,**filter_args):returnNonereturnf(op,**params)returnwrapperreturnactual_decoratordefop_func_chain(convert_func_list):\\'\\'\\'RunfuncsonebyoneuntilfuncreturnisnotNone\\'\\'\\'assertisinstance(convert_func_list,list)def_chain(op):forxinconvert_func_list:ret=x(op)ifretisnotNone:returnretreturnNonereturn_chaindefconvert_op_in_ops(ops_ref,func_or_list):func=func_or_listifisinstance(func_or_list,list):func=op_func_chain(func_or_list)ops=[opforopinops_ref]converted_ops=[]foropinops:new_ops=func(op)ifnew_opsisnotNoneandnotisinstance(new_ops,list):new_ops=[new_ops]converted_ops.extend(new_opsifnew_opsisnotNoneelse[op])delops_ref[:]#ops_refmaybeoftypeRepeatedCompositeFieldContainer#whichdoesnothaveappend()ops_ref.extend(converted_ops)defconvert_op_in_proto(proto,func_or_list):convert_op_in_ops(proto.op,func_or_list)defget_op_arg(op,arg_name):forxinop.arg:ifx.name==arg_name:returnxreturnNonedefget_op_arg_valf(op,arg_name,default_val):arg=get_op_arg(op,arg_name)returnarg.fifargisnotNoneelsedefault_valdefupdate_mobile_engines(net):foropinnet.op:ifop.type==\"Conv\":op.engine=\"NNPACK\"ifop.type==\"ConvTranspose\":op.engine=\"BLOCK\"defpairwise(iterable):\"s->(s0,s1),(s1,s2),(s2,s3),...\"fromitertoolsimportteea,b=tee(iterable)next(b,None)returnzip(a,b)defblob_uses(net,blob):u=[]fori,opinenumerate(net.op):ifblobinop.inputorblobinop.control_input:u.append(i)returnudeffuse_first_affine(net,params,removed_tensors):net=copy.deepcopy(net)params=copy.deepcopy(params)for((i,current),(j,next_))inpairwise(enumerate(net.op)):ifnext_.input[0]!=current.output[0]:continueifcurrent.typenotin(\"Conv\",\"ConvTranspose\")\\\\ornext_.type!=\"AffineChannel\":continueifcurrent.output[0]!=next_.output[0]and\\\\len(blob_uses(net,current.output[0]))!=1:#Can\\'tfuseifmorethanoneuserunlessAffineChannelisinplacecontinue#else,canfuseconv=currentaffine=next_fused_conv=copy.deepcopy(conv)fused_conv.output[0]=affine.output[0]conv_weight=params[conv.input[1]]conv_has_bias=len(conv.input)>2conv_bias=params[conv.input[2]]ifconv_has_biaselse0A=params[affine.input[1]]B=params[affine.input[2]]#Thus,canjusthavetheaffinetransform#X*A+B#where#A=bn_scale*1.0/(sqrt(running_var+eps))#B=(bias-running_mean*(1.0/sqrt(running_var+eps))#*bn_scale)#Thisidentifyshouldholdifwehavecorrectlyfused#np.testing.assert_array_equal(#params[conv.output[0]]*A+B,#params[bn.output[0]])#Now,wehavethatthecomputationmadeisthefollowing:#((X`conv`W)+b)*A+B#Then,wecansimplyfusethisasfollows:#(X`conv`(W*A))+b*A+B#whichissimply#(X`conv`Q)+C#where#Q=W*A#C=b*A+B#ForConvTranspose,fromtheviewofconvolutionsasa#Toepelizmultiplication,wehaveW_=W^T,sotheweights#arelaidoutas(R,S,K,K)(vs(S,R,K,K)foraConv),#sotheweightsbroadcastslightlydifferently.Remember,our#BNscale\\'B\\'isofsize(S,)A_=A.reshape(-1,1,1,1)ifconv.type==\"Conv\"else\\\\A.reshape(1,-1,1,1)C=conv_bias*A+BQ=conv_weight*A_assertparams[conv.input[1]].shape==Q.shapeparams[conv.input[1]]=Qifconv_has_bias:assertparams[conv.input[2]].shape==C.shapeparams[conv.input[2]]=Celse:#makeaf_biastobebiasoftheconvlayerfused_conv.input.append(affine.input[2])params[affine.input[2]]=Bnew_ops=net.op[:i]+[fused_conv]+net.op[j+1:]delnet.op[:]ifconv_has_bias:delparams[affine.input[2]]removed_tensors.append(affine.input[2])removed_tensors.append(affine.input[1])delparams[affine.input[1]]net.op.extend(new_ops)breakreturnnet,params,removed_tensorsdeffuse_affine(net,params,ignore_failure):#Rununtilwehitafixedpointremoved_tensors=[]whileTrue:(next_net,next_params,removed_tensors)=\\\\fuse_first_affine(net,params,removed_tensors)iflen(next_net.op)==len(net.op):if(any(op.type==\"AffineChannel\"foropinnext_net.op)andnotignore_failure):raiseException(\"ModelcontainsAffineChannelopafterfusion:%s\",next_net)return(next_net,next_params,removed_tensors)net,params,removed_tensors=(next_net,next_params,removed_tensors)deffuse_net(fuse_func,net,blobs,ignore_failure=False):is_core_net=isinstance(net,core.Net)ifis_core_net:net=net.Proto()net,params,removed_tensors=fuse_func(net,blobs,ignore_failure)forrtinremoved_tensors:net.external_input.remove(rt)ifis_core_net:net=core.Net(net)returnnet,paramsdeffuse_net_affine(net,blobs):returnfuse_net(fuse_affine,net,blobs)defadd_tensor(net,name,blob):\\'\\'\\'Createanoperatortostorethetensor\\'blob\\',runtheoperatortoputtheblobtoworkspace.uint8isstoredasanarrayofstringwithoneelement.\\'\\'\\'kTypeNameMapper={np.dtype(\\'float32\\'):\"GivenTensorFill\",np.dtype(\\'int32\\'):\"GivenTensorIntFill\",np.dtype(\\'int64\\'):\"GivenTensorInt64Fill\",np.dtype(\\'uint8\\'):\"GivenTensorStringFill\",}shape=blob.shapevalues=blob#passarrayofuint8asastringtosavestorage#storinguint8_thasalargeoverheadfornowifblob.dtype==np.dtype(\\'uint8\\'):shape=[1]values=[str(blob.data)]op=core.CreateOperator(kTypeNameMapper[blob.dtype],[],[name],shape=shape,values=values,#arg=[#putils.MakeArgument(\"shape\",shape),#putils.MakeArgument(\"values\",values),#])net.op.extend([op])defgen_init_net_from_blobs(blobs,blobs_to_use=None,excluded_blobs=None):\\'\\'\\'Generateaninitializationnetbasedonablobdict\\'\\'\\'ret=caffe2_pb2.NetDef()ifblobs_to_useisNone:blobs_to_use={xforxinblobs}else:blobs_to_use=copy.deepcopy(blobs_to_use)ifexcluded_blobsisnotNone:blobs_to_use=[xforxinblobs_to_useifxnotinexcluded_blobs]fornameinblobs_to_use:blob=blobs[name]ifisinstance(blob,str):print(\\'Blob{}withtype{}isnots',\n",
       " 'upportedingeneratinginitnet,\\'\\'skipped.\\'.format(name,type(blob)))continueadd_tensor(ret,name,blob)returnretdefget_ws_blobs(blob_names=None):\\'\\'\\'Getblobsin\\'blob_names\\'inthedefaultworkspace,getallblobsifblob_namesisNone\\'\\'\\'blobs={}ifblob_namesisNone:blob_names=workspace.Blobs()blobs={x:workspace.FetchBlob(x)forxinblob_names}returnblobsdefget_device_option_cpu():device_option=core.DeviceOption(caffe2_pb2.CPU)returndevice_optiondefget_device_option_cuda(gpu_id=0):device_option=caffe2_pb2.DeviceOption()device_option.device_type=caffe2_pb2.CUDAdevice_option.device_id=gpu_idreturndevice_optiondefcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)defcompare_model(model1_func,model2_func,test_image,check_blobs):\\'\\'\\'model_func(test_image,check_blobs)\\'\\'\\'cb1,cb2=check_blobs,check_blobsifisinstance(check_blobs,dict):cb1=check_blobs.keys()cb2=check_blobs.values()print(\\'Runningthefirstmodel...\\')res1=model1_func(test_image,check_blobs)print(\\'Runningthesecondmodel...\\')res2=model2_func(test_image,check_blobs)foridxinrange(len(cb1)):print(\\'Checking{}->{}...\\'.format(cb1[idx],cb2[idx]))n1,n2=cb1[idx],cb2[idx]r1=res1[n1]ifn1inres1elseNoner2=res2[n2]ifn2inres2elseNoneassertr1isnotNoneorr2isNone,\\\\\"Blob{}inmodel1isNone\".format(n1)assertr2isnotNoneorr1isNone,\\\\\"Blob{}inmodel2isNone\".format(n2)assertr1.shape==r2.shape,\\\\\"Blob{}and{}shapemismatched:{}vs{}\".format(n1,n2,r1.shape,r2.shape)np.testing.assert_array_almost_equal(r1,r2,decimal=3,err_msg=\\'{}and{}notmatched.Maxdiff:{}\\'.format(n1,n2,np.amax(np.absolute(r1-r2))))returnTrue#graph_namecouldnotcontainword\\'graph\\'defsave_graph(net,file_name,graph_name=\"net\",op_only=True):fromcaffe2.pythonimportnet_drawergraph=Noneops=net.opifnotop_only:graph=net_drawer.GetPydotGraph(ops,graph_name,rankdir=\"TB\")else:graph=net_drawer.GetPydotGraphMinimal(ops,graph_name,rankdir=\"TB\",minimal_dependency=True)try:graph.write_png(file_name)exceptExceptionase:print(\\'Errorwhenwritinggraphtoimage{}\\'.format(e))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Caffe2blobhelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromsix.movesimportcPickleaspicklefromcaffe2.protoimportcaffe2_pb2fromdetectron.core.configimportcfgdefget_image_blob(im,target_scale,target_max_size):\"\"\"Convertanimageintoanetworkinput.Arguments:im(ndarray):acolorimageinBGRorderReturns:blob(ndarray):adatablobholdinganimagepyramidim_scale(float):imagescale(targetsize)/(originalsize)im_info(ndarray)\"\"\"processed_im,im_scale=prep_im_for_blob(im,cfg.PIXEL_MEANS,target_scale,target_max_size)blob=im_list_to_blob(processed_im)#NOTE:thisheightandwidthmaybelargerthanactualscaledinputimage#duetotheFPN.COARSEST_STRIDErelatedpaddinginim_list_to_blob.Weare#maintainingthisbehaviorfornowtomakeexistingresultsexactly#reproducible(inpracticeusingthetrueinputimageheightandwidth#yieldsnearlythesameresults,buttheyaresometimesslightlydifferent#becausepredictionsneartheedgeoftheimagewillbeprunedmore#aggressively).height,width=blob.shape[2],blob.shape[3]im_info=np.hstack((height,width,im_scale))[np.newaxis,:]returnblob,im_scale,im_info.astype(np.float32)defim_list_to_blob(ims):\"\"\"Convertalistofimagesintoanetworkinput.Assumesimageswerepreparedusingprep_im_for_bloborequivalent:i.e.-BGRchannelorder-pixelmeanssubtracted-resizedtothedesiredinputsize-float32numpyndarrayformatOutputisa4DHCHWtensoroftheimagesconcatenatedalongaxis0withshape.\"\"\"ifnotisinstance(ims,list):ims=[ims]max_shape=np.array([im.shapeforiminims]).max(axis=0)#Padtheimagesotheycanbedivisiblebyastrideifcfg.FPN.FPN_ON:stride=float(cfg.FPN.COARSEST_STRIDE)max_shape[0]=int(np.ceil(max_shape[0]/stride)*stride)max_shape[1]=int(np.ceil(max_shape[1]/stride)*stride)num_images=len(ims)blob=np.zeros((num_images,max_shape[0],max_shape[1],3),dtype=np.float32)foriinrange(num_images):im=ims[i]blob[i,0:im.shape[0],0:im.shape[1],:]=im#Movechannels(axis3)toaxis1#Axisorderwillbecome:(batchelem,channel,height,width)channel_swap=(0,3,1,2)blob=blob.transpose(channel_swap)returnblobdefprep_im_for_blob(im,pixel_means,target_size,max_size):\"\"\"Prepareanimageforuseasanetworkinputblob.Specially:-Subtractper-channelpixelmean-Converttofloat32-Rescaletoeachofthespecifiedtargetsize(cappedatmax_size)Returnsalistoftransformedimages,oneforeachtargetsize.Alsoreturnsthescalefactorsthatwereusedtocomputeeachreturnedimage.\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)#Preventthebiggestaxisfrombeingmorethanmax_sizeifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)returnim,im_scaledefzeros(shape,int32=False):\"\"\"Returnablobofallzerosofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.zeros(shape,dtype=np.int32ifint32elsenp.float32)defones(shape,int32=False):\"\"\"Returnablobofallonesofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.ones(shape,dtype=np.int32ifint32elsenp.float32)defpy_op_copy_blob(blob_in,blob_out):\"\"\"Copyanumpyndarraygivenasblob_inintotheCaffe2CPUTensorblobgivenasblob_out.Supportsfloat32andint32blobdatatypes.ThisfunctionisintendedforcopyingnumpydataintoaCaffe2blobinPythonOps.\"\"\"#SomeawkwardvoodoorequiredbyCaffe2tosupportint32blobsneeds_int32_init=Falsetry:_=blob.data.dtype#noqaexceptException:needs_int32_init=blob_in.dtype==np.int32ifneeds_int32_init:#initcanonlytakealist(failedontuple)blob_out.init(list(blob_in.shape),caffe2_pb2.TensorProto.INT32)else:blob_out.reshape(blob_in.shape)blob_out.data[...]=blob_indefget_loss_gradients(model,loss_blobs):\"\"\"Generateagradientof1foreachlossspecifiedin\\'loss_blobs\\'\"\"\"loss_gradients={}forbinloss_blobs:loss_grad=model.net.ConstantFill(b,[b+\\'_grad\\'],value=1.0)loss_gradients[str(b)]=str(loss_grad)returnloss_gradientsdefserialize(obj):\"\"\"SerializeaPythonobjectusingpickleandencodeitasanarrayoffloat32valuessothatitcanbefeedintotheworkspace.Seedeserialize().\"\"\"returnnp.fromstring(pickle.dumps(obj),dtype=np.uint8).astype(np.float32)defdeserialize(arr):\"\"\"UnserializeaPythonobjectfromanarrayoffloat32valuesfetchedfromaworkspace.Seeserialize().\"\"\"returnpickle.loads(arr.astype(np.uint8).tobytes())#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Asimpleattributedictionaryusedforrepresentingconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsclassAttrDict(dict):IMMUTABLE=\\'__immutable__\\'def__init__(self,*args,**kwargs):super(AttrDict,self).__init__(*args,**kwargs)self.__dict__[AttrDict.IMMUTABLE]=Falsedef__getattr__(self,name):ifnameinself.__dict__:returnself.__dict__[name]elifnameinself:returnself[name]else:raiseAttributeError(name)def__setattr__(self,name,value):ifnotself.__dict__[AttrDict.IMMUTABLE]:ifnameinself.__dict__:self.__dict__[name]=valueelse:self[name]=valueelse:raiseAttributeError(\\'Attemptedtoset\"{}\"to\"{}\",butAttrDictisimmutable\\'.format(name,value))defimmutable(self,is_immutable):\"\"\"Setimmutabilitytois_immutableandrecursivelyapplythesettingtoallnestedAttrDicts.\"\"\"self.__dict__[AttrDict.IMMUTABLE]=is_immutable#Recursivelysetimmutablestateforvinself.__dict__.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)forvinself.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)defis_immutable(self):returnself.__dict__[AttrDict.IMMUTABLE]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Boxmanipulationfunctions.TheinternalDetectronboxformatis[x1,y1,x2,y2]where(x1,y1)specifythetop-leftboxcornerand(x2,y2)specifythebottom-rightboxcorner.Boxesfromexternalsources,e.g.,datasets,maybeinotherformats(suchas[x,y,w,h])andrequireconversion.Thismoduleusesaconventionthatmayseemstrangeatfirst:thewidthofaboxiscomputedasx2-x1+1(likewiseforheight).The\"+1\"datesbacktooldobjectdetectiondayswhenthecoordinateswereintegerpixelindices,ratherthanfloatingpointcoordinatesinasubpixelcoordinateframe.Aboxwithx2=x1andy2=y1wastakentoincludeasinglepixel,havingawidthof1,andhencerequiringthe\"+1\".Now,mostdatasetswilllikelyprovideboxeswithfloatingpointcoordinatesandthewidthshouldbemorereasonablycomputedasx2-x1.Inpractice,aslongasamodelistrainedandtestedwithaconsistentconventioneitherdecisionseemstobeok(atleastinourexperienceonCOCO).Sincewehavealonghistoryoftrainingmodelswiththe\"+1\"convention,wearereluctanttochangeitevenifourmoderntastesprefernottouseit.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.cython_bboxascython_bboximportdetectron.utils.cython_nmsascython_nmsbbox_overlaps=cython_bbox.bbox_overlapsdefboxes_area(boxes):\"\"\"Computetheareaofanarrayofboxes.\"\"\"w=(boxes[:,2]-boxes[:,0]+1)h=(boxes[:,3]-boxes[:,1]+1)areas=w*hassertnp.all(areas>=0),\\'Negativeareasfounds\\'returnareasdefunique_boxes(boxes,scale=1.0):\"\"\"Returnindicesofuniqueboxes.\"\"\"v=np.array([1,1e3,1e6,1e9])hashes=np.round(boxes*scale).dot(v)_,index=np.unique(hashes,return_index=True)returnnp.sort(index)defxywh_to_xyxy(xywh):\"\"\"Convert[x1y1wh]boxformatto[x1y1x2y2]format.\"\"\"ifisinstance(xywh,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xywh)==4x1,y1=xywh[0],xywh[1]x2=x1+np.maximum(0.,xywh[2]-1.)y2=y1+np.maximum(0.,xywh[3]-1.)return(x1,y1,x2,y2)elifisinstance(xywh,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xywh[:,0:2],xywh[:,0:2]+np.maximum(0,xywh[:,2:4]-1)))else:raiseTypeError(\\'Argumentxywhmustbealist,tuple,ornumpyarray.\\')defxyxy_to_xywh(xyxy):\"\"\"Convert[x1y1x2y2]boxformatto[x1y1wh]format.\"\"\"ifisinstance(xyxy,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xyxy)==4x1,y1=xyxy[0],xyxy[1]w=xyxy[2]-x1+1h=xyxy[3]-y1+1return(x1,y1,w,h)elifisinstance(xyxy,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xyxy[:,0:2],xyxy[:,2:4]-xyxy[:,0:2]+1))else:raiseTypeError(\\'Argumentxyxymustbealist,tuple,ornumpyarray.\\')deffilter_small_boxes(boxes,min_size):\"\"\"Keepboxeswithwidthandheightbothgreaterthanmin_size.\"\"\"w=boxes[:,2]-boxes[:,0]+1h=boxes[:,3]-boxes[:,1]+1keep=np.where((w>min_size)&(h>min_size))[0]returnkeepdefclip_boxes_to_image(boxes,height,width):\"\"\"Clipanarrayofboxestoanimagewiththegivenheightandwidth.\"\"\"boxes[:,[0,2]]=np.minimum(width-1.,np.maximum(0.,boxes[:,[0,2]]))boxes[:,[1,3]]=np.minimum(height-1.,np.maximum(0.,boxes[:,[1,3]]))returnboxesdefclip_xyxy_to_image(x1,y1,x2,y2,height,width):\"\"\"Clipcoordinatestoanimagewiththegivenheightandwidth.\"\"\"x1=np.minimum(width-1.,np.maximum(0.,x1))y1=np.minimum(height-1.,np.maximum(0.,y1))x2=np.minimum(width-1.,np.maximum(0.,x2))y2=np.minimum(height-1.,np.maximum(0.,y2))returnx1,y1,x2,y2defclip_tiled_boxes(boxes,im_shape):\"\"\"Clipboxestoimageboundaries.im_shapeis[height,width]andboxeshasshape(N,4*num_tiled_boxes).\"\"\"assertboxes.shape[1]%4==0,\\\\\\'boxes.shape[1]is{:d},butmustbedivisibleby4.\\'.format(boxes.shape[1])#x1>=0boxes[:,0::4]=np.maximum(np.minimum(boxes[:,0::4],im_shape[1]-1),0)#y1>=0boxes[:,1::4]=np.maximum(np.minimum(boxes[:,1::4],im_shape[0]-1),0)#x2<im_shape[1]boxes[:,2::4]=np.maximum(np.minimum(boxes[:,2::4],im_shape[1]-1),0)#y2<im_shape[0]boxes[:,3::4]=np.maximum(np.minimum(boxes[:,3::4],im_shape[0]-1),0)returnboxesdefbbox_transform(boxes,deltas,weights=(1.0,1.0,1.0,1.0)):\"\"\"Forwardtransformthatmapsproposalboxestopredictedground-truthboxesusingbounding-boxregressiondeltas.Seebbox_transform_invforadescriptionoftheweightsargument.\"\"\"ifboxes.shape[0]==0:returnnp.zeros((0,deltas.shape[1]),dtype=deltas.dtype)boxes=boxes.astype(deltas.dtype,copy=False)widths=boxes[:,2]-boxes[:,0]+1.0heights=boxes[:,3]-boxes[:,1]+1.0ctr_x=boxes[:,0]+0.5*widthsctr_y=boxes[:,1]+0.5*heightswx,wy,ww,wh=weightsdx=deltas[:,0::4]/wxdy=deltas[:,1::4]/wydw=deltas[:,2::4]/wwdh=deltas[:,3::4]/wh#Preventsendingtoolargevaluesintonp.exp()dw=np.minimum(dw,cfg.BBOX_XFORM_CLIP)dh=np.minimum(dh,cfg.BBOX_XFORM_CLIP)pred_ctr_x=dx*widths[:,np.newaxis]+ctr_x[:,np.newaxis]pred_ctr_y=dy*heights[:,np.newaxis]+ctr_y[:,np.newaxis]pred_w=np.exp(dw)*widths[:,np.newaxis]pred_h=np.exp(dh)*heights[:,np.newaxis]pred_boxes=np.zeros(deltas.shape,dtype=deltas.dtype)#x1pred_boxes[:,0::4]=pred_ctr_x-0.5*pred_w#y1pred_boxes[:,1::4]=pred_ctr_y-0.5*pred_h#x2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,2::4]=pred_ctr_x+0.5*pred_w-1#y2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,3::4]=pred_ctr_y+0.5*pred_h-1returnpred_boxesdefbbox_transform_inv(boxes,gt_boxes,weights=(1.0,1.0,1.0,1.0)):\"\"\"Inversetransformthatcomputestargetbounding-boxregressiondeltasgivenproposalboxesandground-truthboxes.Theweightsargumentshouldbea4-tupleofmultiplicativeweightsthatareappliedtotheregressiontarget.Inolderversionsofthiscode(andinpy-faster-rcnn),theweightsweresetsuchthattheregressiondeltaswouldhaveunitstandarddeviationonthetrainingdataset.Presently,ratherthancomputingthesestatisticsexactly,weuseafixedsetofweights(10.,10.,5.,5.)bydefault.TheseareapproximatelytheweightsonewouldgetfromCOCOusingthepreviousunitstdevheuristic.\"\"\"ex_widths=boxes[:,2]-boxes[:,0]+1.0ex_heights=boxes[:,3]-boxes[:,1]+1.0ex_ctr_x=boxes[:,0]+0.5*ex_widthsex_ctr_y=boxes[:,1]+0.5*ex_heightsgt_widths=gt_boxes[:,2]-gt_boxes[:,0]+1.0gt_heights=gt_boxes[:,3]-gt_boxes[:,1]+1.0gt_ctr_x=gt_boxes[:,0]+0.5*gt_widthsgt_ctr_y=gt_boxes[:,1]+0.5*gt_heightswx,wy,ww,wh=weightstargets_dx=wx*(gt_ctr_x-ex_ctr_x)/ex_widthstargets_dy=wy*(gt_ctr_y-ex_ctr_y)/ex_heightstargets_dw=ww*np.log(gt_widths/ex_widths)targets_dh=wh*np.log(gt_heights/ex_heights)targets=np.vstack((targets_dx,targets_dy,targets_dw,targets_dh)).transpose()returntargetsdefexpand_boxes(boxes,scale):\"\"\"Expandanarrayofboxesbyagivenscale.\"\"\"w_half=(boxes[:,2]-boxes[:,0])*.5h_half=(boxes[:,3]-boxes[:,1])*.5x_c=(boxes[:,2]+boxes[:,0])*.5y_c=(boxes[:,3]+boxes[:,1])*.5w_half*=scaleh_half*=scaleboxes_exp=np.zeros(boxes.shape)boxes_exp[:,0]=x_c-w_halfboxes_exp[:,2]=x_c+w_halfboxes_exp[:,1]=y_c-h_halfboxes_exp[:,3]=y_c+h_halfreturnboxes_expdefflip_boxes(boxes,im_width):\"\"\"Flipboxeshorizontally.\"\"\"boxes_flipped=boxes.copy()boxes_flipped[:,0::4]=im_width-boxes[:,2::4]-1boxes_flipped[:,2::4]=im_width-boxes[:,0::4]-1returnboxes_flippeddefaspect_ratio(boxes,aspect_ratio):\"\"\"Performwidth-relativeaspectratiotransformation.\"\"\"boxes_ar=boxes.copy()boxes_ar[:,0::4]=aspect_ratio*boxes[:,0::4]boxes_ar[:,2::4]=aspect_ratio*boxes[:,2::4]returnboxes_ardefbox_voting(top_dets,all_dets,thresh,scoring_method=\\'ID\\',beta=1.0):\"\"\"Applybounding-boxvotingtorefine`top_dets`byvotingwith`all_dets`.See:Optionalscoreaveraging(notinthereferencedpaper)canbeappliedbysetting`scoring_method`appropriately.\"\"\"#top_detsis[N,5]eachrowis[x1y1x2y2,sore]#all_detsis[N,5]eachrowis[x1y1x2y2,sore]top_dets_out=top_dets.copy()top_boxes=top_dets[:,:4]all_boxes=all_dets[:,:4]all_scores=all_dets[:,4]top_to_all_overlaps=bbox_overlaps(top_boxes,all_boxes)forkinrange(top_dets_out.shape[0]):inds_to_vote=np.where(top_to_all_overlaps[k]>=thresh)[0]boxes_to_vote=all_boxes[inds_to_vote,:]ws=all_scores[inds_to_vote]top_dets_out[k,:4]=np.average(boxes_to_vote,axis=0,weights=ws)ifscoring_method==\\'ID\\':#Identity,nothingtodopasselifscoring_method==\\'TEMP_AVG\\':#Averageprobabilities(consideredasP(detectedclass)vs.#P(notthedetectedclass))aftersmoothingwithatemperature#hyperparameter.P=np.vstack((ws,1.0-ws))P_max=np.max(P,axis=0)X=np.log(P/P_max)X_exp=np.exp(X/beta)P_temp=X_exp/np.sum(X_exp,axis=0)P_avg=P_temp[0].mean()top_dets_out[k,4]=P_avgelifscoring_method==\\'AVG\\':#Combinenewprobsfromoverlappingboxestop_dets_out[k,4]=ws.mean()elifscoring_method==\\'IOU_AVG\\':P=wsws=top_to_all_overlaps[k,inds_to_vote]P_avg=np.average(P,weights=ws)top_dets_out[k,4]=P_avgelifscoring_method==\\'GENERALIZED_AVG\\':P_avg=np.mean(ws**beta)**(1.0/beta)top_dets_out[k,4]=P_avgelifscoring_method==\\'QUASI_SUM\\':top_dets_out[k,4]=ws.sum()/float(len(ws))**betaelse:raiseNotImplementedError(\\'Unknownscoringmethod{}\\'.format(scoring_method))returntop_dets_outdefnms(dets,thresh):\"\"\"ApplyclassicDPM-stylegreedyNMS.\"\"\"ifdets.shape[0]==0:return[]returncython_nms.nms(dets,thresh)defsoft_nms(dets,sigma=0.5,overlap_thresh=0.3,score_thresh=0.001,method=\\'linear\\'):\"\"\"ApplythesoftNMSalgorithmfrom\"\"\"ifdets.shape[0]==0:returndets,[]methods={\\'hard\\':0,\\'linear\\':1,\\'gaussian\\':2}assertmethodinmethods,\\'Unknownsoft_nmsmethod:{}\\'.format(method)dets,keep=cython_nms.soft_nms(np.ascontiguousarray(dets,dtype=np.float32),np.float32(sigma),np.float32(overlap_thresh),np.float32(score_thresh),np.uint8(methods[method]))returndets,keep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesforlogging.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromemail.mime.textimportMIMETextimportjsonimportloggingimportnumpyasnpimportsmtplibimportsysdeflog_json_stats(stats,sort_keys=True):#hacktocontrolprecisionoftop-levelfloatsstats={k:\\'{:.6f}\\'.format(v)ifisinstance(v,float)elsevfork,vinstats.items()}print(\\'json_stats:{:s}\\'.format(json.dumps(stats,sort_keys=sort_keys)))classSmoothedValue:\"\"\"Trackaseriesofvaluesandprovideaccesstosmoothedvaluesoverawindowortheglobalseriesaverage.\"\"\"def__init__(self,window_size):self.deque=deque(maxlen=window_size)self.series=[]self.total=0.0self.count=0defAddValue(self,value):self.deque.append(value)self.series.append(value)self.count+=1self.total+=valuedefGetMedianValue(self):returnnp.median(self.deque)defGetAverageValue(self):returnnp.mean(self.deque)defGetGlobalAverageValue(self):returnself.total/self.countdefsend_email(subject,body,to):s=smtplib.SMTP(\\'localhost\\')mime=MIMEText(body)mime[\\'Subject\\']=subjectmime[\\'To\\']=tos.sendmail(\\'detectron\\',to,mime.as_string())defsetup_logging(name):FORMAT=\\'%(levelname)s%(filename)s:%(lineno)4d:%(message)s\\'#Manuallyclearrootloggerstopreventanymodulethatmayhavecalled#logging.basicConfig()fromblockingourloggingsetuplogging.root.handlers=[]logging.basicConfig(level=logging.INFO,format=FORMAT,stream=sys.stdout)logger=logging.getLogger(name)returnlogger#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Imagehelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpdefaspect_ratio_rel(im,aspect_ratio):\"\"\"Performswidth-relativeaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_ar_w=int(round(aspect_ratio*im_w))im_ar=cv2.resize(im,dsize=(im_ar_w,im_h))returnim_ardefaspect_ratio_abs(im,aspect_ratio):\"\"\"Performsabsoluteaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_area=im_h*im_wim_ar_w=np.sqrt(im_area*aspect_ratio)im_ar_h=np.sqrt(im_area/aspect_ratio)assertnp.isclose(im_ar_w/im_ar_h,aspect_ratio)im_ar=cv2.resize(im,dsize=(int(im_ar_w),int(im_ar_h)))returnim_ar#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Learningratepolicies.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgdefget_lr_at_iter(it):\"\"\"Getthelearningrateatiterationitaccordingtothecfg.SOLVERsettings.\"\"\"lr=get_lr_func()(it)ifit<cfg.SOLVER.WARM_UP_ITERS:method=cfg.SOLVER.WARM_UP_METHODifmethod==\\'constant\\':warmup_factor=cfg.SOLVER.WARM_UP_FACTORelifmethod==\\'linear\\':alpha=it/cfg.SOLVER.WARM_UP_ITERSwarmup_factor=cfg.SOLVER.WARM_UP_FACTOR*(1-alpha)+alphaelse:raiseKeyError(\\'UnknownSOLVER.WARM_UP_METHOD:{}\\'.format(method))lr*=warmup_factorreturnnp.float32(lr)#----------------------------------------------------------------------------##Learningratepolicyfunctions#----------------------------------------------------------------------------#deflr_func_steps_with_lrs(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_lrs\\'Changethelearningratetospecifiedvaluesatspecifiediterations.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.LRS:[0.02,0.002,0.0002]forcur_iterin[0,59]use0.02in[60,79]use0.002in[80,inf]use0.0002\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.LRS[ind]deflr_func_steps_with_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_decay\\'Changethelearningratespecifiediterationsbasedontheformulalr=base_lr*gamma**lr_step_count.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.BASE_LR:0.02cfg.SOLVER.GAMMA:0.1forcur_iterin[0,59]use0.02=0.02*0.1**0in[60,79]use0.002=0.02*0.1**1in[80,inf]use0.0002=0.02*0.1**2\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**inddeflr_func_step(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'step\\'\"\"\"return(cfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**(cur_iter//cfg.SOLVER.STEP_SIZE))deflr_func_cosine_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'cosine_decay\\'\"\"\"iter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERcos_frac=0.5*(np.cos(np.pi*iter_frac)+1)returncfg.SOLVER.BASE_LR*cos_fracdeflr_func_exp_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'exp_decay\\'\"\"\"#GAMMAisfinal/initiallearningrateratioiter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERexp_frac=np.exp(iter_frac*np.log(cfg.SOLVER.GAMMA))returncfg.SOLVER.BASE_LR*exp_frac#----------------------------------------------------------------------------##Helpers#----------------------------------------------------------------------------#defget_step_index(cur_iter):\"\"\"Givenaniteration,findwhichlearningratestepwe\\'reat.\"\"\"assertcfg.SOLVER.STEPS[0]==0,\\'Thefirststepshouldalwaysstartat0.\\'steps=cfg.SOLVER.STEPS+[cfg.SOLVER.MAX_ITER]forind,stepinenumerate(steps):#NoQAifcur_iter<step:breakreturnind-1defget_lr_func():policy=\\'lr_func_\\'+cfg.SOLVER.LR_POLICYifpolicynotinglobals():raiseNotImplementedError(\\'UnknownLRpolicy:{}\\'.format(cfg.SOLVER.LR_POLICY))else:returnglobals()[policy]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Timingrelatedfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporttimeclassTimer:\"\"\"Asimpletimer.\"\"\"def__init__(self):self.reset()deftic(self):#usingtime.timeinsteadoftime.clockbecausetimetime.clock#doesnotnormalizeformultithreadingself.start_time=time.time()deftoc(self,average=True):self.diff=time.time()-self.start_timeself.total_time+=self.diffself.calls+=1self.average_time=self.total_time/self.callsifaverage:returnself.average_timeelse:returnself.diffdefreset(self):self.total_time=0.self.calls=0self.start_time=0.self.diff=0.self.average_time=0.#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Coordinatedaccesstoasharedmultithreading/processingqueue.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcontextlibimportloggingimportthreadingimporttracebackfromsix.movesimportqueueasQueuelog=logging.getLogger(__name__)classCoordinator:def__init__(self):self._event=threading.Event()defrequest_stop(self):log.debug(\\'Coordinatorstopping\\')self._event.set()defshould_stop(self):returnself._event.is_set()defwait_for_stop(self):returnself._event.wait()@contextlib.contextmanagerdefstop_on_exception(self):try:yieldexceptException:ifnotself.should_stop():traceback.print_exc()self.request_stop()defcoordinated_get(coordinator,queue):whilenotcoordinator.should_stop():try:returnqueue.get(block=True,timeout=1.0)exceptQueue.Empty:continueraiseException(\\'Coordinatorstoppedduringget()\\')defcoordinated_put(coordinator,queue,element):whilenotcoordinator.should_stop():try:queue.put(element,block=True,timeout=1.0)returnexceptQueue.Full:continueraiseException(\\'Coordinatorstoppedduringput()\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Utilitiesdrivingthetrain_netbinary\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromshutilimportcopyfileimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportosimportrefromcaffe2.pythonimportmemongerfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utilsimportlr_policyfromdetectron.utils.training_statsimportTrainingStatsimportdetectron.utils.envasenvuimportdetectron.utils.netasnudeftrain_model():\"\"\"Modeltrainingloop.\"\"\"model,weights_file,start_iter,checkpoints,output_dir=create_model()if\\'final\\'incheckpoints:#Thefinalmodelwasfoundintheoutputdirectory,sonothingtodoreturncheckpointssetup_model_for_training(model,weights_file,output_dir)training_stats=TrainingStats(model)CHECKPOINT_PERIOD=int(cfg.TRAIN.SNAPSHOT_ITERS/cfg.NUM_GPUS)forcur_iterinrange(start_iter,cfg.SOLVER.MAX_ITER):ifmodel.roi_data_loader.has_stopped():handle_critical_error(model,\\'roi_data_loaderfailed\\')training_stats.IterTic()lr=model.UpdateWorkspaceLr(cur_iter,lr_policy.get_lr_at_iter(cur_iter))workspace.RunNet(model.net.Proto().name)ifcur_iter==start_iter:nu.print_net(model)training_stats.IterToc()training_stats.UpdateIterStats()training_stats.LogIterStats(cur_iter,lr)if(cur_iter+1)%CHECKPOINT_PERIOD==0andcur_iter>start_iter:checkpoints[cur_iter]=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(cur_iter))nu.save_model_to_weights_file(checkpoints[cur_iter],model)ifcur_iter==start_iter+training_stats.LOG_PERIOD:#Resettheiterationtimertoremoveoutliersfromthefirstfew#SGDiterationstraining_stats.ResetIterTimer()ifnp.isnan(training_stats.iter_total_loss):handle_critical_error(model,\\'LossisNaN\\')#Savethefinalmodelcheckpoints[\\'final\\']=os.path.join(output_dir,\\'model_final.pkl\\')nu.save_model_to_weights_file(checkpoints[\\'final\\'],model)#Shutdowndataloadingthreadsmodel.roi_data_loader.shutdown()returncheckpointsdefhandle_critical_error(model,msg):logger=logging.getLogger(__name__)logger.critical(msg)model.roi_data_loader.shutdown()raiseException(msg)defcreate_model():\"\"\"Buildthemodelandlookforsavedmodelcheckpointsincasewecanresumefromone.\"\"\"logger=logging.getLogger(__name__)start_iter=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)weights_file=cfg.TRAIN.WEIGHTSifcfg.TRAIN.AUTO_RESUME:#Checkforthefinalmodel(indicatestrainingalreadyfinished)final_path=os.path.join(output_dir,\\'model_final.pkl\\')ifos.path.exists(final_path):logger.info(\\'model_final.pklexists;noneedtotrain!\\')returnNone,None,None,{\\'final\\':final_path},output_dirifcfg.TRAIN.COPY_WEIGHTS:copyfile(weights_file,os.path.join(output_dir,os.path.basename(weights_file)))logger.info(\\'Copy{}to{}\\'.format(weights_file,output_dir))#Findthemostrecentcheckpoint(highestiterationnumber)files=os.listdir(output_dir)forfinfiles:iter_string=re.findall(r\\'(?<=model_iter)\\\\d+(?=\\\\.pkl)\\',f)iflen(iter_string)>0:checkpoint_iter=int(iter_string[0])ifcheckpoint_iter>start_iter:#Startoneiterationimmediatelyafterthecheckpointiterstart_iter=checkpoint_iter+1resume_weights_file=fifstart_iter>0:#Overridetheinitializationweightswiththefoundcheckpointweights_file=os.path.join(output_dir,resume_weights_file)logger.info(\\'========>Resumingfromcheckpoint{}atstartiter{}\\'.format(weights_file,start_iter))logger.info(\\'Buildingmodel:{}\\'.format(cfg.MODEL.TYPE))model=model_builder.create(cfg.MODEL.TYPE,train=True)ifcfg.MEMONGER:optimize_memory(model)#Performsrandomweightinitializationasdefinedbythemodelworkspace.RunNetOnce(model.param_init_net)returnmodel,weights_file,start_iter,checkpoints,output_dirdefoptimize_memory(model):\"\"\"SaveGPUmemorythroughblobsharing.\"\"\"fordeviceinrange(cfg.NUM_GPUS):namescope=\\'gpu_{}/\\'.format(device)losses=[namescope+lforlinmodel.losses]model.net._net=memonger.share_grad_blobs(model.net,losses,set(model.param_to_grad.values()),namescope,share_activations=cfg.MEMONGER_SHARE_ACTIVATIONS)defsetup_model_for_training(model,weights_file,output_dir):\"\"\"LoadedsavedweightsandcreatethenetworkintheC2workspace.\"\"\"logger=logging.getLogger(__name__)add_model_training_inputs(model)ifweights_file:#Overriderandomweightinitializationwithweightsfromasavedmodelnu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)#Evenifwe\\'rerandomlyinitializingwestillneedtosynchronize#parametersacrossGPUsnu.broadcast_parameters(model)workspace.CreateNet(model.net)logger.info(\\'Outputssavedto:{:s}\\'.format(os.path.abspath(output_dir)))dump_proto_files(model,output_dir)#Startloadingmini-batchesandenqueuingblobsmodel.roi_data_loader.register_sigint_handler()model.roi_data_loader.start(prefill=True)returnoutput_dirdefadd_model_training_inputs(model):\"\"\"Loadthetrainingdatasetandattachthetraininginputstothemodel.\"\"\"logger=logging.getLogger(__name__)logger.info(\\'Loadingdataset:{}\\'.format(cfg.TRAIN.DATASETS))roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))model_builder.add_training_inputs(model,roidb=roidb)defdump_proto_files(model,output_dir):\"\"\"Saveprototxtdescriptionsofthetrainingnetworkandparameterinitializationnetwork.\"\"\"withopen(os.path.join(output_dir,\\'net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.net.Proto()))withopen(os.path.join(output_dir,\\'param_init_net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.param_init_net.Proto()))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"IOutilities.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporterrnoimporthashlibimportloggingimportosimportreimportsiximportsysfromsix.movesimportcPickleaspicklefromsix.movesimporturllibfromuuidimportuuid4logger=logging.getLogger(__name__)_DETECTRON_S3_BASE_URL=\\'defsave_object(obj,file_name,pickle_format=2):\"\"\"SaveaPythonobjectbypicklingit.Unlessspecificallyoverridden,wewanttosaveitinPickleformat=2sincethiswillallowotherPython2executablestoloadtheresultingPickle.WhenwewanttocompletelyremovePython2backward-compatibility,wecanbumpitupto3.Weshouldneverusepickle.HIGHEST_PROTOCOLasfaraspossibleiftheresultingfileismanifestedorused,externaltothesystem.\"\"\"file_name=os.path.abspath(file_name)#Avoidfilesystemraceconditions(particularlyonnetworkfilesystems)#bysavingtoarandomtmpfileonthesamefilesystem,andthen#atomicallyrenametothetargetfilename.tmp_file_name=file_name+\".tmp.\"+uuid4().hextry:withopen(tmp_file_name,\\'wb\\')asf:pickle.dump(obj,f,pickle_format)f.flush()#makesureit\\'swrittentodiskos.fsync(f.fileno())os.rename(tmp_file_name,file_name)finally:#Cleanupthetempfileonfailure.Ratherthanusingos.path.exists(),#whichcanbeunreliableonnetworkfilesystems,attempttodeleteand#ignoreoserrors.try:os.remove(tmp_file_name)exceptEnvironmentErrorase:#parentclassofIOError,OSErrorifgetattr(e,\\'errno\\',None)!=errno.ENOENT:#WeexpectENOENTlogger.info(\"Couldnotdeletetempfile%r\",tmp_file_name,exc_info=True)#passthroughsincewedon\\'twantthejobtocrashdefload_object(file_name):withopen(file_name,\\'rb\\')asf:#Thedefaultencodingusedwhileunpicklingis7-bit(ASCII.)However,#theblobsarearbitrary8-bitbyteswhichdon\\'tagree.Theabsolute#correctwaytodothisistouse`encoding=\"bytes\"`andtheninterpret#theblobnameseitherasASCII,orbetter,asunicodeutf-8.A#reasonablefix,however,istotreatittheencodingas8-bitlatin1#(whichagreeswiththefirst256charactersofUnicodeanyway.)ifsix.PY2:returnpickle.load(f)else:returnpickle.load(f,encoding=\\'latin1\\')defcache_url(url_or_file,cache_dir):\"\"\"DownloadthefilespecifiedbytheURLtothecache_dirandreturnthepathtothecachedfile.IftheargumentisnotaURL,simplyreturnitasis.\"\"\"is_url=re.match(r\\'^(?:http)s?://\\',url_or_file,re.IGNORECASE)isnotNoneifnotis_url:returnurl_or_fileurl=url_or_fileasserturl.startswith(_DETECTRON_S3_BASE_URL),\\\\(\\'DetectrononlyautomaticallycachesURLsintheDetectronS3\\'\\'bucket:{}\\').format(_DETECTRON_S3_BASE_URL)cache_file_path=url.replace(_DETECTRON_S3_BASE_URL,cache_dir)ifos.path.exists(cache_file_path):assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathcache_file_dir=os.path.dirname(cache_file_path)ifnotos.path.exists(cache_file_dir):os.makedirs(cache_file_dir)logger.info(\\'Downloadingremotefile{}to{}\\'.format(url,cache_file_path))download_url(url,cache_file_path)assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathdefassert_cache_file_is_ok(url,file_path):\"\"\"Checkthatcachefilehasthecorrecthash.\"\"\"#Fileisalreadyinthecache,verifythatthemd5summatchesand#returnlocalpathcache_file_md5sum=_get_file_md5sum(file_path)ref_md5sum=_get_reference_md5sum(url)assertcache_file_md5sum==ref_md5sum,\\\\(\\'TargetURL{}appearstobedownloadedtothelocalcachefile\\'\\'{},butthemd5hashofthelocalfiledoesnotmatchthe\\'\\'reference(actual:{}vs.expected:{}).Youmaywishtodelete\\'\\'thecachedfileandtryagaintotriggerautomatic\\'\\'download.\\').format(url,file_path,cache_file_md5sum,ref_md5sum)def_progress_bar(count,total):\"\"\"Reportdownloadprogress.Credit:\"\"\"bar_len=60filled_len=int(round(bar_len*count/float(total)))percents=round(100.0*count/float(total),1)bar=\\'=\\'*filled_len+\\'-\\'*(bar_len-filled_len)sys.stdout.write(\\'[{}]{}%of{:.1f}MBfile\\\\r\\'.format(bar,percents,total/1024/1024))sys.stdout.flush()ifcount>=total:sys.stdout.write(\\'\\\\n\\')defdownload_url(url,dst_file_path,chunk_size=8192,progress_hook=_progress_bar):\"\"\"Downloadurlandwriteittodst_file_path.Credit:\"\"\"response=urllib.request.urlopen(url)ifsix.PY2:total_size=response.info().getheader(\\'Content-Length\\').strip()else:total_size=response.info().get(\\'Content-Length\\').strip()total_size=int(total_size)bytes_so_far=0withopen(dst_file_path,\\'wb\\')asf:while1:chunk=response.read(chunk_size)bytes_so_far+=len(chunk)ifnotchunk:breakifprogress_hook:progress_hook(bytes_so_far,total_size)f.write(chunk)returnbytes_so_fardef_get_file_md5sum(file_name):\"\"\"Computethemd5hashofafile.\"\"\"hash_obj=hashlib.md5()withopen(file_name,\\'rb\\')asf:hash_obj.update(f.read())returnhash_obj.hexdigest().encode(\\'utf-8\\')def_get_reference_md5sum(url):\"\"\"Byconventionthemd5hashforurlisstoredinurl+\\'.md5sum\\'.\"\"\"url_md5sum=url+\\'.md5sum\\'md5sum=urllib.request.urlopen(url_md5sum).read().strip()returnmd5sum#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Keypointutilities(somewhatspecifictoCOCOkeypoints).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_keypoints():\"\"\"GettheCOCOkeypointsandtheirleft/rightflipcoorespondencemap.\"\"\"#KeypointsarenotavailableintheCOCOjsonforthetestsplit,sowe#providethemhere.keypoints=[\\'nose\\',\\'left_eye\\',\\'right_eye\\',\\'left_ear\\',\\'right_ear\\',\\'left_shoulder\\',\\'right_shoulder\\',\\'left_elbow\\',\\'right_elbow\\',\\'left_wrist\\',\\'right_wrist\\',\\'left_hip\\',\\'right_hip\\',\\'left_knee\\',\\'right_knee\\',\\'left_ankle\\',\\'right_ankle\\']keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}returnkeypoints,keypoint_flip_mapdefget_person_class_index():\"\"\"IndexofthepersonclassinCOCO.\"\"\"return1defflip_keypoints(keypoints,keypoint_flip_map,keypoint_coords,width):\"\"\"Left/rightflipkeypoint_coords.keypointsandkeypoint_flip_mapareaccessiblefromget_keypoints().\"\"\"flipped_kps=keypoint_coords.copy()forlkp,rkpinkeypoint_flip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)flipped_kps[:,:,lid]=keypoint_coords[:,:,rid]flipped_kps[:,:,rid]=keypoint_coords[:,:,lid]#Flipxcoordinatesflipped_kps[:,0,:]=width-flipped_kps[:,0,:]-1#MaintainCOCOconventionthatifvisibility==0,thenx,y=0inds=np.where(flipped_kps[:,2,:]==0)flipped_kps[inds[0],0,inds[1]]=0returnflipped_kpsdefflip_heatmaps(heatmaps):\"\"\"Flipheatmapshorizontally.\"\"\"keypoints,flip_map=get_keypoints()heatmaps_flipped=heatmaps.copy()forlkp,rkpinflip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)heatmaps_flipped[:,rid,:,:]=heatmaps[:,lid,:,:]heatmaps_flipped[:,lid,:,:]=heatmaps[:,rid,:,:]heatmaps_flipped=heatmaps_flipped[:,:,:,::-1]returnheatmaps_flippeddefheatmaps_to_keypoints(maps,rois):\"\"\"Extractpredictedkeypointlocationsfromheatmaps.Outputhasshape(#rois,4,#keypoints)withthe4rowscorrespondingto(x,y,logit,prob)foreachkeypoint.\"\"\"#ThisfunctionconvertsadiscreteimagecoordinateinaHEATMAP_SIZEx#HEATMAP_SIZEimagetoacontinuouskeypointcoordinate.Wemaintain#consistencywithkeypoints_to_heatmap_labelsbyusingtheconversionfrom#Heckbert1990:c=d+0.5,wheredisadiscretecoordinateandcisa#continuouscoordinate.offset_x=rois[:,0]offset_y=rois[:,1]widths=rois[:,2]-rois[:,0]heights=rois[:,3]-rois[:,1]widths=np.maximum(widths,1)heights=np.maximum(heights,1)widths_ceil=np.ceil(widths)heights_ceil=np.ceil(heights)#NCHWtoNHWCforusewithOpenCVmaps=np.transpose(maps,[0,2,3,1])min_size=cfg.KRCNN.INFERENCE_MIN_SIZExy_preds=np.zeros((len(rois),4,cfg.KRCNN.NUM_KEYPOINTS),dtype=np.float32)foriinrange(len(rois)):ifmin_size>0:roi_map_width=int(np.maximum(widths_ceil[i],min_size))roi_map_height=int(np.maximum(heights_ceil[i],min_size))else:roi_map_width=widths_ceil[i]roi_map_height=heights_ceil[i]width_correction=widths[i]/roi_map_widthheight_correction=heights[i]/roi_map_heightroi_map=cv2.resize(maps[i],(roi_map_width,roi_map_height),interpolation=cv2.INTER_CUBIC)#BringbacktoCHWroi_map=np.transpose(roi_map,[2,0,1])roi_map_probs=scores_to_probs(roi_map.copy())w=roi_map.shape[2]forkinrange(cfg.KRCNN.NUM_KEYPOINTS):pos=roi_map[k,:,:].argmax()x_int=pos%wy_int=(pos-x_int)//wassert(roi_map_probs[k,y_int,x_int]==roi_map_probs[k,:,:].max())x=(x_int+0.5)*width_correctiony=(y_int+0.5)*height_correctionxy_preds[i,0,k]=x+offset_x[i]xy_preds[i,1,k]=y+offset_y[i]xy_preds[i,2,k]=roi_map[k,y_int,x_int]xy_preds[i,3,k]=roi_map_probs[k,y_int,x_int]returnxy_predsdefkeypoints_to_heatmap_labels(keypoints,rois):\"\"\"EncodekeypointlocationinthetargetheatmapforuseinSoftmaxWithLoss.\"\"\"#Mapskeypointsfromthehalf-openinterval[x1,x2)oncontinuousimage#coordinatestotheclosedinterval[0,HEATMAP_SIZE-1]ondiscreteimage#coordinates.WeusethecontinuousdiscreteconversionfromHeckbert#1990(\"Whatisthecoordinateofapixel?\"):d=floor(c)andc=d+0.5,#wheredisadiscretecoordinateandcisacontinuouscoordinate.assertkeypoints.shape[2]==cfg.KRCNN.NUM_KEYPOINTSshape=(len(rois),cfg.KRCNN.NUM_KEYPOINTS)heatmaps=blob_utils.zeros(shape)weights=blob_utils.zeros(shape)offset_x=rois[:,0]offset_y=rois[:,1]scale_x=cfg.KRCNN.HEATMAP_SIZE/(rois[:,2]-rois[:,0])scale_y=cfg.KRCNN.HEATMAP_SIZE/(rois[:,3]-rois[:,1])forkpinrange(keypoints.shape[2]):vis=keypoints[:,2,kp]>0x=keypoints[:,0,kp].astype(np.float32)y=keypoints[:,1,kp].astype(np.float32)#Sinceweusefloorbelow,ifakeypointisexactlyontheroi\\'sright#orbottomboundary,weshiftitinbyeps(conceptually)tokeepitin#thegroundtruthheatmap.x_boundary_inds=np.where(x==rois[:,2])[0]y_boundary_inds=np.where(y==rois[:,3])[0]x=(x-offset_x)*scale_xx=np.floor(x)iflen(x_boundary_inds)>0:x[x_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1y=(y-offset_y)*scale_yy=np.floor(y)iflen(y_boundary_inds)>0:y[y_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1valid_loc=np.logical_and(np.logical_and(x>=0,y>=0),np.logical_and(x<cfg.KRCNN.HEATMAP_SIZE,y<cfg.KRCNN.HEATMAP_SIZE))valid=np.logical_and(valid_loc,vis)valid=valid.astype(np.int32)lin_ind=y*cfg.KRCNN.HEATMAP_SIZE+xheatmaps[:,kp]=lin_ind*validweights[:,kp]=validreturnheatmaps,weightsdefscores_to_probs(scores):\"\"\"TransformsCxHxWofscorestoprobabilitiesspatially.\"\"\"channels=scores.shape[0]forcinrange(channels):temp=scores[c,:,:]max_score=temp.max()temp=np.exp(temp-max_score)/np.sum(np.exp(temp-max_score))scores[c,:,:]=tempreturnscoresdefnms_oks(kp_predictions,rois,thresh):\"\"\"Nmsbasedonkppredictions.\"\"\"scores=np.mean(kp_predictions[:,2,:],axis=1)order=scores.argsort()[::-1]keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=compute_oks(kp_predictions[i],rois[i],kp_predictions[order[1:]],rois[order[1:]])inds=np.where(ovr<=thresh)[0]order=order[inds+1]returnkeepdefcompute_oks(src_keypoints,src_roi,dst_keypoints,dst_roi):\"\"\"ComputeOKSforpredictedkeypointswrtgt_keypoints.src_keypoints:4xKsrc_roi:4x1dst_keypoints:Nx4xKdst_roi:Nx4\"\"\"sigmas=np.array([.26,.25,.25,.35,.35,.79,.79,.72,.72,.62,.62,1.07,1.07,.87,.87,.89,.89])/10.0vars=(sigmas*2)**2#areasrc_area=(src_roi[2]-src_roi[0]+1)*(src_roi[3]-src_roi[1]+1)#measuretheper-keypointdistanceifkeypointsvisibledx=dst_keypoints[:,0,:]-src_keypoints[0,:]dy=dst_keypoints[:,1,:]-src_keypoints[1,:]e=(dx**2+dy**2)/vars/(src_area+np.spacing(1))/2e=np.sum(np.exp(-e),axis=1)/e.shape[1]returne#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fill#----------------------------------------------------------------------------##R-FCNoutputsandlosses#----------------------------------------------------------------------------#defadd_rfcn_outputs(model,blob_in,dim_in,dim_reduce,spatial_scale):ifdim_reduceisnotNone:#Optionaldimreductionblob_in=model.Conv(blob_in,\\'conv_dim_reduce\\',dim_in,dim_reduce,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))blob_in=model.Relu(blob_in,blob_in)dim_in=dim_reduce#Classificationconvmodel.Conv(blob_in,\\'conv_cls\\',dim_in,model.num_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Bounding-boxregressionconvnum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.Conv(blob_in,\\'conv_bbox_pred\\',dim_in,4*num_bbox_reg_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#ClassificationPSRoIpoolingmodel.net.PSRoIPool([\\'conv_cls\\',\\'rois\\'],[\\'psroipooled_cls\\',\\'_mapping_channel_cls\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=model.num_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_cls\\',\\'cls_score_4d\\',kernel=cfg.RFCN.PS_GRID_SIZE)model.net.Reshape(\\'cls_score_4d\\',[\\'cls_score\\',\\'_cls_scores_shape\\'],shape=(-1,cfg.MODEL.NUM_CLASSES))ifnotmodel.train:model.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#BboxregressionPSRoIpoolingmodel.net.PSRoIPool([\\'conv_bbox_pred\\',\\'rois\\'],[\\'psroipooled_bbox\\',\\'_mapping_channel_bbox\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=4*num_bbox_reg_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_bbox\\',\\'bbox_pred\\',kernel=cfg.RFCN.PS_GRID_SIZE)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ImplementsResNetandResNeXt.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.netimportget_group_gn#----------------------------------------------------------------------------##Bitsforspecificarchitectures(ResNet50,ResNet101,...)#----------------------------------------------------------------------------#defadd_ResNet50_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,6))defadd_ResNet50_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,6,3))defadd_ResNet101_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,23))defadd_ResNet101_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,23,3))defadd_ResNet152_conv5_body(model):returnadd_ResNet_convX_body(model,(3,8,36,3))#----------------------------------------------------------------------------##GenericResNetcomponents#----------------------------------------------------------------------------#defadd_stage(model,prefix,blob_in,n,dim_in,dim_out,dim_inner,dilation,stride_init=2):\"\"\"AddaResNetstagetothemodelbystackingnresidualblocks.\"\"\"#e.g.,prefix=res2foriinrange(n):blob_in=add_residual_block(model,\\'{}_{}\\'.format(prefix,i),blob_in,dim_in,dim_out,dim_inner,dilation,stride_init,#Notusinginplaceforthelastblock;#itmaybefetchedexternallyorusedbyFPNinplace_sum=i<n-1)dim_in=dim_outreturnblob_in,dim_indefadd_ResNet_convX_body(model,block_counts):\"\"\"AddaResNetbodyfrominputdataupthroughtheres5(akaconv5)stage.Thefinalres5/conv5stagemaybeoptionallyexcluded(henceconvX,whereX=4or5).\"\"\"freeze_at=cfg.TRAIN.FREEZE_ATassertfreeze_atin[0,2,3,4,5]#addthestem(bydefault,conv1andpool1withbn;cansupportgn)p,dim_in=globals()[cfg.RESNETS.STEM_FUNC](model,\\'data\\')dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUP(n1,n2,n3)=block_counts[:3]s,dim_in=add_stage(model,\\'res2\\',p,n1,dim_in,256,dim_bottleneck,1)iffreeze_at==2:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res3\\',s,n2,dim_in,512,dim_bottleneck*2,1)iffreeze_at==3:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res4\\',s,n3,dim_in,1024,dim_bottleneck*4,1)iffreeze_at==4:model.StopGradient(s,s)iflen(block_counts)==4:n4=block_counts[3]s,dim_in=add_stage(model,\\'res5\\',s,n4,dim_in,2048,dim_bottleneck*8,cfg.RESNETS.RES5_DILATION)iffreeze_at==5:model.StopGradient(s,s)returns,dim_in,1./32.*cfg.RESNETS.RES5_DILATIONelse:returns,dim_in,1./16.defadd_ResNet_roi_conv5_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddsanRoIfeaturetransformation(e.g.,RoIpooling)followedbyares5/conv5headappliedtoeachRoI.\"\"\"#TODO(rbg):ThiscontainsFastR-CNNspecificconfigoptionsmakingitnon-#reusable;makethismoregenericwithmodel-specificwrappersmodel.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=cfg.FAST_RCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUPstride_init=int(cfg.FAST_RCNN.ROI_XFORM_RESOLUTION/7)s,dim_in=add_stage(model,\\'res5\\',\\'pool5\\',3,dim_in,2048,dim_bottleneck*8,1,stride_init)s=model.AveragePool(s,\\'res5_pool\\',kernel=7)returns,2048defadd_residual_block(model,prefix,blob_in,dim_in,dim_out,dim_inner,dilation,stride_init=2,inplace_sum=False):\"\"\"Addaresidualblocktothemodel.\"\"\"#prefix=res_,e.g.,res2_3#Maxpoolingisperformedpriortothefirststage(whichisuniquely#distinguishedbydim_in=64),thuswekeepstride=1forthefirststagestride=stride_initif(dim_in!=dim_outanddim_in!=64anddilation==1)else1#transformationblobtr=globals()[cfg.RESNETS.TRANS_FUNC](model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,group=cfg.RESNETS.NUM_GROUPS,dilation=dilation)#sum->ReLU#shortcutfunction:bydefaultusingbn;supportgnadd_shortcut=globals()[cfg.RESNETS.SHORTCUT_FUNC]sc=add_shortcut(model,prefix,blob_in,dim_in,dim_out,stride)ifinplace_sum:s=model.net.Sum([tr,sc],tr)else:s=model.net.Sum([tr,sc],prefix+\\'_sum\\')returnmodel.Relu(s,s)#------------------------------------------------------------------------------#variousshortcuts(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):\"\"\"Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"ifdim_in==dim_out:returnblob_inc=model.Conv(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,stride=stride,no_bias=1)returnmodel.AffineChannel(c,prefix+\\'_branch1_bn\\',dim=dim_out)defbasic_gn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):ifdim_in==dim_out:returnblob_in#outputnameisprefix+\\'_branch1_gn\\'returnmodel.ConvGN(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=stride,pad=0,group=1,)#------------------------------------------------------------------------------#variousstems(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem.Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"dim=64p=model.Conv(data,\\'conv1\\',3,dim,7,pad=3,stride=2,no_bias=1)p=model.AffineChannel(p,\\'res_conv1_bn\\',dim=dim,inplace=True)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dimdefbasic_gn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem(usingGN)\"\"\"dim=64p=model.ConvGN(data,\\'conv1\\',3,dim,7,group_gn=get_group_gn(dim),pad=3,stride=2)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dim#------------------------------------------------------------------------------#varioustransformations(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbottleneck_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"Addabottlenecktransformationtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->BN->ReLUcur=model.ConvAffine(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,stride=str1x1,pad=0,inplace=True)cur=model.Relu(cur,cur)#conv3x3->BN->ReLUcur=model.ConvAffine(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,stride=str3x3,pad=1*dilation,dilation=dilation,group=group,inplace=True)cur=model.Relu(cur,cur)#conv1x1->BN(noReLU)#NB:fornowthisAffineChannelopcannotbein-placeduetoabuginC2#gradientcomputationforgraphslikethiscur=model.ConvAffine(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,stride=1,pad=0,inplace=False)returncurdefbottleneck_gn_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"AddabottlenecktransformationwithGroupNormtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->GN->ReLUcur=model.ConvGN(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,group_gn=get_group_gn(dim_inner),stride=str1x1,pad=0,)cur=model.Relu(cur,cur)#conv3x3->GN->ReLUcur=model.ConvGN(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,group_gn=get_group_gn(dim_inner),stride=str3x3,pad=1*dilation,dilation=dilation,group=group,)cur=model.Relu(cur,cur)#conv1x1->GN(noReLU)cur=model.ConvGN(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=1,pad=0,)returncur#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingkeypointsinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->keypointhead->keypointoutput->loss...->Feature/MapThekeypointheadproducesafeaturerepresentationoftheRoIforthepurposeofkeypointprediction.Thekeypointoutputmoduleconvertsthefeaturerepresentationintokeypointheatmaps.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##KeypointR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_keypoint_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNkeypointspecificoutputs:keypointheatmaps.\"\"\"#NxKxHxWupsample_heatmap=(cfg.KRCNN.UP_SCALE>1)ifcfg.KRCNN.USE_DECONV:#ApplyConvTransposetothefeaturerepresentation;resultsin2x#upsamplingblob_in=model.ConvTranspose(blob_in,\\'kps_deconv\\',dim,cfg.KRCNN.DECONV_DIM,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'kps_deconv\\',\\'kps_deconv\\')dim=cfg.KRCNN.DECONV_DIMifupsample_heatmap:blob_name=\\'kps_score_lowres\\'else:blob_name=\\'kps_score\\'ifcfg.KRCNN.USE_DECONV_OUTPUT:#UseConvTransposetopredictheatmaps;resultsin2xupsamplingblob_out=model.ConvTranspose(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))else:#UseConvtopredictheatmaps;doesnoupsamplingblob_out=model.Conv(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=1,pad=0,stride=1,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifupsample_heatmap:#Increaseheatmapoutputsizeviabilinearupsamplingblob_out=model.BilinearInterpolation(blob_out,\\'kps_score\\',cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.UP_SCALE)returnblob_outdefadd_keypoint_losses(model):\"\"\"AddMaskR-CNNkeypointspecificlosses.\"\"\"#Reshapeinputfrom(N,K,H,W)to(NK,HW)model.net.Reshape([\\'kps_score\\'],[\\'kps_score_reshaped\\',\\'_kps_score_old_shape\\'],shape=(-1,cfg.KRCNN.HEATMAP_SIZE*cfg.KRCNN.HEATMAP_SIZE))#Softmaxacross**space**(woahh....space!)#Note:thisisnotwhatiscommonlycalled\"spatialsoftmax\"#(i.e.,softmaxappliedalongthechanneldimensionateachspatial#location);Thisissoftmaxappliedoverasetofspatiallocations(i.e.,#eachspatiallocationisa\"class\").kps_prob,loss_kps=model.net.SoftmaxWithLoss([\\'kps_score_reshaped\\',\\'keypoint_locations_int32\\',\\'keypoint_weights\\'],[\\'kps_prob\\',\\'loss_kps\\'],scale=cfg.KRCNN.LOSS_WEIGHT/cfg.NUM_GPUS,spatial=0)ifnotcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS:#Discussion:thesoftmaxlossabovewillaveragethelossbythesumof#keypoint_weights,i.e.thetotalnumberofvisiblekeypoints.Since#thenumberofvisiblekeypointscanvarysignificantlybetween#minibatches,thishastheeffectofup-weightingtheimportanceof#minibatcheswithfewvisiblekeypoints.(Imaginetheextremecaseof#onlyonevisiblekeypointversusN:inthecaseofN,eachone#contributes1/Ntothegradientcomparedtothesinglekeypoint#determiningthegradientdirection).Instead,wecannormalizethe#lossbythetotalnumberofkeypoints,ifitwerethecasethatall#keypointswerevisibleinafullminibatch.(Returningtotheexample,#thismeansthattheonevisiblekeypointcontributesasmuchaseach#oftheNkeypoints.)model.StopGradient(\\'keypoint_loss_normalizer\\',\\'keypoint_loss_normalizer\\')loss_kps=model.net.Mul([\\'loss_kps\\',\\'keypoint_loss_normalizer\\'],\\'loss_kps_normalized\\')loss_gradients=blob_utils.get_loss_gradients(model,[loss_kps])model.AddLosses(loss_kps)returnloss_gradients#----------------------------------------------------------------------------##Keypointheads#----------------------------------------------------------------------------#defadd_ResNet_roi_conv5_head_for_keypoints(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforMaskR-CNNkeypointprediction.\"\"\"model.RoIFeatureTransform(blob_in,\\'_[pose]_pool5\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)#Usingtheprefix\\'_[pose]_\\'to\\'res5\\'enablesinitializingthehead\\'s#parametersusingpretrained\\'res5\\'parametersifgiven(see#utils.net.initialize_from_weights_file)s,dim_in=ResNet.add_stage(model,\\'_[pose]_res5\\',\\'_[pose]_pool5\\',3,dim_in,2048,512,cfg.KRCNN.DILATION,stride_init=int(cfg.KRCNN.ROI_XFORM_RESOLUTION/7))returns,2048defadd_roi_pose_head_v1convX(model,blob_in,dim_in,spatial_scale):\"\"\"AddaMaskR-CNNkeypointhead.v1convXdesign:X*(conv).\"\"\"hidden_dim=cfg.KRCNN.CONV_HEAD_DIMkernel_size=cfg.KRCNN.CONV_HEAD_KERNELpad_size=kernel_size//2current=model.RoIFeatureTransform(blob_in,\\'_[pose]_roi_feat\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)foriinrange(cfg.KRCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'conv_fcn\\'+str(i+1),dim_in,hidden_dim,kernel_size,stride=1,pad=pad_size,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimreturncurrent,hidden_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectronmodelconstructionfunctions.Detectronsupportsalargenumberofmodeltypes.Theconfigurationspaceislarge.Togetasense,agivenmodelisinelementinthecartesianproductof:-backbone(e.g.,VGG16,ResNet,ResNeXt)-FPN(onoroff)-RPNonly(justproposals)-FixedproposalsforFastR-CNN,RFCN,MaskR-CNN(withorwithoutkeypoints)-End-to-endmodelwithRPN+FastR-CNN(i.e.,FasterR-CNN),MaskR-CNN,...-Different\"head\"choicesforthemodel-...manyconfigurationoptions...Agivenmodelismadebycombiningmanybasiccomponents.Theresultisflexiblethoughsomewhatcomplextounderstandatfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportimportlibimportloggingfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.modeling.detectorimportDetectionModelHelperfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.modeling.fast_rcnn_headsasfast_rcnn_headsimportdetectron.modeling.keypoint_rcnn_headsaskeypoint_rcnn_headsimportdetectron.modeling.mask_rcnn_headsasmask_rcnn_headsimportdetectron.modeling.name_compatasname_compatimportdetectron.modeling.optimizerasoptimimportdetectron.modeling.retinanet_headsasretinanet_headsimportdetectron.modeling.rfcn_headsasrfcn_headsimportdetectron.modeling.rpn_headsasrpn_headsimportdetectron.roi_data.minibatchasroi_data_minibatchimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)#----------------------------------------------------------------------------##Genericrecomposablemodelbuilders##Forexample,youcancreateaFastR-CNNmodelwiththeResNet-50-C4backbone#withtheconfiguration:##MODEL:#TYPE:generalized_rcnn#CONV_BODY:ResNet.add_ResNet50_conv4_body#ROI_HEAD:ResNet.add_ResNet_roi_conv5_head#----------------------------------------------------------------------------#defgeneralized_rcnn(model):\"\"\"Thismodeltypehandles:-FastR-CNN-RPNonly(notintegratedwithFastR-CNN)-FasterR-CNN(stagewisetrainingfromNIPSpaper)-FasterR-CNN(end-to-endjointtraining)-MaskR-CNN(stagewisetrainingfromNIPSpaper)-MaskR-CNN(end-to-endjointtraining)\"\"\"returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=cfg.TRAIN.FREEZE_CONV_BODY)defrfcn(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_rfcn_model(model,get_func(cfg.MODEL.CONV_BODY))defretinanet(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_retinanet_model(model,get_func(cfg.MODEL.CONV_BODY))#----------------------------------------------------------------------------##Helperfunctionsforbuildingvariousre-usablenetworkbits#----------------------------------------------------------------------------#defcreate(model_type_func,train=False,gpu_id=0):\"\"\"Genericmodelcreationfunctionthatdispatchestospecificmodelbuildingfunctions.Bydefault,thisfunctionwillgenerateadataparallelmodelconfiguredtorunoncfg.NUM_GPUSdevices.However,youcanrestrictittobuildamodeltargetedtoaspecificGPUbyspecifyinggpu_id.Thisisusedbyoptimizer.build_data_parallel_model()duringtesttime.\"\"\"model=DetectionModelHelper(name=model_type_func,train=train,num_classes=cfg.MODEL.NUM_CLASSES,init_params=train)model.only_build_forward_pass=Falsemodel.target_gpu_id=gpu_idreturnget_func(model_type_func)(model)defget_func(func_name):\"\"\"Helpertoreturnafunctionobjectbyname.func_namemustidentifyafunctioninthismoduleorthepathtoafunctionrelativetothebase\\'modeling\\'module.\"\"\"iffunc_name==\\'\\':returnNonenew_func_name=name_compat.get_new_name(func_name)ifnew_func_name!=func_name:logger.warn(\\'Remappingoldfunctionname:{}->{}\\'.format(func_name,new_func_name))func_name=new_func_nametry:parts=func_name.split(\\'.\\')#Referstoafunctioninthismoduleiflen(parts)==1:returnglobals()[parts[0]]#Otherwise,assumewe\\'rereferencingamoduleundermodelingmodule_name=\\'detectron.modeling.\\'+\\'.\\'.join(parts[:-1])module=importlib.import_module(module_name)returngetattr(module,parts[-1])exceptException:logger.error(\\'Failedtofindfunction:{}\\'.format(func_name))raisedefbuild_generic_detection_model(model,add_conv_body_func,add_roi_box_head_func=None,add_roi_mask_head_func=None,add_roi_keypoint_head_func=None,freeze_conv_body=False):def_single_gpu_build_func(model):\"\"\"BuildthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"#Addtheconvbody(called\"backbonearchitecture\"inpapers)#E.g.,ResNet-50,ResNet-50-FPN,ResNeXt-101-FPN,etc.blob_conv,dim_conv,spatial_scale_conv=add_conv_body_func(model)iffreeze_conv_body:forbinc2_utils.BlobReferenceList(blob_conv):model.StopGradient(b,b)ifnotmodel.train:#==inference#Createanetthatcanbeusedtoexecutetheconvbodyonanimage#(withoutalsoexecutingRPNoranyothernetworkheads)model.conv_body_net=model.net.Clone(\\'conv_body_net\\')head_loss_gradients={\\'rpn\\':None,\\'box\\':None,\\'mask\\':None,\\'keypoints\\':None,}ifcfg.RPN.RPN_ON:#AddtheRPNheadhead_loss_gradients[\\'rpn\\']=rpn_heads.add_generic_rpn_outputs(model,blob_conv,dim_conv,spatial_scale_conv)ifcfg.FPN.FPN_ON:#AfteraddingtheRPNhead,restrictFPNblobsandscalesto#thoseusedintheRoIheadsblob_conv,spatial_scale_conv=_narrow_to_fpn_roi_levels(blob_conv,spatial_scale_conv)ifnotcfg.MODEL.RPN_ONLY:#AddtheFastR-CNNheadhead_loss_gradients[\\'box\\']=_add_fast_rcnn_head(model,add_roi_box_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.MASK_ON:#Addthemaskheadhead_loss_gradients[\\'mask\\']=_add_roi_mask_head(model,add_roi_mask_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.KEYPOINTS_ON:#Addthekeypointheadhead_loss_gradients[\\'keypoint\\']=_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_conv,dim_conv,spatial_scale_conv)ifmodel.train:loss_gradients={}forlginhead_loss_gradients.values():iflgisnotNone:loss_gradients.update(lg)returnloss_gradientselse:returnNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldef_narrow_to_fpn_roi_levels(blobs,spatial_scales):\"\"\"ReturnonlytheblobsandspatialscalesthatwillbeusedforRoIheads.Inputs`blobs`and`spatial_scales`mayincludeextrablobsandscalesthatareusedforRPNproposals,butnotforRoIheads.\"\"\"#CodeonlysupportscasewhenRPNandROIminlevelsarethesameassertcfg.FPN.RPN_MIN_LEVEL==cfg.FPN.ROI_MIN_LEVEL#RPNmaxlevelcanbe>=toROImaxlevelassertcfg.FPN.RPN_MAX_LEVEL>=cfg.FPN.ROI_MAX_LEVEL#FPNRPNmaxlevelmightbe>FPNROImaxlevelinwhichcasewe#needtodiscardsomeleadingconvblobs(blobsareorderedfrom#max/coarsestleveltomin/finestlevel)num_roi_levels=cfg.FPN.ROI_MAX_LEVEL-cfg.FPN.ROI_MIN_LEVEL+1returnblobs[-num_roi_levels:],spatial_scales[-num_roi_levels:]def_add_fast_rcnn_head(model,add_roi_box_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"AddaFastR-CNNheadtothemodel.\"\"\"blob_frcn,dim_frcn=add_roi_box_head_func(model,blob_in,dim_in,spatial_scale_in)fast_rcnn_heads.add_fast_rcnn_outputs(model,blob_frcn,dim_frcn)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)else:loss_gradients=Nonereturnloss_gradientsdef_add_roi_mask_head(model,add_roi_mask_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addamaskpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthemaskheadblob_mask_head,dim_mask_head=add_roi_mask_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthemaskoutputblob_mask=mask_rcnn_heads.add_mask_rcnn_outputs(model,blob_mask_head,dim_mask_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenmaskpredictions.#Thisrequiresseparatenetsforboxandmaskprediction.#Soweextractthemaskpredictionnet,storeitasitsownnetwork,#thenrestoremodel.nettobethebbox-onlynetworkmodel.mask_net,blob_mask=c2_utils.SuffixNet(\\'mask_net\\',model.net,len(bbox_net.op),blob_mask)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=mask_rcnn_heads.add_mask_rcnn_losses(model,blob_mask)returnloss_gradientsdef_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addakeypointpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthekeypointheadblob_keypoint_head,dim_keypoint_head=add_roi_keypoint_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthekeypointoutputblob_keypoint=keypoint_rcnn_heads.add_keypoint_outputs(model,blob_keypoint_head,dim_keypoint_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenkeypointpredictions#Thisrequiresseparatenetsforboxandkeypointprediction.#Soweextractthekeypointpredictionnet,storeitasitsown#network,thenrestoremodel.nettobethebbox-onlynetworkmodel.keypoint_net,keypoint_blob_out=c2_utils.SuffixNet(\\'keypoint_net\\',model.net,len(bbox_net.op),blob_keypoint)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=keypoint_rcnn_heads.add_keypoint_losses(model)returnloss_gradientsdefbuild_generic_rfcn_model(model,add_conv_body_func,dim_reduce=None):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blob,dim,spatial_scale=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')rfcn_heads.add_rfcn_outputs(model,blob,dim,dim_reduce,spatial_scale)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldefbuild_generic_retinanet_model(model,add_conv_body_func,freeze_conv_body=False):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blobs,dim,spatial_scales=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')retinanet_heads.add_fpn_retinanet_outputs(model,blobs,dim,spatial_scales)ifmodel.train:loss_gradients=retinanet_heads.add_fpn_retinanet_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodel#----------------------------------------------------------------------------##Networkinputs#----------------------------------------------------------------------------#defadd_training_inputs(model,roidb=None):\"\"\"Createnetworkinputopsandblobsusedfortraining.Tobecalled*after*model_builder.create().\"\"\"#Implementationnotes:#Typically,onewouldcreatetheinputopsandthentherestofthenet.#However,creatingtheinputopsdependsonloadingthedataset,which#cantakeafewminutesforCOCO.#Weprefertoavoidwaitingsodebuggingcanfailfast.#Thus,wecreatethenet*withoutinputops*priortoloadingthe#dataset,andthenaddtheinputopsafterloadingthedataset.#Sincewedeferinputopcreation,weneedtodoalittlebitofsurgery#toplacetheinputopsatthestartofthenetworkoplist.assertmodel.train,\\'Traininginputscanonlybeaddedtoatrainablemodel\\'ifroidbisnotNone:#Tomakedebuggingeasieryoucansetcfg.DATA_LOADER.NUM_THREADS=1model.roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)orig_num_op=len(model.net._net.op)blob_names=roi_data_minibatch.get_minibatch_blob_names(is_training=True)forgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):forblob_nameinblob_names:workspace.CreateBlob(core.ScopedName(blob_name))model.net.DequeueBlobs(model.roi_data_loader._blobs_queue_name,blob_names)#Alittleopsurgerytomoveinputopstothestartofthenetdiff=len(model.net._net.op)-orig_num_opnew_op=model.net._net.op[-diff:]+model.net._net.op[:-diff]delmodel.net._net.op[:]model.net._net.op.extend(new_op)defadd_inference_inputs(model):\"\"\"Createnetworkinputblobsusedforinference.\"\"\"defcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)create_input_blobs_for_net(model.net.Proto())ifcfg.MODEL.MASK_ON:create_input_blobs_for_net(model.mask_net.Proto())ifcfg.MODEL.KEYPOINTS_ON:create_input_blobs_for_net(model.keypoint_net.Proto())#----------------------------------------------------------------------------##**********************DEPRECATEDFUNCTIONALITYBELOW**********************##----------------------------------------------------------------------------##----------------------------------------------------------------------------##Hardcodedfunctionstocreatevarioustypesofcommonmodels##***Thistypeofmodeldefinitionisdeprecated***#***Usethegenericcomposableversionsinstead***##----------------------------------------------------------------------------#importdetectron.modeling.ResNetasResNetimportdetectron.modeling.VGG16asVGG16importdetectron.modeling.VGG_CNN_M_1024asVGG_CNN_M_1024deffast_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`.\\')returngeneralized_rcnn(model)defmask_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:True`\\')returngeneralized_rcnn(model)defkeypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defmask_and_keypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:Trueand``MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defrpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`\\')returngeneralized_rcnn(model)deffpn_rpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`andFPNenabledviaconfigs\\')returngeneralized_rcnn(model)deffaster_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.FASTER_RCNN:True`\\')returngeneralized_rcnn(model)deffast_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),freeze_conv_body=True)defrpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)deffpn_rpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)defmask_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),freeze_conv_body=True)defkeypoint_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=True)#----------------------------------------------------------------------------##FastR-CNNmodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,VGG_CNN_M_1024.add_VGG_CNN_M_1024_roi_fc_head)defVGG16_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet50_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)defResNet101_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)#----------------------------------------------------------------------------##RPN-onlymodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_rpn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body)defVGG16_rpn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body)defResNet50_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body)defResNet101_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body)defVGG_CNN_M_1024_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,freeze_conv_body=True)defVGG16_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,freeze_conv_body=True)defResNet50_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,freeze_conv_body=True)defResNet101_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,freeze_conv_body=True)#----------------------------------------------------------------------------##FasterR-CNNmodels#----------------------------------------------------------------------------#defVGG16_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)#----------------------------------------------------------------------------##R-FCNmodels#----------------------------------------------------------------------------#defResNet50_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet50_conv5_body,dim_reduce=1024)defResNet101_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet101_conv5_body,dim_reduce=1024)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforusingaFeaturePyramidNetwork(FPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcollectionsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utils#Lowestandhighestpyramidlevelsinthebackbonenetwork.ForFPN,weassume#thatallnetworkshave5spatialreductions,eachbyafactorof2.Level1#wouldcorrespondtotheinputimage,henceitdoesnotmakesensetouseit.LOWEST_BACKBONE_LVL=2#E.g.,\"conv2\"-likelevelHIGHEST_BACKBONE_LVL=5#E.g.,\"conv5\"-likelevel#----------------------------------------------------------------------------##FPNwithResNet#----------------------------------------------------------------------------#defadd_fpn_ResNet50_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5)defadd_fpn_ResNet50_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5,P2only=True)defadd_fpn_ResNet101_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5)defadd_fpn_ResNet101_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5,P2only=True)defadd_fpn_ResNet152_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5)defadd_fpn_ResNet152_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5,P2only=True)#----------------------------------------------------------------------------##FunctionsforboltingFPNontoabackbonearchitectures#----------------------------------------------------------------------------#defadd_fpn_onto_conv_body(model,conv_body_func,fpn_level_info_func,P2only=False):\"\"\"AddthespecifiedconvbodytothemodelandthenaddFPNlevelstoit.\"\"\"#Note:blobs_convisinrevsersedorder:[fpn5,fpn4,fpn3,fpn2]#similarlyfordims_conv:[2048,1024,512,256]#similarlyforspatial_scales_fpn:[1/32,1/16,1/8,1/4]conv_body_func(model)blobs_fpn,dim_fpn,spatial_scales_fpn=add_fpn(model,fpn_level_info_func())ifP2only:#useonlythefinestlevelreturnblobs_fpn[-1],dim_fpn,spatial_scales_fpn[-1]else:#usealllevelsreturnblobs_fpn,dim_fpn,spatial_scales_fpndefadd_fpn(model,fpn_level_info):\"\"\"AddFPNconnectionsbasedonthemodeldescribedintheFPNpaper.\"\"\"#FPNlevelsarebuiltstartingfromthehighest/coarestlevelofthe#backbone(usually\"conv5\").Firstwebuilddown,recursivelyconstructing#lower/finerresolutionFPNlevels.Thenwebuildup,constructinglevels#thatareevenhigher/coarserthanthestartinglevel.fpn_dim=cfg.FPN.DIMmin_level,max_level=get_min_max_levels()#CountthenumberofbackbonestagesthatwewillgenerateFPNlevelsfor#startingfromthecoarestbackbonestage(usuallythe\"conv5\"-likelevel)#E.g.,ifthebackbonelevelinfodefinesstages4stages:\"conv5\",#\"conv4\",...\"conv2\"andmin_level=2,thenweendupwith4-(2-2)=4#backbonestagestoaddFPNto.num_backbone_stages=(len(fpn_level_info.blobs)-(min_level-LOWEST_BACKBONE_LVL))lateral_input_blobs=fpn_level_info.blobs[:num_backbone_stages]output_blobs=[\\'fpn_inner_{}\\'.format(s)forsinfpn_level_info.blobs[:num_backbone_stages]]fpn_dim_lateral=fpn_level_info.dimsxavier_fill=(\\'XavierFill\\',{})#Forthecoarsestbackbonelevel:1x1convonlyseedsrecursionifcfg.FPN.USE_GN:#useGroupNormc=model.ConvGN(lateral_input_blobs[0],output_blobs[0],#note:thisisaprefixdim_in=fpn_dim_lateral[0],dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))output_blobs[0]=c#renameitelse:model.Conv(lateral_input_blobs[0],output_blobs[0],dim_in=fpn_dim_lateral[0],dim_out=fpn_dim,kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))##Step1:recursivelybuilddownstartingfromthecoarsestbackbonelevel##Forotherlevelsaddtop-downandlateralconnectionsforiinrange(num_backbone_stages-1):add_topdown_lateral_module(model,output_blobs[i],#top-downbloblateral_input_blobs[i+1],#lateralbloboutput_blobs[i+1],#nextoutputblobfpn_dim,#outputdimensionfpn_dim_lateral[i+1]#lateralinputdimension)#Post-hocscale-specific3x3convsblobs_fpn=[]spatial_scales=[]foriinrange(num_backbone_stages):ifcfg.FPN.USE_GN:#useGroupNormfpn_blob=model.ConvGN(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))else:fpn_blob=model.Conv(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))blobs_fpn+=[fpn_blob]spatial_scales+=[fpn_level_info.spatial_scales[i]]##Step2:buildupstartingfromthecoarsestbackbonelevel##CheckifweneedtheP6featuremapifnotcfg.FPN.EXTRA_CONV_LEVELSandmax_level==HIGHEST_BACKBONE_LVL+1:#OriginalFPNP6levelimplementationfromourCVPR\\'17FPNpaperP6_blob_in=blobs_fpn[0]P6_name=P6_blob_in+\\'_subsampled_2x\\'#Usemaxpoolingtosimulatestride2subsamplingP6_blob=model.MaxPool(P6_blob_in,P6_name,kernel=1,pad=0,stride=2)blobs_fpn.insert(0,P6_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)#CoarserFPNlevelsintroducedforRetinaNetifcfg.FPN.EXTRA_CONV_LEVELSandmax_level>HIGHEST_BACKBONE_LVL:fpn_blob=fpn_level_info.blobs[0]dim_in=fpn_level_info.dims[0]foriinrange(HIGHEST_BACKBONE_LVL+1,max_level+1):fpn_blob_in=fpn_blobifi>HIGHEST_BACKBONE_LVL+1:fpn_blob_in=model.Relu(fpn_blob,fpn_blob+\\'_relu\\')fpn_blob=model.Conv(fpn_blob_in,\\'fpn_\\'+str(i),dim_in=dim_in,dim_out=fpn_dim,kernel=3,pad=1,stride=2,weight_init=xavier_fill,bias_init=const_fill(0.0))dim_in=fpn_dimblobs_fpn.insert(0,fpn_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)returnblobs_fpn,fpn_dim,spatial_scalesdefadd_topdown_lateral_module(model,fpn_top,fpn_lateral,fpn_bottom,dim_top,dim_lateral):\"\"\"Addatop-downlateralmodule.\"\"\"#Lateral1x1convifcfg.FPN.USE_GN:#useGroupNormlat=model.ConvGN(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,group_gn=get_group_gn(dim_top),kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))else:lat=model.Conv(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))#Top-down2xupsamplingtd=model.net.UpsampleNearest(fpn_top,fpn_bottom+\\'_topdown\\',scale=2)#Sumlateralandtop-downmodel.net.Sum([lat,td],fpn_bottom)defget_min_max_levels():\"\"\"TheminandmaxFPNlevelsrequiredforsupportingRPNand/orRoItransformoperationsonmultipleFPNlevels.\"\"\"min_level=LOWEST_BACKBONE_LVLmax_level=HIGHEST_BACKBONE_LVLifcfg.FPN.MULTILEVEL_RPNandnotcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.RPN_MAX_LEVELmin_level=cfg.FPN.RPN_MIN_LEVELifnotcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.ROI_MAX_LEVELmin_level=cfg.FPN.ROI_MIN_LEVELifcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=max(cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.ROI_MAX_LEVEL)min_level=min(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.ROI_MIN_LEVEL)returnmin_level,max_level#----------------------------------------------------------------------------##RPNwithanFPNbackbone#----------------------------------------------------------------------------#defadd_fpn_rpn_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"AddRPNonFPNspecificoutputs.\"\"\"num_anchors=len(cfg.FPN.RPN_ASPECT_RATIOS)dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scales[k_max-lvl]#inreversedorderslvl=str(lvl)iflvl==k_min:#Createconvopswithrandomlyinitializedweightsand#zeroedbiasesforthefirstFPNlevel;thesewillbesharedby#allotherFPNlevels#RPNhiddenrepresentationconv_rpn_fpn=model.Conv(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.Conv(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.Conv(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))else:#Shareweightsandbiasessk_min=str(k_min)#RPNhiddenrepresentationconv_rpn_fpn=model.ConvShared(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight=\\'conv_rpn_fpn\\'+sk_min+\\'_w\\',bias=\\'conv_rpn_fpn\\'+sk_min+\\'_b\\')model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_b\\')#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_b\\')ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededlvl_anchors=generate_anchors(stride=2.**lvl,sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),),aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOS)rpn_cls_probs_fpn=model.net.Sigmoid(rpn_cls_logits_fpn,\\'rpn_cls_probs_fpn\\'+slvl)model.GenerateProposals([rpn_cls_probs_fpn,rpn_bbox_pred_fpn,\\'im_info\\'],[\\'rpn_rois_fpn\\'+slvl,\\'rpn_roi_probs_fpn\\'+slvl],anchors=lvl_anchors,spatial_scale=sc)defadd_fpn_rpn_losses(model):\"\"\"AddRPNonFPNspecificlosses.\"\"\"loss_gradients={}forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):slvl=str(lvl)#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide_fpn\\'+slvl,\\'rpn_cls_logits_fpn\\'+slvl],\\'rpn_labels_int32_fpn\\'+slvl)forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide_fpn\\'+slvl,\\'rpn_bbox_pred_fpn\\'+slvl],\\'rpn_bbox_\\'+key+\\'_fpn\\'+slvl)loss_rpn_cls_fpn=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits_fpn\\'+slvl,\\'rpn_labels_int32_fpn\\'+slvl],\\'loss_rpn_cls_fpn\\'+slvl,normalize=0,scale=(model.GetLossScale()/cfg.TRAIN.RPN_BATCH_SIZE_PER_IM/cfg.TRAIN.IMS_PER_BATCH))#Normalizationby(1)RPN_BATCH_SIZE_PER_IMand(2)IMS_PER_BATCHis#handledby(1)settingbboxoutsideweightsand(2)SmoothL1Loss#normalizesbyIMS_PER_BATCHloss_rpn_bbox_fpn=model.net.SmoothL1Loss([\\'rpn_bbox_pred_fpn\\'+slvl,\\'rpn_bbox_targets_fpn\\'+slvl,\\'rpn_bbox_inside_weights_fpn\\'+slvl,\\'rpn_bbox_outside_weights_fpn\\'+slvl],\\'loss_rpn_bbox_fpn\\'+slvl,beta=1./9.,scale=model.GetLossScale(),)loss_gradients.update(blob_utils.get_loss_gradients(model,[loss_rpn_cls_fpn,loss_rpn_bbox_fpn]))model.AddLosses([\\'loss_rpn_cls_fpn\\'+slvl,\\'loss_rpn_bbox_fpn\\'+slvl])returnloss_gradients#----------------------------------------------------------------------------##HelperfunctionsforworkingwithmultilevelFPNRoIs#----------------------------------------------------------------------------#defmap_rois_to_fpn_levels(rois,k_min,k_max):\"\"\"DeterminewhichFPNleveleachRoIinasetofRoIsshouldmaptobasedontheheuristicintheFPNpaper.\"\"\"#Computelevelidss=np.sqrt(box_utils.boxes_area(rois))s0=cfg.FPN.ROI_CANONICAL_SCALE#default:224lvl0=cfg.FPN.ROI_CANONICAL_LEVEL#default:4#Eqn.(1)inFPNpapertarget_lvls=np.floor(lvl0+np.log2(s/s0+1e-6))target_lvls=np.clip(target_lvls,k_min,k_max)returntarget_lvlsdefadd_multilevel_roi_blobs(blobs,blob_prefix,rois,target_lvls,lvl_min,lvl_max):\"\"\"AddRoIblobsformultipleFPNlevelstotheblobsdict.blobs:adictmappingfromblobnametonumpyndarrayblob_prefix:nameprefixtousefortheFPNblobsrois:thesourceroisasa2Dnumpyarrayofshape(N,5)whereeachrowisanroiandthecolumnsencode(batch_idx,x1,y1,x2,y2)target_lvls:numpyarrayofshape(N,)indicatingwhichFPNleveleachroiinroisshouldbeassignedtolvl_min:thefinest(highestresolution)FPNlevel(e.g.,2)lvl_max:thecoarest(lowestresolution)FPNlevel(e.g.,6)\"\"\"rois_idx_order=np.empty((0,))rois_stacked=np.zeros((0,5),dtype=np.float32)#forassertforlvlinrange(lvl_min,lvl_max+1):idx_lvl=np.where(target_lvls==lvl)[0]blobs[blob_prefix+\\'_fpn\\'+str(lvl)]=rois[idx_lvl,:]rois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_stacked=np.vstack([rois_stacked,blobs[blob_prefix+\\'_fpn\\'+str(lvl)]])rois_idx_restore=np.argsort(rois_idx_order).astype(np.int32,copy=False)blobs[blob_prefix+\\'_idx_restore_int32\\']=rois_idx_restore#Sanitycheckthatrestoreorderiscorrectassert(rois_stacked[rois_idx_restore]==rois).all()#----------------------------------------------------------------------------##FPNlevelinfoforstages5,4,3,2forselectmodels(morecanbeadded)#----------------------------------------------------------------------------#FpnLevelInfo=collections.namedtuple(\\'FpnLevelInfo\\',[\\'blobs\\',\\'dims\\',\\'spatial_scales\\'])deffpn_level_info_ResNet50_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_5_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet101_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_22_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet152_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_35_sum\\',\\'res3_7_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forclassificationandboundingboxprediction.Thedesignisasfollows:...->RoI----\\\\/->boxclsoutput->clsloss->RoIFeatureXform->boxhead...->Feature/\\\\->boxregoutput->reglossMapTheFastR-CNNheadproducesafeaturerepresentationoftheRoIforthepurposeofboundingboxclassificationandregression.Theboxoutputmoduleconvertsthefeaturerepresentationintoclassificationandregressionpredictions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##FastR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_fast_rcnn_outputs(model,blob_in,dim):\"\"\"AddRoIclassificationandboundingboxregressionoutputops.\"\"\"#Boxclassificationlayermodel.FC(blob_in,\\'cls_score\\',dim,model.num_classes,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.train:#==iftest#Onlyaddsoftmaxwhentesting;duringtrainingthesoftmaxiscombined#withthelabelcrossentropylossfornumericalstabilitymodel.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#Boxregressionlayernum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.FC(blob_in,\\'bbox_pred\\',dim,num_bbox_reg_classes*4,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))defadd_fast_rcnn_losses(model):\"\"\"AddlossesforRoIclassificationandboundingboxregression.\"\"\"cls_prob,loss_cls=model.net.SoftmaxWithLoss([\\'cls_score\\',\\'labels_int32\\'],[\\'cls_prob\\',\\'loss_cls\\'],scale=model.GetLossScale())loss_bbox=model.net.SmoothL1Loss([\\'bbox_pred\\',\\'bbox_targets\\',\\'bbox_inside_weights\\',\\'bbox_outside_weights\\'],\\'loss_bbox\\',scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_cls,loss_bbox])model.Accuracy([\\'cls_prob\\',\\'labels_int32\\'],\\'accuracy_cls\\')model.AddLosses([\\'loss_cls\\',\\'loss_bbox\\'])model.AddMetrics(\\'accuracy_cls\\')returnloss_gradients#----------------------------------------------------------------------------##Boxheads#----------------------------------------------------------------------------#defadd_roi_2mlp_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaReLUMLPwithtwohiddenlayers.\"\"\"hidden_dim=cfg.FAST_RCNN.MLP_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(roi_feat,\\'fc6\\',dim_in*roi_size*roi_size,hidden_dim)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',hidden_dim,hidden_dim)model.Relu(\\'fc7\\',\\'fc7\\')return\\'fc7\\',hidden_dimdefadd_roi_Xconv1fc_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,asareferenceifnotusingGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}),no_bias=0)current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dimdefadd_roi_Xconv1fc_gn_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,withGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.ConvGN(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,group_gn=get_group_gn(hidden_dim),stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingmasksinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->maskhead->maskoutput->loss...->Feature/MapThemaskheadproducesafeaturerepresentationoftheRoIforthepurposeofmaskprediction.Themaskoutputmoduleconvertsthefeaturerepresentationintoreal-valued(soft)masks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##MaskR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_mask_rcnn_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNspecificoutputs:eithermasklogitsorprobs.\"\"\"num_cls=cfg.MODEL.NUM_CLASSESifcfg.MRCNN.CLS_SPECIFIC_MASKelse1ifcfg.MRCNN.USE_FC_OUTPUT:#Predictmaskswithafullyconnectedlayer(ignore\\'fcn\\'intheblob#name)dim_fc=int(dim*(cfg.MRCNN.RESOLUTION/cfg.MRCNN.UPSAMPLE_RATIO)**2)blob_out=model.FC(blob_in,\\'mask_fcn_logits\\',dim_fc,num_cls*cfg.MRCNN.RESOLUTION**2,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))else:#PredictmaskusingConv#UseGaussianFillforclass-agnosticmaskprediction;fillsbasedon#fan-incanbetoolargeinthiscaseandcausedivergencefill=(cfg.MRCNN.CONV_INITifcfg.MRCNN.CLS_SPECIFIC_MASKelse\\'GaussianFill\\')blob_out=model.Conv(blob_in,\\'mask_fcn_logits\\',dim,num_cls,kernel=1,pad=0,stride=1,weight_init=(fill,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifcfg.MRCNN.UPSAMPLE_RATIO>1:blob_out=model.BilinearInterpolation(\\'mask_fcn_logits\\',\\'mask_fcn_logits_up\\',num_cls,num_cls,cfg.MRCNN.UPSAMPLE_RATIO)ifnotmodel.train:#==iftestblob_out=model.net.Sigmoid(blob_out,\\'mask_fcn_probs\\')returnblob_outdefadd_mask_rcnn_losses(model,blob_mask):\"\"\"AddMaskR-CNNspecificlosses.\"\"\"loss_mask=model.net.SigmoidCrossEntropyLoss([blob_mask,\\'masks_int32\\'],\\'loss_mask\\',scale=model.GetLossScale()*cfg.MRCNN.WEIGHT_LOSS_MASK)loss_gradients=blob_utils.get_loss_gradients(model,[loss_mask])model.AddLosses(\\'loss_mask\\')returnloss_gradients#----------------------------------------------------------------------------##Maskheads#----------------------------------------------------------------------------#defmask_rcnn_fcn_head_v1up4convs(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up4convs_gn(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2,withGroupNorm\"\"\"returnmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:2*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,2)defmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2.\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.Conv(current,\\'_[mask]_fcn\\'+str(i+1),dim_in,dim_inner,kernel=3,dilation=dilation,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2,withGroupNorm\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_mask_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.ConvGN(current,\\'_mask_fcn\\'+str(i+1),dim_in,dim_inner,group_gn=get_group_gn(dim_inner),kernel=3,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v0upshare(model,blob_in,dim_in,spatial_scale):\"\"\"UseaResNet\"conv5\"/\"stage5\"headformaskprediction.Weightsandcomputationaresharedwiththeconv5boxhead.Computationcanonlybesharedduringtraining,sinceinferenceiscascaded.v0upsharedesign:conv5,convT2x2.\"\"\"#Sinceboxandmaskheadareshared,thesemustmatchassertcfg.MRCNN.ROI_XFORM_RESOLUTION==cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONifmodel.train:#sharecomputationwithbboxheadattrainingtimedim_conv5=2048blob_conv5=model.net.SampleAs([\\'res5_2_sum\\',\\'roi_has_mask_int32\\'],[\\'_[mask]_res5_2_sum_sliced\\'])else:#re-computeattesttimeblob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDblob_mask=model.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),#stdonlyforgaussbias_init=const_fill(0.0))model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefmask_rcnn_fcn_head_v0up(model,blob_in,dim_in,spatial_scale):\"\"\"v0updesign:conv5,deconv2x2(noweightsharingwiththeboxhead).\"\"\"blob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDmodel.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(\\'GaussianFill\\',{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefadd_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforpredictingmasks.\"\"\"model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_pool5\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONstride_init=int(cfg.MRCNN.ROI_XFORM_RESOLUTION/7)#bydefault:2s,dim_in=ResNet.add_stage(model,\\'_[mask]_res5\\',\\'_[mask]_pool5\\',3,dim_in,2048,512,dilation,stride_init=stride_init)returns,2048#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG_CNN_M_1024from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG_CNN_M_1024_conv5_body(model):model.Conv(\\'data\\',\\'conv1\\',3,96,7,pad=0,stride=2)model.Relu(\\'conv1\\',\\'conv1\\')model.LRN(\\'conv1\\',\\'norm1\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm1\\',\\'pool1\\',kernel=3,pad=0,stride=2)model.StopGradient(\\'pool1\\',\\'pool1\\')#Noupdatesatconv1andbelow(norm1andpool1havenoparams,#sowecanstopgradientsbeforethem,too)model.Conv(\\'pool1\\',\\'conv2\\',96,256,5,pad=0,stride=2)model.Relu(\\'conv2\\',\\'conv2\\')model.LRN(\\'conv2\\',\\'norm2\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm2\\',\\'pool2\\',kernel=3,pad=0,stride=2)model.Conv(\\'pool2\\',\\'conv3\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv3\\',\\'conv3\\')model.Conv(\\'conv3\\',\\'conv4\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4\\',\\'conv4\\')model.Conv(\\'conv4\\',\\'conv5\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5\\',\\'conv5\\')returnblob_out,512,1./16.defadd_VGG_CNN_M_1024_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=6,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*6*6,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,1024)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,1024#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Optimizationoperatorgraphconstruction.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromcaffe2.pythonimportmujifromdetectron.core.configimportcfgimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)defbuild_data_parallel_model(model,single_gpu_build_func):\"\"\"BuildadataparallelmodelgivenafunctionthatbuildsthemodelonasingleGPU.\"\"\"ifmodel.only_build_forward_pass:single_gpu_build_func(model)elifmodel.train:all_loss_gradients=_build_forward_graph(model,single_gpu_build_func)#AddbackwardpassonallGPUsmodel.AddGradientOperators(all_loss_gradients)ifcfg.NUM_GPUS>1:_add_allreduce_graph(model)forgpu_idinrange(cfg.NUM_GPUS):#Afterallreduce,allGPUsperformSGDupdatesontheiridentical#paramsandgradientsinparallelwithc2_utils.NamedCudaScope(gpu_id):add_single_gpu_param_update_ops(model,gpu_id)else:#Test-timenetworkoperatesonsingleGPU#Test-timeparallelismisimplementedthroughmultiprocessingwithc2_utils.NamedCudaScope(model.target_gpu_id):single_gpu_build_func(model)def_build_forward_graph(model,single_gpu_build_func):\"\"\"ConstructtheforwardgraphoneachGPU.\"\"\"all_loss_gradients={}#WillincludelossgradientsfromallGPUs#BuildthemodeloneachGPUwithcorrectnameanddevicescopingforgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):all_loss_gradients.update(single_gpu_build_func(model))returnall_loss_gradientsdef_add_allreduce_graph(model):\"\"\"ConstructthegraphthatperformsAllreduceonthegradients.\"\"\"#Needtoall-reducetheper-GPUgradientsiftrainingwithmorethan1GPUall_params=model.TrainableParams()assertlen(all_params)%cfg.NUM_GPUS==0#ThemodelparametersarereplicatedoneachGPU,getthenumber#distinctparameterblobs(i.e.,thenumberofparameterblobson#eachGPU)params_per_gpu=int(len(all_params)/cfg.NUM_GPUS)withc2_utils.CudaScope(0):#Iterateoverdistinctparameterblobsforiinrange(params_per_gpu):#GradientsfromallGPUsforthisparameterblobgradients=[model.param_to_grad[p]forpinall_params[i::params_per_gpu]]iflen(gradients)>0:ifcfg.USE_NCCL:model.net.NCCLAllreduce(gradients,gradients)else:muji.Allreduce(model.net,gradients,reduced_affix=\\'\\')defadd_single_gpu_param_update_ops(model,gpu_id):#Learningrateof0isadummyvaluetobesetproperlyatthe#startoftraininglr=model.param_init_net.ConstantFill([],\\'lr\\',shape=[1],value=0.0)one=model.param_init_net.ConstantFill([],\\'one\\',shape=[1],value=1.0)wd=model.param_init_net.ConstantFill([],\\'wd\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY)#weightdecayofGroupNorm\\'sparameterswd_gn=model.param_init_net.ConstantFill([],\\'wd_gn\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY_GN)forparaminmodel.TrainableParams(gpu_id=gpu_id):logger.debug(\\'param\\'+str(param)+\\'willbeupdated\\')param_grad=model.param_to_grad[param]#Initializemomentumvectorparam_momentum=model.param_init_net.ConstantFill([param],param+\\'_momentum\\',value=0.0)ifparaminmodel.biases:#Specialtreatmentforbiases(mainlytomatchhistoricalimpl.#details):#(1)Donotapplyweightdecay#(2)Usea2xhigherlearningratemodel.Scale(param_grad,param_grad,scale=2.0)elifparaminmodel.gn_params:#SpecialtreatmentforGroupNorm\\'sparametersmodel.WeightedSum([param_grad,one,param,wd_gn],param_grad)elifcfg.SOLVER.WEIGHT_DECAY>0:#Applyweightdecaytonon-biasweightsmodel.WeightedSum([param_grad,one,param,wd],param_grad)#Updateparam_gradandparam_momentuminplacemodel.net.MomentumSGDUpdate([param_grad,param_momentum,lr,param],[param_grad,param_momentum,param],momentum=cfg.SOLVER.MOMENTUM)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"DefinesDetectionModelHelper,theclassthatrepresentsaDetectronmodel.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcaffe2.pythonimportcnnfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromcaffe2.python.modelingimportinitializersfromcaffe2.python.modeling.parameter_infoimportParameterTagsfromdetectron.core.configimportcfgfromdetectron.ops.collect_and_distribute_fpn_rpn_proposals\\\\importCollectAndDistributeFpnRpnProposalsOpfromdetectron.ops.generate_proposal_labelsimportGenerateProposalLabelsOpfromdetectron.ops.generate_proposalsimportGenerateProposalsOpimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classDetectionModelHelper(cnn.CNNModelHelper):def__init__(self,**kwargs):#HandleargsspecifictotheDetectionModelHelper,otherspassthrough#toCNNModelHelperself.train=kwargs.get(\\'train\\',False)self.num_classes=kwargs.get(\\'num_classes\\',-1)assertself.num_classes>0,\\'num_classesmustbe>0\\'forkin(\\'train\\',\\'num_classes\\'):ifkinkwargs:delkwargs[k]kwargs[\\'order\\']=\\'NCHW\\'#Defensivelysetcudnn_exhaustive_searchtoFalseincasethedefault#changesinCNNModelHelper.Thedetectioncodeusesvariablesize#inputsthatmightnotplaynicelywithcudnn_exhaustive_search.kwargs[\\'cudnn_exhaustive_search\\']=Falsesuper(DetectionModelHelper,self).__init__(**kwargs)self.roi_data_loader=Noneself.losses=[]self.metrics=[]self.do_not_update_params=[]#Paramonthislistarenotupdatedself.net.Proto().type=cfg.MODEL.EXECUTION_TYPEself.net.Proto().num_workers=cfg.NUM_GPUS*4self.prev_use_cudnn=self.use_cudnnself.gn_params=[]#ParamonthislistareGroupNormparametersdefTrainableParams(self,gpu_id=-1):\"\"\"Gettheblobnamesforalltrainableparameters,possiblyfilteredbyGPUid.\"\"\"return[pforpinself.paramsif(pinself.param_to_gradand#phasagradientpnotinself.do_not_update_paramsand#notontheblacklist(gpu_id==-1or#filterforgpuassignment,ifgpu_idsetstr(p).find(\\'gpu_{}\\'.format(gpu_id))==0))]defAffineChannel(self,blob_in,blob_out,dim,inplace=False):\"\"\"AffinetransformationtoreplaceBNinnetworkswhereBNcannotbeused(e.g.,becausetheminibatchsizeistoosmall).Theoperationscanbedoneinplacetosavememory.\"\"\"blob_out=blob_outorself.net.NextName()param_prefix=blob_outscale=self.create_param(param_name=param_prefix+\\'_s\\',initializer=initializers.Initializer(\"ConstantFill\",value=1.),tags=ParameterTags.WEIGHT,shape=[dim,],)bias=self.create_param(param_name=param_prefix+\\'_b\\',initializer=initializers.Initializer(\"ConstantFill\",value=0.),tags=ParameterTags.BIAS,shape=[dim,],)ifinplace:returnself.net.AffineChannel([blob_in,scale,bias],blob_in)else:returnself.net.AffineChannel([blob_in,scale,bias],blob_out)defGenerateProposals(self,blobs_in,blobs_out,anchors,spatial_scale):\"\"\"OpforgeneratingRPNporposals.blobs_in:-\\'rpn_cls_probs\\':4Dtensorofshape(N,A,H,W),whereNisthenumberofminibatchimages,Aisthenumberofanchorsperlocations,and(H,W)isthespatialsizeofthepredictiongrid.Eachvaluerepresentsa\"probabilityofobject\"ratingin[0,1].-\\'rpn_bbox_pred\\':4Dtensorofshape(N,4*A,H,W)ofpredicteddeltasfortransformationanchorboxesintoRPNproposals.-\\'im_info\\':2Dtensorofshape(N,3)wherethethreecolumnsencodetheinputimage\\'s[height,width,scale].Heightandwidtharefortheinputtothenetwork,nottheoriginalimage;scaleisthescalefactorusedtoscaletheoriginalimagetothenetworkinputsize.blobs_out:-\\'rpn_rois\\':2Dtensorofshape(R,5),forRRPNproposalswherethefivecolumnsencode[batchind,x1,y1,x2,y2].Theboxesarew.r.t.thenetworkinput,whichisa*scaled*versionoftheoriginalimage;theseproposalsmustbescaledby1/scale(wherescalecomesfromim_info;seeabove)totransformitbacktotheoriginalinputimagecoordinatesystem.-\\'rpn_roi_probs\\':1Dtensorofobjectnessprobabilityscores(extractedfromrpn_cls_probs;seeabove).\"\"\"cfg_key=\\'TRAIN\\'ifself.trainelse\\'TEST\\'ifcfg[cfg_key].GENERATE_PROPOSALS_ON_GPU:rpn_pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Nrpn_post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nrpn_nms_thresh=cfg[cfg_key].RPN_NMS_THRESHrpn_min_size=float(cfg[cfg_key].RPN_MIN_SIZE)input_name=str(blobs_in[0])lvl=int(input_name[-1])ifinput_name[-1].isdigit()elseNoneanchors_name=\\'anchors{}\\'.format(lvl)iflvlelse\\'anchors\\'foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/{}\\'.format(i,anchors_name),anchors.astype(np.float32))self.net.GenerateProposals(blobs_in+[anchors_name],blobs_out,spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,)else:name=\\'GenerateProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#spatial_scalepassedtothePythonopisonlyusedin#convert_pkl_to_pbself.net.Python(GenerateProposalsOp(anchors,spatial_scale,self.train).forward)(blobs_in,blobs_out,name=name,spatial_scale=spatial_scale)returnblobs_outdefGenerateProposalLabels(self,blobs_in):\"\"\"OpforgeneratingtraininglabelsforRPNproposals.ThisisusedwhentrainingRPNjointlywithFast/MaskR-CNN(asinend-to-endFasterR-CNNtraining).blobs_in:-\\'rpn_rois\\':2DtensorofRPNproposalsoutputbyGenerateProposals-\\'roidb\\':roidbentriesthatwillbelabeled-\\'im_info\\':SeeGenerateProposalsdoc.blobs_out:-(variablesetofblobs):returnswhateverblobsarerequiredfortrainingthemodel.Itdoesthisbyqueryingthedataloaderforthelistofblobsthatareneeded.\"\"\"name=\\'GenerateProposalLabelsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Thelistofblobsisnotknownbeforerun-timebecauseitdependson#thespecificmodelbeingtrained.Querythedataloadertogetthe#listofoutputblobnames.blobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]self.net.Python(GenerateProposalLabelsOp().forward)(blobs_in,blobs_out,name=name)returnblobs_outdefCollectAndDistributeFpnRpnProposals(self):\"\"\"MergeRPNproposalsgeneratedatmultipleFPNlevelsandthendistributethoseproposalstotheirappropriateFPNlevels.AnanchoratoneFPNlevelmaypredictanRoIthatwillmaptoanotherlevel,hencetheneedtoredistributetheproposals.Thisfunctionassumesstandardblobnamesforinputandoutputblobs.Inputblobs:[rpn_rois_fpn,...,rpn_rois_fpn,rpn_roi_probs_fpn,...,rpn_roi_probs_fpn]-rpn_rois_fpnaretheRPNproposalsforFPNleveli;seerpn_roisdocumentationfromGenerateProposals.-rpn_roi_probs_fpnaretheRPNobjectnessprobabilitiesforFPNleveli;seerpn_roi_probsdocumentationfromGenerateProposals.Ifusedduringtraining,thentheinputblobswillalsoinclude:[roidb,im_info](seeGenerateProposalLabels).Outputblobs:[rois_fpn,...,rois_rpn,rois,rois_idx_restore]-rois_fpnaretheRPNproposalsforFPNleveli-rois_idx_restoreisapermutationontheconcatenationofallrois_fpn,i=min...max,suchthatwhenappliedtheRPNRoIsarerestoredtotheiroriginalorderintheinputblobs.Ifusedduringtraining,thentheoutputblobswillalsoinclude:[labels,bbox_targets,bbox_inside_weights,bbox_outside_weights].\"\"\"k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVEL#Prepareinputblobsrois_names=[\\'rpn_rois_fpn\\'+str(l)forlinrange(k_min,k_max+1)]score_names=[\\'rpn_roi_probs_fpn\\'+str(l)forlinrange(k_min,k_max+1)]blobs_in=rois_names+score_namesifself.train:blobs_in+=[\\'roidb\\',\\'im_info\\']blobs_in=[core.ScopedBlobReference(b)forbinblobs_in]name=\\'CollectAndDistributeFpnRpnProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Prepareoutputblobsblobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]outputs=self.net.Python(CollectAndDistributeFpnRpnProposalsOp(self.train).forward)(blobs_in,blobs_out,name=name)returnoutputsdefDropoutIfTraining(self,blob_in,dropout_rate):\"\"\"Adddropouttoblob_inifthemodelisintrainingmodeanddropout_rateis>0.\"\"\"blob_out=blob_inifself.trainanddropout_rate>0:blob_out=self.Dropout(blob_in,blob_in,ratio=dropout_rate,is_test=False)returnblob_outdefRoIFeatureTransform(self,blobs_in,blob_out,blob_rois=\\'rois\\',method=\\'RoIPoolF\\',resolution=7,spatial_scale=1./16.,sampling_ratio=0):\"\"\"AddthespecifiedRoIpoolingmethod.Thesampling_ratioargumentissupportedforsome,butnotall,RoItransformmethods.RoIFeatureTransformabstractsaway:-UseofFPNornot-Specificsofthetransformmethod\"\"\"assertmethodin{\\'RoIPoolF\\',\\'RoIAlign\\'},\\\\\\'Unknownpoolingmethod:{}\\'.format(method)has_argmax=(method==\\'RoIPoolF\\')ifisinstance(blobs_in,list):#FPNcase:addRoIFeatureTransformtoeachFPNlevelk_max=cfg.FPN.ROI_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.ROI_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1bl_out_list=[]forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scale[k_max-lvl]#inreversedorderbl_rois=blob_rois+\\'_fpn\\'+str(lvl)bl_out=blob_out+\\'_fpn\\'+str(lvl)bl_out_list.append(bl_out)bl_argmax=[\\'_argmax_\\'+bl_out]ifhas_argmaxelse[]self.net.__getattr__(method)([bl_in,bl_rois],[bl_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=sc,sampling_ratio=sampling_ratio)#Thepooledfeaturesfromalllevelsareconcatenatedalongthe#batchdimensionintoasingle4Dtensor.xform_shuffled,_=self.net.Concat(bl_out_list,[blob_out+\\'_shuffled\\',\\'_concat_\\'+blob_out],axis=0)#Unshuffletomatchroisfromdataloaderrestore_bl=blob_rois+\\'_idx_restore_int32\\'xform_out=self.net.BatchPermutation([xform_shuffled,restore_bl],blob_out)else:#Singlefeaturelevelbl_argmax=[\\'_argmax_\\'+blob_out]ifhas_argmaxelse[]#sampling_ratioisignoredforRoIPoolFxform_out=self.net.__getattr__(method)([blobs_in,blob_rois],[blob_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=spatial_scale,sampling_ratio=sampling_ratio)#Onlyreturnthefirstblob(thetransformedfeatures)returnxform_out[0]ifisinstance(xform_out,tuple)elsexform_outdefConvShared(self,blob_in,blob_out,dim_in,dim_out,kernel,weight=None,bias=None,**kwargs):\"\"\"Addconvopthatsharesweightsand/orbiaseswithanotherconvop.\"\"\"use_bias=(Falseif(\\'no_bias\\'inkwargsandkwargs[\\'no_bias\\'])elseTrue)ifself.use_cudnn:kwargs[\\'engine\\']=\\'CUDNN\\'kwargs[\\'exhaustive_search\\']=self.cudnn_exhaustive_searchifself.ws_nbytes_limit:kwargs[\\'ws_nbytes_limit\\']=self.ws_nbytes_limitifuse_bias:blobs_in=[blob_in,weight,bias]else:blobs_in=[blob_in,weight]if\\'no_bias\\'inkwargs:delkwargs[\\'no_bias\\']returnself.net.Conv(blobs_in,blob_out,kernel=kernel,order=self.order,**kwargs)defBilinearInterpolation(self,blob_in,blob_out,dim_in,dim_out,up_scale):\"\"\"Bilinearinterpolationinspaceofscale.TakesinputofNxKxHxWandoutputsNxKx(sH)x(sW),wheres:=up_scaleAdaptedfromtheCVPR\\'15FCNcode.See:\"\"\"assertdim_in==dim_outassertup_scale%2==0,\\'Scaleshouldbeeven\\'defupsample_filt(size):factor=(size+1)//2ifsize%2==1:center=factor-1else:center=factor-0.5og=np.ogrid[:size,:size]return((1-abs(og[0]-center)/factor)*(1-abs(og[1]-center)/factor))kernel_size=up_scale*2bil_filt=upsample_filt(kernel_size)kernel=np.zeros((dim_in,dim_out,kernel_size,kernel_size),dtype=np.float32)kernel[range(dim_out),range(dim_in),:,:]=bil_filtblob=self.ConvTranspose(blob_in,blob_out,dim_in,dim_out,kernel_size,stride=int(up_scale),pad=int(up_scale/2),weight_init=(\\'GivenTensorFill\\',{\\'values\\':kernel}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))self.do_not_update_params.append(self.weights[-1])self.do_not_update_params.append(self.biases[-1])returnblobdefConvAffine(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_bn\\',inplace=False):\"\"\"ConvAffineaddsaConvopfollowedbyaAffineChannelop(whichreplacesBNduringfinetuning).\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=1)blob_out=self.AffineChannel(conv_blob,prefix+suffix,dim=dim_out,inplace=inplace)returnblob_outdefConvGN(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group_gn,#numofgroupsingngroup=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_gn\\',no_conv_bias=1,):\"\"\"ConvGNaddsaConvopfollowedbyaGroupNormop,includinglearnablescale/bias(gamma/beta)\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=no_conv_bias)ifgroup_gn<1:logger.warning(\\'Layer:{}(dim{}):\\'\\'group_gn<1;resetto1.\\'.format(prefix,dim_in))group_gn=1blob_out=self.SpatialGN(conv_blob,prefix+suffix,dim_out,group=group_gn,#op\\'sargnameis\"group\"epsilon=cfg.GROUP_NORM.EPSILON,)self.gn_params.append(self.params[-1])#addgn\\'sbiastolistself.gn_params.append(self.params[-2])#addgn\\'sscaletolistreturnblob_outdefDisableCudnn(self):self.prev_use_cudnn=self.use_cudnnself.use_cudnn=FalsedefRestorePreviousUseCudnn(self):prev_use_cudnn=self.use_cudnnself.use_cudnn=self.prev_use_cudnnself.prev_use_cudnn=prev_use_cudnndefUpdateWorkspaceLr(self,cur_iter,new_lr):\"\"\"Updatesthemodel\\'scurrentlearningrateandtheworkspace(learningrateandupdatehistory/momentumblobs).\"\"\"#Theworkspaceistheonesourceoftruthforthelr#ThelrisalwaysthesameonallGPUscur_lr=workspace.FetchBlob(\\'gpu_0/lr\\')[0]#TherearenotypeconversionsbetweenthelrinPythonandthelrin#theGPU(botharefloat32),soexactcomparisionisokifcur_lr!=new_lr:ratio=_get_lr_change_ratio(cur_lr,new_lr)ifratio>cfg.SOLVER.LOG_LR_CHANGE_THRESHOLD:logger.info(\\'Changinglearningrate{:.6f}->{:.6f}atiter{:d}\\'.format(cur_lr,new_lr,cur_iter))self._SetNewLr(cur_lr,new_lr)returnnew_lrdef_SetNewLr(self,cur_lr,new_lr):\"\"\"Dotheactualworkofupdatingthemodelandworkspaceblobs.\"\"\"foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/lr\\'.format(i),np.array([new_lr],dtype=np.float32))ratio=_get_lr_change_ratio(cur_lr,new_lr)ifcfg.SOLVER.SCALE_MOMENTUMandcur_lr>1e-7and\\\\ratio>cfg.SOLVER.SCALE_MOMENTUM_THRESHOLD:self._CorrectMomentum(new_lr/cur_lr)def_CorrectMomentum(self,correction):\"\"\"TheMomentumSGDUpdateopimplementstheupdateVasV:=mu*V+lr*grad,wheremuisthemomentumfactor,lristhelearningrate,andgradisthestochasticgradient.SinceVisnotdefinedindependentlyofthelearningrate(asitshouldideallybe),whenthelearningrateischangedweshouldscaletheupdatehistoryVinordertomakeitcompatibleinscalewithlr*grad.\"\"\"logger.info(\\'Scalingupdatehistoryby{:.6f}(newlr/oldlr)\\'.format(correction))foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):forparaminself.TrainableParams(gpu_id=i):op=core.CreateOperator(\\'Scale\\',[param+\\'_momentum\\'],[param+\\'_momentum\\'],scale=correction)workspace.RunOperatorOnce(op)defGetLossScale(self):\"\"\"Allowawaytoconfigurethelossscaledynamically.Thismaybeusedinadistributeddataparallelsetting.\"\"\"return1.0/cfg.NUM_GPUSdefAddLosses(self,losses):ifnotisinstance(losses,list):losses=[losses]#ConversiontostrallowslossestoincludeBlobReferenceslosses=[c2_utils.UnscopeName(str(l))forlinlosses]self.losses=list(set(self.losses+losses))defAddMetrics(self,metrics):ifnotisinstance(metrics,list):metrics=[metrics]self.metrics=list(set(self.metrics+metrics))def_get_lr_change_ratio(cur_lr,new_lr):eps=1e-10ratio=np.max((new_lr/np.max((cur_lr,eps)),cur_lr/np.max((new_lr,eps))))returnratio#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Handlemappingfromoldnetworkbuildingfunctionnamestonewnames.Flexiblenetworkconfigurationisachievedbyspecifyingthefunctionnamethatbuildsanetworkmodule(e.g.,thenameoftheconvbackboneorthemaskroihead).Howeverwemaywishtochangenamesovertimewithoutbreakingpreviousconfigfiles.Thismoduleprovidesbackwardsnamingcompatibilitybyprovidingamappingfromtheoldnametothenewname.Whenrenamingfunctions,it\\'sgenerallyagoodideatocodemodexistingyamlconfigfiles.Aneasywaytobatchedit,byexample,isashellcommandlike$find.-name\"*.yaml\"-execsed-i-e\\\\\\'s/head_builder\\\\.add_roi_2mlp_head/fast_rcnn_heads.add_roi_2mlp_head/g\\'{}\\\\;toperformtherenaming:head_builder.add_roi_2mlp_head=>fast_rcnn_heads.add_roi_2mlp_head\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literals_RENAME={#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up\\':\\'mask_rcnn_heads.mask_rc',\n",
       " 'nn_fcn_head_v1up\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0upshare\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0upshare\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0up\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0up\\',#Removedhead_buildermoduleinfavorofthemorespecificfast_rcnnname\\'head_builder.add_roi_2mlp_head\\':\\'fast_rcnn_heads.add_roi_2mlp_head\\',}defget_new_name(func_name):iffunc_namein_RENAME:func_name=_RENAME[func_name]returnfunc_name#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.FPNasFPNimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##RPNandFasterR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_generic_rpn_outputs(model,blob_in,dim_in,spatial_scale_in):\"\"\"AddRPNoutputs(objectnessclassificationandboundingboxregression)toanRPNmodel.AbstractsawaytheuseofFPN.\"\"\"loss_gradients=Noneifcfg.FPN.FPN_ON:#DelegatetotheFPNmoduleFPN.add_fpn_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifcfg.MODEL.FASTER_RCNN:#CollectAndDistributeFpnRpnProposalsalsolabelsproposalswhenin#trainingmodemodel.CollectAndDistributeFpnRpnProposals()ifmodel.train:loss_gradients=FPN.add_fpn_rpn_losses(model)else:#NotusingFPN,addRPNtoasinglescaleadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifmodel.train:loss_gradients=add_single_scale_rpn_losses(model)returnloss_gradientsdefadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale):\"\"\"AddRPNoutputstoasinglescalemodel(i.e.,noFPN).\"\"\"anchors=generate_anchors(stride=1./spatial_scale,sizes=cfg.RPN.SIZES,aspect_ratios=cfg.RPN.ASPECT_RATIOS)num_anchors=anchors.shape[0]dim_out=dim_in#RPNhiddenrepresentationmodel.Conv(blob_in,\\'conv_rpn\\',dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'conv_rpn\\',\\'conv_rpn\\')#Proposalclassificationscoresmodel.Conv(\\'conv_rpn\\',\\'rpn_cls_logits\\',dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasmodel.Conv(\\'conv_rpn\\',\\'rpn_bbox_pred\\',dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededmodel.net.Sigmoid(\\'rpn_cls_logits\\',\\'rpn_cls_probs\\')model.GenerateProposals([\\'rpn_cls_probs\\',\\'rpn_bbox_pred\\',\\'im_info\\'],[\\'rpn_rois\\',\\'rpn_roi_probs\\'],anchors=anchors,spatial_scale=spatial_scale)ifcfg.MODEL.FASTER_RCNN:ifmodel.train:#Addopthatgeneratestraininglabelsforin-networkRPNproposalsmodel.GenerateProposalLabels([\\'rpn_rois\\',\\'roidb\\',\\'im_info\\'])else:#Aliasroistorpn_roisforinferencemodel.net.Alias(\\'rpn_rois\\',\\'rois\\')defadd_single_scale_rpn_losses(model):\"\"\"AddlossesforasinglescaleRPNmodel(i.e.,noFPN).\"\"\"#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide\\',\\'rpn_cls_logits\\'],\\'rpn_labels_int32\\')forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide\\',\\'rpn_bbox_pred\\'],\\'rpn_bbox_\\'+key)loss_rpn_cls=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits\\',\\'rpn_labels_int32\\'],\\'loss_rpn_cls\\',scale=model.GetLossScale())loss_rpn_bbox=model.net.SmoothL1Loss([\\'rpn_bbox_pred\\',\\'rpn_bbox_targets\\',\\'rpn_bbox_inside_weights\\',\\'rpn_bbox_outside_weights\\'],\\'loss_rpn_bbox\\',beta=1./9.,scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_rpn_cls,loss_rpn_bbox])model.AddLosses([\\'loss_rpn_cls\\',\\'loss_rpn_bbox\\'])returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG16from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG16_conv5_body(model):model.Conv(\\'data\\',\\'conv1_1\\',3,64,3,pad=1,stride=1)model.Relu(\\'conv1_1\\',\\'conv1_1\\')model.Conv(\\'conv1_1\\',\\'conv1_2\\',64,64,3,pad=1,stride=1)model.Relu(\\'conv1_2\\',\\'conv1_2\\')model.MaxPool(\\'conv1_2\\',\\'pool1\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool1\\',\\'conv2_1\\',64,128,3,pad=1,stride=1)model.Relu(\\'conv2_1\\',\\'conv2_1\\')model.Conv(\\'conv2_1\\',\\'conv2_2\\',128,128,3,pad=1,stride=1)model.Relu(\\'conv2_2\\',\\'conv2_2\\')model.MaxPool(\\'conv2_2\\',\\'pool2\\',kernel=2,pad=0,stride=2)model.StopGradient(\\'pool2\\',\\'pool2\\')model.Conv(\\'pool2\\',\\'conv3_1\\',128,256,3,pad=1,stride=1)model.Relu(\\'conv3_1\\',\\'conv3_1\\')model.Conv(\\'conv3_1\\',\\'conv3_2\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_2\\',\\'conv3_2\\')model.Conv(\\'conv3_2\\',\\'conv3_3\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_3\\',\\'conv3_3\\')model.MaxPool(\\'conv3_3\\',\\'pool3\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool3\\',\\'conv4_1\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv4_1\\',\\'conv4_1\\')model.Conv(\\'conv4_1\\',\\'conv4_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_2\\',\\'conv4_2\\')model.Conv(\\'conv4_2\\',\\'conv4_3\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_3\\',\\'conv4_3\\')model.MaxPool(\\'conv4_3\\',\\'pool4\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool4\\',\\'conv5_1\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_1\\',\\'conv5_1\\')model.Conv(\\'conv5_1\\',\\'conv5_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_2\\',\\'conv5_2\\')model.Conv(\\'conv5_2\\',\\'conv5_3\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5_3\\',\\'conv5_3\\')returnblob_out,512,1./16.defadd_VGG16_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=7,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*7*7,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,4096)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,4096#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RetinaNetmodelheadsandlosses.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_retinanet_bias_init(model):\"\"\"Initializethebiasesfortheconvopsthatpredictclassprobabilities.Initializationisperformedsuchthatatthestartoftraining,alllocationsarepredictedtobebackgroundwithhighprobability(e.g.,~0.99=1-cfg.RETINANET.PRIOR_PROB).SeetheFocalLosspaperfordetails.\"\"\"prior_prob=cfg.RETINANET.PRIOR_PROBscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)ifcfg.RETINANET.SOFTMAX:#Multiclasssoftmaxcasebias=np.zeros((model.num_classes,1),dtype=np.float32)bias[0]=np.log((model.num_classes-1)*(1-prior_prob)/(prior_prob))bias=np.vstack([biasfor_inrange(scales_per_octave*aspect_ratios)])bias_init=(\\'GivenTensorFill\\',{\\'values\\':bias.astype(dtype=np.float32)})else:#Per-classsigmoid(binaryclassification)casebias_init=(\\'ConstantFill\\',{\\'value\\':-np.log((1-prior_prob)/prior_prob)})returnbias_initdefadd_fpn_retinanet_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"RetinaNethead.Forclassificationandboxregression,wecanchosetohavethesameconvtoweroraseparatetower.\"bl_feat_list\"storesthelistoffeatureblobsforbboxprediction.Theseblobscanbesharedclsfeatureblobsifwesharethetowerorelseareindependentblobs.\"\"\"dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidA=len(cfg.RETINANET.ASPECT_RATIOS)*cfg.RETINANET.SCALES_PER_OCTAVE#computeinitforbiasbias_init=get_retinanet_bias_init(model)assertlen(blobs_in)==k_max-k_min+1bbox_feat_list=[]cls_pred_dim=(model.num_classesifcfg.RETINANET.SOFTMAXelse(model.num_classes-1))#unpackedbboxfeatureandaddpredictionlayersbbox_regr_dim=(4*(model.num_classes-1)ifcfg.RETINANET.CLASS_SPECIFIC_BBOXelse4)#==========================================================================#classificationtowerwithlogitsandprobprediction#==========================================================================forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorder#classificationtowerstackconvolutionstartsfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_cls_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_cls_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)bl_feat=bl_in#clstowerstackconvolutionends.Addthelogitslayernowiflvl==k_min:retnet_cls_pred=model.Conv(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=bias_init)else:retnet_cls_pred=model.ConvShared(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight=\\'retnet_cls_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_cls_pred_fpn{}_b\\'.format(k_min))ifnotmodel.train:ifcfg.RETINANET.SOFTMAX:model.net.GroupSpatialSoftmax(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl),num_classes=cls_pred_dim)else:model.net.Sigmoid(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl))ifcfg.RETINANET.SHARE_CLS_BBOX_TOWER:bbox_feat_list.append(bl_feat)#==========================================================================#bboxtowerifnotsharingfeatureswiththeclassificationtowerwith#logitsandprobprediction#==========================================================================ifnotcfg.RETINANET.SHARE_CLS_BBOX_TOWER:forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorderfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_bbox_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_bbox_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)#Addoctavescalesandaspectratio#Atleast1convolutionfordealingdifferentaspectratiosbl_feat=bl_inbbox_feat_list.append(bl_feat)#Dependingonthefeatures[shared/separate]forbbox,addpredictionlayerfori,lvlinenumerate(range(k_min,k_max+1)):bbox_pred=\\'retnet_bbox_pred_fpn{}\\'.format(lvl)bl_feat=bbox_feat_list[i]iflvl==k_min:model.Conv(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:model.ConvShared(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight=\\'retnet_bbox_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_bbox_pred_fpn{}_b\\'.format(k_min))defadd_fpn_retinanet_losses(model):loss_gradients={}gradients,losses=[],[]k_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidmodel.AddMetrics([\\'retnet_fg_num\\',\\'retnet_bg_num\\'])#==========================================================================#bboxregressionloss-SelectSmoothL1Lossformultipleanchorsatalocation#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)bbox_loss=model.net.SelectSmoothL1Loss([\\'retnet_bbox_pred_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,\\'retnet_fg_num\\'],\\'retnet_loss_bbox_\\'+suffix,beta=cfg.RETINANET.BBOX_REG_BETA,scale=model.GetLossScale()*cfg.RETINANET.BBOX_REG_WEIGHT)gradients.append(bbox_loss)losses.append(\\'retnet_loss_bbox_\\'+suffix)#==========================================================================#clsloss-dependsonsoftmax/sigmoidoutputs#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_lvl_logits=\\'retnet_cls_pred_\\'+suffixifnotcfg.RETINANET.SOFTMAX:cls_focal_loss=model.net.SigmoidFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes-1)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))else:cls_focal_loss,gated_prob=model.net.SoftmaxFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix),\\'retnet_prob_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))loss_gradients.update(blob_utils.get_loss_gradients(model,gradients))model.AddLosses(losses)returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnp#VerifythatwecomputethesameanchorsasShaoqing\\'smatlabimplementation:##>>loadoutput/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat#>>anchors##anchors=##-83-3910056#-175-87192104#-359-183376200#-55-557272#-119-119136136#-247-247264264#-35-795296#-79-16796184#-167-343184360#array([[-83.,-39.,100.,56.],#[-175.,-87.,192.,104.],#[-359.,-183.,376.,200.],#[-55.,-55.,72.,72.],#[-119.,-119.,136.,136.],#[-247.,-247.,264.,264.],#[-35.,-79.,52.,96.],#[-79.,-167.,96.,184.],#[-167.,-343.,184.,360.]])defgenerate_anchors(stride=16,sizes=(32,64,128,256,512),aspect_ratios=(0.5,1,2)):\"\"\"Generatesamatrixofanchorboxesin(x1,y1,x2,y2)format.Anchorsarecenteredonstride/2,have(approximate)sqrtareasofthespecifiedsizes,andaspectratiosasgiven.\"\"\"return_generate_anchors(stride,np.array(sizes,dtype=float)/stride,np.array(aspect_ratios,dtype=float))def_generate_anchors(base_size,scales,aspect_ratios):\"\"\"Generateanchor(reference)windowsbyenumeratingaspectratiosXscaleswrtareference(0,0,base_size-1,base_size-1)window.\"\"\"anchor=np.array([1,1,base_size,base_size],dtype=float)-1anchors=_ratio_enum(anchor,aspect_ratios)anchors=np.vstack([_scale_enum(anchors[i,:],scales)foriinrange(anchors.shape[0])])returnanchorsdef_whctrs(anchor):\"\"\"Returnwidth,height,xcenter,andycenterforananchor(window).\"\"\"w=anchor[2]-anchor[0]+1h=anchor[3]-anchor[1]+1x_ctr=anchor[0]+0.5*(w-1)y_ctr=anchor[1]+0.5*(h-1)returnw,h,x_ctr,y_ctrdef_mkanchors(ws,hs,x_ctr,y_ctr):\"\"\"Givenavectorofwidths(ws)andheights(hs)aroundacenter(x_ctr,y_ctr),outputasetofanchors(windows).\"\"\"ws=ws[:,np.newaxis]hs=hs[:,np.newaxis]anchors=np.hstack((x_ctr-0.5*(ws-1),y_ctr-0.5*(hs-1),x_ctr+0.5*(ws-1),y_ctr+0.5*(hs-1)))returnanchorsdef_ratio_enum(anchor,ratios):\"\"\"Enumerateasetofanchorsforeachaspectratiowrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)size=w*hsize_ratios=size/ratiosws=np.round(np.sqrt(size_ratios))hs=np.round(ws*ratios)anchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchorsdef_scale_enum(anchor,scales):\"\"\"Enumerateasetofanchorsforeachscalewrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)ws=w*scaleshs=h*scalesanchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchors#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsclassCollectAndDistributeFpnRpnProposalsOp:def__init__(self,train):self._train=traindefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.CollectAndDistributeFpnRpnProposalsforinputs/outputsdocumentation.\"\"\"#inputsis#[rpn_rois_fpn2,...,rpn_rois_fpn6,#rpn_roi_probs_fpn2,...,rpn_roi_probs_fpn6]#IftrainingwithFasterR-CNN,theninputswilladditionallyinclude#+[roidb,im_info]rois=collect(inputs,self._train)ifself._train:#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]im_info=inputs[-1].dataim_scales=im_info[:,2]roidb=blob_utils.deserialize(inputs[-2].data)#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)#ComputetraininglabelsfortheRPNproposals;alsohandles#distributingtheproposalsoverFPNlevelsoutput_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])else:#Forinferencewehaveaspecialcodepaththatavoidssomedata#loaderoverheaddistribute(rois,None,outputs,self._train)defcollect(inputs,is_training):cfg_key=\\'TRAIN\\'ifis_trainingelse\\'TEST\\'post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELnum_lvls=k_max-k_min+1roi_inputs=inputs[:num_lvls]score_inputs=inputs[num_lvls:]ifis_training:score_inputs=score_inputs[:-2]#roisarein[[batch_idx,x0,y0,x1,y2],...]format#Combinepredictionsacrossalllevelsandretainthetopscoringrois=np.concatenate([blob.dataforblobinroi_inputs])scores=np.concatenate([blob.dataforblobinscore_inputs]).squeeze()inds=np.argsort(-scores)[:post_nms_topN]rois=rois[inds,:]returnroisdefdistribute(rois,label_blobs,outputs,train):\"\"\"Tounderstandtheoutputbloborderseereturnvalueofdetectron.roi_data.fast_rcnn.get_fast_rcnn_blob_names(is_training=False)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(rois[:,1:5],lvl_min,lvl_max)outputs[0].reshape(rois.shape)outputs[0].data[...]=rois#CreatenewroiblobsforeachFPNlevel#(See:modeling.FPN.add_multilevel_roi_blobswhichissimilarbutannoying#togeneralizetosupportthisparticularcase.)rois_idx_order=np.empty((0,))foroutput_idx,lvlinenumerate(range(lvl_min,lvl_max+1)):idx_lvl=np.where(lvls==lvl)[0]blob_roi_level=rois[idx_lvl,:]outputs[output_idx+1].reshape(blob_roi_level.shape)outputs[output_idx+1].data[...]=blob_roi_levelrois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_idx_restore=np.argsort(rois_idx_order)blob_utils.py_op_copy_blob(rois_idx_restore.astype(np.int32),outputs[-1])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.boxesasbox_utilsclassGenerateProposalsOp:\"\"\"Outputobjectdetectionproposalsbyapplyingestimatedbounding-boxtransformationstoasetofregularboxes(called\"anchors\").Seecommentinutils/boxes:bbox_transform_invfordetailsaboutstheoptional`reg_weights`parameter.\"\"\"def__init__(self,anchors,spatial_scale,train,reg_weights=(1.0,1.0,1.0,1.0)):self._anchors=anchorsself._num_anchors=self._anchors.shape[0]self._feat_stride=1./spatial_scaleself._train=trainself._reg_weights=reg_weightsdefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalsforinputs/outputsdocumentation.\"\"\"#1.foreachlocationiina(H,W)grid:#generateAanchorboxescenteredoncelli#applypredictedbboxdeltastoeachoftheAanchorsatcelli#2.clippredictedboxestoimage#3.removepredictedboxeswitheitherheightorwidth<threshold#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.takethetoppre_nms_topNproposalsbeforeNMS#6.applyNMSwithaloosethreshold(0.7)totheremainingproposals#7.takeafter_nms_topNproposalsafterNMS#8.returnthetopproposals#predictedprobabilityoffgobjectforeachRPNanchorscores=inputs[0].data#predictedachorstransformationsbbox_deltas=inputs[1].data#inputimage(height,width,scale),inwhichscaleisthescalefactor#appliedtotheoriginaldatasetimagetogetthenetworkinputimageim_info=inputs[2].data#1.Generateproposalsfrombboxdeltasandshiftedanchorsheight,width=scores.shape[-2:]#Enumerateallshiftedpositionsonthe(H,W)gridshift_x=np.arange(0,width)*self._feat_strideshift_y=np.arange(0,height)*self._feat_strideshift_x,shift_y=np.meshgrid(shift_x,shift_y,copy=False)#Convertto(K,4),K=H*W,wherethecolumnsare(dx,dy,dx,dy)#shiftpointingtoeachgridlocationshifts=np.vstack((shift_x.ravel(),shift_y.ravel(),shift_x.ravel(),shift_y.ravel())).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsnum_images=inputs[0].shape[0]A=self._num_anchorsK=shifts.shape[0]all_anchors=self._anchors[np.newaxis,:,:]+shifts[:,np.newaxis,:]all_anchors=all_anchors.reshape((K*A,4))rois=np.empty((0,5),dtype=np.float32)roi_probs=np.empty((0,1),dtype=np.float32)forim_iinrange(num_images):im_i_boxes,im_i_probs=self.proposals_for_one_image(im_info[im_i,:],all_anchors,bbox_deltas[im_i,:,:,:],scores[im_i,:,:,:])batch_inds=im_i*np.ones((im_i_boxes.shape[0],1),dtype=np.float32)im_i_rois=np.hstack((batch_inds,im_i_boxes))rois=np.append(rois,im_i_rois,axis=0)roi_probs=np.append(roi_probs,im_i_probs,axis=0)outputs[0].reshape(rois.shape)outputs[0].data[...]=roisiflen(outputs)>1:outputs[1].reshape(roi_probs.shape)outputs[1].data[...]=roi_probsdefproposals_for_one_image(self,im_info,all_anchors,bbox_deltas,scores):#Getmode-dependentconfigurationcfg_key=\\'TRAIN\\'ifself._trainelse\\'TEST\\'pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Npost_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nnms_thresh=cfg[cfg_key].RPN_NMS_THRESHmin_size=cfg[cfg_key].RPN_MIN_SIZE#Transposeandreshapepredictedbboxtransformationstogetthem#intothesameorderastheanchors:#-bboxdeltaswillbe(4*A,H,W)formatfromconvoutput#-transposeto(H,W,4*A)#-reshapeto(H*W*A,4)whererowsareorderedby(H,W,A)#inslowesttofastestordertomatchtheenumeratedanchorsbbox_deltas=bbox_deltas.transpose((1,2,0)).reshape((-1,4))#Samestoryforthescores:#-scoresare(A,H,W)formatfromconvoutput#-transposeto(H,W,A)#-reshapeto(H*W*A,1)whererowsareorderedby(H,W,A)#tomatchtheorderofanchorsandbbox_deltasscores=scores.transpose((1,2,0)).reshape((-1,1))#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.taketoppre_nms_topN(e.g.6000)ifpre_nms_topN=len(scores):order=np.argsort(-scores.squeeze())else:#Avoidsortingpossiblylargearrays;FirstpartitiontogettopK#unsortedandthensortjustthose(~20xfasterfor200kscores)inds=np.argpartition(-scores.squeeze(),pre_nms_topN)[:pre_nms_topN]order=np.argsort(-scores[inds].squeeze())order=inds[order]bbox_deltas=bbox_deltas[order,:]all_anchors=all_anchors[order,:]scores=scores[order]#Transformanchorsintoproposalsviabboxtransformationsproposals=box_utils.bbox_transform(all_anchors,bbox_deltas,self._reg_weights)#2.clipproposalstoimage(mayresultinproposalswithzeroarea#thatwillberemovedinthenextstep)proposals=box_utils.clip_tiled_boxes(proposals,im_info[:2])#3.removepredictedboxeswitheitherheightorwidth<min_sizekeep=_filter_boxes(proposals,min_size,im_info)proposals=proposals[keep,:]scores=scores[keep]#6.applyloosenms(e.g.threshold=0.7)#7.takeafter_nms_topN(e.g.300)#8.returnthetopproposals(->RoIstop)ifnms_thresh>0:keep=box_utils.nms(np.hstack((proposals,scores)),nms_thresh)ifpost_nms_topN>0:keep=keep[:post_nms_topN]proposals=proposals[keep,:]scores=scores[keep]returnproposals,scoresdef_filter_boxes(boxes,min_size,im_info):\"\"\"Onlykeepboxeswithbothsides>=min_sizeandcenterwithintheimage.\"\"\"#Computethewidthandheightoftheproposalboxesasmeasuredintheoriginal#imagecoordinatesystem(thisisrequiredtoavoid\"NegativeAreasFound\"#assertionsinotherpartsofthecodethatmeasure).im_scale=im_info[2]ws_orig_scale=(boxes[:,2]-boxes[:,0])/im_scale+1hs_orig_scale=(boxes[:,3]-boxes[:,1])/im_scale+1#Toavoidnumericalissueswerequirethemin_sizetobeatleast1pixelinthe#originalimagemin_size=np.maximum(min_size,1)#Proposalcenteriscomputedrelativetothescaledinputimagews=boxes[:,2]-boxes[:,0]+1hs=boxes[:,3]-boxes[:,1]+1x_ctr=boxes[:,0]+ws/2.y_ctr=boxes[:,1]+hs/2.keep=np.where((ws_orig_scale>=min_size)&(hs_orig_scale>=min_size)&(x_ctr<im_info[1])&(y_ctr<im_info[0]))[0]returnkeep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsfromdetectron.utilsimportblobasblob_utilsimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_datalogger=logging.getLogger(__name__)classGenerateProposalLabelsOp:defforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalLabelsforinputs/outputsdocumentation.\"\"\"#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]rois=inputs[0].dataroidb=blob_utils.deserialize(inputs[1].data)im_info=inputs[2].dataim_scales=im_info[:,2]output_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaDetectronnetworkonanimdb(imagedatabase).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.core.rpn_generatorimportgenerate_rpn_on_datasetfromdetectron.core.rpn_generatorimportgenerate_rpn_on_rangefromdetectron.core.testimportim_detect_allfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnet_utilsimportdetectron.utils.subprocessassubprocess_utilsimportdetectron.utils.visasvis_utilslogger=logging.getLogger(__name__)defget_eval_functions():#Determinewhichparentorchildfunctionshouldhandleinferenceifcfg.MODEL.RPN_ONLY:child_func=generate_rpn_on_rangeparent_func=generate_rpn_on_datasetelse:#GenericcasethathandlesallnetworktypesotherthanRPN-onlynets#andRetinaNetchild_func=test_netparent_func=test_net_on_datasetreturnparent_func,child_funcdefget_inference_dataset(index,is_parent=True):assertis_parentorlen(cfg.TEST.DATASETS)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingledataset\\'dataset_name=cfg.TEST.DATASETS[index]ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertis_parentorlen(cfg.TEST.PROPOSAL_FILES)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingleproposalfile\\'assertlen(cfg.TEST.PROPOSAL_FILES)==len(cfg.TEST.DATASETS),\\\\\\'Ifproposalsareused,oneproposalfilemustbespecifiedfor\\'\\\\\\'eachdataset\\'proposal_file=cfg.TEST.PROPOSAL_FILES[index]else:proposal_file=Nonereturndataset_name,proposal_filedefrun_inference(weights_file,ind_range=None,multi_gpu_testing=False,gpu_id=0,check_expected_results=False,):parent_func,child_func=get_eval_functions()is_parent=ind_rangeisNonedefresult_getter():ifis_parent:#Parentcase:#Inthiscasewe\\'reeitherrunninginferenceontheentiredatasetina#singleprocessor(ifmulti_gpu_testingisTrue)usingthisprocessto#launchsubprocessesthateachruninferenceonarangeofthedatasetall_results={}foriinrange(len(cfg.TEST.DATASETS)):dataset_name,proposal_file=get_inference_dataset(i)output_dir=get_output_dir(dataset_name,training=False)results=parent_func(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=multi_gpu_testing)all_results.update(results)returnall_resultselse:#Subprocesschildcase:#Inthiscasetest_netwascalledviasubprocess.Popentoexecuteona#rangeofinputsonasingledatasetdataset_name,proposal_file=get_inference_dataset(0,is_parent=False)output_dir=get_output_dir(dataset_name,training=False)returnchild_func(weights_file,dataset_name,proposal_file,output_dir,ind_range=ind_range,gpu_id=gpu_id)all_results=result_getter()ifcheck_expected_resultsandis_parent:task_evaluation.check_expected_results(all_results,atol=cfg.EXPECTED_RESULTS_ATOL,rtol=cfg.EXPECTED_RESULTS_RTOL)task_evaluation.log_copy_paste_friendly_results(all_results)returnall_resultsdeftest_net_on_dataset(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())all_boxes,all_segms,all_keyps=multi_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir)else:all_boxes,all_segms,all_keyps=test_net(weights_file,dataset_name,proposal_file,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))results=task_evaluation.evaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir)returnresultsdefmulti_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"binary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetandproposalfile(ifany)viathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]ifproposal_file:opts+=[\\'TEST.PROPOSAL_FILES\\',\\'(\"{}\",)\\'.format(proposal_file)]#Runinferenceinparallelinsubprocesses#Outputswillbealistofoutputsfromeachsubprocess,wheretheoutput#ofeachsubprocessisthedictionarysavedbytest_net().outputs=subprocess_utils.process_in_parallel(\\'detection\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessall_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_segms=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_keyps=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]fordet_datainoutputs:all_boxes_batch=det_data[\\'all_boxes\\']all_segms_batch=det_data[\\'all_segms\\']all_keyps_batch=det_data[\\'all_keyps\\']forcls_idxinrange(1,cfg.MODEL.NUM_CLASSES):all_boxes[cls_idx]+=all_boxes_batch[cls_idx]all_segms[cls_idx]+=all_segms_batch[cls_idx]all_keyps[cls_idx]+=all_keyps_batch[cls_idx]det_file=os.path.join(output_dir,\\'detections.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdeftest_net(weights_file,dataset_name,proposal_file,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertnotcfg.MODEL.RPN_ONLY,\\\\\\'Userpn_generatetogenerateproposalsfromRPN-onlymodels\\'roidb,dataset,start_ind,end_ind,total_num_images=get_roidb_and_dataset(dataset_name,proposal_file,ind_range)model=initialize_model_from_cfg(weights_file,gpu_id=gpu_id)num_images=len(roidb)num_classes=cfg.MODEL.NUM_CLASSESall_boxes,all_segms,all_keyps=empty_results(num_classes,num_images)timers=defaultdict(Timer)fori,entryinenumerate(roidb):ifcfg.TEST.PRECOMPUTED_PROPOSALS:#Theroidbmaycontainground-truthrois(forexample,iftheroidb#comesfromthetrainingorvalsplit).Weonlywanttoevaluate#detectiononthe*non*-ground-truthrois.Weselectonlytherois#thathavethegt_classesfieldsetto0,whichmeansthere\\'sno#groundtruth.box_proposals=entry[\\'boxes\\'][entry[\\'gt_classes\\']==0]iflen(box_proposals)==0:continueelse:#FasterR-CNNtypemodelsgenerateproposalson-the-flywithan#in-networkRPN;1-stagemodelsdon\\'trequireproposals.box_proposals=Noneim=cv2.imread(entry[\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):cls_boxes_i,cls_segms_i,cls_keyps_i=im_detect_all(model,im,box_proposals,timers)extend_results(i,all_boxes,cls_boxes_i)ifcls_segms_iisnotNone:extend_results(i,all_segms,cls_segms_i)ifcls_keyps_iisnotNone:extend_results(i,all_keyps,cls_keyps_i)ifi%10==0:#Reducelogfilesizeave_total_time=np.sum([t.average_timefortintimers.values()])eta_seconds=ave_total_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))det_time=(timers[\\'im_detect_bbox\\'].average_time+timers[\\'im_detect_mask\\'].average_time+timers[\\'im_detect_keypoints\\'].average_time)misc_time=(timers[\\'misc_bbox\\'].average_time+timers[\\'misc_mask\\'].average_time+timers[\\'misc_keypoints\\'].average_time)logger.info((\\'im_detect:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s+{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,det_time,misc_time,eta))ifcfg.VIS:im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(i,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=cfg.VIS_TH,box_alpha=0.8,dataset=dataset,show_class=True)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:det_name=\\'detection_range_%s_%s.pkl\\'%tuple(ind_range)else:det_name=\\'detections.pkl\\'det_file=os.path.join(output_dir,det_name)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdefinitialize_model_from_cfg(weights_file,gpu_id=0):\"\"\"Initializeamodelfromtheglobalcfg.Loadstest-timeweightsandcreatesthenetworksintheCaffe2workspace.\"\"\"model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)net_utils.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)workspace.CreateNet(model.conv_body_net)ifcfg.MODEL.MASK_ON:workspace.CreateNet(model.mask_net)ifcfg.MODEL.KEYPOINTS_ON:workspace.CreateNet(model.keypoint_net)returnmodeldefget_roidb_and_dataset(dataset_name,proposal_file,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertproposal_file,\\'Noproposalfilegiven\\'roidb=dataset.get_roidb(proposal_file=proposal_file,proposal_limit=cfg.TEST.PROPOSAL_LIMIT)else:roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,dataset,start,end,total_num_imagesdefempty_results(num_classes,num_images):\"\"\"Returnemptyresultslistsforboxes,masks,andkeypoints.Boxdetectionsarecollectedinto:all_boxes[cls][image]=Nx5arraywithcolumns(x1,y1,x2,y2,score)Instancemaskpredictionsarecollectedinto:all_segms[cls][image]=[...]listofCOCORLEencodedmasksthatarein1:1correspondencewiththeboxesinall_boxes[cls][image]Keypointpredictionsarecollectedinto:all_keyps[cls][image]=[...]listofkeypointsresults,eachencodedasa3Darray(#rois,4,#keypoints)withthe4rowscorrespondingto[x,y,logit,prob](See:utils.keypoints.heatmaps_to_keypoints).Keypointsarerecordedforperson(cls=1);theyarein1:1correspondencewiththeboxesinall_boxes[cls][image].\"\"\"#Note:donotbetemptedtouse[[]*N],whichgivesNreferencestothe#*same*emptylist.all_boxes=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_segms=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_keyps=[[[]for_inrange(num_images)]for_inrange(num_classes)]returnall_boxes,all_segms,all_keypsdefextend_results(index,all_res,im_res):\"\"\"Addresultsforanimagetothesetofallresultsatthespecifiedindex.\"\"\"#Skipcls_idx0(__background__)forcls_idxinrange(1,len(im_res)):all_res[cls_idx][index]=im_res[cls_idx]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"FunctionsforRPNproposalgeneration.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnuimportdetectron.utils.subprocessassubprocess_utilslogger=logging.getLogger(__name__)defgenerate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())_boxes,_scores,_ids,rpn_file=multi_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir)else:#Processesentiredatasetrangebydefault_boxes,_scores,_ids,rpn_file=generate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))returnevaluate_proposal_file(dataset,rpn_file,output_dir)defmulti_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"#Retrievethetest_netbinarypathbinary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetviathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]#Runinferenceinparallelinsubprocessesoutputs=subprocess_utils.process_in_parallel(\\'rpn_proposals\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessboxes,scores,ids=[],[],[]forrpn_datainoutputs:boxes+=rpn_data[\\'boxes\\']scores+=rpn_data[\\'scores\\']ids+=rpn_data[\\'ids\\']rpn_file=os.path.join(output_dir,\\'rpn_proposals.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertcfg.MODEL.RPN_ONLYorcfg.MODEL.FASTER_RCNNroidb,start_ind,end_ind,total_num_images=get_roidb(dataset_name,ind_range)logger.info(\\'Outputwillbesavedto:{:s}\\'.format(os.path.abspath(output_dir)))model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)nu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)boxes,scores,ids=generate_proposals_on_roidb(model,roidb,start_ind=start_ind,end_ind=end_ind,total_num_images=total_num_images,gpu_id=gpu_id,)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:rpn_name=\\'rpn_proposals_range_%s_%s.pkl\\'%tuple(ind_range)else:rpn_name=\\'rpn_proposals.pkl\\'rpn_file=os.path.join(output_dir,rpn_name)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_proposals_on_roidb(model,roidb,start_ind=None,end_ind=None,total_num_images=None,gpu_id=0,):\"\"\"GenerateRPNproposalsonallimagesinanimdb.\"\"\"_t=Timer()num_images=len(roidb)roidb_boxes=[[]for_inrange(num_images)]roidb_scores=[[]for_inrange(num_images)]roidb_ids=[[]for_inrange(num_images)]ifstart_indisNone:start_ind=0end_ind=num_imagestotal_num_images=num_imagesforiinrange(num_images):roidb_ids[i]=roidb[i][\\'id\\']im=cv2.imread(roidb[i][\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):_t.tic()roidb_boxes[i],roidb_scores[i]=im_proposals(model,im)_t.toc()ifi%10==0:ave_time=_t.average_timeeta_seconds=ave_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))logger.info((\\'rpn_generate:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,ave_time,eta))returnroidb_boxes,roidb_scores,roidb_idsdefim_proposals(model,im):\"\"\"GenerateRPNproposalsonasingleimage.\"\"\"inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELrois_names=[core.ScopedName(\\'rpn_rois_fpn\\'+str(l))forlinrange(k_min,k_max+1)]score_names=[core.ScopedName(\\'rpn_roi_probs_fpn\\'+str(l))forlinrange(k_min,k_max+1)]blobs=workspace.FetchBlobs(rois_names+score_names)#Combinepredictionsacrossalllevelsandretainthetopscoringboxes=np.concatenate(blobs[:len(rois_names)])scores=np.concatenate(blobs[len(rois_names):]).squeeze()#Discussion:onecoulddoNMSagainaftercombiningpredictionsfrom#thedifferentFPNlevels.Conceptually,it\\'sprobablytherightthing#todo.Forarbitraryreasons,theoriginalFPNRPNimplementationdid#notdoanotherroundofNMS.inds=np.argsort(-scores)[:cfg.TEST.RPN_POST_NMS_TOP_N]scores=scores[inds]boxes=boxes[inds,:]else:boxes,scores=workspace.FetchBlobs([core.ScopedName(\\'rpn_rois\\'),core.ScopedName(\\'rpn_roi_probs\\')])scores=scores.squeeze()#Column0isthebatchindexinthe(batchind,x1,y1,x2,y2)encoding,#soweremoveitsincewejustwanttoreturnboxes#Scaleproposalsbacktotheoriginalinputimagescaleboxes=boxes[:,1:]/im_scalereturnboxes,scoresdefget_roidb(dataset_name,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,start,end,total_num_imagesdefevaluate_proposal_file(dataset,proposal_file,output_dir):\"\"\"Evaluateboxproposalaveragerecall.\"\"\"roidb=dataset.get_roidb(gt=True,proposal_file=proposal_file)results=task_evaluation.evaluate_box_proposals(dataset,roidb)task_evaluation.log_box_proposal_results(results)recall_file=os.path.join(output_dir,\\'rpn_proposal_recall.pkl\\')save_object(results,recall_file)returnresults#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaRetinaNetnetworkonanimagedatabase\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcollectionsimportdefaultdictfromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)def_create_cell_anchors():\"\"\"Generatealltypesofanchorsforallfpnlevels/scales/aspectratios.Thisfunctioniscalledonlyonceatthebeginningofinference.\"\"\"k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALEA=scales_per_octave*len(aspect_ratios)anchors={}forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=np.zeros((A,4))a=0foroctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foraspectinaspect_ratios:anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect,)cell_anchors[a,:]=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)a+=1anchors[lvl]=cell_anchorsreturnanchorsdefim_detect_bbox(model,im,timers=None):\"\"\"GenerateRetinaNetdetectionsonasingleimage.\"\"\"iftimersisNone:timers=defaultdict(Timer)#Althoughanchorsareinputindependentandcouldbeprecomputed,#recomputingthemperimageonlybringsasmalloverheadanchors=_create_cell_anchors()timers[\\'im_detect_bbox\\'].tic()k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELA=cfg.RETINANET.SCALES_PER_OCTAVE*len(cfg.RETINANET.ASPECT_RATIOS)inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)cls_probs,box_preds=[],[]forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_probs.append(core.ScopedName(\\'retnet_cls_prob_{}\\'.format(suffix)))box_preds.append(core.ScopedName(\\'retnet_bbox_pred_{}\\'.format(suffix)))fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)cls_probs=workspace.FetchBlobs(cls_probs)box_preds=workspace.FetchBlobs(box_preds)#heretheboxes_allare[x0,y0,x1,y1,score]boxes_all=defaultdict(list)cnt=0forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=anchors[lvl]#fetchperlevelprobabilitycls_prob=cls_probs[cnt]box_pred=box_preds[cnt]cls_prob=cls_prob.reshape((cls_prob.shape[0],A,int(cls_prob.shape[1]/A),cls_prob.shape[2],cls_prob.shape[3]))box_pred=box_pred.reshape((box_pred.shape[0],A,4,box_pred.shape[2],box_pred.shape[3]))cnt+=1ifcfg.RETINANET.SOFTMAX:cls_prob=cls_prob[:,:,1::,:,:]cls_prob_ravel=cls_prob.ravel()#Insomecases[especiallyforverysmallimgsizes],it\\'spossiblethat#candidate_indisemptyifweimposethreshold0.05atalllevels.This#willleadtoerrorssincenodetectionsarefoundforthisimage.Hence,#forlvl7whichhassmallspatialresolution,wetakethethreshold0.0th=cfg.RETINANET.INFERENCE_THiflvl<k_maxelse0.0candidate_inds=np.where(cls_prob_ravel>th)[0]if(len(candidate_inds)==0):continuepre_nms_topn=min(cfg.RETINANET.PRE_NMS_TOP_N,len(candidate_inds))inds=np.argpartition(cls_prob_ravel[candidate_inds],-pre_nms_topn)[-pre_nms_topn:]inds=candidate_inds[inds]inds_5d=np.array(np.unravel_index(inds,cls_prob.shape)).transpose()classes=inds_5d[:,2]anchor_ids,y,x=inds_5d[:,1],inds_5d[:,3],inds_5d[:,4]scores=cls_prob[:,anchor_ids,classes,y,x]boxes=np.column_stack((x,y,x,y)).astype(dtype=np.float32)boxes*=strideboxes+=cell_anchors[anchor_ids,:]ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:box_deltas=box_pred[0,anchor_ids,:,y,x]else:box_cls_inds=classes*4box_deltas=np.vstack([box_pred[0,ind:ind+4,yi,xi]forind,yi,xiinzip(box_cls_inds,y,x)])pred_boxes=(box_utils.bbox_transform(boxes,box_deltas)ifcfg.TEST.BBOX_REGelseboxes)pred_boxes/=im_scalepred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)box_scores=np.zeros((pred_boxes.shape[0],5))box_scores[:,0:4]=pred_boxesbox_scores[:,4]=scoresforclsinrange(1,cfg.MODEL.NUM_CLASSES):inds=np.where(classes==cls-1)[0]iflen(inds)>0:boxes_all[cls].extend(box_scores[inds,:])timers[\\'im_detect_bbox\\'].toc()#Combinepredictionsacrossalllevelsandretainthetopscoringbyclasstimers[\\'misc_bbox\\'].tic()detections=[]forcls,boxesinboxes_all.items():cls_dets=np.vstack(boxes).astype(dtype=np.float32)#doclassspecificnmshereifcfg.TEST.SOFT_NMS.ENABLED:cls_dets,keep=box_utils.soft_nms(cls_dets,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(cls_dets,cfg.TEST.NMS)cls_dets=cls_dets[keep,:]out=np.zeros((len(keep),6))out[:,0:5]=cls_detsout[:,5].fill(cls)detections.append(out)#detections(N,6)format:#detections[:,:4]-boxes#detections[:,4]-scores#detections[:,5]-classesdetections=np.vstack(detections)#sortallagaininds=np.argsort(-detections[:,4])detections=detections[inds[0:cfg.TEST.DETECTIONS_PER_IM],:]#Convertthedetectionstoimagecls_format(seecore/test_engine.py)num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]forcinrange(1,num_classes):inds=np.where(detections[:,5]==c)[0]cls_boxes[c]=detections[inds,:5]timers[\\'misc_bbox\\'].toc()returncls_boxes#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Detectronconfigsystem.ThisfilespecifiesdefaultconfigoptionsforDetectron.Youshouldnotchangevaluesinthisfile.Instead,youshouldwriteaconfigfile(inyaml)andusemerge_cfg_from_file(yaml_file)toloaditandoverridethedefaultoptions.Mosttoolsinthetoolsdirectorytakea--cfgoptiontospecifyanoverridefileandanoptionallistofoverride(key,value)pairs:-Seetools/{train,test}_net.pyforexamplecodethatusesmerge_cfg_from_file-Seeconfigs/*/*.yamlforexampleconfigfilesDetectronsupportsalotofdifferentmodeltypes,eachofwhichhasalotofdifferentoptions.TheresultisaHUGEsetofconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromastimportliteral_evalfromfuture.utilsimportiteritemsimportcopyimportioimportloggingimportnumpyasnpimportosimportos.pathasospimportsixfromdetectron.utils.collectionsimportAttrDictfromdetectron.utils.ioimportcache_urllogger=logging.getLogger(__name__)__C=AttrDict()#Consumerscangetconfigby:#fromdetectron.core.configimportcfgcfg=__C#Randomnote:avoidusing\\'.ON\\'asaconfigkeysinceyamlconvertsittoTrue;#prefer\\'ENABLED\\'instead#----------------------------------------------------------------------------##Trainingoptions#----------------------------------------------------------------------------#__C.TRAIN=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TRAIN.WEIGHTS=\\'\\'#Datasetstotrainon#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,themodelistrainedontheirunion__C.TRAIN.DATASETS=()#Scalestouseduringtraining#Eachscaleisthepixelsizeofanimage\\'sshortestside#Ifmultiplescalesarelisted,thenoneisselecteduniformlyatrandomfor#eachtrainingimage(i.e.,scalejitterdataaugmentation)__C.TRAIN.SCALES=(600,)#Maxpixelsizeofthelongestsideofascaledinputimage__C.TRAIN.MAX_SIZE=1000#Images*perGPU*inthetrainingminibatch#Totalimagesperminibatch=TRAIN.IMS_PER_BATCH*NUM_GPUS__C.TRAIN.IMS_PER_BATCH=2#RoIminibatchsize*perimage*(numberofregionsofinterest[ROIs])#TotalnumberofRoIspertrainingminibatch=#TRAIN.BATCH_SIZE_PER_IM*TRAIN.IMS_PER_BATCH*NUM_GPUS#E.g.,acommonconfigurationis:512*2*8=8192__C.TRAIN.BATCH_SIZE_PER_IM=64#TargetfractionofRoIminibatchthatislabeledforeground(i.e.class>0)__C.TRAIN.FG_FRACTION=0.25#OverlapthresholdforanRoItobeconsideredforeground(if>=FG_THRESH)__C.TRAIN.FG_THRESH=0.5#OverlapthresholdforanRoItobeconsideredbackground(class=0if#overlapin[LO,HI))__C.TRAIN.BG_THRESH_HI=0.5__C.TRAIN.BG_THRESH_LO=0.0#Usehorizontally-flippedimagesduringtraining?__C.TRAIN.USE_FLIPPED=True#OverlaprequiredbetweenanRoIandaground-truthboxinorderforthat#(RoI,gtbox)pairtobeusedasabounding-boxregressiontrainingexample__C.TRAIN.BBOX_THRESH=0.5#Snapshot(modelcheckpoint)period#DividebyNUM_GPUStodetermineactualperiod(e.g.,80000/8=>10000iters)#toallowforlineartrainingschedulescaling__C.TRAIN.SNAPSHOT_ITERS=80000#Trainusingtheseproposals#Duringtraining,allproposalsspecifiedinthefileareused(nolimitis#applied)#Proposalfilesmustbeincorrespondencewiththedatasetslistedin#TRAIN.DATASETS__C.TRAIN.PROPOSAL_FILES=()#Makeminibatchesfromimagesthathavesimilaraspectratios(i.e.both#tallandthinorbothshortandwide)#Thisfeatureiscriticalforsavingmemory(andmakestrainingslightly#faster)__C.TRAIN.ASPECT_GROUPING=True#----------------------------------------------------------------------------##RPNtrainingoptions#----------------------------------------------------------------------------##RunGenerateProposalsonGPUifsettoTrue__C.TRAIN.GENERATE_PROPOSALS_ON_GPU=False#Minimumoverlaprequiredbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeapositiveexample(IOU>=thresh==>positiveRPN#example)__C.TRAIN.RPN_POSITIVE_OVERLAP=0.7#Maximumoverlapallowedbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeanegativeexamples(IOUnegativeRPN#example)__C.TRAIN.RPN_NEGATIVE_OVERLAP=0.3#Targetfractionofforeground(positive)examplesperRPNminibatch__C.TRAIN.RPN_FG_FRACTION=0.5#TotalnumberofRPNexamplesperimage__C.TRAIN.RPN_BATCH_SIZE_PER_IM=256#NMSthresholdusedonRPNproposals(usedduringend-to-endtrainingwithRPN)__C.TRAIN.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TRAIN.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TRAIN.RPN_POST_NMS_TOP_N=2000#RemoveRPNanchorsthatgooutsidetheimagebyRPN_STRADDLE_THRESHpixels#Setto-1oralargevalue,e.g.100000,todisablepruninganchors__C.TRAIN.RPN_STRADDLE_THRESH=0#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TRAIN.RPN_MIN_SIZE=0#FilterproposalsthatareinsideofcrowdregionsbyCROWD_FILTER_THRESH#\"Inside\"ismeasuredas:proposal-with-crowdintersectionareadividedby#proposalarea__C.TRAIN.CROWD_FILTER_THRESH=0.7#Ignoreground-truthobjectswitharea<thisthreshold__C.TRAIN.GT_MIN_AREA=-1#FreezethebackbonearchitectureduringtrainingifsettoTrue__C.TRAIN.FREEZE_CONV_BODY=False#Trainingwillresumefromthelatestsnapshot(modelcheckpoint)foundinthe#outputdirectory__C.TRAIN.AUTO_RESUME=True#TrainingwillcopyTRAIN.WEIGHTSandtreatitasacandidatecheckpoint__C.TRAIN.COPY_WEIGHTS=False#AddStopGradataspecifiedstagesothebottomlayersarefrozen__C.TRAIN.FREEZE_AT=2#----------------------------------------------------------------------------##Dataloaderoptions(seedetectron/roi_data/loader.pyformoreinfo)#----------------------------------------------------------------------------#__C.DATA_LOADER=AttrDict()#NumberofPythonthreadstouseforthedataloader(warning:usingtoomany#threadscancauseGIL-basedinterferencewithPythonOpsleadingto*slower*#training;4seemstobethesweetspotinourexperience)__C.DATA_LOADER.NUM_THREADS=4#Sizeofthesharedminibatchqueue__C.DATA_LOADER.MINIBATCH_QUEUE_SIZE=64#CapacityoftheperGPUblobsqueue__C.DATA_LOADER.BLOBS_QUEUE_CAPACITY=8#----------------------------------------------------------------------------##Inference(\\'test\\')options#----------------------------------------------------------------------------#__C.TEST=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TEST.WEIGHTS=\\'\\'#Datasetstoteston#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,testingisperformedoneachonesequentially__C.TEST.DATASETS=()#Scaletouseduringtesting__C.TEST.SCALE=600#Maxpixelsizeofthelongestsideofascaledinputimage__C.TEST.MAX_SIZE=1000#Overlapthresholdusedfornon-maximumsuppression(suppressboxeswith#IoU>=thisthreshold)__C.TEST.NMS=0.3#ApplyFastR-CNNstylebounding-boxregressionifTrue__C.TEST.BBOX_REG=True#Testusingtheseproposalfiles(mustcorrespondwithTEST.DATASETS)__C.TEST.PROPOSAL_FILES=()#RunGenerateProposalsonGPUifsettoTrue__C.TEST.GENERATE_PROPOSALS_ON_GPU=False#Limitonthenumberofproposalsperimageusedduringinference__C.TEST.PROPOSAL_LIMIT=2000#NMSthresholdusedonRPNproposals__C.TEST.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TEST.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TEST.RPN_POST_NMS_TOP_N=2000#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TEST.RPN_MIN_SIZE=0#Maximumnumberofdetectionstoreturnperimage(100isbasedonthelimit#establishedfortheCOCOdataset)__C.TEST.DETECTIONS_PER_IM=100#Minimumscorethreshold(assumingscoresina[0,1]range);avaluechosento#balanceobtaininghighrecallwithnothavingtoomanylowprecision#detectionsthatwillslowdowninferencepostprocessingsteps(likeNMS)__C.TEST.SCORE_THRESH=0.05#SavedetectionresultsfilesifTrue#Iffalse,resultsfilesarecleanedup(theycanbelarge)afterlocal#evaluation__C.TEST.COMPETITION_MODE=True#EvaluatedetectionswiththeCOCOjsondatasetevalcodeevenifit\\'snotthe#evaluationcodeforthedataset(e.g.evaluatePASCALVOCresultsusingthe#COCOAPItogetCOCOstyleAPonPASCALVOC)__C.TEST.FORCE_JSON_DATASET_EVAL=False#[Inferredvalue;donotsetdirectlyinaconfig]#Indicatesifprecomputedproposalsareusedattesttime#Notsetfor1-stagemodelsand2-stagemodelswithRPNsubnetworkenabled__C.TEST.PRECOMPUTED_PROPOSALS=True#Evaluateproposalsinclass-specificAverageRecall(AR).#ItmeansthatonefirstcomputesARwithineachcategoryandthenaverages#overthecategories.ItisnotbiasedtowardstheARoffrequentcategories#comparedwithclass-agnosticAR.__C.TEST.CLASS_SPECIFIC_AR=False#----------------------------------------------------------------------------##Test-timeaugmentationsforboundingboxdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.BBOX_AUG=AttrDict()#Enabletest-timeaugmentationforboundingboxdetectionifTrue__C.TEST.BBOX_AUG.ENABLED=False#Heuristicusedtocombinepredictedboxscores#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.SCORE_HEUR=\\'UNION\\'#Heuristicusedtocombinepredictedboxcoordinates#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.COORD_HEUR=\\'UNION\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.BBOX_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.BBOX_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.BBOX_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.BBOX_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.BBOX_AUG.SCALE_SIZE_DEP=False__C.TEST.BBOX_AUG.AREA_TH_LO=50**2__C.TEST.BBOX_AUG.AREA_TH_HI=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.BBOX_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-timeaugmentationsformaskdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.MASK_AUG=AttrDict()#Enabletest-timeaugmentationforinstancemaskdetectionifTrue__C.TEST.MASK_AUG.ENABLED=False#Heuristicusedtocombinemaskpredictions#SOFTprefixindicatesthatthecomputationisperformedonsoftmasks#Validoptions:(\\'SOFT_AVG\\',\\'SOFT_MAX\\',\\'LOGIT_AVG\\')__C.TEST.MASK_AUG.HEUR=\\'SOFT_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.MASK_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.MASK_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.MASK_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.MASK_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.MASK_AUG.SCALE_SIZE_DEP=False__C.TEST.MASK_AUG.AREA_TH=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.MASK_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-augmentationsforkeypointsdetection#configs/test_time_aug/keypoint_rcnn_R-50-FPN_1x.yaml#----------------------------------------------------------------------------#__C.TEST.KPS_AUG=AttrDict()#Enabletest-timeaugmentationforkeypointdetectionifTrue__C.TEST.KPS_AUG.ENABLED=False#Heuristicusedtocombinekeypointpredictions#Validoptions:(\\'HM_AVG\\',\\'HM_MAX\\')__C.TEST.KPS_AUG.HEUR=\\'HM_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.KPS_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.KPS_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.KPS_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.KPS_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.KPS_AUG.SCALE_SIZE_DEP=False__C.TEST.KPS_AUG.AREA_TH=180**2#Eeachaspectratioisrealtivetoimagewidth__C.TEST.KPS_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##SoftNMS#----------------------------------------------------------------------------#__C.TEST.SOFT_NMS=AttrDict()#UsesoftNMSinsteadofstandardNMSifsettoTrue__C.TEST.SOFT_NMS.ENABLED=False#SeesoftNMSpaperfordefinitionoftheseoptions__C.TEST.SOFT_NMS.METHOD=\\'linear\\'__C.TEST.SOFT_NMS.SIGMA=0.5#ForthesoftNMSoverlapthreshold,wesimplyuseTEST.NMS#----------------------------------------------------------------------------##Boundingboxvoting(fromtheMulti-RegionCNNpaper)#----------------------------------------------------------------------------#__C.TEST.BBOX_VOTE=AttrDict()#UseboxvotingifsettoTrue__C.TEST.BBOX_VOTE.ENABLED=False#WeuseTEST.NMSthresholdfortheNMSstep.VOTE_THoverlapthreshold#isusedtoselectvotingboxes(IoU>=VOTE_TH)foreachboxthatsurvivesNMS__C.TEST.BBOX_VOTE.VOTE_TH=0.8#Themethodusedtocombinescoreswhendoingboundingboxvoting#Validoptionsinclude(\\'ID\\',\\'AVG\\',\\'IOU_AVG\\',\\'GENERALIZED_AVG\\',\\'QUASI_SUM\\')__C.TEST.BBOX_VOTE.SCORING_METHOD=\\'ID\\'#Hyperparameterusedbythescoringmethod(ithasdifferentmeaningsfor#differentmethods)__C.TEST.BBOX_VOTE.SCORING_METHOD_BETA=1.0#----------------------------------------------------------------------------##Modeloptions#----------------------------------------------------------------------------#__C.MODEL=AttrDict()#Thetypeofmodeltouse#Thestringmustmatchafunctioninthemodeling.model_buildermodule#(e.g.,\\'generalized_rcnn\\',\\'mask_rcnn\\',...)__C.MODEL.TYPE=\\'\\'#Thebackboneconvbodytouse#Thestringmustmatchafunctionthatisimportedinmodeling.model_builder#(e.g.,\\'FPN.add_fpn_ResNet101_conv5_body\\'tospecifyaResNet-101-FPN#backbone)__C.MODEL.CONV_BODY=\\'\\'#Numberofclassesinthedataset;mustbeset#E.g.,81forCOCO(80foreground+1background)__C.MODEL.NUM_CLASSES=-1#Useaclassagnosticboundingboxregressorinsteadofthedefaultper-class#regressor__C.MODEL.CLS_AGNOSTIC_BBOX_REG=False#Defaultweightson(dx,dy,dw,dh)fornormalizingbboxregressiontargets#Theseareempiricallychosentoapproximatelyleadtounitvariancetargets__C.MODEL.BBOX_REG_WEIGHTS=(10.,10.,5.,5.)#ThemeaningofFASTER_RCNNdependsonthecontext(trainingvs.inference):#1)Duringtraining,FASTER_RCNN=Truemeansthatend-to-endtrainingwillbe#usedtojointlytraintheRPNsubnetworkandtheFastR-CNNsubnetwork#(FasterR-CNN=RPN+FastR-CNN).#2)Duringinference,FASTER_RCNN=Truemeansthatthemodel\\'sRPNsubnetwork#willbeusedtogenerateproposalsratherthanrelyingonprecomputed#proposals.NotethatFASTER_RCNN=Truecanbeusedatinferencetimeeven#iftheFasterR-CNNmodelwastrainedwithstagewisetraining(which#consistsofalternatingbetweenRPNandFastR-CNNtraininginawaythat#finallyleadstoasinglenetwork).__C.MODEL.FASTER_RCNN=False#Indicatesthemodelmakesinstancemaskpredictions(asinMaskR-CNN)__C.MODEL.MASK_ON=False#Indicatesthemodelmakeskeypointpredictions(asinMaskR-CNNfor#keypoints)__C.MODEL.KEYPOINTS_ON=False#Indicatesthemodel\\'scomputationterminateswiththeproductionofRPN#proposals(i.e.,itoutputsproposalsONLY,noactualobjectdetections)__C.MODEL.RPN_ONLY=False#Caffe2netexecutiontype#Use\\'prof_dag\\'togetprofilingstatistics__C.MODEL.EXECUTION_TYPE=\\'dag\\'#----------------------------------------------------------------------------##RetinaNetoptions#----------------------------------------------------------------------------#__C.RETINANET=AttrDict()#RetinaNetisused(insteadofFast/er/MaskR-CNN/R-FCN/RPN)ifTrue__C.RETINANET.RETINANET_ON=False#Anchoraspectratiostouse__C.RETINANET.ASPECT_RATIOS=(0.5,1.0,2.0)#Anchorscalesperoctave__C.RETINANET.SCALES_PER_OCTAVE=3#AteachFPNlevel,wegenerateanchorsbasedontheirscale,aspect_ratio,#strideofthelevel,andwemultiplytheresultinganchorbyANCHOR_SCALE__C.RETINANET.ANCHOR_SCALE=4#Convolutionstouseintheclsandbboxtower#NOTE:thisdoesn\\'tincludethelastconvforlogits__C.RETINANET.NUM_CONVS=4#Weightforbbox_regressionloss__C.RETINANET.BBOX_REG_WEIGHT=1.0#SmoothL1lossbetaforbboxregression__C.RETINANET.BBOX_REG_BETA=0.11#Duringinference,#locstoselectbasedonclsscorebeforeNMSisperformed#perFPNlevel__C.RETINANET.PRE_NMS_TOP_N=1000#IoUoverlapratioforlabelingananchoraspositive#Anchorswith>=iouoverlaparelabeledpositive__C.RETINANET.POSITIVE_OVERLAP=0.5#IoUoverlapratioforlabelingananchorasnegative#Anchorswith<iouoverlaparelabelednegative__C.RETINANET.NEGATIVE_OVERLAP=0.4#Focallossparameter:alpha__C.RETINANET.LOSS_ALPHA=0.25#Focallossparameter:gamma__C.RETINANET.LOSS_GAMMA=2.0#Priorprobforthepositivesatthebeginningoftraining.Thisisusedtoset#thebiasinitforthelogitslayer__C.RETINANET.PRIOR_PROB=0.01#Whetherclassificationandbboxbranchtowershouldbesharedornot__C.RETINANET.SHARE_CLS_BBOX_TOWER=False#Useclassspecificboundingboxregressioninsteadofthedefaultclass#agnosticregression__C.RETINANET.CLASS_SPECIFIC_BBOX=False#Whethersoftmaxshouldbeusedinclassificationbranchtraining__C.RETINANET.SOFTMAX=False#Inferenceclsscorethreshold,anchorswithscore>INFERENCE_THare#consideredforinference__C.RETINANET.INFERENCE_TH=0.05#----------------------------------------------------------------------------##Solveroptions#Note:allsolveroptionsareusedexactlyasspecified;theimplicationis#thatifyouswitchfromtrainingon1GPUtoNGPUs,youMUSTadjustthe#solverconfigurationaccordingly.Wesuggestusinggradualwarmupandthe#linearlearningratescalingruleasdescribedin#\"Accurate,LargeMinibatchSGD:TrainingImageNetin1Hour\"Goyaletal.##----------------------------------------------------------------------------#__C.SOLVER=AttrDict()#Baselearningrateforthespecifiedschedule__C.SOLVER.BASE_LR=0.001#Scheduletype(seefunctionsinutils.lr_policyforoptions)#E.g.,\\'step\\',\\'steps_with_decay\\',...__C.SOLVER.LR_POLICY=\\'step\\'#SomeLRPolicies(byexample):#\\'step\\'#lr=SOLVER.BASE_LR*SOLVER.GAMMA**(cur_iter//SOLVER.STEP_SIZE)#\\'steps_with_decay\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.GAMMA=0.1#lr=SOLVER.BASE_LR*SOLVER.GAMMA**current_step#iters[0,59999]areincurrent_step=0,iters[60000,79999]arein#current_step=1,andsoon#\\'steps_with_lrs\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.LRS=[0.02,0.002,0.0002]#lr=LRS[current_step]#\\'cosine_decay\\'#lr=SOLVER.BASE_LR*(cos(PI*cur_iter/SOLVER.MAX_ITER)*0.5+0.5)#\\'exp_decay\\'#lrsmoothlydecaysfromSOLVER.BASE_LRtoSOLVER.GAMMA*SOLVER.BASE_LR#lr=SOLVER.BASE_LR*exp(np.log(SOLVER.GAMMA)*cur_iter/SOLVER.MAX_ITER)#Hyperparameterusedbythespecifiedpolicy#For\\'step\\',thecurrentLRismultipliedbySOLVER.GAMMAateachstep#For\\'exp_decay\\',SOLVER.GAMMAistheratiobetweenthefinalandinitialLR.__C.SOLVER.GAMMA=0.1#Uniformstepsizefor\\'steps\\'policy__C.SOLVER.STEP_SIZE=30000#Non-uniformstepiterationsfor\\'steps_with_decay\\'or\\'steps_with_lrs\\'#policies__C.SOLVER.STEPS=[]#Learningratestousewith\\'steps_with_lrs\\'policy__C.SOLVER.LRS=[]#MaximumnumberofSGDiterations__C.SOLVER.MAX_ITER=40000#MomentumtousewithSGD__C.SOLVER.MOMENTUM=0.9#L2regularizationhyperparameter__C.SOLVER.WEIGHT_DECAY=0.0005#L2regularizationhyperparameterforGroupNorm\\'sparameters__C.SOLVER.WEIGHT_DECAY_GN=0.0#WarmuptoSOLVER.BASE_LRoverthisnumberofSGDiterations__C.SOLVER.WARM_UP_ITERS=500#StartthewarmupfromSOLVER.BASE_LR*SOLVER.WARM_UP_FACTOR__C.SOLVER.WARM_UP_FACTOR=1.0/3.0#WARM_UP_METHODcanbeeither\\'constant\\'or\\'linear\\'(i.e.,gradual)__C.SOLVER.WARM_UP_METHOD=\\'linear\\'#Scalethemomentumupdatehistorybynew_lr/old_lrwhenupdatingthe#learningrate(thisiscorrectgivenMomentumSGDUpdateOp)__C.SOLVER.SCALE_MOMENTUM=True#OnlyapplythecorrectioniftherelativeLRchangeexceedsthisthreshold#(preventseverchangeinlinearwarmupfromscalingthemomentumbyatiny#amount;momentumscalingisonlyimportantiftheLRchangeislarge)__C.SOLVER.SCALE_MOMENTUM_THRESHOLD=1.1#SuppressloggingofchangestoLRunlesstherelativechangeexceedsthis#threshold(preventslinearwarmupfromspammingthetraininglog)__C.SOLVER.LOG_LR_CHANGE_THRESHOLD=1.1#----------------------------------------------------------------------------##FastR-CNNoptions#----------------------------------------------------------------------------#__C.FAST_RCNN=AttrDict()#ThetypeofRoIheadtouseforboundingboxclassificationandregression#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'head_builder.add_roi_2mlp_head\\'tospecifyatwohiddenlayerMLP)__C.FAST_RCNN.ROI_BOX_HEAD=\\'\\'#HiddenlayerdimensionwhenusinganMLPfortheRoIboxhead__C.FAST_RCNN.MLP_HEAD_DIM=1024#HiddenConvlayerdimensionwhenusingConvsfortheRoIboxhead__C.FAST_RCNN.CONV_HEAD_DIM=256#NumberofstackedConvlayersintheRoIboxhead__C.FAST_RCNN.NUM_STACKED_CONVS=4#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)#(RoIPoolFisthesameasRoIPool;ignorethetrailing\\'F\\')__C.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIPoolF\\'#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO=0#RoItransformoutputresolution#Note:somemodelsmayhaveconstraintsonwhattheycanuse,e.g.theyuse#pretrainedFClayerslikeinVGG16,andwillignorethisoption__C.FAST_RCNN.ROI_XFORM_RESOLUTION=14#----------------------------------------------------------------------------##RPNoptions#----------------------------------------------------------------------------#__C.RPN=AttrDict()#[Inferedvalue;donotsetdirectlyinaconfig]#IndicatesthatthemodelcontainsanRPNsubnetwork__C.RPN.RPN_ON=False#RPNanchorsizesgiveninabsolutepixelsw.r.t.thescalednetworkinput#Note:theseoptionsare*not*usedbyFPNRPN;seeFPN.RPN*options__C.RPN.SIZES=(64,128,256,512)#StrideofthefeaturemapthatRPNisattached__C.RPN.STRIDE=16#RPNanchoraspectratios__C.RPN.ASPECT_RATIOS=(0.5,1,2)#----------------------------------------------------------------------------##FPNoptions#----------------------------------------------------------------------------#__C.FPN=AttrDict()#FPNisenabledifTrue__C.FPN.FPN_ON=False#ChanneldimensionoftheFPNfeaturelevels__C.FPN.DIM=256#InitializethelateralconnectionstooutputzeroifTrue__C.FPN.ZERO_INIT_LATERAL=False#StrideofthecoarsestFPNlevel#Thisisneededsotheinputcanbepaddedproperly__C.FPN.COARSEST_STRIDE=32##FPNmaybeusedforjustRPN,justobjectdetection,orboth##UseFPNforRoItransformforobjectdetectionifTrue__C.FPN.MULTILEVEL_ROIS=False#HyperparametersfortheRoI-to-FPNlevelmappingheuristic__C.FPN.ROI_CANONICAL_SCALE=224#s0__C.FPN.ROI_CANONICAL_LEVEL=4#k0:wheres0mapsto#CoarsestleveloftheFPNpyramid__C.FPN.ROI_MAX_LEVEL=5#FinestleveloftheFPNpyramid__C.FPN.ROI_MIN_LEVEL=2#UseFPNforRPNifTrue__C.FPN.MULTILEVEL_RPN=False#CoarsestleveloftheFPNpyramid__C.FPN.RPN_MAX_LEVEL=6#FinestleveloftheFPNpyramid__C.FPN.RPN_MIN_LEVEL=2#FPNRPNanchoraspectratios__C.FPN.RPN_ASPECT_RATIOS=(0.5,1,2)#RPNanchorsstartatthissizeonRPN_MIN_LEVEL#Theanchorsizedoubledeachlevelafterthat#Withadefaultof32andlevels2to6,wegetanchorsizesof32to512__C.FPN.RPN_ANCHOR_START_SIZE=32#UseextraFPNlevels,asdoneintheRetinaNetpaper__C.FPN.EXTRA_CONV_LEVELS=False#UseGroupNormintheFPN-specificlayers(lateral,etc.)__C.FPN.USE_GN=False#----------------------------------------------------------------------------##MaskR-CNNoptions(\"MRCNN\"meansMaskR-CNN)#----------------------------------------------------------------------------#__C.MRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancemaskprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\')__C.MRCNN.ROI_MASK_HEAD=\\'\\'#Resolutionofmaskpredictions__C.MRCNN.RESOLUTION=14#RoItransformationfunctionandassociatedoptions__C.MRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)__C.MRCNN.ROI_XFORM_RESOLUTION=7#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.MRCNN.ROI_XFORM_SAMPLING_RATIO=0#Numberofchannelsinthemaskhead__C.MRCNN.DIM_REDUCED=256#Usedilatedconvolutioninthemaskhead__C.MRCNN.DILATION=2#Upsamplethepredictedmasksbythisfactor__C.MRCNN.UPSAMPLE_RATIO=1#Useafully-connectedlayertopredictthefinalmasksinsteadofaconvlayer__C.MRCNN.USE_FC_OUTPUT=False#Weightinitializationmethodforthemaskheadandmaskoutputlayers__C.MRCNN.CONV_INIT=\\'GaussianFill\\'#UseclassspecificmaskpredictionsifTrue(otherwiseuseclassagnosticmask#predictions)__C.MRCNN.CLS_SPECIFIC_MASK=True#Multi-tasklossweightformasks__C.MRCNN.WEIGHT_LOSS_MASK=1.0#Binarizationthresholdforconvertingsoftmaskstohardmasks__C.MRCNN.THRESH_BINARIZE=0.5#----------------------------------------------------------------------------##KeypointMaskR-CNNoptions(\"KRCNN\"=MaskR-CNNwithKeypointsupport)#----------------------------------------------------------------------------#__C.KRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancekeypointprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'keypoint_rcnn_heads.add_roi_pose_head_v1convX\\')__C.KRCNN.ROI_KEYPOINTS_HEAD=\\'\\'#Outputsize(andsizelossiscomputedon),e.g.,56x56__C.KRCNN.HEATMAP_SIZE=-1#Usebilinearinterpolationtoupsamplethefinalheatmapbythisfactor__C.KRCNN.UP_SCALE=-1#ApplyaConvTransposelayertothehiddenrepresentationcomputedbythe#keypointheadpriortopredictingtheper-keypointheatmaps__C.KRCNN.USE_DECONV=False#ChanneldimensionofthehiddenrepresentationproducedbytheConvTranspose__C.KRCNN.DECONV_DIM=256#UseaConvTransposelayertopredicttheper-keypointheatmaps__C.KRCNN.USE_DECONV_OUTPUT=False#Usedilationinthekeypointhead__C.KRCNN.DILATION=1#SizeofthekernelstouseinallConvTransposeoperations__C.KRCNN.DECONV_KERNEL=4#Numberofkeypointsinthedataset(e.g.,17forCOCO)__C.KRCNN.NUM_KEYPOINTS=-1#NumberofstackedConvlayersinkeypointhead__C.KRCNN.NUM_STACKED_CONVS=8#Dimensionofthehiddenrepresentationoutputbythekeypointhead__C.KRCNN.CONV_HEAD_DIM=256#Convkernelsizeusedinthekeypointhead__C.KRCNN.CONV_HEAD_KERNEL=3#Convkernelweightfillingfunction__C.KRCNN.CONV_INIT=\\'GaussianFill\\'#UseNMSbasedonOKSifTrue__C.KRCNN.NMS_OKS=False#Sourceofkeypointconfidence#Validoptions:(\\'bbox\\',\\'logit\\',\\'prob\\')__C.KRCNN.KEYPOINT_CONFIDENCE=\\'bbox\\'#StandardROIXFORMoptions(seeFAST_RCNNorMRCNNoptions)__C.KRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'__C.KRCNN.ROI_XFORM_RESOLUTION=7__C.KRCNN.ROI_XFORM_SAMPLING_RATIO=0#Minimumnumberoflabeledkeypointsthatmustexistinaminibatch(otherwise#theminibatchisdiscarded)__C.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH=20#Wheninferingthekeypointlocationsfromtheheatmap,don\\'tscaletheheatmap#belowthisminimumsize__C.KRCNN.INFERENCE_MIN_SIZE=0#Multi-tasklossweighttouseforkeypoints#Recommendedvalues:#-use1.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisTrue#-use4.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse__C.KRCNN.LOSS_WEIGHT=1.0#NormalizebythetotalnumberofvisiblekeypointsintheminibatchifTrue.#Otherwise,normalizebythetotalnumberofkeypointsthatcouldeverexist#intheminibatch.Seecommentsinmodeling.model_builder.add_keypoint_losses#fordetaileddiscussion.__C.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS=True#----------------------------------------------------------------------------##R-FCNoptions#----------------------------------------------------------------------------#__C.RFCN=AttrDict()#Position-sensitiveRoIpoolingoutputgridsize(heightandwidth)__C.RFCN.PS_GRID_SIZE=3#----------------------------------------------------------------------------##ResNetsoptions(\"ResNets\"=ResNetandResNeXt)#----------------------------------------------------------------------------#__C.RESNETS=AttrDict()#Numberofgroupstouse;1==>ResNet;>1==>ResNeXt__C.RESNETS.NUM_GROUPS=1#Baselinewidthofeachgroup__C.RESNETS.WIDTH_PER_GROUP=64#Placethestride2convonthe1x1filter#UseTrueonlyfortheoriginalMSRAResNet;useFalseforC2andTorchmodels__C.RESNETS.STRIDE_1X1=True#Residualtransformationfunction__C.RESNETS.TRANS_FUNC=\\'bottleneck_transformation\\'#ResNet\\'sstemfunction(conv1andpool1)__C.RESNETS.STEM_FUNC=\\'basic_bn_stem\\'#ResNet\\'sshortcutfunction__C.RESNETS.SHORTCUT_FUNC=\\'basic_bn_shortcut\\'#Applydilationinstage\"res5\"__C.RESNETS.RES5_DILATION=1#----------------------------------------------------------------------------##GroupNormoptions#----------------------------------------------------------------------------#__C.GROUP_NORM=AttrDict()#NumberofdimensionspergroupinGroupNorm(-1ifusingNUM_GROUPS)__C.GROUP_NORM.DIM_PER_GP=-1#NumberofgroupsinGroupNorm(-1ifusingDIM_PER_GP)__C.GROUP_NORM.NUM_GROUPS=32#GroupNorm\\'ssmallconstantinthedenominator__C.GROUP_NORM.EPSILON=1e-5#----------------------------------------------------------------------------##Miscoptions#----------------------------------------------------------------------------##NumberofGPUstouse(appliestobothtrainingandtesting)__C.NUM_GPUS=1#UseNCCLforallreduce,otherwiseusemuji#Warning:ifsettoTrue,youmayexperiencedeadlocks__C.USE_NCCL=False#Themappingfromimagecoordinatestofeaturemapcoordinatesmightcause#someboxesthataredistinctinimagespacetobecomeidenticalinfeature#coordinates.IfDEDUP_BOXES>0,thenDEDUP_BOXESisusedasthescalefactor#foridentifyingduplicateboxes.#1/16iscorrectfor{Alex,Caffe}Net,VGG_CNN_M_1024,andVGG16__C.DEDUP_BOXES=1/16.#Clipboundingboxtransformationpredictionstopreventnp.expfrom#overflowing#Heuristicchoicebasedonthatwouldscalea16pixelanchorupto1000pixels__C.BBOX_XFORM_CLIP=np.log(1000./16.)#Pixelmeanvalues(BGRorder)asa(1,1,3)array#Weusethesamepixelmeanforallnetworkseventhoughit\\'snotexactlywhat#theyweretrainedwith#\"Fun\"fact:thehistoryofwherethesevaluescomesfromislost__C.PIXEL_MEANS=np.array([[[102.9801,115.9465,122.7717]]])#Forreproducibility...butnotreallybecausemodernfastGPUlibrariesuse#non-deterministicopimplementations__C.RNG_SEED=3#Asmallnumberthat\\'susedmanytimes__C.EPS=1e-14#Rootdirectoryofproject__C.ROOT_DIR=os.getcwd()#Outputbasedir__C.OUTPUT_DIR=\\'/tmp\\'#Name(orpathto)thematlabexecutable__C.MATLAB=\\'matlab\\'#Reducememoryusagewithmemongergradientblobsharing__C.MEMONGER=True#Futherreducememorybyallowingforwardpassactivationstobesharedwhen#possible.Notethatthiswillcauseactivationblobinspection(values,#shapes,etc.)tobemeaninglesswhenactivationblobsarereused.__C.MEMONGER_SHARE_ACTIVATIONS=False#Dumpdetectionvisualizations__C.VIS=False#Scorethresholdforvisualization__C.VIS_TH=0.9#Expectedresultsshouldtaketheformofalistofexpectations,each#specifiedbyfourelements(dataset,task,metric,expectedvalue).For#example:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387]]__C.EXPECTED_RESULTS=[]#AbsoluteandrelativetolerancetousewhencomparingtoEXPECTED_RESULTS__C.EXPECTED_RESULTS_RTOL=0.1__C.EXPECTED_RESULTS_ATOL=0.005#Whentheexpectedvaluespecifiesameanandstandarddeviation,wecheck#thattheactualvalueiswithinmean+/-SIGMA_TOL*std__C.EXPECTED_RESULTS_SIGMA_TOL=4#SettosendemailincaseofanEXPECTED_RESULTSfailure__C.EXPECTED_RESULTS_EMAIL=\\'\\'#ModelsandproposalsreferredtobyURLaredownloadedtoalocalcache#specifiedbyDOWNLOAD_CACHE__C.DOWNLOAD_CACHE=\\'/tmp/detectron-download-cache\\'#----------------------------------------------------------------------------##Clusteroptions#----------------------------------------------------------------------------#__C.CLUSTER=AttrDict()#Flagtoindicateifthecodeisrunninginaclusterenvironment__C.CLUSTER.ON_CLUSTER=False#----------------------------------------------------------------------------##Deprecatedoptions#Ifanoptionisremovedfromthecodeandyoudon\\'twanttobreakexisting#yamlconfigs,youcanaddthefullconfigkeyasastringtothesetbelow.#----------------------------------------------------------------------------#_DEPRECATED_KEYS=set({\\'FINAL_MSG\\',\\'MODEL.DILATION\\',\\'ROOT_GPU_ID\\',\\'RPN.ON\\',\\'TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED\\',\\'TRAIN.DROPOUT\\',\\'USE_GPU_NMS\\',\\'TEST.NUM_TEST_IMAGES\\',})#----------------------------------------------------------------------------##Renamedoptions#Ifyourenameaconfigoption,recordthemappingfromtheoldnametothenew#nameinthedictionarybelow.Optionally,ifthetypealsochanged,youcan#makethevalueatuplethatspecifiesfirsttherenamedkeyandthen#instructionsforhowtoedittheconfigfile.#----------------------------------------------------------------------------#_RENAMED_KEYS={\\'EXAMPLE.RENAMED.KEY\\':\\'EXAMPLE.KEY\\',#Dummyexampletofollow\\'MODEL.PS_GRID_SIZE\\':\\'RFCN.PS_GRID_SIZE\\',\\'MODEL.ROI_HEAD\\':\\'FAST_RCNN.ROI_BOX_HEAD\\',\\'MRCNN.MASK_HEAD_NAME\\':\\'MRCNN.ROI_MASK_HEAD\\',\\'TRAIN.DATASET\\':(\\'TRAIN.DATASETS\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'coco_2014_train\\'->(\\'coco_2014_train\\',)or\"+\"\\'coco_2014_train:coco_2014_valminusminival\\'->\"+\"(\\'coco_2014_train\\',\\'coco_2014_valminusminival\\')\"),\\'TRAIN.PROPOSAL_FILE\\':(\\'TRAIN.PROPOSAL_FILES\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'path/to/file\\'->(\\'path/to/file\\',)or\"+\"\\'path/to/file1:path/to/file2\\'->\"+\"(\\'path/to/file1\\',\\'path/to/file2\\')\"),\\'TEST.SCALES\\':(\\'TEST.SCALE\\',\"Alsoconvertfromatuple,e.g.(600,),\"+\"toainteger,e.g.600.\"),\\'TEST.DATASET\\':(\\'TEST.DATASETS\\',\"Alsoconvertfromastring,e.g\\'coco_2014_minival\\',\"+\"toatuple,e.g.(\\'coco_2014_minival\\',).\"),\\'TEST.PROPOSAL_FILE\\':(\\'TEST.PROPOSAL_FILES\\',\"Alsoconvertfromastring,e.g.\\'/path/to/props.pkl\\',\"+\"toatuple,e.g.(\\'/path/to/props.pkl\\',).\"),}#----------------------------------------------------------------------------##Renamedmodules#Ifamodulecontainingadatastructureusedintheconfig(e.g.AttrDict)#isrenamed/movedandyoudon\\'twanttobreakloadingofexistingyamlconfigs#(e.g.fromweightsfiles)youcanspecifytherenamedmodulebelow.#----------------------------------------------------------------------------#_RENAMED_MODULES={\\'utils.collections\\':\\'detectron.utils.collections\\',}defassert_and_infer_cfg(cache_urls=True,make_immutable=True):\"\"\"Callthisfunctioninyourscriptafteryouhavefinishedsettingallcfgvaluesthatarenecessary(e.g.,mergingaconfigfromafile,mergingcommandlineconfigoptions,etc.).Bydefault,thisfunctionwillalsomarktheglobalcfgasimmutabletopreventchangingtheglobalcfgsettingsduringscriptexecution(whichcanleadtohardtodebugerrorsorcodethat\\'shardertounderstandthanisnecessary).\"\"\"if__C.MODEL.RPN_ONLYor__C.MODEL.FASTER_RCNN:__C.RPN.RPN_ON=Trueif__C.RPN.RPN_ONor__C.RETINANET.RETINANET_ON:__C.TEST.PRECOMPUTED_PROPOSALS=Falseifcache_urls:cache_cfg_urls()ifmake_immutable:cfg.immutable(True)defcache_cfg_urls():\"\"\"DownloadURLsintheconfig,cachethemlocally,andrewritecfgtomakeuseofthelocallycachedfile.\"\"\"__C.TRAIN.WEIGHTS=cache_url(__C.TRAIN.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TEST.WEIGHTS=cache_url(__C.TEST.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TRAIN.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TRAIN.PROPOSAL_FILES)__C.TEST.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TEST.PROPOSAL_FILES)defget_output_dir(datasets,training=True):\"\"\"Gettheoutputdirectorydeterminedbythecurrentglobalconfig.\"\"\"assertisinstance(datasets,tuple([tuple,list]+list(six.string_types))),\\\\\\'datasetsargumentmustbeoftypetuple,listorstring\\'is_string=isinstance(datasets,six.string_types)dataset_name=datasetsifis_stringelse\\':\\'.join(datasets)tag=\\'train\\'iftrainingelse\\'test\\'#////outdir=osp.join(__C.OUTPUT_DIR,tag,dataset_name,__C.MODEL.TYPE)ifnotosp.exists(outdir):os.makedirs(outdir)returnoutdirdefload_cfg(cfg_to_load):\"\"\"Wrapperaroundyaml.loadusedformaintainingbackwardcompatibility\"\"\"file_types=[file,io.IOBase]ifsix.PY2else[io.IOBase]#noqafalsepositiveexpected_types=tuple(file_types+list(six.string_types))assertisinstance(cfg_to_load,expected_types),\\\\\\'Expectedoneof{},got{}\\'.format(expected_types,type(cfg_to_load))ifisinstance(cfg_to_load,tuple(file_types)):cfg_to_load=\\'\\'.join(cfg_to_load.readlines())forold_module,new_moduleiniteritems(_RENAMED_MODULES):#yamlobjectencoding:!!python/object/new:.old_module,new_module=\\'new:\\'+old_module,\\'new:\\'+new_modulecfg_to_load=cfg_to_load.replace(old_module,new_module)#Importinlineduetoacirculardependencybetweenenv.pyandconfig.pyimportdetectron.utils.envasenvureturnenvu.yaml_load(cfg_to_load)defmerge_cfg_from_file(cfg_filename):\"\"\"Loadayamlconfigfileandmergeitintotheglobalconfig.\"\"\"withopen(cfg_filename,\\'r\\')asf:yaml_cfg=AttrDict(load_cfg(f))_merge_a_into_b(yaml_cfg,__C)defmerge_cfg_from_cfg(cfg_other):\"\"\"Merge`cfg_other`intotheglobalconfig.\"\"\"_merge_a_into_b(cfg_other,__C)defmerge_cfg_from_list(cfg_list):\"\"\"Mergeconfigkeys,valuesinalist(e.g.,fromcommandline)intotheglobalconfig.Forexample,`cfg_list=[\\'TEST.NMS\\',0.5]`.\"\"\"assertlen(cfg_list)%2==0forfull_key,vinzip(cfg_list[0::2],cfg_list[1::2]):if_key_is_deprecated(full_key):continueif_key_is_renamed(full_key):_raise_key_rename_error(full_key)key_list=full_key.split(\\'.\\')d=__Cforsubkeyinkey_list[:-1]:assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)d=d[subkey]subkey=key_list[-1]assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)value=_decode_cfg_value(v)value=_check_and_coerce_cfg_value_type(value,d[subkey],subkey,full_key)d[subkey]=valuedef_merge_a_into_b(a,b,stack=None):\"\"\"Mergeconfigdictionaryaintoconfigdictionaryb,clobberingtheoptionsinbwhenevertheyarealsospecifiedina.\"\"\"assertisinstance(a,AttrDict),\\\\\\'`a`(curtype{})mustbeaninstanceof{}\\'.format(type(a),AttrDict)assertisinstance(b,AttrDict),\\\\\\'`b`(curtype{})mustbeaninstanceof{}\\'.format(type(b),AttrDict)fork,v_ina.items():full_key=\\'.\\'.join(stack)+\\'.\\'+kifstackisnotNoneelsek#amustspecifykeysthatareinbifknotinb:if_key_is_deprecated(full_key):continueelif_key_is_renamed(full_key):_raise_key_rename_error(full_key)else:raiseKeyError(\\'Non-existentconfigkey:{}\\'.format(full_key))v=copy.deepcopy(v_)v=_decode_cfg_value(v)v=_check_and_coerce_cfg_value_type(v,b[k],k,full_key)#Recursivelymergedictsifisinstance(v,AttrDict):try:stack_push=[k]ifstackisNoneelsestack+[k]_merge_a_into_b(v,b[k],stack=stack_push)exceptBaseException:raiseelse:b[k]=vdef_key_is_deprecated(full_key):iffull_keyin_DEPRECATED_KEYS:logger.warn(\\'Deprecatedconfigkey(ignoring):{}\\'.format(full_key))returnTruereturnFalsedef_key_is_renamed(full_key):returnfull_keyin_RENAMED_KEYSdef_raise_key_rename_error(full_key):new_key=_RENAMED_KEYS[full_key]ifisinstance(new_key,tuple):msg=\\'Note:\\'+new_key[1]new_key=new_key[0]else:msg=\\'\\'raiseKeyError(\\'Key{}wasrenamedto{};pleaseupdateyourconfig.{}\\'.format(full_key,new_key,msg))def_decode_cfg_value(v):\"\"\"Decodesarawconfigvalue(e.g.,fromayamlconfigfilesorcommandlineargument)intoaPythonobject.\"\"\"#Configsparsedfromrawyamlwillcontaindictionarykeysthatneedtobe#convertedtoAttrDictobjectsifisinstance(v,dict):returnAttrDict(v)#Allremainingprocessingisonlyappliedtostringsifnotisinstance(v,six.string_types):returnv#Trytointerpret`v`asa:#string,number,tuple,list,dict,boolean,orNonetry:v=literal_eval(v)#Thefollowingtwoexceptsallowvtopassthroughwhenitrepresentsa#string.##Longerexplanation:#Thetypeofvisalwaysastring(beforecallingliteral_eval),but#sometimesit*represents*astringandothertimesadatastructure,like#alist.Inthecasethatvrepresentsastring,whatwegotbackfromthe#yamlparseris\\'foo\\'*withoutquotes*(so,not\\'\"foo\"\\').literal_evalis#okwith\\'\"foo\"\\',butwillraiseaValueErrorifgiven\\'foo\\'.Inother#cases,likepaths(v=\\'foo/bar\\'andnotv=\\'\"foo/bar\"\\'),literal_eval#willraiseaSyntaxError.exceptValueError:passexceptSyntaxError:passreturnvdef_check_and_coerce_cfg_value_type(value_a,value_b,key,full_key):\"\"\"Checksthat`value_a`,whichisintendedtoreplace`value_b`isoftherighttype.Thetypeiscorrectifitmatchesexactlyorisoneofafewcasesinwhichthetypecanbeeasilycoerced.\"\"\"#Thetypesmustmatch(withsomeexceptions)type_b=type(value_b)type_a=type(value_a)iftype_aistype_b:returnvalue_a#Exceptions:numpyarrays,strings,tuplelistifisinstance(value_b,np.ndarray):value_a=np.array(value_a,dtype=value_b.dtype)elifisinstance(value_b,six.string_types):value_a=str(value_a)elifisinstance(value_a,tuple)andisinstance(value_b,list):value_a=list(value_a)elifisinstance(value_a,list)andisinstance(value_b,tuple):value_a=tuple(value_a)else:raiseValueError(\\'Typemismatch({}vs.{})withvalues({}vs.{})forconfig\\'\\'key:{}\\'.format(type_b,type_a,value_b,value_a,full_key))returnvalue_a#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"InferencefunctionalityformostDetectronmodels.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importloggingimportnumpyasnpfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.core.test_retinanetastest_retinanetimportdetectron.modeling.FPNasfpnimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.imageasimage_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defim_detect_all(model,im,box_proposals,timers=None):iftimersisNone:timers=defaultdict(Timer)#HandleRetinaNettestingseparatelyfornowifcfg.RETINANET.RETINANET_ON:cls_boxes=test_retinanet.im_detect_bbox(model,im,timers)returncls_boxes,None,Nonetimers[\\'im_detect_bbox\\'].tic()ifcfg.TEST.BBOX_AUG.ENABLED:scores,boxes,im_scale=im_detect_bbox_aug(model,im,box_proposals)else:scores,boxes,im_scale=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)timers[\\'im_detect_bbox\\'].toc()#scoreandboxesarefromthewholeimageafterscorethresholdingandnms#(theyarenotseparatedbyclass)#cls_boxesboxesandscoresareseparatedbyclassandintheformatused#forevaluatingresultstimers[\\'misc_bbox\\'].tic()scores,boxes,cls_boxes=box_results_with_nms_and_limit(scores,boxes)timers[\\'misc_bbox\\'].toc()ifcfg.MODEL.MASK_ONandboxes.shape[0]>0:timers[\\'im_detect_mask\\'].tic()ifcfg.TEST.MASK_AUG.ENABLED:masks=im_detect_mask_aug(model,im,boxes)else:masks=im_detect_mask(model,im_scale,boxes)timers[\\'im_detect_mask\\'].toc()timers[\\'misc_mask\\'].tic()cls_segms=segm_results(cls_boxes,masks,boxes,im.shape[0],im.shape[1])timers[\\'misc_mask\\'].toc()else:cls_segms=Noneifcfg.MODEL.KEYPOINTS_ONandboxes.shape[0]>0:timers[\\'im_detect_keypoints\\'].tic()ifcfg.TEST.KPS_AUG.ENABLED:heatmaps=im_detect_keypoints_aug(model,im,boxes)else:heatmaps=im_detect_keypoints(model,im_scale,boxes)timers[\\'im_detect_keypoints\\'].toc()timers[\\'misc_keypoints\\'].tic()cls_keyps=keypoint_results(cls_boxes,heatmaps,boxes)timers[\\'misc_keypoints\\'].toc()else:cls_keyps=Nonereturncls_boxes,cls_segms,cls_keypsdefim_conv_body_only(model,im,target_scale,target_max_size):\"\"\"Runs`model.conv_body_net`onthegivenimage`im`.\"\"\"im_blob,im_scale,_im_info=blob_utils.get_image_blob(im,target_scale,target_max_size)workspace.FeedBlob(core.ScopedName(\\'data\\'),im_blob)workspace.RunNet(model.conv_body_net.Proto().name)returnim_scaledefim_detect_bbox(model,im,target_scale,target_max_size,boxes=None):\"\"\"Boundingboxobjectdetectionforanimagewithgivenboxproposals.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):colorimagetotest(inBGRorder)boxes(ndarray):Rx4arrayofobjectproposalsin0-indexed[x1,y1,x2,y2]format,orNoneifusingRPNReturns:scores(ndarray):RxKarrayofobjectclassscoresforKclasses(Kincludesbackgroundasobjectcategory0)boxes(ndarray):Rx4*Karrayofpredictedboundingboxesim_scales(list):listofimagescalesusedintheinputblob(asreturnedby_get_blobsandforusewithim_detect_mask,etc.)\"\"\"inputs,im_scale=_get_blobs(im,boxes,target_scale,target_max_size)#WhenmappingfromimageROIstofeaturemapROIs,there\\'ssomealiasing#(somedistinctimageROIsgetmappedtothesamefeatureROI).#Here,weidentifyduplicatefeatureROIs,soweonlycomputefeatures#ontheuniquesubset.ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:v=np.array([1,1e3,1e6,1e9,1e12])hashes=np.round(inputs[\\'rois\\']*cfg.DEDUP_BOXES).dot(v)_,index,inv_index=np.unique(hashes,return_index=True,return_inverse=True)inputs[\\'rois\\']=inputs[\\'rois\\'][index,:]boxes=boxes[index,:]#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROISandnotcfg.MODEL.FASTER_RCNN:_add_multilevel_rois_for_test(inputs,\\'rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.net.Proto().name)#Readoutblobsifcfg.MODEL.FASTER_RCNN:rois=workspace.FetchBlob(core.ScopedName(\\'rois\\'))#unscalebacktorawimagespaceboxes=rois[:,1:5]/im_scale#Softmaxclassprobabilitiesscores=workspace.FetchBlob(core.ScopedName(\\'cls_prob\\')).squeeze()#Incasethereis1proposalscores=scores.reshape([-1,scores.shape[-1]])ifcfg.TEST.BBOX_REG:#Applybounding-boxregressiondeltasbox_deltas=workspace.FetchBlob(core.ScopedName(\\'bbox_pred\\')).squeeze()#Incasethereis1proposalbox_deltas=box_deltas.reshape([-1,box_deltas.shape[-1]])ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:#Removepredictionsforbgclass(compatwithMSRAcode)box_deltas=box_deltas[:,-4:]pred_boxes=box_utils.bbox_transform(boxes,box_deltas,cfg.MODEL.BBOX_REG_WEIGHTS)pred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:pred_boxes=np.tile(pred_boxes,(1,scores.shape[1]))else:#Simplyrepeattheboxes,onceforeachclasspred_boxes=np.tile(boxes,(1,scores.shape[1]))ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:#Mapscoresandpredictionsbacktotheoriginalsetofboxesscores=scores[inv_index,:]pred_boxes=pred_boxes[inv_index,:]returnscores,pred_boxes,im_scaledefim_detect_bbox_aug(model,im,box_proposals=None):\"\"\"Performsbboxdetectionwithtest-timeaugmentations.Functionsignatureisthesameasforim_detect_bbox.\"\"\"assertnotcfg.TEST.BBOX_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'assertnotcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\',\\\\\\'Coordheuristicmustbeunionwheneverscoreheuristicisunion\\'assertnotcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'Scoreheuristicmustbeunionwhenevercoordheuristicisunion\\'assertnotcfg.MODEL.FASTER_RCNNor\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'UnionheuristicmustbeusedtocombineFasterRCNNpredictions\\'#Collectdetectionscomputedunderdifferenttransformationsscores_ts=[]boxes_ts=[]defadd_preds_t(scores_t,boxes_t):scores_ts.append(scores_t)boxes_ts.append(boxes_t)#Performdetectiononthehorizontallyflippedimageifcfg.TEST.BBOX_AUG.H_FLIP:scores_hf,boxes_hf,_=im_detect_bbox_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals)add_preds_t(scores_hf,boxes_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.BBOX_AUG.SCALES:max_size=cfg.TEST.BBOX_AUG.MAX_SIZEscores_scl,boxes_scl=im_detect_bbox_scale(model,im,scale,max_size,box_proposals)add_preds_t(scores_scl,boxes_scl)ifcfg.TEST.BBOX_AUG.SCALE_H_FLIP:scores_scl_hf,boxes_scl_hf=im_detect_bbox_scale(model,im,scale,max_size,box_proposals,hflip=True)add_preds_t(scores_scl_hf,boxes_scl_hf)#Performdetectionatdifferentaspectratiosforaspect_ratioincfg.TEST.BBOX_AUG.ASPECT_RATIOS:scores_ar,boxes_ar=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals)add_preds_t(scores_ar,boxes_ar)ifcfg.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP:scores_ar_hf,boxes_ar_hf=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals,hflip=True)add_preds_t(scores_ar_hf,boxes_ar_hf)#Computedetectionsfortheoriginalimage(identitytransform)lastto#ensurethattheCaffe2workspaceispopulatedwithblobscorresponding#totheoriginalimageonreturn(postconditionofim_detect_bbox)scores_i,boxes_i,im_scale_i=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)add_preds_t(scores_i,boxes_i)#Combinethepredictedscoresifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'ID\\':scores_c=scores_ielifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'AVG\\':scores_c=np.mean(scores_ts,axis=0)elifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\':scores_c=np.vstack(scores_ts)else:raiseNotImplementedError(\\'Scoreheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.SCORE_HEUR))#Combinethepredictedboxesifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'ID\\':boxes_c=boxes_ielifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'AVG\\':boxes_c=np.mean(boxes_ts,axis=0)elifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\':boxes_c=np.vstack(boxes_ts)else:raiseNotImplementedError(\\'Coordheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.COORD_HEUR))returnscores_c,boxes_c,im_scale_idefim_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=None):\"\"\"Performsbboxdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_bbox.\"\"\"#Computepredictionsontheflippedimageim_hf=im[:,::-1,:]im_width=im.shape[1]ifnotcfg.MODEL.FASTER_RCNN:box_proposals_hf=box_utils.flip_boxes(box_proposals,im_width)else:box_proposals_hf=Nonescores_hf,boxes_hf,im_scale=im_detect_bbox(model,im_hf,target_scale,target_max_size,boxes=box_proposals_hf)#Invertthedetectionscomputedontheflippedimageboxes_inv=box_utils.flip_boxes(boxes_hf,im_width)returnscores_hf,boxes_inv,im_scaledefim_detect_bbox_scale(model,im,target_scale,target_max_size,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenscale.Returnspredictionsintheoriginalimagespace.\"\"\"ifhflip:scores_scl,boxes_scl,_=im_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=box_proposals)else:scores_scl,boxes_scl,_=im_detect_bbox(model,im,target_scale,target_max_size,boxes=box_proposals)returnscores_scl,boxes_scldefim_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenwidth-relativeaspectratio.Returnspredictionsintheoriginalimagespace.\"\"\"#Computepredictionsonthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)ifnotcfg.MODEL.FASTER_RCNN:box_proposals_ar=box_utils.aspect_ratio(box_proposals,aspect_ratio)else:box_proposals_ar=Noneifhflip:scores_ar,boxes_ar,_=im_detect_bbox_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals_ar)else:scores_ar,boxes_ar,_=im_detect_bbox(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals_ar)#Invertthedetectedboxesboxes_inv=box_utils.aspect_ratio(boxes_ar,1.0/aspect_ratio)returnscores_ar,boxes_invdefim_detect_mask(model,im_scale,boxes):\"\"\"Inferinstancesegmentationmasks.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_masks(ndarray):RxKxMxMarrayofclassspecificsoftmasksoutputbythenetwork(mustbeprocessedbysegm_resultstoconvertintohardmasksintheoriginalimagecoordinatespace)\"\"\"M=cfg.MRCNN.RESOLUTIONifboxes.shape[0]==0:pred_masks=np.zeros((0,M,M),np.float32)returnpred_masksinputs={\\'mask_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'mask_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.mask_net.Proto().name)#Fetchmaskspred_masks=workspace.FetchBlob(core.ScopedName(\\'mask_fcn_probs\\')).squeeze()ifcfg.MRCNN.CLS_SPECIFIC_MASK:pred_masks=pred_masks.reshape([-1,cfg.MODEL.NUM_CLASSES,M,M])else:pred_masks=pred_masks.reshape([-1,1,M,M])returnpred_masksdefim_detect_mask_aug(model,im,boxes):\"\"\"Performsmaskdetectionwithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:masks(ndarray):RxKxMxMarrayofclassspecificsoftmasks\"\"\"assertnotcfg.TEST.MASK_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'#Collectmaskscomputedunderdifferenttransformationsmasks_ts=[]#Computemasksfortheoriginalimage(identitytransform)im_scale_i=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_i=im_detect_mask(model,im_scale_i,boxes)masks_ts.append(masks_i)#Performmaskdetectiononthehorizontallyflippedimageifcfg.TEST.MASK_AUG.H_FLIP:masks_hf=im_detect_mask_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)masks_ts.append(masks_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.MASK_AUG.SCALES:max_size=cfg.TEST.MASK_AUG.MAX_SIZEmasks_scl=im_detect_mask_scale(model,im,scale,max_size,boxes)masks_ts.append(masks_scl)ifcfg.TEST.MASK_AUG.SCALE_H_FLIP:masks_scl_hf=im_detect_mask_scale(model,im,scale,max_size,boxes,hflip=True)masks_ts.append(masks_scl_hf)#Computemasksatdifferentaspectratiosforaspect_ratioincfg.TEST.MASK_AUG.ASPECT_RATIOS:masks_ar=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes)masks_ts.append(masks_ar)ifcfg.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP:masks_ar_hf=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)masks_ts.append(masks_ar_hf)#Combinethepredictedsoftmasksifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_AVG\\':masks_c=np.mean(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_MAX\\':masks_c=np.amax(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'LOGIT_AVG\\':deflogit(y):return-1.0*np.log((1.0-y)/np.maximum(y,1e-20))logit_masks=[logit(y)foryinmasks_ts]logit_masks=np.mean(logit_masks,axis=0)masks_c=1.0/(1.0+np.exp(-logit_masks))else:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.MASK_AUG.HEUR))returnmasks_cdefim_detect_mask_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Performsmaskdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_mask_aug.\"\"\"#Computethemasksfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)masks_hf=im_detect_mask(model,im_scale,boxes_hf)#Invertthepredictedsoftmasksmasks_inv=masks_hf[:,:,:,::-1]returnmasks_invdefim_detect_mask_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computesmasksatthegivenscale.\"\"\"ifhflip:masks_scl=im_detect_mask_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)masks_scl=im_detect_mask(model,im_scale,boxes)returnmasks_scldefim_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Computesmaskdetectionsatthegivenwidth-relativeaspectratio.\"\"\"#Performmaskdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:masks_ar=im_detect_mask_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_ar=im_detect_mask(model,im_scale,boxes_ar)returnmasks_ardefim_detect_keypoints(model,im_scale,boxes):\"\"\"Inferinstancekeypointposes.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits(softmaxinputs)foreachoftheJkeypointtypesoutputbythenetwork(mustbeprocessedbykeypoint_resultstoconvertintopointpredictionsintheoriginalimagecoordinatespace)\"\"\"M=cfg.KRCNN.HEATMAP_SIZEifboxes.shape[0]==0:pred_heatmaps=np.zeros((0,cfg.KRCNN.NUM_KEYPOINTS,M,M),np.float32)returnpred_heatmapsinputs={\\'keypoint_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'keypoint_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.keypoint_net.Proto().name)pred_heatmaps=workspace.FetchBlob(core.ScopedName(\\'kps_score\\')).squeeze()#Incaseof1ifpred_heatmaps.ndim==3:pred_heatmaps=np.expand_dims(pred_heatmaps,axis=0)returnpred_heatmapsdefim_detect_keypoints_aug(model,im,boxes):\"\"\"Computeskeypointpredictionswithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits\"\"\"#Collectheatmapspredictedunderdifferenttransformationsheatmaps_ts=[]#Tagpredictionscomputedunderdownscalingandupscalingtransformationsds_ts=[]us_ts=[]defadd_heatmaps_t(heatmaps_t,ds_t=False,us_t=False):heatmaps_ts.append(heatmaps_t)ds_ts.append(ds_t)us_ts.append(us_t)#Computetheheatmapsfortheoriginalimage(identitytransform)im_scale=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_i=im_detect_keypoints(model,im_scale,boxes)add_heatmaps_t(heatmaps_i)#Performkeypointsdetectiononthehorizontallyflippedimageifcfg.TEST.KPS_AUG.H_FLIP:heatmaps_hf=im_detect_keypoints_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.KPS_AUG.SCALES:ds_scl=scale<cfg.TEST.SCALEus_scl=scale>cfg.TEST.SCALEheatmaps_scl=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_scl,ds_scl,us_scl)ifcfg.TEST.KPS_AUG.SCALE_H_FLIP:heatmaps_scl_hf=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes,hflip=True)add_heatmaps_t(heatmaps_scl_hf,ds_scl,us_scl)#Computekeypointsatdifferentaspectratiosforaspect_ratioincfg.TEST.KPS_AUG.ASPECT_RATIOS:heatmaps_ar=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes)add_heatmaps_t(heatmaps_ar)ifcfg.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP:heatmaps_ar_hf=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)add_heatmaps_t(heatmaps_ar_hf)#Selecttheheuristicfunctionforcombiningtheheatmapsifcfg.TEST.KPS_AUG.HEUR==\\'HM_AVG\\':np_f=np.meanelifcfg.TEST.KPS_AUG.HEUR==\\'HM_MAX\\':np_f=np.amaxelse:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.KPS_AUG.HEUR))defheur_f(hms_ts):returnnp_f(hms_ts,axis=0)#Combinetheheatmapsifcfg.TEST.KPS_AUG.SCALE_SIZE_DEP:heatmaps_c=combine_heatmaps_size_dep(heatmaps_ts,ds_ts,us_ts,boxes,heur_f)else:heatmaps_c=heur_f(heatmaps_ts)returnheatmaps_cdefim_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Computeskeypointpredictionsonthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_keypoints_aug.\"\"\"#Computekeypointsfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)heatmaps_hf=im_detect_keypoints(model,im_scale,boxes_hf)#Invertthepredictedkeypointsheatmaps_inv=keypoint_utils.flip_heatmaps(heatmaps_hf)returnheatmaps_invdefim_detect_keypoints_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computeskeypointpredictionsatthegivenscale.\"\"\"ifhflip:heatmaps_scl=im_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)heatmaps_scl=im_detect_keypoints(model,im_scale,boxes)returnheatmaps_scldefim_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Detectskeypointsatthegivenwidth-relativeaspectratio.\"\"\"#Performkeypointdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:heatmaps_ar=im_detect_keypoints_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_ar=im_detect_keypoints(model,im_scale,boxes_ar)returnheatmaps_ardefcombine_heatmaps_size_dep(hms_ts,ds_ts,us_ts,boxes,heur_f):\"\"\"Combinesheatmapswhiletakingobjectsizesintoaccount.\"\"\"assertlen(hms_ts)==len(ds_ts)andlen(ds_ts)==len(us_ts),\\\\\\'Allsetsofhmsmustbetaggedwithdownscalingandupscalingflags\\'#Classifyobjectsintosmall+mediumandlargebasedontheirboxareasareas=box_utils.boxes_area(boxes)sm_objs=areas<cfg.TEST.KPS_AUG.AREA_THl_objs=areas>=cfg.TEST.KPS_AUG.AREA_TH#Combineheatmapscomputedunderdifferenttransformationsforeachobjecthms_c=np.zeros_like(hms_ts[0])foriinrange(hms_c.shape[0]):hms_to_combine=[]forhms_t,ds_t,us_tinzip(hms_ts,ds_ts,us_ts):#Discarddownscalingpredictionsforsmallandmediumobjectsifsm_objs[i]andds_t:continue#Discardupscalingpredictionsforlargeobjectsifl_objs[i]andus_t:continuehms_to_combine.append(hms_t[i])hms_c[i]=heur_f(hms_to_combine)returnhms_cdefbox_results_with_nms_and_limit(scores,boxes):\"\"\"Returnsbounding-boxdetectionresultsbythresholdingonscoresandapplyingnon-maximumsuppression(NMS).`boxes`hasshape(#detections,4*#classes),whereeachrowrepresentsalistofpredictedboundingboxesforeachoftheobjectclassesinthedataset(includingthebackgroundclass).Thedetectionsineachroworiginatefromthesameobjectproposal.`scores`hasshape(#detection,#classes),whereeachrowrepresentsalistofobjectdetectionconfidencescoresforeachoftheobjectclassesinthedataset(includingthebackgroundclass).`scores[i,j]``correspondstotheboxat`boxes[i,j*4:(j+1)*4]`.\"\"\"num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(num_classes)]#ApplythresholdondetectionprobabilitiesandapplyNMS#Skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):inds=np.where(scores[:,j]>cfg.TEST.SCORE_THRESH)[0]scores_j=scores[inds,j]boxes_j=boxes[inds,j*4:(j+1)*4]dets_j=np.hstack((boxes_j,scores_j[:,np.newaxis])).astype(np.float32,copy=False)ifcfg.TEST.SOFT_NMS.ENABLED:nms_dets,_=box_utils.soft_nms(dets_j,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(dets_j,cfg.TEST.NMS)nms_dets=dets_j[keep,:]#Refinethepost-NMSboxesusingbounding-boxvotingifcfg.TEST.BBOX_VOTE.ENABLED:nms_dets=box_utils.box_voting(nms_dets,dets_j,cfg.TEST.BBOX_VOTE.VOTE_TH,scoring_method=cfg.TEST.BBOX_VOTE.SCORING_METHOD)cls_boxes[j]=nms_dets#Limittomax_per_imagedetections**overallclasses**ifcfg.TEST.DETECTIONS_PER_IM>0:image_scores=np.hstack([cls_boxes[j][:,-1]forjinrange(1,num_classes)])iflen(image_scores)>cfg.TEST.DETECTIONS_PER_IM:image_thresh=np.sort(image_scores)[-cfg.TEST.DETECTIONS_PER_IM]forjinrange(1,num_classes):keep=np.where(cls_boxes[j][:,-1]>=image_thresh)[0]cls_boxes[j]=cls_boxes[j][keep,:]im_results=np.vstack([cls_boxes[j]forjinrange(1,num_classes)])boxes=im_results[:,:-1]scores=im_results[:,-1]returnscores,boxes,cls_boxesdefsegm_results(cls_boxes,masks,ref_boxes,im_h,im_w):num_classes=cfg.MODEL.NUM_CLASSEScls_segms=[[]for_inrange(num_classes)]mask_ind=0#Toworkaroundanissuewithcv2.resize(itseemstoautomaticallypad#withrepeatedbordervalues),wemanuallyzero-padthemasksby1pixel#priortoresizingbacktotheoriginalimageresolution.Thisprevents#\"tophat\"artifacts.Wethereforeneedtoexpandthereferenceboxesbyan#appropriatefactor.M=cfg.MRCNN.RESOLUTIONscale=(M+2.0)/Mref_boxes=box_utils.expand_boxes(ref_boxes,scale)ref_boxes=ref_boxes.astype(np.int32)padded_mask=np.zeros((M+2,M+2),dtype=np.float32)#skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):segms=[]for_inrange(cls_boxes[j].shape[0]):ifcfg.MRCNN.CLS_SPECIFIC_MASK:padded_mask[1:-1,1:-1]=masks[mask_ind,j,:,:]else:padded_mask[1:-1,1:-1]=masks[mask_ind,0,:,:]ref_box=ref_boxes[mask_ind,:]w=ref_box[2]-ref_box[0]+1h=ref_box[3]-ref_box[1]+1w=np.maximum(w,1)h=np.maximum(h,1)mask=cv2.resize(padded_mask,(w,h))mask=np.array(mask>cfg.MRCNN.THRESH_BINARIZE,dtype=np.uint8)im_mask=np.zeros((im_h,im_w),dtype=np.uint8)x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,im_w)y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,im_h)im_mask[y_0:y_1,x_0:x_1]=mask[(y_0-ref_box[1]):(y_1-ref_box[1]),(x_0-ref_box[0]):(x_1-ref_box[0])]#GetRLEencodingusedbytheCOCOevaluationAPIrle=mask_util.encode(np.array(im_mask[:,:,np.newaxis],order=\\'F\\'))[0]segms.append(rle)mask_ind+=1cls_segms[j]=segmsassertmask_ind==masks.shape[0]returncls_segmsdefkeypoint_results(cls_boxes,pred_heatmaps,ref_boxes):num_classes=cfg.MODEL.NUM_CLASSEScls_keyps=[[]for_inrange(num_classes)]person_idx=keypoint_utils.get_person_class_index()xy_preds=keypoint_utils.heatmaps_to_keypoints(pred_heatmaps,ref_boxes)#NMSOKSifcfg.KRCNN.NMS_OKS:keep=keypoint_utils.nms_oks(xy_preds,ref_boxes,0.3)xy_preds=xy_preds[keep,:,:]ref_boxes=ref_boxes[keep,:]pred_heatmaps=pred_heatmaps[keep,:,:,:]cls_boxes[person_idx]=cls_boxes[person_idx][keep,:]kps=[xy_preds[i]foriinrange(xy_preds.shape[0])]cls_keyps[person_idx]=kpsreturncls_keypsdef_get_rois_blob(im_rois,im_scale):\"\"\"ConvertsRoIsintonetworkinputs.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesim_scale_factors(list):scalefactorsasreturnedby_get_image_blobReturns:blob(ndarray):Rx5matrixofRoIsintheimagepyramidwithcolumns[level,x1,y1,x2,y2]\"\"\"rois,levels=_project_im_rois(im_rois,im_scale)rois_blob=np.hstack((levels,rois))returnrois_blob.astype(np.float32,copy=False)def_project_im_rois(im_rois,scales):\"\"\"ProjectimageRoIsintotheimagepyramidbuiltby_get_image_blob.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesscales(list):scalefactorsasreturnedby_get_image_blobReturns:rois(ndarray):Rx4matrixofprojectedRoIcoordinateslevels(ndarray):imagepyramidlevelsusedbyeachprojectedRoI\"\"\"rois=im_rois.astype(float,copy=False)*scaleslevels=np.zeros((im_rois.shape[0],1),dtype=int)returnrois,levelsdef_add_multilevel_rois_for_test(blobs,name):\"\"\"DistributesasetofRoIsacrossFPNpyramidlevelsbycreatingnewlevelspecificRoIblobs.Arguments:blobs(dict):dictionaryofblobsname(str):akeyin\\'blobs\\'identifyingthesourceRoIblobReturns:[byref]blobs(dict):newkeysnamedby`name+\\'fpn\\'+level`areaddedtodicteachwithavaluethat\\'sanR_levelx5ndarrayofRoIs(see_get_rois_blobforformat)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(blobs[name][:,1:5],lvl_min,lvl_max)fpn.add_multilevel_roi_blobs(blobs,name,blobs[name],lvls,lvl_min,lvl_max)def_get_blobs(im,rois,target_scale,target_max_size):\"\"\"ConvertanimageandRoIswithinthatimageintonetworkinputs.\"\"\"blobs={}blobs[\\'data\\'],im_scale,blobs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,target_scale,target_max_size)ifroisisnotNone:blobs[\\'rois\\']=_get_rois_blob(rois,im_scale)returnblobs,im_scale#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyBharathHariharan#--------------------------------------------------------\"\"\"PythonimplementationofthePASCALVOCdevkit\\'sAPevaluationcode.\"\"\"importloggingimportnumpyasnpimportosimportxml.etree.ElementTreeasETfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defparse_rec(filename):\"\"\"ParseaPASCALVOCxmlfile.\"\"\"tree=ET.parse(filename)objects=[]forobjintree.findall(\\'object\\'):obj_struct={}obj_struct[\\'name\\']=obj.find(\\'name\\').textobj_struct[\\'pose\\']=obj.find(\\'pose\\').textobj_struct[\\'truncated\\']=int(obj.find(\\'truncated\\').text)obj_struct[\\'difficult\\']=int(obj.find(\\'difficult\\').text)bbox=obj.find(\\'bndbox\\')obj_struct[\\'bbox\\']=[int(bbox.find(\\'xmin\\').text),int(bbox.find(\\'ymin\\').text),int(bbox.find(\\'xmax\\').text),int(bbox.find(\\'ymax\\').text)]objects.append(obj_struct)returnobjectsdefvoc_ap(rec,prec,use_07_metric=False):\"\"\"ComputeVOCAPgivenprecisionandrecall.Ifuse_07_metricistrue,usestheVOC0711-pointmethod(default:False).\"\"\"ifuse_07_metric:#11pointmetricap=0.fortinnp.arange(0.,1.1,0.1):ifnp.sum(rec>=t)==0:p=0else:p=np.max(prec[rec>=t])ap=ap+p/11.else:#correctAPcalculation#firstappendsentinelvaluesattheendmrec=np.concatenate(([0.],rec,[1.]))mpre=np.concatenate(([0.],prec,[0.]))#computetheprecisionenvelopeforiinrange(mpre.size-1,0,-1):mpre[i-1]=np.maximum(mpre[i-1],mpre[i])#tocalculateareaunderPRcurve,lookforpoints#whereXaxis(recall)changesvaluei=np.where(mrec[1:]!=mrec[:-1])[0]#andsum(\\\\Deltarecall)*precap=np.sum((mrec[i+1]-mrec[i])*mpre[i+1])returnapdefvoc_eval(detpath,annopath,imagesetfile,classname,cachedir,ovthresh=0.5,use_07_metric=False):\"\"\"rec,prec,ap=voc_eval(detpath,annopath,imagesetfile,classname,[ovthresh],[use_07_metric])ToplevelfunctionthatdoesthePASCALVOCevaluation.detpath:Pathtodetectionsdetpath.format(classname)shouldproducethedetectionresultsfile.annopath:Pathtoannotationsannopath.format(imagename)shouldbethexmlannotationsfile.imagesetfile:Textfilecontainingthelistofimages,oneimageperline.classname:Categoryname(duh)cachedir:Directoryforcachingtheannotations[ovthresh]:Overlapthreshold(default=0.5)[use_07_metric]:WhethertouseVOC07\\'s11pointAPcomputation(defaultFalse)\"\"\"#assumesdetectionsareindetpath.format(classname)#assumesannotationsareinannopath.format(imagename)#assumesimagesetfileisatextfilewitheachlineanimagename#cachedircachestheannotationsinapicklefile#firstloadgtifnotos.path.isdir(cachedir):os.mkdir(cachedir)imageset=os.path.splitext(os.path.basename(imagesetfile))[0]cachefile=os.path.join(cachedir,imageset+\\'_annots.pkl\\')#readlistofimageswithopen(imagesetfile,\\'r\\')asf:lines=f.readlines()imagenames=[x.strip()forxinlines]ifnotos.path.isfile(cachefile):#loadannotsrecs={}fori,imagenameinenumerate(imagenames):recs[imagename]=parse_rec(annopath.format(imagename))ifi%100==0:logger.info(\\'Readingannotationfor{:d}/{:d}\\'.format(i+1,len(imagenames)))#savelogger.info(\\'Savingcachedannotationsto{:s}\\'.format(cachefile))save_object(recs,cachefile)else:recs=load_object(cachefile)#extractgtobjectsforthisclassclass_recs={}npos=0forimagenameinimagenames:R=[objforobjinrecs[imagename]ifobj[\\'name\\']==classname]bbox=np.array([x[\\'bbox\\']forxinR])difficult=np.array([x[\\'difficult\\']forxinR]).astype(bool)det=[False]*len(R)npos=npos+sum(~difficult)class_recs[imagename]={\\'bbox\\':bbox,\\'difficult\\':difficult,\\'det\\':det}#readdetsdetfile=detpath.format(classname)withopen(detfile,\\'r\\')asf:lines=f.readlines()splitlines=[x.strip().split(\\'\\')forxinlines]image_ids=[x[0]forxinsplitlines]confidence=np.array([float(x[1])forxinsplitlines])BB=np.array([[float(z)forzinx[2:]]forxinsplitlines])#sortbyconfidencesorted_ind=np.argsort(-confidence)BB=BB[sorted_ind,:]image_ids=[image_ids[x]forxinsorted_ind]#godowndetsandmarkTPsandFPsnd=len(image_ids)tp=np.zeros(nd)fp=np.zeros(nd)fordinrange(nd):R=class_recs[image_ids[d]]bb=BB[d,:].astype(float)ovmax=-np.infBBGT=R[\\'bbox\\'].astype(float)ifBBGT.size>0:#computeoverlaps#intersectionixmin=np.maximum(BBGT[:,0],bb[0])iymin=np.maximum(BBGT[:,1],bb[1])ixmax=np.minimum(BBGT[:,2],bb[2])iymax=np.minimum(BBGT[:,3],bb[3])iw=np.maximum(ixmax-ixmin+1.,0.)ih=np.maximum(iymax-iymin+1.,0.)inters=iw*ih#unionuni=((bb[2]-bb[0]+1.)*(bb[3]-bb[1]+1.)+(BBGT[:,2]-BBGT[:,0]+1.)*(BBGT[:,3]-BBGT[:,1]+1.)-inters)overlaps=inters/uniovmax=np.max(overlaps)jmax=np.argmax(overlaps)ifovmax>ovthresh:ifnotR[\\'difficult\\'][jmax]:ifnotR[\\'det\\'][jmax]:tp[d]=1.R[\\'det\\'][jmax]=1else:fp[d]=1.else:fp[d]=1.#computeprecisionrecallfp=np.cumsum(fp)tp=np.cumsum(tp)rec=tp/float(npos)#avoiddividebyzeroincasethefirstdetectionmatchesadifficult#groundtruthprec=tp/np.maximum(tp+fp,np.finfo(np.float64).eps)ap=voc_ap(rec,prec,use_07_metric)returnrec,prec,ap#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforevaluatingresultscomputedforajsondataset.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportjsonimportloggingimportnumpyasnpimportosimportsiximportuuidfrompycocotools.cocoevalimportCOCOevalfromdetectron.core.configimportcfgfromdetectron.utils.ioimportsave_objectimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_segmentation_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Segmentation\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"segmentation\":[...],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_segms_results_one_category(json_dataset,all_boxes[cls_ind],all_segms[cls_ind],cat_id))logger.info(\\'Writingsegmentationresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:#\"counts\"isanarrayencodedbymask_utilasabyte-stream.Python3\\'s#jsonwriterwhich/alwaysproducesstrings/cannotserializeabytestream#unlessyoudecodeit.Thankfully,utf-8worksout(whichisalsowhat#thepycocotools/_mask.pyxdoes.ifsix.PY3:forrinresults:rle=r[\\'segmentation\\']if\\'counts\\'inrle:rle[\\'counts\\']=rle[\\'counts\\'].decode(\"utf8\")json.dump(results,fid)def_coco_segms_results_one_category(json_dataset,boxes,segms,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)assertlen(segms)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]rles=segms[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'segmentation\\':rles[k],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_segmentation_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'segm\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'segmentation_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldefevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'bbox_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_bbox_results_file(json_dataset,all_boxes,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_detection_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Bbox\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_bbox_results_file(json_dataset,all_boxes,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"bbox\":[258.15,41.29,348.26,243.78],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_bbox_results_one_category(json_dataset,all_boxes[cls_ind],cat_id))logger.info(\\'Writingbboxresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_bbox_results_one_category(json_dataset,boxes,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]xywh_dets=box_utils.xyxy_to_xywh(dets[:,0:4])xs=xywh_dets[:,0]ys=xywh_dets[:,1]ws=xywh_dets[:,2]hs=xywh_dets[:,3]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'bbox\\':[xs[k],ys[k],ws[k],hs[k]],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_detection_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'bbox\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'detection_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldef_log_detection_eval_metrics(json_dataset,coco_eval):def_get_thr_ind(coco_eval,thr):ind=np.where((coco_eval.params.iouThrs>thr-1e-5)&(coco_eval.params.iouThrs<thr+1e-5))[0][0]iou_thr=coco_eval.params.iouThrs[ind]assertnp.isclose(iou_thr,thr)returnindIoU_lo_thresh=0.5IoU_hi_thresh=0.95ind_lo=_get_thr_ind(coco_eval,IoU_lo_thresh)ind_hi=_get_thr_ind(coco_eval,IoU_hi_thresh)#precisionhasdims(iou,recall,cls,arearange,maxdets)#arearangeindex0:allarearanges#maxdetsindex2:100perimageprecision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,:,0,2]ap_default=np.mean(precision[precision>-1])logger.info(\\'~~~~Meanandper-categoryAP@IoU=[{:.2f},{:.2f}]~~~~\\'.format(IoU_lo_thresh,IoU_hi_thresh))logger.info(\\'{:.1f}\\'.format(100*ap_default))forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continue#minus1becauseof__background__precision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,cls_ind-1,0,2]ap=np.mean(precision[precision>-1])logger.info(\\'{:.1f}\\'.format(100*ap))logger.info(\\'~~~~Summarymetrics~~~~\\')coco_eval.summarize()defevaluate_box_proposals(json_dataset,roidb,thresholds=None,area=\\'all\\',l',\n",
       " 'imit=None,class_specific=False):\"\"\"Evaluatedetectionproposalrecallmetrics.ThisfunctionisamuchfasteralternativetotheofficialCOCOAPIrecallevaluationcode.However,itproducesslightlydifferentresults.\"\"\"#Recordmaxoverlapvalueforeachgtbox#Returnvectorofoverlapvaluesareas={\\'all\\':0,\\'small\\':1,\\'medium\\':2,\\'large\\':3,\\'96-128\\':4,\\'128-256\\':5,\\'256-512\\':6,\\'512-inf\\':7}area_ranges=[[0**2,1e5**2],#all[0**2,32**2],#small[32**2,96**2],#medium[96**2,1e5**2],#large[96**2,128**2],#96-128[128**2,256**2],#128-256[256**2,512**2],#256-512[512**2,1e5**2]]#512-infassertareainareas,\\'Unknownarearange:{}\\'.format(area)area_range=area_ranges[areas[area]]gt_overlaps=np.zeros(0)gt_classes=np.zeros(0)num_pos=0forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_areas=entry[\\'seg_areas\\'][gt_inds]valid_gt_inds=np.where((gt_areas>=area_range[0])&(gt_areas<=area_range[1]))[0]gt_boxes=gt_boxes[valid_gt_inds,:]_gt_classes=entry[\"gt_classes\"][valid_gt_inds]assertgt_boxes.shape[0]==_gt_classes.shape[0]gt_classes=np.hstack((gt_classes,_gt_classes))num_pos+=len(valid_gt_inds)non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]boxes=entry[\\'boxes\\'][non_gt_inds,:]ifboxes.shape[0]==0:continueiflimitisnotNoneandboxes.shape[0]>limit:boxes=boxes[:limit,:]overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))_gt_overlaps=np.zeros((gt_boxes.shape[0]))forjinrange(min(boxes.shape[0],gt_boxes.shape[0])):#findwhichproposalboxmaximallycoverseachgtboxargmax_overlaps=overlaps.argmax(axis=0)#andgettheiouamountofcoverageforeachgtboxmax_overlaps=overlaps.max(axis=0)#findwhichgtboxis\\'best\\'covered(i.e.\\'best\\'=mostiou)gt_ind=max_overlaps.argmax()gt_ovr=max_overlaps.max()assertgt_ovr>=0#findtheproposalboxthatcoversthebestcoveredgtboxbox_ind=argmax_overlaps[gt_ind]#recordtheioucoverageofthisgtbox_gt_overlaps[j]=overlaps[box_ind,gt_ind]assert_gt_overlaps[j]==gt_ovr#marktheproposalboxandthegtboxasusedoverlaps[box_ind,:]=-1overlaps[:,gt_ind]=-1#appendrecordedioucoveragelevelgt_overlaps=np.hstack((gt_overlaps,_gt_overlaps))ifthresholdsisNone:step=0.05thresholds=np.arange(0.5,0.95+1e-5,step)ifnotclass_specific:gt_overlaps=np.sort(gt_overlaps)recalls=np.zeros_like(thresholds)#computerecallforeachiouthresholdfori,tinenumerate(thresholds):recalls[i]=(gt_overlaps>=t).sum()/float(num_pos)ar=recalls.mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}else:gt_classes_unique=np.unique(gt_classes)recalls=np.zeros((gt_classes_unique.shape[0],thresholds.shape[0]))#computerecallforeachcategoryandeachiouthresholdfori,category_idinenumerate(gt_classes_unique):inds=(gt_classes==category_id)num_pos_per_category=float(inds.sum())forj,threshinenumerate(thresholds):recalls[i][j]=(gt_overlaps[inds]>=thresh).sum()/num_pos_per_categoryar=recalls.mean(axis=1).mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}defevaluate_keypoints(json_dataset,all_boxes,all_keypoints,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'keypoints_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_keypoint_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Keypoints\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file):results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_keypoints):breaklogger.info(\\'Collecting{}results({:d}/{:d})\\'.format(cls,cls_ind,len(all_keypoints)-1))cat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_kp_results_one_category(json_dataset,all_boxes[cls_ind],all_keypoints[cls_ind],cat_id))logger.info(\\'Writingkeypointresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_kp_results_one_category(json_dataset,boxes,kps,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(kps)==len(image_ids)assertlen(boxes)==len(image_ids)use_box_score=Falseifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'logit\\':#Thisisugly;seeutils.keypoints.heatmap_to_keypointsforthemagic#indexesscore_index=2elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'prob\\':score_index=3elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'bbox\\':use_box_score=Trueelse:raiseValueError(\\'KRCNN.KEYPOINT_CONFIDENCEmustbe\"logit\",\"prob\",or\"bbox\"\\')fori,image_idinenumerate(image_ids):iflen(boxes[i])==0:continuekps_dets=kps[i]scores=boxes[i][:,-1].astype(float)iflen(kps_dets)==0:continueforjinrange(len(kps_dets)):xy=[]kps_score=0forkinrange(kps_dets[j].shape[1]):xy.append(float(kps_dets[j][0,k]))xy.append(float(kps_dets[j][1,k]))xy.append(1)ifnotuse_box_score:kps_score+=kps_dets[j][score_index,k]ifuse_box_score:kps_score=scores[j]else:kps_score/=kps_dets[j].shape[1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'keypoints\\':xy,\\'score\\':kps_score}])returnresultsdef_do_keypoint_eval(json_dataset,res_file,output_dir):ann_type=\\'keypoints\\'imgIds=json_dataset.COCO.getImgIds()imgIds.sort()coco_dt=json_dataset.COCO.loadRes(res_file)coco_eval=COCOeval(json_dataset.COCO,coco_dt,ann_type)coco_eval.params.imgIds=imgIdscoco_eval.evaluate()coco_eval.accumulate()eval_file=os.path.join(output_dir,\\'keypoint_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))coco_eval.summarize()returncoco_eval#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Collectionofavailabledatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportos#Pathtodatadir_DATA_DIR=os.path.join(os.path.dirname(__file__),\\'data\\')#Requireddatasetentrykeys_IM_DIR=\\'image_directory\\'_ANN_FN=\\'annotation_file\\'#Optionaldatasetentrykeys_IM_PREFIX=\\'image_prefix\\'_DEVKIT_DIR=\\'devkit_directory\\'_RAW_DIR=\\'raw_dir\\'#Availabledatasets_DATASETS={\\'cityscapes_fine_instanceonly_seg_train\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_train.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_val\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',#usefilteredvalidationasthereisanissueconvertingcontours_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_filtered_gtFine_val.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_test\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_test.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_train2014.json\\'},\\'coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_val2014.json\\'},\\'coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_minival2014.json\\'},\\'coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_valminusminival2014.json\\'},\\'coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'coco_2017_test\\':{#2017testuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_2017_test-dev\\':{#2017test-devuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_stuff_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_train.json\\'},\\'coco_stuff_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_val.json\\'},\\'keypoints_coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_train2014.json\\'},\\'keypoints_coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_val2014.json\\'},\\'keypoints_coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_minival2014.json\\'},\\'keypoints_coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_valminusminival2014.json\\'},\\'keypoints_coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'keypoints_coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'voc_2007_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_test\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_test.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2012_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'},\\'voc_2012_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'}}defdatasets():\"\"\"Retrievethelistofavailabledatasetnames.\"\"\"return_DATASETS.keys()defcontains(name):\"\"\"Determineifthedatasetisinthecatalog.\"\"\"returnnamein_DATASETS.keys()defget_im_dir(name):\"\"\"Retrievetheimagedirectoryforthedataset.\"\"\"return_DATASETS[name][_IM_DIR]defget_ann_fn(name):\"\"\"Retrievetheannotationfileforthedataset.\"\"\"return_DATASETS[name][_ANN_FN]defget_im_prefix(name):\"\"\"Retrievetheimageprefixforthedataset.\"\"\"return_DATASETS[name][_IM_PREFIX]if_IM_PREFIXin_DATASETS[name]else\\'\\'defget_devkit_dir(name):\"\"\"Retrievethedevkitdirforthedataset.\"\"\"return_DATASETS[name][_DEVKIT_DIR]defget_raw_dir(name):\"\"\"Retrievetherawdirforthedataset.\"\"\"return_DATASETS[name][_RAW_DIR]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"PASCALVOCdatasetevaluationinterface.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimportuuidfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_devkit_dirfromdetectron.datasets.voc_evalimportvoc_evalfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=True,use_matlab=False):salt=\\'_{}\\'.format(str(uuid.uuid4()))ifuse_saltelse\\'\\'filenames=_write_voc_results_files(json_dataset,all_boxes,salt)_do_python_eval(json_dataset,salt,output_dir)ifuse_matlab:_do_matlab_eval(json_dataset,salt,output_dir)ifcleanup:forfilenameinfilenames:shutil.copy(filename,output_dir)os.remove(filename)returnNonedef_write_voc_results_files(json_dataset,all_boxes,salt):filenames=[]image_set_path=voc_info(json_dataset)[\\'image_set_path\\']assertos.path.exists(image_set_path),\\\\\\'Imagesetpathdoesnotexist:{}\\'.format(image_set_path)withopen(image_set_path,\\'r\\')asf:image_index=[x.strip()forxinf.readlines()]#Sanitycheckthatorderofimagesinjsondatasetmatchesorderinthe#imagesetroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):index=os.path.splitext(os.path.split(entry[\\'image\\'])[1])[0]assertindex==image_index[i]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuelogger.info(\\'WritingVOCresultsfor:{}\\'.format(cls))filename=_get_voc_results_file_template(json_dataset,salt).format(cls)filenames.append(filename)assertlen(all_boxes[cls_ind])==len(image_index)withopen(filename,\\'wt\\')asf:forim_ind,indexinenumerate(image_index):dets=all_boxes[cls_ind][im_ind]iftype(dets)==list:assertlen(dets)==0,\\\\\\'detsshouldbenumpy.ndarrayoremptylist\\'continue#theVOCdevkitexpects1-basedindicesforkinrange(dets.shape[0]):f.write(\\'{:s}{:.3f}{:.1f}{:.1f}{:.1f}{:.1f}\\\\n\\'.format(index,dets[k,-1],dets[k,0]+1,dets[k,1]+1,dets[k,2]+1,dets[k,3]+1))returnfilenamesdef_get_voc_results_file_template(json_dataset,salt):info=voc_info(json_dataset)year=info[\\'year\\']image_set=info[\\'image_set\\']devkit_path=info[\\'devkit_path\\']#VOCdevkit/results/VOC2007/Main/_det_test_aeroplane.txtfilename=\\'comp4\\'+salt+\\'_det_\\'+image_set+\\'_{:s}.txt\\'returnos.path.join(devkit_path,\\'results\\',\\'VOC\\'+year,\\'Main\\',filename)def_do_python_eval(json_dataset,salt,output_dir=\\'output\\'):info=voc_info(json_dataset)year=info[\\'year\\']anno_path=info[\\'anno_path\\']image_set_path=info[\\'image_set_path\\']devkit_path=info[\\'devkit_path\\']cachedir=os.path.join(devkit_path,\\'annotations_cache\\')aps=[]#ThePASCALVOCmetricchangedin2010use_07_metric=Trueifint(year)<2010elseFalselogger.info(\\'VOC07metric?\\'+(\\'Yes\\'ifuse_07_metricelse\\'No\\'))ifnotos.path.isdir(output_dir):os.mkdir(output_dir)for_,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuefilename=_get_voc_results_file_template(json_dataset,salt).format(cls)rec,prec,ap=voc_eval(filename,anno_path,image_set_path,cls,cachedir,ovthresh=0.5,use_07_metric=use_07_metric)aps+=[ap]logger.info(\\'APfor{}={:.4f}\\'.format(cls,ap))res_file=os.path.join(output_dir,cls+\\'_pr.pkl\\')save_object({\\'rec\\':rec,\\'prec\\':prec,\\'ap\\':ap},res_file)logger.info(\\'MeanAP={:.4f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'Results:\\')forapinaps:logger.info(\\'{:.3f}\\'.format(ap))logger.info(\\'{:.3f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'\\')logger.info(\\'----------------------------------------------------------\\')logger.info(\\'Resultscomputedwiththe**unofficial**Pythonevalcode.\\')logger.info(\\'ResultsshouldbeveryclosetotheofficialMATLABcode.\\')logger.info(\\'Use`./tools/reval.py--matlab...`foryourpaper.\\')logger.info(\\'--Thanks,TheManagement\\')logger.info(\\'----------------------------------------------------------\\')def_do_matlab_eval(json_dataset,salt,output_dir=\\'output\\'):importsubprocesslogger.info(\\'-----------------------------------------------------\\')logger.info(\\'ComputingresultswiththeofficialMATLABevalcode.\\')logger.info(\\'-----------------------------------------------------\\')info=voc_info(json_dataset)path=os.path.join(cfg.ROOT_DIR,\\'detectron\\',\\'datasets\\',\\'VOCdevkit-matlab-wrapper\\')cmd=\\'cd{}&&\\'.format(path)cmd+=\\'{:s}-nodisplay-nodesktop\\'.format(cfg.MATLAB)cmd+=\\'-r\"dbstopiferror;\\'cmd+=\\'voc_eval(\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\');quit;\"\\'\\\\.format(info[\\'devkit_path\\'],\\'comp4\\'+salt,info[\\'image_set\\'],output_dir)logger.info(\\'Running:\\\\n{}\\'.format(cmd))subprocess.call(cmd,shell=True)defvoc_info(json_dataset):year=json_dataset.name[4:8]image_set=json_dataset.name[9:]devkit_path=get_devkit_dir(json_dataset.name)assertos.path.exists(devkit_path),\\\\\\'Devkitdirectory{}notfound\\'.format(devkit_path)anno_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'Annotations\\',\\'{:s}.xml\\')image_set_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'ImageSets\\',\\'Main\\',image_set+\\'.txt\\')returndict(year=year,image_set=image_set,devkit_path=devkit_path,anno_path=anno_path,image_set_path=image_set_path)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################mappingcococategoriestocityscapes(ourconvertedjson)id#cityscapes#INFOroidb.py:220:1bicycle:7286#INFOroidb.py:220:2car:53684#INFOroidb.py:220:3person:35704#INFOroidb.py:220:4train:336#INFOroidb.py:220:5truck:964#INFOroidb.py:220:6motorcycle:1468#INFOroidb.py:220:7bus:758#INFOroidb.py:220:8rider:3504#coco(val5k)#INFOroidb.py:220:1person:21296#INFOroidb.py:220:2bicycle:628#INFOroidb.py:220:3car:3818#INFOroidb.py:220:4motorcycle:732#INFOroidb.py:220:5airplane:286<------irrelevant#INFOroidb.py:220:6bus:564#INFOroidb.py:220:7train:380#INFOroidb.py:220:8truck:828defcityscapes_to_coco(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(-1meansrandinit)}returnlookup[cityscapes_id]defcityscapes_to_coco_with_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:1,#rider(\"person\",*riderhashumanright!*)}returnlookup[cityscapes_id]defcityscapes_to_coco_without_person_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:-1,#person(ignore)4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]defcityscapes_to_coco_all_random(cityscapes_id):lookup={0:-1,#...background1:-1,#bicycle2:-1,#car3:-1,#person(ignore)4:-1,#train5:-1,#truck6:-1,#motorcycle7:-1,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforcommonroidbmanipulations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfrompast.builtinsimportbasestringimportloggingimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasets.json_datasetimportJsonDatasetimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.keypointsaskeypoint_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defcombined_roidb_for_training(dataset_names,proposal_files):\"\"\"Loadandconcatenateroidbsforoneormoredatasets,alongwithoptionalobjectproposals.Theroidbentriesarethenpreparedforuseintraining,whichinvolvescachingcertaintypesofmetadataforeachroidbentry.\"\"\"defget_roidb(dataset_name,proposal_file):ds=JsonDataset(dataset_name)roidb=ds.get_roidb(gt=True,proposal_file=proposal_file,crowd_filter_thresh=cfg.TRAIN.CROWD_FILTER_THRESH)ifcfg.TRAIN.USE_FLIPPED:logger.info(\\'Appendinghorizontally-flippedtrainingexamples...\\')extend_with_flipped_entries(roidb,ds)logger.info(\\'Loadeddataset:{:s}\\'.format(ds.name))returnroidbifisinstance(dataset_names,basestring):dataset_names=(dataset_names,)ifisinstance(proposal_files,basestring):proposal_files=(proposal_files,)iflen(proposal_files)==0:proposal_files=(None,)*len(dataset_names)assertlen(dataset_names)==len(proposal_files)roidbs=[get_roidb(*args)forargsinzip(dataset_names,proposal_files)]roidb=roidbs[0]forrinroidbs[1:]:roidb.extend(r)roidb=filter_for_training(roidb)logger.info(\\'Computingbounding-boxregressiontargets...\\')add_bbox_regression_targets(roidb)logger.info(\\'done\\')_compute_and_log_stats(roidb)returnroidbdefextend_with_flipped_entries(roidb,dataset):\"\"\"Flipeachentryinthegivenroidbandreturnanewroidbthatistheconcatenationoftheoriginalroidbandtheflippedentries.\"Flipping\"anentrymeansthatthatimageandassociatedmetadata(e.g.,groundtruthboxesandobjectproposals)arehorizontallyflipped.\"\"\"flipped_roidb=[]forentryinroidb:width=entry[\\'width\\']boxes=entry[\\'boxes\\'].copy()oldx1=boxes[:,0].copy()oldx2=boxes[:,2].copy()boxes[:,0]=width-oldx2-1boxes[:,2]=width-oldx1-1assert(boxes[:,2]>=boxes[:,0]).all()flipped_entry={}dont_copy=(\\'boxes\\',\\'segms\\',\\'gt_keypoints\\',\\'flipped\\')fork,vinentry.items():ifknotindont_copy:flipped_entry[k]=vflipped_entry[\\'boxes\\']=boxesflipped_entry[\\'segms\\']=segm_utils.flip_segms(entry[\\'segms\\'],entry[\\'height\\'],entry[\\'width\\'])ifdataset.keypointsisnotNone:flipped_entry[\\'gt_keypoints\\']=keypoint_utils.flip_keypoints(dataset.keypoints,dataset.keypoint_flip_map,entry[\\'gt_keypoints\\'],entry[\\'width\\'])flipped_entry[\\'flipped\\']=Trueflipped_roidb.append(flipped_entry)roidb.extend(flipped_roidb)deffilter_for_training(roidb):\"\"\"RemoveroidbentriesthathavenousableRoIsbasedonconfigsettings.\"\"\"defis_valid(entry):#Validimageshave:#(1)AtleastoneforegroundRoIOR#(2)AtleastonebackgroundRoIoverlaps=entry[\\'max_overlaps\\']#findboxeswithsufficientoverlapfg_inds=np.where(overlaps>=cfg.TRAIN.FG_THRESH)[0]#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((overlaps<cfg.TRAIN.BG_THRESH_HI)&(overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#imageisonlyvalidifsuchboxesexistvalid=len(fg_inds)>0orlen(bg_inds)>0ifcfg.MODEL.KEYPOINTS_ON:#Ifwe\\'retrainingforkeypoints,excludeimageswithnokeypointsvalid=validandentry[\\'has_visible_keypoints\\']returnvalidnum=len(roidb)filtered_roidb=[entryforentryinroidbifis_valid(entry)]num_after=len(filtered_roidb)logger.info(\\'Filtered{}roidbentries:{}->{}\\'.format(num-num_after,num,num_after))returnfiltered_roidbdefadd_bbox_regression_targets(roidb):\"\"\"Addinformationneededtotrainbounding-boxregressors.\"\"\"forentryinroidb:entry[\\'bbox_targets\\']=compute_bbox_regression_targets(entry)defcompute_bbox_regression_targets(entry):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"#Indicesofground-truthROIsrois=entry[\\'boxes\\']overlaps=entry[\\'max_overlaps\\']labels=entry[\\'max_classes\\']gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]#Targetshasformat(class,tx,ty,tw,th)targets=np.zeros((rois.shape[0],5),dtype=np.float32)iflen(gt_inds)==0:#Bailiftheimagehasnoground-truthROIsreturntargets#Indicesofexamplesforwhichwetrytomakepredictionsex_inds=np.where(overlaps>=cfg.TRAIN.BBOX_THRESH)[0]#GetIoUoverlapbetweeneachexROIandgtROIex_gt_overlaps=box_utils.bbox_overlaps(rois[ex_inds,:].astype(dtype=np.float32,copy=False),rois[gt_inds,:].astype(dtype=np.float32,copy=False))#FindwhichgtROIeachexROIhasmaxoverlapwith:#thiswillbetheexROI\\'sgttargetgt_assignment=ex_gt_overlaps.argmax(axis=1)gt_rois=rois[gt_inds[gt_assignment],:]ex_rois=rois[ex_inds,:]#Useclass\"1\"forallboxesifusingclass_agnostic_bbox_regtargets[ex_inds,0]=(1ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelselabels[ex_inds])targets[ex_inds,1:]=box_utils.bbox_transform_inv(ex_rois,gt_rois,cfg.MODEL.BBOX_REG_WEIGHTS)returntargetsdef_compute_and_log_stats(roidb):classes=roidb[0][\\'dataset\\'].classeschar_len=np.max([len(c)forcinclasses])hist_bins=np.arange(len(classes)+1)#Histogramofground-truthobjectsgt_hist=np.zeros((len(classes)),dtype=int)forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_classes=entry[\\'gt_classes\\'][gt_inds]gt_hist+=np.histogram(gt_classes,bins=hist_bins)[0]logger.debug(\\'Ground-truthclasshistogram:\\')fori,vinenumerate(gt_hist):logger.debug(\\'{:d}{:s}:{:d}\\'.format(i,classes[i].rjust(char_len),v))logger.debug(\\'-\\'*char_len)logger.debug(\\'{:s}:{:d}\\'.format(\\'total\\'.rjust(char_len),np.sum(gt_hist)))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Evaluationinterfaceforsupportedtasks(boxdetection,instancesegmentation,keypointdetection,...).ResultsarestoredinanOrderedDictwiththefollowingnestedstructure::::isanyvaliddataset(e.g.,\\'coco_2014_minival\\')isin[\\'box\\',\\'mask\\',\\'keypoint\\',\\'box_proposal\\']canbe[\\'AP\\',\\'AP50\\',\\'AP75\\',\\'APs\\',\\'APm\\',\\'APl\\',\\'\\',\\'\\',\\'\\',\\'\\',...]isafloatingpointnumber\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportosimportpprintfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportsend_emailimportdetectron.datasets.cityscapes_json_dataset_evaluator\\\\ascs_json_dataset_evaluatorimportdetectron.datasets.json_dataset_evaluatorasjson_dataset_evaluatorimportdetectron.datasets.voc_dataset_evaluatorasvoc_dataset_evaluatorlogger=logging.getLogger(__name__)defevaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir,use_matlab=False):\"\"\"Evaluate\"all\"tasks,where\"all\"includesboxdetection,instancesegmentation,andkeypointdetection.\"\"\"all_results=evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)logger.info(\\'Evaluatingboundingboxesisdone!\\')ifcfg.MODEL.MASK_ON:results=evaluate_masks(dataset,all_boxes,all_segms,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingsegmentationsisdone!\\')ifcfg.MODEL.KEYPOINTS_ON:results=evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingkeypointsisdone!\\')returnall_resultsdefevaluate_boxes(dataset,all_boxes,output_dir,use_matlab=False):\"\"\"Evaluateboundingboxdetection.\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_cityscapes_evaluator(dataset):logger.warn(\\'CityscapesbboxevaluatedusingCOCOmetrics/conversions\\')coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_voc_evaluator(dataset):#ForVOC,alwaysusesaltandalwayscleanupbecauseresultsare#writtentothesharedVOCdevkitresultsdirectoryvoc_eval=voc_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)box_results=_voc_eval_to_box_results(voc_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,box_results)])defevaluate_masks(dataset,all_boxes,all_segms,output_dir):\"\"\"Evaluateinstancesegmentation.\"\"\"logger.info(\\'Evaluatingsegmentations\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_coco_eval_to_mask_results(coco_eval)elif_use_cityscapes_evaluator(dataset):cs_eval=cs_json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_cs_eval_to_mask_results(cs_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,mask_results)])defevaluate_keypoints(dataset,all_boxes,all_keyps,output_dir):\"\"\"Evaluatehumankeypointdetection(i.e.,2Dposeestimation).\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEassertdataset.name.startswith(\\'keypoints_coco_\\'),\\\\\\'OnlyCOCOkeypointsarecurrentlysupported\\'coco_eval=json_dataset_evaluator.evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir,use_salt=not_comp,cleanup=not_comp)keypoint_results=_coco_eval_to_keypoint_results(coco_eval)returnOrderedDict([(dataset.name,keypoint_results)])defevaluate_box_proposals(dataset,roidb):\"\"\"Evaluateboundingboxobjectproposals.\"\"\"res=_empty_box_proposal_results()areas={\\'all\\':\\'\\',\\'small\\':\\'s\\',\\'medium\\':\\'m\\',\\'large\\':\\'l\\'}forlimitin[100,1000]:forarea,suffixinareas.items():stats=json_dataset_evaluator.evaluate_box_proposals(dataset,roidb,area=area,limit=limit,class_specific=cfg.TEST.CLASS_SPECIFIC_AR)key=\\'AR{}@{:d}\\'.format(suffix,limit)res[\\'box_proposal\\'][key]=stats[\\'ar\\']returnOrderedDict([(dataset.name,res)])deflog_box_proposal_results(results):\"\"\"Logboundingboxproposalresults.\"\"\"fordatasetinresults.keys():keys=results[dataset][\\'box_proposal\\'].keys()pad=max([len(k)forkinkeys])logger.info(dataset)fork,vinresults[dataset][\\'box_proposal\\'].items():logger.info(\\'{}:{:.3f}\\'.format(k.ljust(pad),v))deflog_copy_paste_friendly_results(results):\"\"\"Logresultsinaformatthatmakesiteasytocopy-and-pasteinaspreadsheet.Linesareprefixedwith\\'copypaste:\\'tomakegreppingeasy.\"\"\"fordatasetinresults.keys():logger.info(\\'copypaste:Dataset:{}\\'.format(dataset))fortask,metricsinresults[dataset].items():logger.info(\\'copypaste:Task:{}\\'.format(task))metric_names=metrics.keys()metric_vals=[\\'{:.4f}\\'.format(v)forvinmetrics.values()]logger.info(\\'copypaste:\\'+\\',\\'.join(metric_names))logger.info(\\'copypaste:\\'+\\',\\'.join(metric_vals))defcheck_expected_results(results,atol=0.005,rtol=0.1):\"\"\"Checkactualresultsagainstexpectedresultsstoredincfg.EXPECTED_RESULTS.Optionallyemailifthematchexceedsthespecifiedtolerance.Expectedresultsshouldtaketheformofalistofexpectations,eachspecifiedbyfourelements:[dataset,task,metric,expectedvalue].Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387],...].Theexpectedvaluemayalsobeformattedasalist[mean,std]providinganempiricalmeanandstandarddeviationfromwhichavalidrangeiscomputedusingcfg.EXPECTED_RESULTS_SIGMA_TOL.Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',[0.387,0.001]],...]\"\"\"#cfgcontainsareferencesetofresultsthatwewanttocheckagainstiflen(cfg.EXPECTED_RESULTS)==0:returnfordataset,task,metric,expected_valincfg.EXPECTED_RESULTS:assertdatasetinresults,\\'Dataset{}notinresults\\'.format(dataset)asserttaskinresults[dataset],\\'Task{}notinresults\\'.format(task)assertmetricinresults[dataset][task],\\\\\\'Metric{}notinresults\\'.format(metric)actual_val=results[dataset][task][metric]ok=Falseifisinstance(expected_val,list):assertlen(expected_val)==2,(\\'Expectedresultmustbein(mean,std)format\\')mean,std=expected_vallo=mean-cfg.EXPECTED_RESULTS_SIGMA_TOL*stdhi=mean+cfg.EXPECTED_RESULTS_SIGMA_TOL*stdok=(lo<actual_val)and(actual_val<hi)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.mean={:.4f},std={:.4},range=({:.4f},{:.4f})\\').format(dataset,task,metric,actual_val,mean,std,lo,hi)else:err=abs(actual_val-expected_val)tol=atol+rtol*abs(expected_val)ok=(err>tol)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.{:.3f},err={:.3f},tol={:.3f}\\').format(dataset,task,metric,actual_val,expected_val,err,tol)ifnotok:msg=\\'FAIL:\\'+msglogger.error(msg)ifcfg.EXPECTED_RESULTS_EMAIL!=\\'\\':subject=\\'Detectronend-to-endtestfailure\\'job_name=os.environ[\\'DETECTRON_JOB_NAME\\']if\\'DETECTRON_JOB_NAME\\'inos.environelse\\'\\'job_id=os.environ[\\'WORKFLOW_RUN_ID\\']if\\'WORKFLOW_RUN_ID\\'inos.environelse\\'\\'body=[\\'Name:\\',job_name,\\'RunID:\\',job_id,\\'Failure:\\',msg,\\'Config:\\',pprint.pformat(cfg),\\'Env:\\',pprint.pformat(dict(os.environ)),]send_email(subject,\\'\\\\n\\\\n\\'.join(body),cfg.EXPECTED_RESULTS_EMAIL)else:msg=\\'PASS:\\'+msglogger.info(msg)def_use_json_dataset_evaluator(dataset):\"\"\"Checkifthedatasetusesthegeneraljsondatasetevaluator.\"\"\"returndataset.name.find(\\'coco_\\')>-1orcfg.TEST.FORCE_JSON_DATASET_EVALdef_use_cityscapes_evaluator(dataset):\"\"\"CheckifthedatasetusestheCityscapesdatasetevaluator.\"\"\"returndataset.name.find(\\'cityscapes_\\')>-1def_use_voc_evaluator(dataset):\"\"\"CheckifthedatasetusesthePASCALVOCdatasetevaluator.\"\"\"returndataset.name[:4]==\\'voc_\\'#IndicesinthestatsarrayforCOCOboxesandmasksCOCO_AP=0COCO_AP50=1COCO_AP75=2COCO_APS=3COCO_APM=4COCO_APL=5#SlightdifferenceforkeypointsCOCO_KPS_APM=3COCO_KPS_APL=4#----------------------------------------------------------------------------##Helperfunctionsforproducingproperlyformattedresults.#----------------------------------------------------------------------------#def_coco_eval_to_box_results(coco_eval):res=_empty_box_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'box\\'][\\'AP\\']=s[COCO_AP]res[\\'box\\'][\\'AP50\\']=s[COCO_AP50]res[\\'box\\'][\\'AP75\\']=s[COCO_AP75]res[\\'box\\'][\\'APs\\']=s[COCO_APS]res[\\'box\\'][\\'APm\\']=s[COCO_APM]res[\\'box\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_mask_results(coco_eval):res=_empty_mask_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'mask\\'][\\'AP\\']=s[COCO_AP]res[\\'mask\\'][\\'AP50\\']=s[COCO_AP50]res[\\'mask\\'][\\'AP75\\']=s[COCO_AP75]res[\\'mask\\'][\\'APs\\']=s[COCO_APS]res[\\'mask\\'][\\'APm\\']=s[COCO_APM]res[\\'mask\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_keypoint_results(coco_eval):res=_empty_keypoint_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'keypoint\\'][\\'AP\\']=s[COCO_AP]res[\\'keypoint\\'][\\'AP50\\']=s[COCO_AP50]res[\\'keypoint\\'][\\'AP75\\']=s[COCO_AP75]res[\\'keypoint\\'][\\'APm\\']=s[COCO_KPS_APM]res[\\'keypoint\\'][\\'APl\\']=s[COCO_KPS_APL]returnresdef_voc_eval_to_box_results(voc_eval):#Notsupported(returnemptyresults)return_empty_box_results()def_cs_eval_to_mask_results(cs_eval):#Notsupported(returnemptyresults)return_empty_mask_results()def_empty_box_results():returnOrderedDict({\\'box\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_mask_results():returnOrderedDict({\\'mask\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_keypoint_results():returnOrderedDict({\\'keypoint\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_box_proposal_results():returnOrderedDict({\\'box_proposal\\':OrderedDict([(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),])})#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforevaluatingresultsonCityscapes.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportosimportuuidimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_raw_dirlogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):ifcfg.CLUSTER.ON_CLUSTER:#Ontheclusteravoidsavingthesefilesinthejobdirectoryoutput_dir=\\'/tmp\\'res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'results_dir=os.path.join(output_dir,\\'results\\')ifnotos.path.exists(results_dir):os.mkdir(results_dir)os.environ[\\'CITYSCAPES_DATASET\\']=get_raw_dir(json_dataset.name)os.environ[\\'CITYSCAPES_RESULTS\\']=output_dir#LoadtheCityscapesevalscript*after*settingtherequiredenvvars,#sincethescriptreadstheirvaluesintoglobalvariables(atloadtime).importcityscapesscripts.evaluation.evalInstanceLevelSemanticLabeling\\\\ascityscapes_evalroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):im_name=entry[\\'image\\']basename=os.path.splitext(os.path.basename(im_name))[0]txtname=os.path.join(output_dir,basename+\\'pred.txt\\')withopen(txtname,\\'w\\')asfid_txt:ifi%10==0:logger.info(\\'i:{}:{}\\'.format(i,basename))forjinrange(1,len(all_segms)):clss=json_dataset.classes[j]clss_id=cityscapes_eval.name2label[clss].idsegms=all_segms[j][i]boxes=all_boxes[j][i]ifsegms==[]:continuemasks=mask_util.decode(segms)forkinrange(boxes.shape[0]):score=boxes[k,-1]mask=masks[:,:,k]pngname=os.path.join(\\'results\\',basename+\\'_\\'+clss+\\'_{}.png\\'.format(k))#writetxtfid_txt.write(\\'{}{}{}\\\\n\\'.format(pngname,clss_id,score))#savemaskcv2.imwrite(os.path.join(output_dir,pngname),mask*255)logger.info(\\'Evaluating...\\')cityscapes_eval.main([])returnNone#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Providestubobjectsthatcanactasstand-in\"dummy\"datasetsforsimpleusecases,likegettingallclassesinadataset.Thisexistssothatdemoscanberunwithoutrequiringuserstodownload/installdatasetsfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.utils.collectionsimportAttrDictdefget_coco_dataset():\"\"\"AdummyCOCOdatasetthatincludesonlythe\\'classes\\'field.\"\"\"ds=AttrDict()classes=[\\'__background__\\',\\'person\\',\\'bicycle\\',\\'car\\',\\'motorcycle\\',\\'airplane\\',\\'bus\\',\\'train\\',\\'truck\\',\\'boat\\',\\'trafficlight\\',\\'firehydrant\\',\\'stopsign\\',\\'parkingmeter\\',\\'bench\\',\\'bird\\',\\'cat\\',\\'dog\\',\\'horse\\',\\'sheep\\',\\'cow\\',\\'elephant\\',\\'bear\\',\\'zebra\\',\\'giraffe\\',\\'backpack\\',\\'umbrella\\',\\'handbag\\',\\'tie\\',\\'suitcase\\',\\'frisbee\\',\\'skis\\',\\'snowboard\\',\\'sportsball\\',\\'kite\\',\\'baseballbat\\',\\'baseballglove\\',\\'skateboard\\',\\'surfboard\\',\\'tennisracket\\',\\'bottle\\',\\'wineglass\\',\\'cup\\',\\'fork\\',\\'knife\\',\\'spoon\\',\\'bowl\\',\\'banana\\',\\'apple\\',\\'sandwich\\',\\'orange\\',\\'broccoli\\',\\'carrot\\',\\'hotdog\\',\\'pizza\\',\\'donut\\',\\'cake\\',\\'chair\\',\\'couch\\',\\'pottedplant\\',\\'bed\\',\\'diningtable\\',\\'toilet\\',\\'tv\\',\\'laptop\\',\\'mouse\\',\\'remote\\',\\'keyboard\\',\\'cellphone\\',\\'microwave\\',\\'oven\\',\\'toaster\\',\\'sink\\',\\'refrigerator\\',\\'book\\',\\'clock\\',\\'vase\\',\\'scissors\\',\\'teddybear\\',\\'hairdrier\\',\\'toothbrush\\']ds.classes={i:namefori,nameinenumerate(classes)}returnds#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RepresentationofthestandardCOCOjsondatasetformat.Whenworkingwithanewdataset,westronglysuggesttoconvertthedatasetintotheCOCOjsonformatandusetheexistingcode;itisnotrecommendedtowritecodetosupportnewdatasetformats.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportloggingimportnumpyasnpimportosimportscipy.sparse#MusthappenbeforeimportingCOCOAPI(whichimportsmatplotlib)importdetectron.utils.envasenvuenvu.set_up_matplotlib()#COCOAPIfrompycocotoolsimportmaskasCOCOmaskfrompycocotools.cocoimportCOCOfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.datasets.dataset_catalogasdataset_catalogimportdetectron.utils.boxesasbox_utilsfromdetectron.utils.ioimportload_objectimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)classJsonDataset:\"\"\"AclassrepresentingaCOCOjsondataset.\"\"\"def__init__(self,name):assertdataset_catalog.contains(name),\\\\\\'Unknowndatasetname:{}\\'.format(name)assertos.path.exists(dataset_catalog.get_im_dir(name)),\\\\\\'Imdir\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_im_dir(name))assertos.path.exists(dataset_catalog.get_ann_fn(name)),\\\\\\'Annfn\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_ann_fn(name))logger.debug(\\'Creating:{}\\'.format(name))self.name=nameself.image_directory=dataset_catalog.get_im_dir(name)self.image_prefix=dataset_catalog.get_im_prefix(name)self.COCO=COCO(dataset_catalog.get_ann_fn(name))self.debug_timer=Timer()#Setupdatasetclassescategory_ids=self.COCO.getCatIds()categories=[c[\\'name\\']forcinself.COCO.loadCats(category_ids)]self.category_to_id_map=dict(zip(categories,category_ids))self.classes=[\\'__background__\\']+categoriesself.num_classes=len(self.classes)self.json_category_id_to_contiguous_id={v:i+1fori,vinenumerate(self.COCO.getCatIds())}self.contiguous_category_id_to_json_id={v:kfork,vinself.json_category_id_to_contiguous_id.items()}self._init_keypoints()defget_roidb(self,gt=False,proposal_file=None,min_proposal_size=2,proposal_limit=-1,crowd_filter_thresh=0):\"\"\"Returnanroidbcorrespondingtothejsondataset.Optionally:-includegroundtruthboxesintheroidb-addproposalsspecifiedinaproposalsfile-filterproposalsbasedonaminimumsidelength-filterproposalsthatintersectwithcrowdregions\"\"\"assertgtisTrueorcrowd_filter_thresh==0,\\\\\\'Crowdfilterthresholdmustbe0ifground-truthannotations\\'\\\\\\'arenotincluded.\\'image_ids=self.COCO.getImgIds()image_ids.sort()roidb=copy.deepcopy(self.COCO.loadImgs(image_ids))forentryinroidb:self._prep_roidb_entry(entry)ifgt:#Includeground-truthobjectannotationsself.debug_timer.tic()forentryinroidb:self._add_gt_annotations(entry)logger.debug(\\'_add_gt_annotationstook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))ifproposal_fileisnotNone:#Includeproposalsfromafileself.debug_timer.tic()self._add_proposals_from_file(roidb,proposal_file,min_proposal_size,proposal_limit,crowd_filter_thresh)logger.debug(\\'_add_proposals_from_filetook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))_add_class_assignments(roidb)returnroidbdef_prep_roidb_entry(self,entry):\"\"\"Addsemptymetadatafieldstoanroidbentry.\"\"\"#Referencebacktotheparentdatasetentry[\\'dataset\\']=self#Makefile_nameanabspathim_path=os.path.join(self.image_directory,self.image_prefix+entry[\\'file_name\\'])assertos.path.exists(im_path),\\'Image\\\\\\'{}\\\\\\'notfound\\'.format(im_path)entry[\\'image\\']=im_pathentry[\\'flipped\\']=Falseentry[\\'has_visible_keypoints\\']=False#Emptyplaceholdersentry[\\'boxes\\']=np.empty((0,4),dtype=np.float32)entry[\\'segms\\']=[]entry[\\'gt_classes\\']=np.empty((0),dtype=np.int32)entry[\\'seg_areas\\']=np.empty((0),dtype=np.float32)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(np.empty((0,self.num_classes),dtype=np.float32))entry[\\'is_crowd\\']=np.empty((0),dtype=bool)#\\'box_to_gt_ind_map\\':Shapeis(#rois).Mapsfromeachroitotheindex#inthelistofroisthatsatisfynp.where(entry[\\'gt_classes\\']>0)entry[\\'box_to_gt_ind_map\\']=np.empty((0),dtype=np.int32)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.empty((0,3,self.num_keypoints),dtype=np.int32)#Removeunwantedfieldsthatcomefromthejsonfile(iftheyexist)forkin[\\'date_captured\\',\\'url\\',\\'license\\',\\'file_name\\']:ifkinentry:delentry[k]def_add_gt_annotations(self,entry):\"\"\"Addgroundtruthannotationmetadatatoanroidbentry.\"\"\"ann_ids=self.COCO.getAnnIds(imgIds=entry[\\'id\\'],iscrowd=None)objs=self.COCO.loadAnns(ann_ids)#Sanitizebboxes--someareinvalidvalid_objs=[]valid_segms=[]width=entry[\\'width\\']height=entry[\\'height\\']forobjinobjs:#crowdregionsareRLEencodedifsegm_utils.is_poly(obj[\\'segmentation\\']):#Validpolygonshave>=3points,sorequire>=6coordinatesobj[\\'segmentation\\']=[pforpinobj[\\'segmentation\\']iflen(p)>=6]ifobj[\\'area\\']<cfg.TRAIN.GT_MIN_AREA:continueif\\'ignore\\'inobjandobj[\\'ignore\\']==1:continue#Convertform(x1,y1,w,h)to(x1,y1,x2,y2)x1,y1,x2,y2=box_utils.xywh_to_xyxy(obj[\\'bbox\\'])x1,y1,x2,y2=box_utils.clip_xyxy_to_image(x1,y1,x2,y2,height,width)#Requirenon-zerosegareaandmorethan1x1boxsizeifobj[\\'area\\']>0andx2>x1andy2>y1:obj[\\'clean_bbox\\']=[x1,y1,x2,y2]valid_objs.append(obj)valid_segms.append(obj[\\'segmentation\\'])num_valid_objs=len(valid_objs)boxes=np.zeros((num_valid_objs,4),dtype=entry[\\'boxes\\'].dtype)gt_classes=np.zeros((num_valid_objs),dtype=entry[\\'gt_classes\\'].dtype)gt_overlaps=np.zeros((num_valid_objs,self.num_classes),dtype=entry[\\'gt_overlaps\\'].dtype)seg_areas=np.zeros((num_valid_objs),dtype=entry[\\'seg_areas\\'].dtype)is_crowd=np.zeros((num_valid_objs),dtype=entry[\\'is_crowd\\'].dtype)box_to_gt_ind_map=np.zeros((num_valid_objs),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)ifself.keypointsisnotNone:gt_keypoints=np.zeros((num_valid_objs,3,self.num_keypoints),dtype=entry[\\'gt_keypoints\\'].dtype)im_has_visible_keypoints=Falseforix,objinenumerate(valid_objs):cls=self.json_category_id_to_contiguous_id[obj[\\'category_id\\']]boxes[ix,:]=obj[\\'clean_bbox\\']gt_classes[ix]=clsseg_areas[ix]=obj[\\'area\\']is_crowd[ix]=obj[\\'iscrowd\\']box_to_gt_ind_map[ix]=ixifself.keypointsisnotNone:gt_keypoints[ix,:,:]=self._get_gt_keypoints(obj)ifnp.sum(gt_keypoints[ix,2,:])>0:im_has_visible_keypoints=Trueifobj[\\'iscrowd\\']:#Setoverlapto-1forallclassesforcrowdobjects#sotheywillbeexcludedduringtraininggt_overlaps[ix,:]=-1.0else:gt_overlaps[ix,cls]=1.0entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes,axis=0)entry[\\'segms\\'].extend(valid_segms)#Tomatchtheoriginalimplementation:#entry[\\'boxes\\']=np.append(#entry[\\'boxes\\'],boxes.astype(int).astype(float),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],gt_classes)entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],seg_areas)entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],is_crowd)entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.append(entry[\\'gt_keypoints\\'],gt_keypoints,axis=0)entry[\\'has_visible_keypoints\\']=im_has_visible_keypointsdef_add_proposals_from_file(self,roidb,proposal_file,min_proposal_size,top_k,crowd_thresh):\"\"\"Addproposalsfromaproposalsfiletoanroidb.\"\"\"logger.info(\\'Loadingproposalsfrom:{}\\'.format(proposal_file))proposals=load_object(proposal_file)id_field=\\'indexes\\'if\\'indexes\\'inproposalselse\\'ids\\'#compatfix_remove_proposals_not_in_roidb(proposals,roidb,id_field)_sort_proposals(proposals,id_field)box_list=[]fori,entryinenumerate(roidb):ifi%2500==0:logger.info(\\'{:d}/{:d}\\'.format(i+1,len(roidb)))boxes=proposals[\\'boxes\\'][i]#Sanitycheckthattheseboxesareforthecorrectimageidassertentry[\\'id\\']==proposals[id_field][i]#Removeduplicateboxesandverysmallboxesandthentaketopkboxes=box_utils.clip_boxes_to_image(boxes,entry[\\'height\\'],entry[\\'width\\'])keep=box_utils.unique_boxes(boxes)boxes=boxes[keep,:]keep=box_utils.filter_small_boxes(boxes,min_proposal_size)boxes=boxes[keep,:]iftop_k>0:boxes=boxes[:top_k,:]box_list.append(boxes)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)def_init_keypoints(self):\"\"\"InitializeCOCOkeypointinformation.\"\"\"self.keypoints=Noneself.keypoint_flip_map=Noneself.keypoints_to_id_map=Noneself.num_keypoints=0#Thusfaronlythe\\'person\\'categoryhaskeypointsif\\'person\\'inself.category_to_id_map:cat_info=self.COCO.loadCats([self.category_to_id_map[\\'person\\']])else:return#Checkiftheannotationscontainkeypointdataornotif\\'keypoints\\'incat_info[0]:keypoints=cat_info[0][\\'keypoints\\']self.keypoints_to_id_map=dict(zip(keypoints,range(len(keypoints))))self.keypoints=keypointsself.num_keypoints=len(keypoints)self.keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}def_get_gt_keypoints(self,obj):\"\"\"Returngroundtruthkeypoints.\"\"\"if\\'keypoints\\'notinobj:returnNonekp=np.array(obj[\\'keypoints\\'])x=kp[0::3]#0-indexedxcoordinatesy=kp[1::3]#0-indexedycoordinates#0:notlabeled;1:labeled,notinsidemask;#2:labeledandinsidemaskv=kp[2::3]num_keypoints=len(obj[\\'keypoints\\'])/3assertnum_keypoints==self.num_keypointsgt_kps=np.ones((3,self.num_keypoints),dtype=np.int32)foriinrange(self.num_keypoints):gt_kps[0,i]=x[i]gt_kps[1,i]=y[i]gt_kps[2,i]=v[i]returngt_kpsdefadd_proposals(roidb,rois,scales,crowd_thresh):\"\"\"Addproposalboxes(rois)toanroidbthathasground-truthannotationsbutnoproposals.Iftheproposalsarenotattheoriginalimagescale,specifythescalefactorthatseparatetheminscales.\"\"\"box_list=[]foriinrange(len(roidb)):inv_im_scale=1./scales[i]idx=np.where(rois[:,0]==i)[0]box_list.append(rois[idx,1:]*inv_im_scale)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)_add_class_assignments(roidb)def_merge_proposal_boxes_into_roidb(roidb,box_list):\"\"\"Addproposalboxestoeachroidbentry.\"\"\"assertlen(box_list)==len(roidb)fori,entryinenumerate(roidb):boxes=box_list[i]num_boxes=boxes.shape[0]gt_overlaps=np.zeros((num_boxes,entry[\\'gt_overlaps\\'].shape[1]),dtype=entry[\\'gt_overlaps\\'].dtype)box_to_gt_ind_map=-np.ones((num_boxes),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)#Note:unlikeinotherplaces,hereweintentionallyincludeallgt#rois,evenonesmarkedascrowd.Boxesthatoverlapwithcrowdswill#befilteredoutlater(see:_filter_crowd_proposals).gt_inds=np.where(entry[\\'gt_classes\\']>0)[0]iflen(gt_inds)>0:gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_classes=entry[\\'gt_classes\\'][gt_inds]proposal_to_gt_overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))#Gtboxthatoverlapseachinputboxthemost#(tiesarebrokenarbitrarilybyclassorder)argmaxes=proposal_to_gt_overlaps.argmax(axis=1)#Amountofthatoverlapmaxes=proposal_to_gt_overlaps.max(axis=1)#Thoseboxeswithnon-zerooverlapwithgtboxesI=np.where(maxes>0)[0]#Recordmaxoverlapswiththeclassoftheappropriategtboxgt_overlaps[I,gt_classes[argmaxes[I]]]=maxes[I]box_to_gt_ind_map[I]=gt_inds[argmaxes[I]]entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes.astype(entry[\\'boxes\\'].dtype,copy=False),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],np.zeros((num_boxes),dtype=entry[\\'gt_classes\\'].dtype))entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],np.zeros((num_boxes),dtype=entry[\\'seg_areas\\'].dtype))entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],np.zeros((num_boxes),dtype=entry[\\'is_crowd\\'].dtype))entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map.astype(entry[\\'box_to_gt_ind_map\\'].dtype,copy=False))def_filter_crowd_proposals(roidb,crowd_thresh):\"\"\"Findsproposalsthatareinsidecrowdregionsandmarksthemasoverlap=-1witheachground-truthrois,whichmeanstheywillbeexcludedfromtraining.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()crowd_inds=np.where(entry[\\'is_crowd\\']==1)[0]non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]iflen(crowd_inds)==0orlen(non_gt_inds)==0:continuecrowd_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][crowd_inds,:])non_gt_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][non_gt_inds,:])iscrowd_flags=[int(True)]*len(crowd_inds)ious=COCOmask.iou(non_gt_boxes,crowd_boxes,iscrowd_flags)bad_inds=np.where(ious.max(axis=1)>crowd_thresh)[0]gt_overlaps[non_gt_inds[bad_inds],:]=-1entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(gt_overlaps)def_add_class_assignments(roidb):\"\"\"Computeobjectcategoryassignmentforeachboxassociatedwitheachroidbentry.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()#maxoverlapwithgtoverclasses(columns)max_overlaps=gt_overlaps.max(axis=1)#gtclassthathadthemaxoverlapmax_classes=gt_overlaps.argmax(axis=1)entry[\\'max_classes\\']=max_classesentry[\\'max_overlaps\\']=max_overlaps#sanitychecks#ifmaxoverlapis0,theclassmustbebackground(class0)zero_inds=np.where(max_overlaps==0)[0]assertall(max_classes[zero_inds]==0)#ifmaxoverlap>0,theclassmustbeafgclass(notclass0)nonzero_inds=np.where(max_overlaps>0)[0]assertall(max_classes[nonzero_inds]!=0)def_sort_proposals(proposals,id_field):\"\"\"Sortproposalsbythespecifiedidfield.\"\"\"order=np.argsort(proposals[id_field])fields_to_sort=[\\'boxes\\',id_field,\\'scores\\']forkinfields_to_sort:proposals[k]=[proposals[k][i]foriinorder]def_remove_proposals_not_in_roidb(proposals,roidb,id_field):#fixproposalssotheydon\\'tcontainentriesforimagesnotintheroidbroidb_ids=set({entry[\"id\"]forentryinroidb})keep=[ifori,idinenumerate(proposals[id_field])ifidinroidb_ids]forfin[\\'boxes\\',id_field,\\'scores\\']:proposals[f]=[proposals[f][i]foriinkeep]#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.Allowsforusingacombinationofmultiplemodels.Forexample,onemodelmaybeusedforRPN,anothermodelforFastR-CNNstyleboxdetection,yetanothermodeltopredictmasks,andyetanothermodeltopredictkeypoints.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportosimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.core.configimportmerge_cfg_from_cfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.rpn_generatorasrpn_engineimportdetectron.core.test_engineasmodel_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)#infer.py#--im[path/to/image.jpg]\\\\#--rpn-model[path/to/rpn/model.pkl]\\\\#--rpn-cfg[path/to/rpn/config.yaml]\\\\#--output-dir[path/to/output/dir]\\\\#[model1][config1][model2][config2]...defparse_args():parser=argparse.ArgumentParser(description=\\'Inferenceonanimage\\')parser.add_argument(\\'--im\\',dest=\\'im_file\\',help=\\'inputimage\\',default=None,type=str)parser.add_argument(\\'--rpn-pkl\\',dest=\\'rpn_pkl\\',help=\\'rpnmodelfile(pkl)\\',default=None,type=str)parser.add_argument(\\'--rpn-cfg\\',dest=\\'rpn_cfg\\',help=\\'cfgmodelfile(yaml)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer)\\',default=\\'/tmp/infer\\',type=str)parser.add_argument(\\'models_to_run\\',help=\\'pairsofmodels&configs,listedlikeso:[pkl1][yaml1][pkl2][yaml2]...\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defget_rpn_box_proposals(im,args):cfg.immutable(False)merge_cfg_from_file(args.rpn_cfg)cfg.NUM_GPUS=1cfg.MODEL.RPN_ONLY=Truecfg.TEST.RPN_PRE_NMS_TOP_N=10000cfg.TEST.RPN_POST_NMS_TOP_N=2000assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(args.rpn_pkl)withc2_utils.NamedCudaScope(0):boxes,scores=rpn_engine.im_proposals(model,im)returnboxes,scoresdefmain(args):logger=logging.getLogger(__name__)dummy_coco_dataset=dummy_datasets.get_coco_dataset()cfg_orig=load_cfg(envu.yaml_dump(cfg))im=cv2.imread(args.im_file)ifargs.rpn_pklisnotNone:proposal_boxes,_proposal_scores=get_rpn_box_proposals(im,args)workspace.ResetWorkspace()else:proposal_boxes=Nonecls_boxes,cls_segms,cls_keyps=None,None,Noneforiinrange(0,len(args.models_to_run),2):pkl=args.models_to_run[i]yml=args.models_to_run[i+1]cfg.immutable(False)merge_cfg_from_cfg(cfg_orig)merge_cfg_from_file(yml)iflen(pkl)>0:weights_file=pklelse:weights_file=cfg.TEST.WEIGHTScfg.NUM_GPUS=1assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(weights_file)withc2_utils.NamedCudaScope(0):cls_boxes_,cls_segms_,cls_keyps_=\\\\model_engine.im_detect_all(model,im,proposal_boxes)cls_boxes=cls_boxes_ifcls_boxes_isnotNoneelsecls_boxescls_segms=cls_segms_ifcls_segms_isnotNoneelsecls_segmscls_keyps=cls_keyps_ifcls_keyps_isnotNoneelsecls_keypsworkspace.ResetWorkspace()out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(args.im_file)+\\'.pdf\\'))logger.info(\\'Processing{}->{}\\'.format(args.im_file,out_name))vis_utils.vis_one_image(im[:,:,::-1],args.im_file,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=0.7,kp_thresh=2)defcheck_args(args):assert((args.rpn_pklisnotNoneandargs.rpn_cfgisnotNone)or(args.rpn_pklisNoneandargs.rpn_cfgisNone))ifargs.rpn_pklisnotNone:args.rpn_pkl=cache_url(args.rpn_pkl,cfg.DOWNLOAD_CACHE)assertos.path.exists(args.rpn_pkl)assertos.path.exists(args.rpn_cfg)ifargs.models_to_runisnotNone:assertlen(args.models_to_run)%2==0fori,model_fileinenumerate(args.models_to_run):iflen(model_file)>0:ifi%2==0:model_file=cache_url(model_file,cfg.DOWNLOAD_CACHE)args.models_to_run[i]=model_fileassertos.path.exists(model_file),\\\\\\'\\\\\\'{}\\\\\\'doesnotexist\\'.format(model_file)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()check_args(args)main(args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceononeormoredatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importosimportpprintimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TestaFastR-CNNnetwork\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--wait\\',dest=\\'wait\\',help=\\'waituntilnetfileexists\\',default=True,type=bool)parser.add_argument(\\'--vis\\',dest=\\'vis\\',help=\\'visualizedetections\\',action=\\'store_true\\')parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'usingcfg.NUM_GPUSforinference\\',action=\\'store_true\\')parser.add_argument(\\'--range\\',dest=\\'range\\',help=\\'start(inclusive)andend(exclusive)indices\\',default=None,type=int,nargs=2)parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Testingwithconfig:\\')logger.info(pprint.pformat(cfg))whilenotos.path.exists(cfg.TEST.WEIGHTS)andargs.wait:logger.info(\\'Waitingfor\\\\\\'{}\\\\\\'toexist...\\'.format(cfg.TEST.WEIGHTS))time.sleep(10)run_inference(cfg.TEST.WEIGHTS,ind_range=args.range,multi_gpu_testing=args.multi_gpu_testing,check_expected_results=True,)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scriptforvisualizingresultssavedinadetections.pklfile.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2importosimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectimportdetectron.utils.visasvis_utils#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--dataset\\',dest=\\'dataset\\',help=\\'dataset\\',default=\\'coco_2014_minival\\',type=str)parser.add_argument(\\'--detections\\',dest=\\'detections\\',help=\\'detectionspklfile\\',default=\\'\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'detectionprobthreshold\\',default=0.9,type=float)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'./tmp/vis-output\\',type=str)parser.add_argument(\\'--first\\',dest=\\'first\\',help=\\'onlyvisualizethefirstkimages\\',default=0,type=int)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefvis(dataset,detections_pkl,thresh,output_dir,limit=0):ds=JsonDataset(dataset)roidb=ds.get_roidb()dets=load_object(detections_pkl)assertall(kindetsforkin[\\'all_boxes\\',\\'all_segms\\',\\'all_keyps\\']),\\\\\\'Expecteddetectionspklfileintheformatusedbytest_engine.py\\'all_boxes=dets[\\'all_boxes\\']all_segms=dets[\\'all_segms\\']all_keyps=dets[\\'all_keyps\\']defid_or_index(ix,val):iflen(val)==0:returnvalelse:returnval[ix]forix,entryinenumerate(roidb):iflimit>0andix>=limit:breakifix%10==0:print(\\'{:d}/{:d}\\'.format(ix+1,len(roidb)))im=cv2.imread(entry[\\'image\\'])im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]cls_boxes_i=[id_or_index(ix,cls_k_boxes)forcls_k_boxesinall_boxes]cls_segms_i=[id_or_index(ix,cls_k_segms)forcls_k_segmsinall_segms]cls_keyps_i=[id_or_index(ix,cls_k_keyps)forcls_k_keypsinall_keyps]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(ix,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=thresh,box_alpha=0.8,dataset=ds,show_class=True)if__name__==\\'__main__\\':opts=parse_args()vis(opts.dataset,opts.detections,opts.thresh,opts.output_dir,limit=opts.first)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TrainanetworkwithDetectron.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportpprintimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.trainc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TrainanetworkwithDetectron\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'Configfilefortraining(andoptionallytesting)\\',default=None,type=str)parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'Usecfg.NUM_GPUSGPUsforinference\\',action=\\'store_true\\')parser.add_argument(\\'--skip-test\\',dest=\\'skip_test\\',help=\\'Donottestthefinalmodel\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain():#InitializeC2workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\',\\'--caffe2_gpu_memory_tracking=1\\'])#Setuploggingandloadconfigoptionslogger=setup_logging(__name__)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()smi_output,cuda_ver,cudnn_ver=c2_utils.get_nvidia_info()logger.info(\"cudaversion:{}\".format(cuda_ver))logger.info(\"cudnnversion:{}\".format(cudnn_ver))logger.info(\"nvidia-smioutput:\\\\n{}\".format(smi_output))logger.info(\\'Trainingwithconfig:\\')logger.info(pprint.pformat(cfg))#Notethatwhilewesetthenumpyrandomseednetworktrainingwillnotbe#deterministicingeneral.Therearesourcesofnon-determinismthatcannot#beremovedwithareasonbleexecution-speedtradeoff(suchascertain#non-deterministiccudnnfunctions).np.random.seed(cfg.RNG_SEED)#Executethetrainingruncheckpoints=detectron.utils.train.train_model()#Testthetrainedmodelifnotargs.skip_test:test_model(checkpoints[\\'final\\'],args.multi_gpu_testing,args.opts)deftest_model(model_file,multi_gpu_testing,opts=None):\"\"\"Testamodel.\"\"\"#Clearmemorybeforeinferenceworkspace.ResetWorkspace()#Runinferencerun_inference(model_file,multi_gpu_testing=multi_gpu_testing,check_expected_results=True,)if__name__==\\'__main__\\':main()#!/usr/bin/envpython3#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scripttoconvertthemodel(.yamland.pkl)trainedbytrain_nettoastandardCaffe2modelinpbformat(model.pbandmodel_init.pb).Theconvertedmodelisgoodforproductionusage,asitcouldrunindependentlyandefficientlyonCPU,GPUandmobilewithoutdependingonthedetectroncodebase.PleaseseeCaffe2tutorial(forloadingtheconvertedmodel,andrun_model_pb()forrunningthemodelforinference.\"\"\"from__future__importabsolute_import,division,print_function,unicode_literalsimportargparseimportcopyimportosimportpprintimportsysimportcaffe2.python.utilsasputilsimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importdetectron.core.test_engineastest_engineimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.model_convert_utilsasmutilsimportdetectron.utils.visasvis_utilsimportnumpyasnpfromcaffe2.caffe2.fb.predictorimportpredictor_exporter,predictor_py_utilsfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcore,workspacefromcaffe2.python.predictor_constantsimportpredictor_constantsfromdetectron.core.configimport(assert_and_infer_cfg,cfg,merge_cfg_from_file,merge_cfg_from_list,)fromdetectron.modelingimportgenerate_anchorsfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.model_convert_utilsimportconvert_op_in_proto,op_filterc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)logger=setup_logging(__name__)defparse_args():parser=argparse.ArgumentParser(description=\"Convertatrainednetworktopbformat\")parser.add_argument(\"--cfg\",dest=\"cfg_file\",help=\"optionalconfigfile\",default=None,type=str)parser.add_argument(\"--net_name\",dest=\"net_name\",help=\"optionalnameforthenet\",default=\"detectron\",type=str,)parser.add_argument(\"--out_dir\",dest=\"out_dir\",help=\"outputdir\",default=None,type=str)parser.add_argument(\"--test_img\",dest=\"test_img\",help=\"optionaltestimage,usedtoverifythemodelconversion\",default=None,type=str,)parser.add_argument(\"--fuse_af\",dest=\"fuse_af\",help=\"1tofuse_af\",default=1,type=int)parser.add_argument(\"--device\",dest=\"device\",help=\"Devicetorunthemodelon\",choices=[\"cpu\",\"gpu\"],default=\"cpu\",type=str,)parser.add_argument(\"--net_execution_type\",dest=\"net_execution_type\",help=\"caffe2netexecutiontype\",choices=[\"simple\",\"dag\"],default=\"simple\",type=str,)parser.add_argument(\"--use_nnpack\",dest=\"use_nnpack\",help=\"Usennpackforconv\",default=1,type=int,)parser.add_argument(\"--logdb\",dest=\"logdb\",help=\"outputtologfiledbinsteadofpbfiles\",default=0,type=int,)parser.add_argument(\"opts\",help=\"Seedetectron/core/config.pyforalloptions\",default=None,nargs=argparse.REMAINDER,)iflen(sys.argv)==1:parser.print_help()sys.exit(1)ret=parser.parse_args()ret.out_dir=os.path.abspath(ret.out_dir)ifret.device==\"gpu\"andret.use_nnpack:logger.warn(\"Shouldnotusemobileengineforgpumodel.\")ret.use_nnpack=0returnretdefunscope_name(name):returnc2_utils.UnscopeName(name)defreset_names(names):foriinrange(len(names)):names[i]=unscope_name(names[i])defconvert_collect_and_distribute(op,blobs,roi_canonical_scale,roi_canonical_level,roi_max_level,roi_min_level,rpn_max_level,rpn_min_level,rpn_post_nms_topN,):print(\"ConvertingCollectAndDistributeFpnRpnProposals\"\"Python->C++:\\\\n{}\".format(op))assertop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"),\"NotvalidCollectAndDistributeFpnRpnProposalsOp\"inputs=[xforxinop.input]ret=core.CreateOperator(\"CollectAndDistributeFpnRpnProposals\",inputs,list(op.output),roi_canonical_scale=roi_canonical_scale,roi_canonical_level=roi_canonical_level,roi_max_level=roi_max_level,roi_min_level=roi_min_level,rpn_max_level=rpn_max_level,rpn_min_level=rpn_min_level,rpn_post_nms_topN=rpn_post_nms_topN,)returnretdefconvert_gen_proposals(op,blobs,rpn_pre_nms_topN,rpn_post_nms_topN,rpn_nms_thresh,rpn_min_size):print(\"ConvertingGenerateProposalsPython->C++:\\\\n{}\".format(op))assertop.name.startswith(\"GenerateProposalsOp\"),\"NotvalidGenerateProposalsOp\"spatial_scale=mutils.get_op_arg_valf(op,\"spatial_scale\",None)assertspatial_scaleisnotNonelvl=int(op.input[0][-1])ifop.input[0][-1].isdigit()elseNoneinputs=[xforxinop.input]anchor_name=\"anchor{}\".format(lvl)iflvlelse\"anchor\"inputs.append(anchor_name)anchor_sizes=((cfg.FPN.RPN_ANCHOR_START_SIZE*2.0**(lvl-cfg.FPN.RPN_MIN_LEVEL),)iflvlelsecfg.RPN.SIZES)blobs[anchor_name]=get_anchors(spatial_scale,anchor_sizes)print(\"anchors{}\".format(blobs[anchor_name]))ret=core.CreateOperator(\"GenerateProposals\",inputs,list(op.output),spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,correct_transform_coords=True,)returnret,anchor_namedefget_anchors(spatial_scale,anchor_sizes):anchors=generate_anchors.generate_anchors(stride=1.0/spatial_scale,sizes=anchor_sizes,aspect_ratios=cfg.RPN.ASPECT_RATIOS,).astype(np.float32)returnanchorsdefreset_blob_names(blobs):ret={unscope_name(x):blobs[x]forxinblobs}blobs.clear()blobs.update(ret)defconvert_net(args,net,blobs):@op_filter()defconvert_op_name(op):ifargs.device!=\"gpu\":ifop.engine!=\"DEPTHWISE_3x3\":op.engine=\"\"op.device_option.CopyFrom(caffe2_pb2.DeviceOption())reset_names(op.input)reset_names(op.output)return[op]@op_filter(type=\"Python\")defconvert_python(op):ifop.name.startswith(\"GenerateProposalsOp\"):gen_proposals_op,ext_input=convert_gen_proposals(op,blobs,rpn_min_size=float(cfg.TEST.RPN_MIN_SIZE),rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,rpn_pre_nms_topN=cfg.TEST.RPN_PRE_NMS_TOP_N,rpn_nms_thresh=cfg.TEST.RPN_NMS_THRESH,)net.external_input.extend([ext_input])return[gen_proposals_op]elifop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"):collect_dist_op=convert_collect_and_distribute(op,blobs,roi_canonical_scale=cfg.FPN.ROI_CANONICAL_SCALE,roi_canonical_level=cfg.FPN.ROI_CANONICAL_LEVEL,roi_max_level=cfg.FPN.ROI_MAX_LEVEL,roi_min_level=cfg.FPN.ROI_MIN_LEVEL,rpn_max_level=cfg.FPN.RPN_MAX_LEVEL,rpn_min_level=cfg.FPN.RPN_MIN_LEVEL,rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,)return[collect_dist_op]else:raiseValueError(\"FailedtoconvertPythonop{}\".format(op.name))#OnlyconvertUpsampleNearesttoResizeNearestwhenconvertingtopbsothattheexistingmodelsisunchanged##issuecomment-410248561@op_filter(type=\"UpsampleNearest\")defconvert_upsample_nearest(op):forarginop.arg:ifarg.name==\"scale\":scale=arg.ibreakelse:raiseKeyError(\\'Noattribute\"scale\"inUpsampleNearestop\\')resize_nearest_op=core.CreateOperator(\"ResizeNearest\",list(op.input),list(op.output),name=op.name,width_scale=float(scale),height_scale=float(scale),)returnresize_nearest_op@op_filter()defconvert_rpn_rois(op):forjinrange(len(op.input)):ifop.input[j]==\"rois\":print(\"Convertingop{}inputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.input[j]=\"rpn_rois\"forjinrange(len(op.output)):ifop.output[j]==\"rois\":print(\"Convertingop{}outputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.output[j]=\"rpn_rois\"return[op]@op_filter(type_in=[\"StopGradient\",\"Alias\"])defconvert_remove_op(op):print(\"Removingop{}:\\\\n{}\".format(op.type,op))return[]#Wewanttoapplytoalloperators,includingconverted#sorunseparatelyconvert_op_in_proto(net,convert_remove_op)convert_op_in_proto(net,convert_upsample_nearest)convert_op_in_proto(net,convert_python)convert_op_in_proto(net,convert_op_name)convert_op_in_proto(net,convert_rpn_rois)reset_names(net.external_input)reset_names(net.external_output)reset_blob_names(blobs)defadd_bbox_ops(args,net,blobs):new_ops=[]new_external_outputs=[]#Operatorsforbboxesop_box=core.CreateOperator(\"BBoxTransform\",[\"rpn_rois\",\"bbox_pred\",\"im_info\"],[\"pred_bbox\"],weights=cfg.MODEL.BBOX_REG_WEIGHTS,apply_scale=False,correct_transform_coords=True,)new_ops.extend([op_box])blob_prob=\"cls_prob\"blob_box=\"pred_bbox\"op_nms=core.CreateOperator(\"BoxWithNMSLimit\",[blob_prob,blob_box],[\"score_nms\",\"bbox_nms\",\"class_nms\"],arg=[putils.MakeArgument(\"score_thresh\",cfg.TEST.SCORE_THRESH),putils.MakeArgument(\"nms\",cfg.TEST.NMS),putils.MakeArgument(\"detections_per_im\",cfg.TEST.DETECTIONS_PER_IM),putils.MakeArgument(\"soft_nms_enabled\",cfg.TEST.SOFT_NMS.ENABLED),putils.MakeArgument(\"soft_nms_method\",cfg.TEST.SOFT_NMS.METHOD),putils.MakeArgument(\"soft_nms_sigma\",cfg.TEST.SOFT_NMS.SIGMA),],)new_ops.extend([op_nms])new_external_outputs.extend([\"score_nms\",\"bbox_nms\",\"class_nms\"])net.Proto().op.extend(new_ops)net.Proto().external_output.extend(new_external_outputs)defconvert_model_gpu(args,net,init_net):assertargs.device==\"gpu\"ret_net=copy.deepcopy(net)ret_init_net=copy.deepcopy(init_net)cdo_cuda=mutils.get_device_option_cuda()cdo_cpu=mutils.get_device_option_cpu()CPU_OPS=[[\"CollectAndDistributeFpnRpnProposals\",None],[\"GenerateProposals\",None],[\"BBoxTransform\",None],[\"BoxWithNMSLimit\",None],]CPU_BLOBS=[\"im_info\",\"anchor\"]@op_filter()defconvert_op_gpu(op):forxinCPU_OPS:ifmutils.filter_op(op,type=x[0],inputs=x[1]):returnNoneop.device_option.CopyFrom(cdo_cuda)return[op]@op_filter()defconvert_init_op_gpu(op):ifop.output[0]inCPU_BLOBS:op.device_option.CopyFrom(cdo_cpu)else:op.device_option.CopyFrom(cdo_cuda)return[op]convert_op_in_proto(ret_init_net.Proto(),convert_init_op_gpu)convert_op_in_proto(ret_net.Proto(),convert_op_gpu)ret=core.InjectDeviceCopiesAmongNets([ret_init_net,ret_net])return[ret[0][1],ret[0][0]]defgen_init_net(net,blobs,empty_blobs):blobs=copy.deepcopy(blobs)forxinempty_blobs:blobs[x]=np.array([],dtype=np.float32)init_net=mutils.gen_init_net_from_blobs(blobs,net.external_inputs)init_net=core.Net(init_net)returninit_netdef_save_image_graphs(args,all_net,all_init_net):print(\"Savingmodelgraph...\")mutils.save_graph(all_net.Proto(),os.path.join(args.out_dir,\"model_def.png\"),op_only=False)print(\"Modeldefimagesavedto{}.\".format(args.out_dir))def_save_models(all_net,all_init_net,args):print(\"Writingconvertedmodelto{}...\".format(args.out_dir))fname=\"model\"ifnotos.path.exists(args.out_dir):os.makedirs(args.out_dir)withopen(os.path.join(args.out_dir,fname+\".pb\"),\"wb\")asf:f.write(all_net.Proto().SerializeToString())withopen(os.path.join(args.out_dir,fname+\".pbtxt\"),\"wb\")asf:f.write(str(all_net.Proto()))withopen(os.path.join(args.out_dir,fname+\"_init.pb\"),\"wb\")asf:f.write(all_init_net.Proto().SerializeToString())_save_image_graphs(args,all_net,all_init_net)defload_model(args):model=test_engine.initialize_model_from_cfg(cfg.TEST.WEIGHTS)blobs=mutils.get_ws_blobs()returnmodel,blobsdef_get_result_blobs(check_blobs):ret={}forxincheck_blobs:sn=core.ScopedName(x)ifworkspace.HasBlob(sn):ret[x]=workspace.FetchBlob(sn)else:ret[x]=Nonereturnretdef_sort_results(boxes,segms,keypoints,classes):indices=np.argsort(boxes[:,-1])[::-1]ifboxesisnotNone:boxes=boxes[indices,:]ifsegmsisnotNone:segms=[segms[x]forxinindices]ifkeypointsisnotNone:keypoints=[keypoints[x]forxinindices]ifclassesisnotNone:ifisinstance(classes,list):classes=[classes[x]forxinindices]else:classes=classes[indices]returnboxes,segms,keypoints,classesdefrun_model_cfg(args,im,check_blobs):workspace.ResetWorkspace()model,_=load_model(args)withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=test_engine.im_detect_all(model,im,None,None)boxes,segms,keypoints,classes=vis_utils.convert_from_cls_format(cls_boxes,cls_segms,cls_keyps)#sorttheresultsbasedonscoreforcomparisionboxes,segms,keypoints,classes=_sort_results(boxes,segms,keypoints,classes)#writefinalresultsbacktoworkspacedef_ornone(res):returnnp.array(res)ifresisnotNoneelsenp.array([],dtype=np.float32)withc2_utils.NamedCudaScope(0):workspace.FeedBlob(core.ScopedName(\"result_boxes\"),_ornone(boxes))workspace.FeedBlob(core.ScopedName(\"result_segms\"),_ornone(segms))workspace.FeedBlob(core.ScopedName(\"result_keypoints\"),_ornone(keypoints))workspace.FeedBlob(core.ScopedName(\"result_classids\"),_ornone(classes))#getresultblobswithc2_utils.NamedCudaScope(0):ret=_get_result_blobs(check_blobs)returnretdef_prepare_blobs(im,pixel_means,target_size,max_size):\"\"\"Reference:blob.prep_im_for_blob()\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)ifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)#Reusecodeinblob_utilsandfitFPNblob=blob_utils.im_list_to_blob([im])blobs={}blobs[\"data\"]=blobblobs[\"im_info\"]=np.array([[blob.shape[2],blob.shape[3],im_scale]],dtype=np.float32)returnblobsdefrun_model_pb(args,net,init_net,im,check_blobs):workspace.ResetWorkspace()workspace.RunNetOnce(init_net)mutils.create_input_blobs_for_net(net.Proto())workspace.CreateNet(net)#input_blobs,_=core_test._get_blobs(im,None)input_blobs=_prepare_blobs(im,cfg.PIXEL_MEANS,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)gpu_blobs=[]ifargs.device==\"gpu\":gpu_blobs=[\"data\"]fork,vininput_blobs.items():workspace.FeedBlob(core.ScopedName(k),v,mutils.get_device_option_cuda()ifkingpu_blobselsemutils.get_device_option_cpu(),)try:workspace.RunNet(net)scores=workspace.FetchBlob(\"score_nms\")classids=workspace.FetchBlob(\"class_nms\")boxes=workspace.FetchBlob(\"bbox_nms\")exceptExceptionase:print(\"Runningpbmodelfailed.\\\\n{}\".format(e))#maynotdetectanythingatallR=0scores=np.zeros((R,),dtype=np.float32)boxes=np.zeros((R,4),dtype=np.float32)classids=np.zeros((R,),dtype=np.float32)boxes=np.column_stack((boxes,scores))#sorttheresultsbasedonscoreforcomparisionboxes,_,_,classids=_sort_results(boxes,None,None,classids)#writefinalresultbacktoworkspaceworkspace.FeedBlob(\"result_boxes\",boxes)workspace.FeedBlob(\"result_classids\",classids)ret=_get_result_blobs(check_blobs)returnretdefverify_model(args,model_pb,test_img_file):check_blobs=[\"result_boxes\",\"result_classids\"]#resultprint(\"Loadingtestfile{}...\".format(test_img_file))test_img=cv2.imread(test_img_file)asserttest_imgisnotNonedef_run_cfg_func(im,blobs):returnrun_model_cfg(args,im,check_blobs)def_run_pb_func(im,blobs):returnrun_model_pb(args,model_pb[0],model_pb[1],im,check_blobs)print(\"Checkingmodels...\")assertmutils.compare_model(_run_cfg_func,_run_pb_func,test_img,check_blobs)def_export_to_logfiledb(args,net,init_net,inputs,out_file,extra_out_tensors=None):out_tensors=list(net.Proto().external_output)ifextra_out_tensorsisnotNone:out_tensors+=extra_out_tensorsparams=list(set(net.Proto().external_input)-set(inputs))net_type=Nonepredictor_export_meta=predictor_exporter.PredictorExportMeta(predict_net=net,parameters=params,inputs=inputs,outputs=out_tensors,net_type=net_type,)logger.info(\"ExportingCaffe2modelto{}\".format(out_file))predictor_exporter.save_to_db(db_type=\"log_file_db\",db_destination=out_file,predictor_export_meta=predictor_export_meta,)defmain():workspace.GlobalInit([\"caffe2\",\"--caffe2_log_level=0\"])args=parse_args()logger.info(\"Calledwithargs:\")logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)cfg.NUM_GPUS=1assert_and_infer_cfg()logger.info(\"Convertingmodelwithconfig:\")logger.info(pprint.pformat(cfg))#scriptwillstopwhenitcan\\'tfindanoperatorrather#thanstoppingbasedontheseflags##assertnotcfg.MODEL.KEYPOINTS_ON,\"Keypointmodelnotsupported.\"#assertnotcfg.MODEL.MASK_ON,\"Maskmodelnotsupported.\"#assertnotcfg.FPN.FPN_ON,\"FPNnotsupported.\"#assertnotcfg.RETINANET.RETINANET_ON,\"RetinaNetmodelnotsupported.\"#loadmodelfromcfgmodel,blobs=load_model(args)net=core.Net(\"\")net.Proto().op.extend(copy.deepcopy(model.net.Proto().op))net.Proto().external_input.extend(copy.deepcopy(model.net.Proto().external_input))net.Proto().external_output.extend(copy.deepcopy(model.net.Proto().external_output))net.Proto().type=args.net_execution_typenet.Proto().num_workers=1ifargs.net_execution_type==\"simple\"else4#Resetthedevice_option,changetounscopenameandreplacepythonoperatorsconvert_net(args,net.Proto(),blobs)#addoperatorsforbboxadd_bbox_ops(args,net,blobs)ifargs.fuse_af:print(\"Fusingaffinechannel...\")net,blobs=mutils.fuse_net_affine(net,blobs)ifargs.use_nnpack:mutils.update_mobile_engines(net.Proto())#generateinitnetempty_blobs=[\"data\",\"im_info\"]init_net=gen_init_net(net,blobs,empty_blobs)ifargs.device==\"gpu\":[net,init_net]=convert_model_gpu(args,net,init_net)net.Proto().name=args.net_nameinit_net.Proto().name=args.net_name+\"_init\"ifargs.test_imgisnotNone:verify_model(args,[net,init_net],args.test_img)ifargs.logdb==1:output_file=os.path.join(args.out_dir,\"model.logfiledb\")_export_to_logfiledb(args,net,init_net,empty_blobs,output_file)else:_save_models(net,init_net,args)if__name__==\"__main__\":main()#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScriptforconvertingCaffe(<=1.0)modelsintothethesimplestatedictformatusedbyDetectron.Forexample,thisscriptcanconverttheorignalResNetmodelsreleasedbyMSRA.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysfromcaffe.protoimportcaffe_pb2fromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcaffe_translatorfromcaffe2.pythonimportutilsfromgoogle.protobufimporttext_formatfromdetectron.utils.ioimportsave_objectdefparse_args():parser=argparse.ArgumentParser(description=\\'DumpweightsfromaCaffemodel\\')parser.add_argument(\\'--prototxt\\',dest=\\'prototxt_file_name\\',help=\\'Networkdefinitionprototxtfilepath\\',default=None,type=str)parser.add_argument(\\'--caffemodel\\',dest=\\'caffemodel_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefnormalize_resnet_name(name):ifname.find(\\'res\\')==0andname.find(\\'res_\\')==-1:#E.g.,#res4b11_branch2c->res4_11_branch2c#res2a_branch1->res2_0_branch1chunk=name[len(\\'res\\'):name.find(\\'_\\')]name=(\\'res\\'+chunk[0]+\\'_\\'+str(int(chunk[2:])iflen(chunk)>2#e.g.,\"b1\"->1elseord(chunk[1])-ord(\\'a\\'))+#e.g.,\"a\"->0name[name.find(\\'_\\'):])returnnamedefpickle_weights(out_file_name,weights):blobs={normalize_resnet_name(blob.name):utils.Caffe2TensorToNumpyArray(blob)forblobinweights.protos}save_object(blobs,out_file_name)print(\\'Wroteblobs:\\')print(sorted(blobs.keys()))defadd_missing_biases(caffenet_weights):forlayerincaffenet_weights.layer:iflayer.type==\\'Convolution\\'andlen(layer.blobs)==1:num_filters=layer.blobs[0].shape.dim[0]bias_blob=caffe_pb2.BlobProto()bias_blob.data.extend(np.zeros(num_filters))bias_blob.num,bias_blob.channels,bias_blob.height=1,1,1bias_blob.width=num_filterslayer.blobs.extend([bias_blob])defremove_spatial_bn_layers(caffenet,caffenet_weights):#Layertypesassociatedwithspatialbatchnormremove_types=[\\'BatchNorm\\',\\'Scale\\']def_remove_layers(net):foriinreversed(range(len(net.layer))):ifnet.layer[i].typeinremove_types:net.layer.pop(i)#Firstremovelayersfromcaffenetproto_remove_layers(caffenet)#We\\'llreturnthesesowecansavethebatchnormparametersbn_layers=[layerforlayerincaffenet_weights.layeriflayer.typeinremove_types]_remove_layers(caffenet_weights)def_create_tensor(arr,shape,name):t=caffe2_pb2.TensorProto()t.name=namet.data_type=caffe2_pb2.TensorProto.FLOATt.dims.extend(shape.dim)t.float_data.extend(arr)assertlen(t.float_data)==np.prod(t.dims),\\'Datasize,shapemismatch\\'returntbn_tensors=[]for(bn,scl)inzip(bn_layers[0::2],bn_layers[1::2]):assertbn.name[len(\\'bn\\'):]==scl.name[len(\\'scale\\'):],\\'Pairmismatch\\'blob_out=\\'res\\'+bn.name[len(\\'bn\\'):]+\\'_bn\\'bn_mean=np.asarray(bn.blobs[0].data)bn_var=np.asarray(bn.blobs[1].data)scale=np.asarray(scl.blobs[0].data)bias=np.asarray(scl.blobs[1].data)std=np.sqrt(bn_var+1e-5)new_scale=scale/stdnew_bias=bias-bn_mean*scale/stdnew_scale_tensor=_create_tensor(new_scale,bn.blobs[0].shape,blob_out+\\'_s\\')new_bias_tensor=_create_tensor(new_bias,bn.blobs[0].shape,blob_out+\\'_b\\')bn_tensors.extend([new_scale_tensor,new_bias_tensor])returnbn_tensorsdefremove_layers_without_parameters(caffenet,caffenet_weights):foriinreversed(range(len(caffenet_weights.layer))):iflen(caffenet_weights.layer[i].blobs)==0:#Searchforthecorrespondinglayerincaffenetandremoveitname=caffenet_weights.layer[i].namefound=Falseforjinrange(len(caffenet.layer)):ifcaffenet.layer[j].name==name:caffenet.layer.pop(j)found=Truebreakifnotfoundandname[-len(\\'_split\\'):]!=\\'_split\\':print(\\'Warning:layer{}notfoundincaffenet\\'.format(name))caffenet_weights.layer.pop(i)defnormalize_shape(caffenet_weights):forlayerincaffenet_weights.layer:forblobinlayer.blobs:shape=(blob.num,blob.channels,blob.height,blob.width)iflen(blob.data)!=np.prod(shape):shape=tuple(blob.shape.dim)iflen(shape)==1:#Handlebiasesshape=(1,1,1,shape[0])iflen(shape)==2:#HandleInnerProductlayersshape=(1,1,shape[0],shape[1])assertlen(shape)==4blob.num,blob.channels,blob.height,blob.width=shapedefload_and_convert_caffe_model(prototxt_file_name,caffemodel_file_name):caffenet=caffe_pb2.NetParameter()caffenet_weights=caffe_pb2.NetParameter()text_format.Merge(open(prototxt_file_name).read(),caffenet)caffenet_weights.ParseFromString(open(caffemodel_file_name).read())#C2convlayerscurrentrequirebiases,buttheyareoptionalinC1#Addzerosasbiasesistheyaremissingadd_missing_biases(caffenet_weights)#Weonlycareaboutgettingparameters,soremovelayersw/oparametersremove_layers_without_parameters(caffenet,caffenet_weights)#BatchNormisnotimplementedinthetranslator*and*weneedtofoldScale#layersintothenewC2SpatialBNop,henceweremovethebatchnormlayers#andapplycustomtranslationscodebn_weights=remove_spatial_bn_layers(caffenet,caffenet_weights)#Setnum,channel,heightandwidthforblobsthatuseshape.diminsteadnormalize_shape(caffenet_weights)#Translatetherestofthemodelnet,pretrained_weights=caffe_translator.TranslateModel(caffenet,caffenet_weights)pretrained_weights.protos.extend(bn_weights)returnnet,pretrained_weightsif__name__==\\'__main__\\':args=parse_args()assertos.path.exists(args.prototxt_file_name),\\\\\\'Prototxtfiledoesnotexist\\'assertos.path.exists(args.caffemodel_file_name),\\\\\\'Weightsfiledoesnotexist\\'net,weights=load_and_convert_caffe_model(args.prototxt_file_name,args.caffemodel_file_name)pickle_weights(args.out_file_name,weights)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################ConvertadetectionmodeltrainedforCOCOintoamodelthatcanbefine-tuned#oncityscapes##cityscapes_to_cocofrom__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysimportdetectron.datasets.coco_to_cityscapes_idascsfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectNUM_CS_CLS=9NUM_COCO_CLS=81defparse_args():parser=argparse.ArgumentParser(description=\\'ConvertaCOCOpre-trainedmodelforusewithCityscapes\\')parser.add_argument(\\'--coco_model\\',dest=\\'coco_model_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--convert_func\\',dest=\\'convert_func\\',help=\\'Blobconversionfunction\\',default=\\'cityscapes_to_coco\\',type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert_coco_blobs_to_cityscape_blobs(model_dict):fork,vinmodel_dict[\\'blobs\\'].items():ifv.shape[0]==NUM_COCO_CLSorv.shape[0]==4*NUM_COCO_CLS:coco_blob=model_dict[\\'blobs\\'][k]print(\\'ConvertingCOCOblob{}withshape{}\\'.format(k,coco_blob.shape))cs_blob=convert_coco_blob_to_cityscapes_blob(coco_blob,args.convert_func)print(\\'->convertedshape{}\\'.format(cs_blob.shape))model_dict[\\'blobs\\'][k]=cs_blobdefconvert_coco_blob_to_cityscapes_blob(coco_blob,convert_func):#cocoblob(81,...)or(81*4,...)coco_shape=coco_blob.shapeleading_factor=int(coco_shape[0]/NUM_COCO_CLS)tail_shape=list(coco_shape[1:])assertleading_factor==1orleading_factor==4#Reshapein[num_classes,...]formforeasiermanipulationscoco_blob=coco_blob.reshape([NUM_COCO_CLS,-1]+tail_shape)#DefaultinitializationusesGaussianwithmeanandstdtomatchthe#existingparametersstd=coco_blob.std()mean=coco_blob.mean()cs_shape=[NUM_CS_CLS]+list(coco_blob.shape[1:])cs_blob=(np.random.randn(*cs_shape)*std+mean).astype(np.float32)#ReplacerandomparameterswithCOCOparametersifclassmappingexistsforiinrange(NUM_CS_CLS):coco_cls_id=getattr(cs,convert_func)(i)ifcoco_cls_id>=0:#otherwiseignore(randinit)cs_blob[i]=coco_blob[coco_cls_id]cs_shape=[NUM_CS_CLS*leading_factor]+tail_shapereturncs_blob.reshape(cs_shape)defremove_momentum(model_dict):forkinmodel_dict[\\'blobs\\'].keys():ifk.endswith(\\'_momentum\\'):delmodel_dict[\\'blobs\\'][k]defload_and_convert_coco_model(args):model_dict=load_object(args.coco_model_file_name)remove_momentum(model_dict)convert_coco_blobs_to_cityscape_blobs(model_dict)returnmodel_dictif__name__==\\'__main__\\':args=parse_args()print(args)assertos.path.exists(args.coco_model_file_name),\\\\\\'Weightsfiledoesnotexist\\'weights=load_and_convert_coco_model(args)save_object(weights,args.out_file_name)print(\\'Wroteblobsto{}:\\'.format(args.out_file_name))print(sorted(weights[\\'blobs\\'].keys()))#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimporth5pyimportjsonimportosimportimageioimportsysimportcityscapesscripts.evaluation.instances2dict_with_polygonsascsimportdetectron.utils.segmsassegms_utilimportdetectron.utils.boxesasbboxs_utildefparse_args():parser=argparse.ArgumentParser(description=\\'Convertdataset\\')parser.add_argument(\\'--dataset\\',help=\"cocostuff,cityscapes\",default=None,type=str)parser.add_argument(\\'--outdir\\',help=\"outputdirforjsonfiles\",default=None,type=str)parser.add_argument(\\'--datadir\\',help=\"datadirforannotationstobeconverted\",default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defconvert_coco_stuff_mat(data_dir,out_dir):\"\"\"Converttopngandsavejsonwithpath.Thiscurrentlyonlycontainsthesegmentationlabelsforobjects+stuffincocostuff-ifweneedtocombinewithotherlabelsfromoriginalCOCOthatwillbeaTODO.\"\"\"sets=[\\'train\\',\\'val\\']categories=[]json_name=\\'coco_stuff_%s.json\\'ann_dict={}fordata_setinsets:file_list=os.path.join(data_dir,\\'%s.txt\\')images=[]withopen(file_list%data_set)asf:forimg_id,img_nameinenumerate(f):img_name=img_name.replace(\\'coco\\',\\'COCO\\').strip(\\'\\\\n\\')image={}mat_file=os.path.join(data_dir,\\'annotations/%s.mat\\'%img_name)data=h5py.File(mat_file,\\'r\\')labelMap=data.get(\\'S\\')iflen(categories)==0:labelNames=data.get(\\'names\\')foridx,ninenumerate(labelNames):categories.append({\"id\":idx,\"name\":\\'\\'.join(chr(i)foriindata[n[0]])})ann_dict[\\'categories\\']=categoriesimageio.imsave(os.path.join(data_dir,img_name+\\'.png\\'),labelMap)image[\\'width\\']=labelMap.shape[0]image[\\'height\\']=labelMap.shape[1]image[\\'file_name\\']=img_nameimage[\\'seg_file_name\\']=img_nameimage[\\'id\\']=img_idimages.append(image)ann_dict[\\'images\\']=imagesprint(\"Numimages:%s\"%len(images))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))#forCityscapesdefgetLabelID(self,instID):if(instID<1000):returninstIDelse:returnint(instID/1000)defconvert_cityscapes_instance_only(data_dir,out_dir):\"\"\"ConvertfromcityscapesformattoCOCOinstancesegformat-polygons\"\"\"sets=[\\'gtFine_val\\',#\\'gtFine_train\\',#\\'gtFine_test\\',#\\'gtCoarse_train\\',#\\'gtCoarse_val\\',#\\'gtCoarse_train_extra\\']ann_dirs=[\\'gtFine_trainvaltest/gtFine/val\\',#\\'gtFine_trainvaltest/gtFine/train\\',#\\'gtFine_trainvaltest/gtFine/test\\',#\\'gtCoarse/train\\',#\\'gtCoarse/train_extra\\',#\\'gtCoarse/val\\']json_name=\\'instancesonly_filtered_%s.json\\'ends_in=\\'%s_polygons.json\\'img_id=0ann_id=0cat_id=1category_dict={}category_instancesonly=[\\'person\\',\\'rider\\',\\'car\\',\\'truck\\',\\'bus\\',\\'train\\',\\'motorcycle\\',\\'bicycle\\',]fordata_set,ann_dirinzip(sets,ann_dirs):print(\\'Starting%s\\'%data_set)ann_dict={}images=[]annotations=[]ann_dir=os.path.join(data_dir,ann_dir)forroot,_,filesinos.walk(ann_dir):forfilenameinfiles:iffilename.endswith(ends_in%data_set.split(\\'_\\')[0]):iflen(images)%50==0:print(\"Processed%simages,%sannotations\"%(len(images),len(annotations)))json_ann=json.load(open(os.path.join(root,filename)))image={}image[\\'id\\']=img_idimg_id+=1image[\\'width\\']=json_ann[\\'imgWidth\\']image[\\'height\\']=json_ann[\\'imgHeight\\']image[\\'file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\'leftImg8bit.png\\'image[\\'seg_file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\\\\\'%s_instanceIds.png\\'%data_set.split(\\'_\\')[0]images.append(image)fullname=os.path.join(root,image[\\'seg_file_name\\'])objects=cs.instances2dict_with_polygons([fullname],verbose=False)[fullname]forobject_clsinobjects:ifobject_clsnotincategory_instancesonly:continue#skipnon-instancecategoriesforobjinobjects[object_cls]:ifobj[\\'contours\\']==[]:print(\\'Warning:emptycontours.\\')continue#skipnon-instancecategorieslen_p=[len(p)forpinobj[\\'contours\\']]ifmin(len_p)<=4:print(\\'Warning:invalidcontours.\\')continue#skipnon-instancecategoriesann={}ann[\\'id\\']=ann_idann_id+=1ann[\\'image_id\\']=image[\\'id\\']ann[\\'segmentation\\']=obj[\\'contours\\']ifobject_clsnotincategory_dict:category_dict[object_cls]=cat_idcat_id+=1ann[\\'category_id\\']=category_dict[object_cls]ann[\\'iscrowd\\']=0ann[\\'area\\']=obj[\\'pixelCount\\']ann[\\'bbox\\']=bboxs_util.xyxy_to_xywh(segms_util.polys_to_boxes([ann[\\'segmentation\\']])).tolist()[0]annotations.append(ann)ann_dict[\\'images\\']=imagescategories=[{\"id\":category_dict[name],\"name\":name}fornameincategory_dict]ann_dict[\\'categories\\']=categoriesann_dict[\\'annotations\\']=annotationsprint(\"Numcategories:%s\"%len(categories))print(\"Numimages:%s\"%len(images))print(\"Numannotations:%s\"%len(annotations))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))if__name__==\\'__main__\\':args=parse_args()ifargs.dataset==\"cityscapes_instance_only\":convert_cityscapes_instance_only(args.datadir,args.outdir)elifargs.dataset==\"cocostuff\":convert_coco_stuff_mat(args.datadir,args.outdir)else:print(\"Datasetnotsupported:%s\"%args.dataset)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Givenafullsetofresults(boxes,masks,orkeypoints)onthe2017COCOtestset,thisscriptextractstheresultssubsetthatcorrespondsto2017test-dev.Thetest-devsubsetcanthenbesubmittedtotheCOCOevaluationserver.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportjsonimportosimportsysfromdetectron.datasets.dataset_catalogimportget_ann_fnfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--json\\',dest=\\'json_file\\',help=\\'detectionsjsonfile\\',default=\\'\\',type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'/tmp\\',type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert(json_file,output_dir):print(\\'Reading:{}\\'.format(json_file))withopen(json_file,\\'r\\')asfid:dt=json.load(fid)print(\\'done!\\')test_image_info=get_ann_fn(\\'coco_2017_test\\')withopen(test_image_info,\\'r\\')asfid:info_test=json.load(fid)image_test=info_test[\\'images\\']image_test_id=[i[\\'id\\']foriinimage_test]print(\\'{}has{}images\\'.format(test_image_info,len(image_test_id)))test_dev_image_info=get_ann_fn(\\'coco_2017_test-dev\\')withopen(test_dev_image_info,\\'r\\')asfid:info_testdev=json.load(fid)image_testdev=info_testdev[\\'images\\']image_testdev_id=[i[\\'id\\']foriinimage_testdev]print(\\'{}has{}images\\'.format(test_dev_image_info,len(image_testdev_id)))dt_testdev=[]print(\\'Filteringtest-devfromtest...\\')t=Timer()t.tic()foriinrange(len(dt)):ifi%1000==0:print(\\'{}/{}\\'.format(i,len(dt)))ifdt[i][\\'image_id\\']inimage_testdev_id:dt_testdev.append(dt[i])print(\\'Donefiltering({:2}s)!\\'.format(t.toc()))filename,file_extension=os.path.splitext(os.path.basename(json_file))filename=filename+\\'_test-dev\\'filename=os.path.join(output_dir,filename+file_extension)withopen(filename,\\'w\\')asfid:info_test=json.dump(dt_testdev,fid)print(\\'Donewriting:{}!\\'.format(filename))if__name__==\\'__main__\\':opts=parse_args()convert(opts.json_file,opts.output_dir)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Reval=re-eval.Re-evaluatesaveddetections.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportosimportsysfromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.configascore_configdefparse_args():parser=argparse.ArgumentParser(description=\\'Re-evaluateresults\\')parser.add_argument(\\'output_dir\\',nargs=1,help=\\'resultsdirectory\\',type=str)parser.add_argument(\\'--dataset\\',dest=\\'dataset_name\\',help=\\'datasettore-evaluate\\',default=\\'voc_2007_test\\',type=str)parser.add_argument(\\'--matlab\\',dest=\\'matlab_eval\\',help=\\'usematlabforevaluation\\',action=\\'store_true\\')parser.add_argument(\\'--comp\\',dest=\\'comp_mode\\',help=\\'competitionmode\\',action=\\'store_true\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefdo_reval(dataset_name,output_dir,args):dataset=JsonDataset(dataset_name)dets=load_object(os.path.join(output_dir,\\'detections.pkl\\'))#Overrideconfigwiththeonesavedinthedetectionsfileifargs.cfg_fileisnotNone:core_config.merge_cfg_from_cfg(core_config.load_cfg(dets[\\'cfg\\']))else:core_config._merge_a_into_b(core_config.load_cfg(dets[\\'cfg\\']),cfg)results=task_evaluation.evaluate_all(dataset,dets[\\'all_boxes\\'],dets[\\'all_segms\\'],dets[\\'all_keyps\\'],output_dir,use_matlab=args.matlab_eval)task_evaluation.log_copy_paste_friendly_results(results)if__name__==\\'__main__\\':setup_logging(__name__)args=parse_args()ifargs.comp_mode:cfg.TEST.COMPETITION_MODE=Trueoutput_dir=os.path.abspath(args.output_dir[0])do_reval(args.dataset_name,output_dir,args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScripttoconvertSelectiveSearchproposalboxesintotheDetectronproposalfileformat.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportscipy.ioassioimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportsave_objectif__name__==\\'__main__\\':dataset_name=sys.argv[1]file_in=sys.argv[2]file_out=sys.argv[3]ds=JsonDataset(dataset_name)roidb=ds.get_roidb()raw_data=sio.loadmat(file_in)[\\'boxes\\'].ravel()assertraw_data.shape[0]==len(roidb)boxes=[]scores=[]ids=[]foriinrange(raw_data.shape[0]):ifi%1000==0:print(\\'{}/{}\\'.format(i+1,len(roidb)))#selectivesearchboxesare1-indexedand(y1,x1,y2,x2)i_boxes=raw_data[i][:,(1,0,3,2)]-1boxes.append(i_boxes.astype(np.float32))scores.append(np.zeros((i_boxes.shape[0]),dtype=np.float32))ids.append(roidb[i][\\'id\\'])save_object(dict(boxes=boxes,scores=scores,indexes=ids),file_out)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importglobimportloggingimportosimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerimportdetectron.core.test_engineasinfer_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'End-to-endinference\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg\\',help=\\'cfgmodelfile(/path/to/model_config.yaml)\\',default=None,type=str)parser.add_argument(\\'--wts\\',dest=\\'weights\\',help=\\'weightsmodelfile(/path/to/model_weights.pkl)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer_simple)\\',default=\\'/tmp/infer_simple\\',type=str)parser.add_argument(\\'--image-ext\\',dest=\\'image_ext\\',help=\\'imagefilenameextension(default:jpg)\\',default=\\'jpg\\',type=str)parser.add_argument(\\'--always-out\\',dest=\\'out_when_no_box\\',help=\\'outputimageevenwhennoobjectisfound\\',action=\\'store_true\\')parser.add_argument(\\'--output-ext\\',dest=\\'output_ext\\',help=\\'outputimagefileformat(default:pdf)\\',default=\\'pdf\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'Thresholdforvisualizingdetections\\',default=0.7,type=float)parser.add_argument(\\'--kp-thresh\\',dest=\\'kp_thresh\\',help=\\'Thresholdforvisualizingkeypoints\\',default=2.0,type=float)parser.add_argument(\\'im_or_folder\\',help=\\'imageorfolderofimages\\',default=None)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain(args):logger=logging.getLogger(__name__)merge_cfg_from_file(args.cfg)cfg.NUM_GPUS=1args.weights=cache_url(args.weights,cfg.DOWNLOAD_CACHE)assert_and_infer_cfg(cache_urls=False)assertnotcfg.MODEL.RPN_ONLY,\\\\\\'RPNmodelsarenotsupported\\'assertnotcfg.TEST.PRECOMPUTED_PROPOSALS,\\\\\\'Modelsthatrequireprecomputedproposalsarenotsupported\\'model=infer_engine.initialize_model_from_cfg(args.weights)dummy_coco_dataset=dummy_datasets.get_coco_dataset()ifos.path.isdir(args.im_or_folder):im_list=glob.iglob(args.im_or_folder+\\'/*.\\'+args.image_ext)else:im_list=[args.im_or_folder]fori,im_nameinenumerate(im_list):out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(im_name)+\\'.\\'+args.output_ext))logger.info(\\'Processing{}->{}\\'.format(im_name,out_name))im=cv2.imread(im_name)timers=defaultdict(Timer)t=time.time()withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=infer_engine.im_detect_all(model,im,None,timers=timers)logger.info(\\'Inferencetime:{:.3f}s\\'.format(time.time()-t))fork,vintimers.items():logger.info(\\'|{}:{:.3f}s\\'.format(k,v.average_time))ifi==0:logger.info(\\'\\\\Note:inferenceonthefirstimagewillbeslowerthanthe\\'\\'rest(cachesandauto-tuningneedtowarmup)\\')vis_utils.vis_one_image(im[:,:,::-1],#BGR->RGBforvisualizationim_name,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=args.thresh,kp_thresh=args.kp_thresh,ext=args.output_ext,out_when_no_box=args.out_when_no_box)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()main(args)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97370855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<|begin_of_text|>#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfromCython.BuildimportcythonizefromsetuptoolsimportExtensionfromsetuptoolsimportsetupimportnumpyasnp_NP_INCLUDE_DIRS=np.get_include()#Extensionmodulesext_modules=[Extension(name=\\'detectron.utils.cython_bbox\\',sources=[\\'detectron/utils/cython_bbox.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS]),Extension(name=\\'detectron.utils.cython_nms\\',sources=[\\'detectron/utils/cython_nms.pyx\\'],extra_compile_args=[\\'-Wno-cpp\\'],include_dirs=[_NP_INCLUDE_DIRS])]setup(name=\\'Detectron\\',packages=[\\'detectron\\'],ext_modules=cythonize(ext_modules))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ComputeminibatchblobsfortrainingaRetinaNetnetwork.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportdetectron.utils.boxesasbox_utilsimportdetectron.roi_data.data_utilsasdata_utilsfromdetectron.core.configimportcfglogger=logging.getLogger(__name__)defget_retinanet_blob_names(is_training=True):\"\"\"Returnsblobnamesintheorderinwhichtheyarereadbythedataloader.N=numberofimagesperminibatchA=numberofanchors=num_scales*num_aspect_ratios(forexample9usedinRetinaNetpaper)H,W=spatialdimensions(differentforeachFPNlevel)M=Outofalltheanchorsgenerated,dependingonthepositive/negativeIoUoverlapthresholds,wewillhaveMpositiveanchors.Thesearetheanchorsthatboundingboxbranchwillregresson.retnet_cls_labels->labelsfortheclsbranchforeachFPNlevelShape:NxAxHxWretnet_roi_bbox_targets->targetsforthebboxregressionbranchShape:Mx4retnet_roi_fg_bbox_locs->forthebboxregression,sinceweareonlyinterestedinregressingonfgbboxeswhichareMinnumberandtheoutputpredictionofthenetworkisofshapeNx(A*4)xHxW(incaseofnonclass-specificbbox),sowestorethelocationsofpositivefgboxesinthisblobretnet_roi_fg_bbox_locsofshapeMx4whereeachrowlookslike:[img_id,anchor_id,x_loc,y_loc]\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']assertcfg.FPN.FPN_ON,\"RetinaNetusesFPNfordensedetection\"#SameformatasRPNblobs,butoneperFPNlevelifis_training:blob_names+=[\\'retnet_fg_num\\',\\'retnet_bg_num\\']forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):suffix=\\'fpn{}\\'.format(lvl)blob_names+=[\\'retnet_cls_labels_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,]returnblob_namesdefadd_retinanet_blobs(blobs,im_scales,roidb,image_width,image_height):\"\"\"AddRetinaNetblobs.\"\"\"#RetinaNetisappliedtomanyfeaturelevels,asintheFPNpaperk_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEnum_aspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)aspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALE#getanchorsfromalllevelsforallscales/aspectratiosfoas=[]forlvlinrange(k_min,k_max+1):stride=2.**lvlforoctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foridxinrange(num_aspect_ratios):anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect_ratios[idx],)foa=data_utils.get_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave,idx)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])blobs[\\'retnet_fg_num\\'],blobs[\\'retnet_bg_num\\']=0.0,0.0forim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]assertlen(gt_inds)>0,\\\\\\'Emptygroundtruthemptyforimageisnotallowed.Pleasecheck.\\'gt_rois=entry[\\'boxes\\'][gt_inds,:]*scalegt_classes=entry[\\'gt_classes\\'][gt_inds]im_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)retinanet_blobs,fg_num,bg_num=_get_retinanet_blobs(foas,all_anchors,gt_rois,gt_classes,image_width,image_height)fori,foainenumerate(foas):fork,vinretinanet_blobs[i].items():#thewayitstacksis:#[[anchorsforimage1]+[anchorsforimages2]]level=int(np.log2(foa.stride))key=\\'{}_fpn{}\\'.format(k,level)ifk==\\'retnet_roi_fg_bbox_locs\\':v[:,0]=im_i#loc_stride:80*4ifcls_specificelse4loc_stride=4#4coordinatecorrespondingtobboxpredictionifcfg.RETINANET.CLASS_SPECIFIC_BBOX:loc_stride*=(cfg.MODEL.NUM_CLASSES-1)anchor_ind=foa.octave*num_aspect_ratios+foa.aspect#v[:,1]istheclasslabel[range0-80]ifwedo#class-specficbboxotherwiseitis0.Incaseofclass#specific,basedonthelabel,thelocationofcurrent#anchorisclass_label*4andthenwetakeintoaccount#theanchor_indiftheanchorsv[:,1]*=4v[:,1]+=loc_stride*anchor_indblobs[key].append(v)blobs[\\'retnet_fg_num\\']+=fg_numblobs[\\'retnet_bg_num\\']+=bg_numblobs[\\'retnet_fg_num\\']=blobs[\\'retnet_fg_num\\'].astype(np.float32)blobs[\\'retnet_bg_num\\']=blobs[\\'retnet_bg_num\\'].astype(np.float32)N=len(roidb)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:#computenumberofanchorsA=int(len(v)/N)#fortheclsbranchlabels[perfpnlevel],#wehaveblobs[\\'retnet_cls_labels_fpn{}\\']asalistuntilthisstep#andlengthofthislistisNxAwhere#N=num_images,A=num_anchorsforexample,N=2,A=9#Eachelementofthelisthastheshape1x1xHxWwhereH,Ware#spatialdimensionofcurretfpnlvl.Leta{i}denotetheelement#correspondingtoanchori[9anchorstotal]inthelist.#Theelementsinthelistareinorder[[a0,...,a9],[a0,...,a9]]#howeverthenetworkwillmakepredictionslike2x(9*80)xHxW#sowefirstconcatenatetheelementsofeachimagetoanumpyarray#andthenconcatenatethetwoimagestogetthe2x9xHxWifk.find(\\'retnet_cls_labels\\')>=0:tmp=[]#concatanchorswithinanimageforiinrange(0,len(v),A):tmp.append(np.concatenate(v[i:i+A],axis=1))#concatimagesblobs[k]=np.concatenate(tmp,axis=0)else:#forthebboxbranchelements[perFPNlevel],#wehavethetargetsandthefgboxeslocations#intheshape:Mx4whereMisthenumberoffglocationsina#givenimageatthecurrentFPNlevel.Forthegivenlevel,#thebboxpredictionswillbe.Theelementsinthelistarein#order[[a0,...,a9],[a0,...,a9]]#ConcatenatethemtoformMx4blobs[k]=np.concatenate(v,axis=0)returnTruedef_get_retinanet_blobs(foas,all_anchors,gt_boxes,gt_classes,im_width,im_height):total_anchors=all_anchors.shape[0]logger.debug(\\'Gettingmadblobs:im_height{}im_width:{}\\'.format(im_height,im_width))inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.float32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)gt_inds=anchor_to_gt_argmax[anchors_with_max_overlap]labels[anchors_with_max_overlap]=gt_classes[gt_inds]#Fglabel:abovethresholdIOUinds=anchor_to_gt_max>=cfg.RETINANET.POSITIVE_OVERLAPgt_inds=anchor_to_gt_argmax[inds]labels[inds]=gt_classes[gt_inds]fg_inds=np.where(labels>=1)[0]bg_inds=np.where(anchor_to_gt_max<cfg.RETINANET.NEGATIVE_OVERLAP)[0]labels[bg_inds]=0num_fg,num_bg=len(fg_inds),len(bg_inds)bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeend_idx=start_idx+H*W_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,height,width)_labels=_labels.reshape((1,1,H,W))#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,4)).transpose(0,3,1,2)stride=foa.stridew=int(im_width/stride)h=int(im_height/stride)#dataforselect_smooth_l1lossnum_classes=cfg.MODEL.NUM_CLASSES-1inds_4d=np.where(_labels>0)M=len(inds_4d)_roi_bbox_targets=np.zeros((0,4))_roi_fg_bbox_locs=np.zeros((0,4))ifM>0:im_inds,y,x=inds_4d[0],inds_4d[2],inds_4d[3]_roi_bbox_targets=np.zeros((len(im_inds),4))_roi_fg_bbox_locs=np.zeros((len(im_inds),4))lbls=_labels[im_inds,:,y,x]fori,lblinenumerate(lbls):l=lbl[0]-1ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:l=0assertl>=0andl<num_classes,\\'labeloutoftherange\\'_roi_bbox_targets[i,:]=_bbox_targets[:,:,y[i],x[i]]_roi_fg_bbox_locs[i,:]=np.array([[0,l,y[i],x[i]]])blobs_out.append(dict(retnet_cls_labels=_labels[:,:,0:h,0:w].astype(np.int32),retnet_roi_bbox_targets=_roi_bbox_targets.astype(np.float32),retnet_roi_fg_bbox_locs=_roi_fg_bbox_locs.astype(np.float32),))out_num_fg=np.array([num_fg+1.0],dtype=np.float32)out_num_bg=(np.array([num_bg+1.0])*(cfg.MODEL.NUM_CLASSES-1)+out_num_fg*(cfg.MODEL.NUM_CLASSES-2))returnblobs_out,out_num_fg,out_num_bg#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"CommonutilityfunctionsforRPNandRetinaNetminibtachblobspreparation.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportnamedtupleimportloggingimportnumpyasnpimportthreadingfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)#octaveandaspectfieldsareonlyusedonRetinaNet.Octavecorrespondstothe#scaleoftheanchorandaspectdenoteswhichaspectratioisusedintherange#ofaspectratiosFieldOfAnchors=namedtuple(\\'FieldOfAnchors\\',[\\'field_of_anchors\\',\\'num_cell_anchors\\',\\'stride\\',\\'field_size\\',\\'octave\\',\\'aspect\\'])#Cacheformemoizing_get_field_of_anchors_threadlocal_foa=threading.local()defget_field_of_anchors(stride,anchor_sizes,anchor_aspect_ratios,octave=None,aspect=None):global_threadlocal_foaifnothasattr(_threadlocal_foa,\\'cache\\'):_threadlocal_foa.cache={}cache_key=str(stride)+str(anchor_sizes)+str(anchor_aspect_ratios)ifcache_keyin_threadlocal_foa.cache:return_threadlocal_foa.cache[cache_key]#Anchorsatasinglefeaturecellcell_anchors=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)num_cell_anchors=cell_anchors.shape[0]#Generatecanonicalproposalsfromshiftedanchors#Enumerateallshiftedpositionsonthe(H,W)gridfpn_max_size=cfg.FPN.COARSEST_STRIDE*np.ceil(cfg.TRAIN.MAX_SIZE/float(cfg.FPN.COARSEST_STRIDE))field_size=int(np.ceil(fpn_max_size/float(stride)))shifts=np.arange(0,field_size)*strideshift_x,shift_y=np.meshgrid(shifts,shifts)shift_x=shift_x.ravel()shift_y=shift_y.ravel()shifts=np.vstack((shift_x,shift_y,shift_x,shift_y)).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAcellanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsA=num_cell_anchorsK=shifts.shape[0]field_of_anchors=(cell_anchors.reshape((1,A,4))+shifts.reshape((1,K,4)).transpose((1,0,2)))field_of_anchors=field_of_anchors.reshape((K*A,4))foa=FieldOfAnchors(field_of_anchors=field_of_anchors.astype(np.float32),num_cell_anchors=num_cell_anchors,stride=stride,field_size=field_size,octave=octave,aspect=aspect)_threadlocal_foa.cache[cache_key]=foareturnfoadefunmap(data,count,inds,fill=0):\"\"\"Unmapasubsetofitem(data)backtotheoriginalsetofitems(ofsizecount)\"\"\"ifcount==len(inds):returndataiflen(data.shape)==1:ret=np.empty((count,),dtype=data.dtype)ret.fill(fill)ret[inds]=dataelse:ret=np.empty((count,)+data.shape[1:],dtype=data.dtype)ret.fill(fill)ret[inds,:]=datareturnretdefcompute_targets(ex_rois,gt_rois,weights=(1.0,1.0,1.0,1.0)):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"returnbox_utils.bbox_transform_inv(ex_rois,gt_rois,weights).astype(np.float32,copy=False)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectrondataloader.Thedesignisgenericandabstractedawayfromanydetailsoftheminibatch.Aminibatchisadictionaryofblobnamekeysandtheirassociatednumpy(float32orint32)ndarrayvalues.Outlineofthedataloaderdesign:loaderthread\\\\loaderthread\\\\/GPU1enqueuethread->feed->EnqueueOp...->minibatchqueue->...loaderthread/\\\\GPUNenqueuethread->feed->EnqueueOploaderthread/Apoolofloaderthreadsconstructminibatchesthatareputontothesharedminibatchqueue.EachGPUhasanenqueuethreadthatpullsaminibatchofftheminibatchqueue,feedstheminibatchblobsintotheworkspace,andthenrunsanEnqueueBlobsOptoplacetheminibatchblobsintotheGPU\\'sblobsqueue.DuringeachfpropthefirstthingthenetworkdoesisrunaDequeueBlobsOpinordertopopulatetheworkspacewiththeblobsfromaqueuedminibatch.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportsignalimportthreadingimporttimeimportuuidfromsix.movesimportqueueasQueuefromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.roi_data.minibatchimportget_minibatchfromdetectron.roi_data.minibatchimportget_minibatch_blob_namesfromdetectron.utils.coordinatorimportcoordinated_getfromdetectron.utils.coordinatorimportcoordinated_putfromdetectron.utils.coordinatorimportCoordinatorimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classRoIDataLoader:def__init__(self,roidb,num_loaders=4,minibatch_queue_size=64,blobs_queue_capacity=8):self._roidb=roidbself._lock=threading.Lock()self._perm=deque(range(len(self._roidb)))self._cur=0#_permcursor#Theminibatchqueueholdspreparedtrainingdatainhost(CPU)memory#WhentrainingwithN>1GPUs,eachelementintheminibatchqueue#isactuallyapartialminibatchwhichcontributes1/Nofthe#examplestotheoverallminibatchself._minibatch_queue=Queue.Queue(maxsize=minibatch_queue_size)self._blobs_queue_capacity=blobs_queue_capacity#RandomqueuenameincaseoneinstantiatesmultpleRoIDataLoadersself._loader_id=uuid.uuid4()self._blobs_queue_name=\\'roi_blobs_queue_{}\\'.format(self._loader_id)#Loaderthreadsconstruct(partial)minibatchesandputthemonthe#minibatchqueueself._num_loaders=num_loadersself._num_gpus=cfg.NUM_GPUSself.coordinator=Coordinator()self._output_names=get_minibatch_blob_names()self._shuffle_roidb_inds()self.create_threads()defminibatch_loader_thread(self):\"\"\"Loadmini-batchesandputthemontothemini-batchqueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():blobs=self.get_next_minibatch()#Blobsmustbequeuedintheorderspecifiedby#self.get_output_namesordered_blobs=OrderedDict()forkeyinself.get_output_names():assertblobs[key].dtypein(np.int32,np.float32),\\\\\\'Blob{}ofdtype{}musthavedtypeof\\'\\\\\\'np.int32ornp.float32\\'.format(key,blobs[key].dtype)ordered_blobs[key]=blobs[key]coordinated_put(self.coordinator,self._minibatch_queue,ordered_blobs)logger.info(\\'Stoppingmini-batchloadingthread\\')defenqueue_blobs_thread(self,gpu_id,blob_names):\"\"\"Transfermini-batchesfromamini-batchqueuetoaBlobsQueue.\"\"\"withself.coordinator.stop_on_exception():whilenotself.coordinator.should_stop():ifself._minibatch_queue.qsize==0:logger.warning(\\'Mini-batchqueueisempty\\')blobs=coordinated_get(self.coordinator,self._minibatch_queue)self.enqueue_blobs(gpu_id,blob_names,blobs.values())logger.debug(\\'batchqueuesize{}\\'.format(self._minibatch_queue.qsize()))logger.info(\\'Stoppingenqueuethread\\')defget_next_minibatch(self):\"\"\"Returntheblobstobeusedforthenextminibatch.Threadsafe.\"\"\"valid=Falsewhilenotvalid:db_inds=self._get_next_minibatch_inds()minibatch_db=[self._roidb[i]foriindb_inds]blobs,valid=get_minibatch(minibatch_db)returnblobsdef_shuffle_roidb_inds(self):\"\"\"Randomlypermutethetrainingroidb.Notthreadsafe.\"\"\"ifcfg.TRAIN.ASPECT_GROUPING:widths=np.array([r[\\'width\\']forrinself._roidb])heights=np.array([r[\\'height\\']forrinself._roidb])horz=(widths>=heights)vert=np.logical_not(horz)horz_inds=np.where(horz)[0]vert_inds=np.where(vert)[0]horz_inds=np.random.permutation(horz_inds)vert_inds=np.random.permutation(vert_inds)mb=cfg.TRAIN.IMS_PER_BATCHhorz_inds=horz_inds[:(len(horz_inds)//mb)*mb]vert_inds=vert_inds[:(len(vert_inds)//mb)*mb]inds=np.hstack((horz_inds,vert_inds))inds=np.reshape(inds,(-1,mb))row_perm=np.random.permutation(np.arange(inds.shape[0]))inds=np.reshape(inds[row_perm,:],(-1,))self._perm=indselse:self._perm=np.random.permutation(np.arange(len(self._roidb)))self._perm=deque(self._perm)self._cur=0def_get_next_minibatch_inds(self):\"\"\"Returntheroidbindicesforthenextminibatch.Threadsafe.\"\"\"withself._lock:#Weuseadequeandalwaystakethe*first*IMS_PER_BATCHitems#followedby*rotating*thedequesothatweseefreshitems#eachtime.Ifthelengthof_permisnotdivisibleby#IMS_PER_BATCH,thenweendupwrappingaroundthepermutation.db_inds=[self._perm[i]foriinrange(cfg.TRAIN.IMS_PER_BATCH)]self._perm.rotate(-cfg.TRAIN.IMS_PER_BATCH)self._cur+=cfg.TRAIN.IMS_PER_BATCHifself._cur>=len(self._perm):self._shuffle_roidb_inds()returndb_indsdefget_output_names(self):returnself._output_namesdefenqueue_blobs(self,gpu_id,blob_names,blobs):\"\"\"Putamini-batchonaBlobsQueue.\"\"\"assertlen(blob_names)==len(blobs)t=time.time()dev=c2_utils.CudaDevice(gpu_id)queue_name=\\'gpu_{}/{}\\'.format(gpu_id,self._blobs_queue_name)blob_names=[\\'gpu_{}/{}\\'.format(gpu_id,b)forbinblob_names]for(blob_name,blob)inzip(blob_names,blobs):workspace.FeedBlob(blob_name,blob,device_option=dev)logger.debug(\\'enqueue_blobs{}:workspace.FeedBlob:{}\\'.format(gpu_id,time.time()-t))t=time.time()op=core.CreateOperator(\\'SafeEnqueueBlobs\\',[queue_name]+blob_names,blob_names+[queue_name+\\'_enqueue_status\\'],device_option=dev)workspace.RunOperatorOnce(op)logger.debug(\\'enqueue_blobs{}:workspace.RunOperatorOnce:{}\\'.format(gpu_id,time.time()-t))defcreate_threads(self):#Createmini-batchloaderthreads,eachofwhichbuildsmini-batches#andplacesthemintoaqueueinCPUmemoryself._workers=[threading.Thread(target=self.minibatch_loader_thread)for_inrange(self._num_loaders)]#CreateoneBlobsQueueperGPU#(enqueue_blob_namesareunscoped)enqueue_blob_names=self.create_blobs_queues()#CreateoneenqueuerthreadperGPUself._enqueuers=[threading.Thread(target=self.enqueue_blobs_thread,args=(gpu_id,enqueue_blob_names))forgpu_idinrange(self._num_gpus)]defstart(self,prefill=False):forwinself._workers+self._enqueuers:w.setDaemon(True)w.start()ifprefill:logger.info(\\'Pre-fillingmini-batchqueue...\\')whilenotself._minibatch_queue.full():logger.info(\\'[{:d}/{:d}]\\'.format(self._minibatch_queue.qsize(),self._minibatch_queue.maxsize))time.sleep(0.1)#Detectfailureandshutdownifself.coordinator.should_stop():self.shutdown()breakdefhas_stopped(self):returnself.coordinator.should_stop()defshutdown(self):self.coordinator.request_stop()self.coordinator.wait_for_stop()self.close_blobs_queues()forwinself._workers+self._enqueuers:w.join()defcreate_blobs_queues(self):\"\"\"CreateoneBlobsQueueforeachGPUtoholdmini-batches.\"\"\"forgpu_idinrange(self._num_gpus):withc2_utils.GpuNameScope(gpu_id):workspace.RunOperatorOnce(core.CreateOperator(\\'CreateBlobsQueue\\',[],[self._blobs_queue_name],num_blobs=len(self.get_output_names()),capacity=self._blobs_queue_capacity))returnself.create_enqueue_blobs()defclose_blobs_queues(self):\"\"\"CloseaBlobsQueue.\"\"\"forgpu_idinrange(self._num_gpus):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):workspace.RunOperatorOnce(core.CreateOperator(\\'CloseBlobsQueue\\',[self._blobs_queue_name],[]))defcreate_enqueue_blobs(self):blob_names=self.get_output_names()enqueue_blob_names=[\\'{}_enqueue_{}\\'.format(b,self._loader_id)forbinblob_names]forgpu_idinrange(self._num_gpus):withc2_utils.NamedCudaScope(gpu_id):forblobinenqueue_blob_names:workspace.CreateBlob(core.ScopedName(blob))returnenqueue_blob_namesdefregister_sigint_handler(self):defsignal_handler(signal,frame):logger.info(\\'SIGINT:ShuttingdownRoIDataLoaderthreadsandexiting...\\')self.shutdown()signal.signal(signal.SIGINT,signal_handler)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"ConstructminibatchesforDetectronnetworks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.roi_data.retinanetasretinanet_roi_dataimportdetectron.roi_data.rpnasrpn_roi_dataimportdetectron.utils.blobasblob_utilslogger=logging.getLogger(__name__)defget_minibatch_blob_names(is_training=True):\"\"\"Returnblobnamesintheorderinwhichtheyarereadbythedataloader.\"\"\"#datablob:holdsabatchofNimages,eachwith3channelsblob_names=[\\'data\\']ifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFasterR-CNNblob_names+=rpn_roi_data.get_rpn_blob_names(is_training=is_training)elifcfg.RETINANET.RETINANET_ON:blob_names+=retinanet_roi_data.get_retinanet_blob_names(is_training=is_training)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsblob_names+=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=is_training)returnblob_namesdefget_minibatch(roidb):\"\"\"Givenaroidb,constructaminibatchsampledfromit.\"\"\"#Wecollectblobsfromeachimageontoalistandthenconcatthemintoa#singletensor,henceweinitializeeachblobtoanemptylistblobs={k:[]forkinget_minibatch_blob_names()}#Gettheinputimageblob,formattedforcaffe2im_blob,im_scales=_get_image_blob(roidb)blobs[\\'data\\']=im_blobifcfg.RPN.RPN_ON:#RPN-onlyorend-to-endFaster/MaskR-CNNvalid=rpn_roi_data.add_rpn_blobs(blobs,im_scales,roidb)elifcfg.RETINANET.RETINANET_ON:im_width,im_height=im_blob.shape[3],im_blob.shape[2]#im_width,im_heightcorrespondstothenetworkinput:paddedimage#(ifneeded)widthandheight.Wepassitasinputandslicethedata#accordinglysothatwedon\\'tneedtouseSampleAsOpvalid=retinanet_roi_data.add_retinanet_blobs(blobs,im_scales,roidb,im_width,im_height)else:#FastR-CNNlikemodelstrainedonprecomputedproposalsvalid=fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)returnblobs,validdef_get_image_blob(roidb):\"\"\"Buildsaninputblobfromtheimagesintheroidbatthespecifiedscales.\"\"\"num_images=len(roidb)#Samplerandomscalestouseforeachimageinthisbatchscale_inds=np.random.randint(0,high=len(cfg.TRAIN.SCALES),size=num_images)processed_ims=[]im_scales=[]foriinrange(num_images):im=cv2.imread(roidb[i][\\'image\\'])assertimisnotNone,\\\\\\'Failedtoreadimage\\\\\\'{}\\\\\\'\\'.format(roidb[i][\\'image\\'])ifroidb[i][\\'flipped\\']:im=im[:,::-1,:]target_size=cfg.TRAIN.SCALES[scale_inds[i]]im,im_scale=blob_utils.prep_im_for_blob(im,cfg.PIXEL_MEANS,target_size,cfg.TRAIN.MAX_SIZE)im_scales.append(im_scale)processed_ims.append(im)#Createablobtoholdtheinputimagesblob=blob_utils.im_list_to_blob(processed_ims)returnblob,im_scales#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforFastR-CNNtraining.HandlestheminibatchblobsthatarespecifictoFastR-CNN.OtherblobsthataregenerictoRPN,etc.arehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.keypoint_rcnnaskeypoint_rcnn_roi_dataimportdetectron.roi_data.mask_rcnnasmask_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_fast_rcnn_blob_names(is_training=True):\"\"\"FastR-CNNblobnames.\"\"\"#roisblob:holdsRregionsofinterest,eachisa5-tuple#(batch_idx,x1,y1,x2,y2)specifyinganimagebatchindexanda#rectangle(x1,y1,x2,y2)blob_names=[\\'rois\\']ifis_training:#labels_int32blob:Rcategoricallabelsin[0,...,K]forK#foregroundclassesplusbackgroundblob_names+=[\\'labels_int32\\']ifis_training:#bbox_targetsblob:Rbounding-boxregressiontargetswith4#targetsperclassblob_names+=[\\'bbox_targets\\']#bbox_inside_weightsblob:Atmost4targetsperroiareactive#thisbinaryvectorsepcifiesthesubsetofactivetargetsblob_names+=[\\'bbox_inside_weights\\']blob_names+=[\\'bbox_outside_weights\\']ifis_trainingandcfg.MODEL.MASK_ON:#\\'mask_rois\\':RoIssampledfortrainingthemaskpredictionbranch.#Shapeis(#masks,5)informat(batch_idx,x1,y1,x2,y2).blob_names+=[\\'mask_rois\\']#\\'roi_has_mask\\':binarylabelsfortheRoIsspecifiedin\\'rois\\'#indicatingifeachRoIhasamaskornot.Notethatinsomecases#a*bg*RoIwillhaveanall-1(ignore)maskassociatedwithitin#thecasethatnofgRoIscanbesampled.Shapeis(batchsize).blob_names+=[\\'roi_has_mask_int32\\']#\\'masks_int32\\'holdsbinarymasksfortheRoIsspecifiedin#\\'mask_rois\\'.Shapeis(#fg,M*M)whereMisthegroundtruth#masksize.blob_names+=[\\'masks_int32\\']ifis_trainingandcfg.MODEL.KEYPOINTS_ON:#\\'keypoint_rois\\':RoIssampledfortrainingthekeypointprediction#branch.Shapeis(#instances,5)informat(batch_idx,x1,y1,x2,#y2).blob_names+=[\\'keypoint_rois\\']#\\'keypoint_locations_int32\\':indexofkeypointin#KRCNN.HEATMAP_SIZE**2sizedarray.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_locations_int32\\']#\\'keypoint_weights\\':weightassignedtoeachtargetin#\\'keypoint_locations_int32\\'.Shapeis(#instances).Usedin#SoftmaxWithLoss.blob_names+=[\\'keypoint_weights\\']#\\'keypoint_loss_normalizer\\':optionalnormalizationfactortouseif#cfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.blob_names+=[\\'keypoint_loss_normalizer\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:#SupportforFPNmulti-levelroiswithoutbboxregisn\\'t#implemented(...andmayneverbeimplemented)k_max=cfg.FPN.ROI_MAX_LEVELk_min=cfg.FPN.ROI_MIN_LEVEL#Sameformatasroisblob,butoneperFPNlevelforlvlinrange(k_min,k_max+1):blob_names+=[\\'rois_fpn\\'+str(lvl)]blob_names+=[\\'rois_idx_restore_int32\\']ifis_training:ifcfg.MODEL.MASK_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'mask_rois_fpn\\'+str(lvl)]blob_names+=[\\'mask_rois_idx_restore_int32\\']ifcfg.MODEL.KEYPOINTS_ON:forlvlinrange(k_min,k_max+1):blob_names+=[\\'keypoint_rois_fpn\\'+str(lvl)]blob_names+=[\\'keypoint_rois_idx_restore_int32\\']returnblob_namesdefadd_fast_rcnn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededfortrainingFastR-CNNstylemodels.\"\"\"#SampletrainingRoIsfromeachimageandappendthemtothebloblistsforim_i,entryinenumerate(roidb):frcn_blobs=_sample_rois(entry,im_scales[im_i],im_i)fork,vinfrcn_blobs.items():blobs[k].append(v)#Concatthetrainingbloblistsintotensorsfork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)#AddFPNmultileveltrainingRoIs,ifconfiguredifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois(blobs)#Performanyfinalworkandvaliditychecksafterthecollatingblobsfor#allminibatchimagesvalid=Trueifcfg.MODEL.KEYPOINTS_ON:valid=keypoint_rcnn_roi_data.finalize_keypoint_minibatch(blobs,valid)returnvaliddef_sample_rois(roidb,im_scale,batch_idx):\"\"\"GeneratearandomsampleofRoIscomprisingforegroundandbackgroundexamples.\"\"\"rois_per_image=int(cfg.TRAIN.BATCH_SIZE_PER_IM)fg_rois_per_image=int(np.round(cfg.TRAIN.FG_FRACTION*rois_per_image))max_overlaps=roidb[\\'max_overlaps\\']#SelectforegroundRoIsasthosewith>=FG_THRESHoverlapfg_inds=np.where(max_overlaps>=cfg.TRAIN.FG_THRESH)[0]#Guardagainstthecasewhenanimagehasfewerthanfg_rois_per_image#foregroundRoIsfg_rois_per_this_image=np.minimum(fg_rois_per_image,fg_inds.size)#Sampleforegroundregionswithoutreplacementiffg_inds.size>0:fg_inds=npr.choice(fg_inds,size=fg_rois_per_this_image,replace=False)#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((max_overlaps<cfg.TRAIN.BG_THRESH_HI)&(max_overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#ComputenumberofbackgroundRoIstotakefromthisimage(guarding#againsttherebeingfewerthandesired)bg_rois_per_this_image=rois_per_image-fg_rois_per_this_imagebg_rois_per_this_image=np.minimum(bg_rois_per_this_image,bg_inds.size)#Sampleforegroundregionswithoutreplacementifbg_inds.size>0:bg_inds=npr.choice(bg_inds,size=bg_rois_per_this_image,replace=False)#Theindicesthatwe\\'reselecting(bothfgandbg)keep_inds=np.append(fg_inds,bg_inds)#LabelistheclasseachRoIhasmaxoverlapwithsampled_labels=roidb[\\'max_classes\\'][keep_inds]sampled_labels[fg_rois_per_this_image:]=0#LabelbgRoIswithclass0sampled_boxes=roidb[\\'boxes\\'][keep_inds]bbox_targets,bbox_inside_weights=_expand_bbox_targets(roidb[\\'bbox_targets\\'][keep_inds,:])bbox_outside_weights=np.array(bbox_inside_weights>0,dtype=bbox_inside_weights.dtype)#Scaleroisandformatas(batch_idx,x1,y1,x2,y2)sampled_rois=sampled_boxes*im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_rois.shape[0],1))sampled_rois=np.hstack((repeated_batch_idx,sampled_rois))#BaseFastR-CNNblobsblob_dict=dict(labels_int32=sampled_labels.astype(np.int32,copy=False),rois=sampled_rois,bbox_targets=bbox_targets,bbox_inside_weights=bbox_inside_weights,bbox_outside_weights=bbox_outside_weights)#OptionallyaddMaskR-CNNblobsifcfg.MODEL.MASK_ON:mask_rcnn_roi_data.add_mask_rcnn_blobs(blob_dict,sampled_boxes,roidb,im_scale,batch_idx)#OptionallyaddKeypointR-CNNblobsifcfg.MODEL.KEYPOINTS_ON:keypoint_rcnn_roi_data.add_keypoint_rcnn_blobs(blob_dict,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx)returnblob_dictdef_expand_bbox_targets(bbox_target_data):\"\"\"Bounding-boxregressiontargetsarestoredinacompactformintheroidb.Thisfunctionexpandsthosetargetsintothe4-of-4*Krepresentationusedbythenetwork(i.e.onlyoneclasshasnon-zerotargets).Thelossweightsaresimilarlyexpanded.Returns:bbox_target_data(ndarray):Nx4Kblobofregressiontargetsbbox_inside_weights(ndarray):Nx4Kbloboflossweights\"\"\"num_bbox_reg_classes=cfg.MODEL.NUM_CLASSESifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:num_bbox_reg_classes=2#bgandfgclss=bbox_target_data[:,0]bbox_targets=blob_utils.zeros((clss.size,4*num_bbox_reg_classes))bbox_inside_weights=blob_utils.zeros(bbox_targets.shape)inds=np.where(clss>0)[0]forindininds:cls=int(clss[ind])start=4*clsend=start+4bbox_targets[ind,start:end]=bbox_target_data[ind,1:]bbox_inside_weights[ind,start:end]=(1.0,1.0,1.0,1.0)returnbbox_targets,bbox_inside_weightsdef_add_multilevel_rois(blobs):\"\"\"BydefaulttrainingRoIsareaddedforasinglefeaturemaplevelonly.WhenusingFPN,theRoIsmustbedistributedoverdifferentFPNlevelsaccordingthelevelassignmentheuristic(see:modeling.FPN.map_rois_to_fpn_levels).\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELdef_distribute_rois_over_fpn_levels(rois_blob_name):\"\"\"DistributeroisoverthedifferentFPNlevels.\"\"\"#Gettargetlevelforeachroi#Recallblobroisarein(batch_idx,x1,y1,x2,y2)format,hencetake#theboxcoordinatesfromcolumns1:5target_lvls=fpn.map_rois_to_fpn_levels(blobs[rois_blob_name][:,1:5],lvl_min,lvl_max)#AddperFPNlevelroiblobsnamedlike:_fpnfpn.add_multilevel_roi_blobs(blobs,rois_blob_name,blobs[rois_blob_name],target_lvls,lvl_min,lvl_max)_distribute_rois_over_fpn_levels(\\'rois\\')ifcfg.MODEL.MASK_ON:_distribute_rois_over_fpn_levels(\\'mask_rois\\')ifcfg.MODEL.KEYPOINTS_ON:_distribute_rois_over_fpn_levels(\\'keypoint_rois\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtraining.HandlestheminibatchblobsthatarespecifictoMaskR-CNN.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defadd_mask_rcnn_blobs(blobs,sampled_boxes,roidb,im_scale,batch_idx):\"\"\"AddMaskR-CNNspecificblobstotheinputblobdictionary.\"\"\"#Preparethemasktargetsbyassociatingonegtmasktoeachtrainingroi#thathasafg(non-bg)classlabel.M=cfg.MRCNN.RESOLUTIONpolys_gt_inds=np.where((roidb[\\'gt_classes\\']>0)&(roidb[\\'is_crowd\\']==0))[0]polys_gt=[roidb[\\'segms\\'][i]foriinpolys_gt_inds]boxes_from_polys=segm_utils.polys_to_boxes(polys_gt)fg_inds=np.where(blobs[\\'labels_int32\\']>0)[0]roi_has_mask=blobs[\\'labels_int32\\'].copy()roi_has_mask[roi_has_mask>0]=1iffg_inds.shape[0]>0:#Classlabelsfortheforegroundroismask_class_labels=blobs[\\'labels_int32\\'][fg_inds]masks=blob_utils.zeros((fg_inds.shape[0],M**2),int32=True)#Findoverlapbetweenallforegroundroisandtheboundingboxes#enclosingeachsegmentationrois_fg=sampled_boxes[fg_inds]overlaps_bbfg_bbpolys=box_utils.bbox_overlaps(rois_fg.astype(np.float32,copy=False),boxes_from_polys.astype(np.float32,copy=False))#Mapfromeachfgroistotheindexofthemaskwithhighestoverlap#(measuredbybboxoverlap)fg_polys_inds=np.argmax(overlaps_bbfg_bbpolys,axis=1)#addfgtargetsforiinrange(rois_fg.shape[0]):fg_polys_ind=fg_polys_inds[i]poly_gt=polys_gt[fg_polys_ind]roi_fg=rois_fg[i]#Rasterizetheportionofthepolygonmaskwithinthegivenfgroi#toanMxMbinaryimagemask=segm_utils.polys_to_mask_wrt_box(poly_gt,roi_fg,M)mask=np.array(mask>0,dtype=np.int32)#Ensureit\\'sbinarymasks[i,:]=np.reshape(mask,M**2)else:#Iftherearenofgmasks(itdoeshappen)#Thenetworkcannothandleemptyblobs,sowemustprovideamask#Wesimplytakethefirstbgroi,givenitanall-1\\'smask(ignore#label),andlabelitwithclasszero(bg).bg_inds=np.where(blobs[\\'labels_int32\\']==0)[0]#rois_fgisactuallyonebackgroundroi,butthat\\'sokbecause...rois_fg=sampled_boxes[bg_inds[0]].reshape((1,-1))#Wegiveitan-1\\'sblob(ignorelabel)masks=-blob_utils.ones((1,M**2),int32=True)#Welabelitwithclass=0(background)mask_class_labels=blob_utils.zeros((1,))#Markthatthefirstroihasamaskroi_has_mask[0]=1ifcfg.MRCNN.CLS_SPECIFIC_MASK:masks=_expand_to_class_specific_mask_targets(masks,mask_class_labels)#Scalerois_fgandformatas(batch_idx,x1,y1,x2,y2)rois_fg*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((rois_fg.shape[0],1))rois_fg=np.hstack((repeated_batch_idx,rois_fg))#UpdateblobsdictwithMaskR-CNNblobsblobs[\\'mask_rois\\']=rois_fgblobs[\\'roi_has_mask_int32\\']=roi_has_maskblobs[\\'masks_int32\\']=masksdef_expand_to_class_specific_mask_targets(masks,mask_class_labels):\"\"\"Expandmasksfromshape(#masks,M**2)to(#masks,#classes*M**2)toencodeclassspecificmasktargets.\"\"\"assertmasks.shape[0]==mask_class_labels.shape[0]M=cfg.MRCNN.RESOLUTION#Targetvaluesof-1are\"don\\'tcare\"/ignorelabelsmask_targets=-blob_utils.ones((masks.shape[0],cfg.MODEL.NUM_CLASSES*M**2),int32=True)foriinrange(masks.shape[0]):cls=int(mask_class_labels[i])start=M**2*clsend=start+M**2#Ignorebackgroundinstance#(onlyhappenswhenthereisnofgsamplesinanimage)ifcls>0:mask_targets[i,start:end]=masks[i,:]returnmask_targets#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"MinibatchconstructionforRegionProposalNetworks(RPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportnumpy.randomasnprfromdetectron.core.configimportcfgimportdetectron.roi_data.data_utilsasdata_utilsimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defget_rpn_blob_names(is_training=True):\"\"\"BlobnamesusedbyRPN.\"\"\"#im_info:(height,width,imagescale)blob_names=[\\'im_info\\']ifis_training:#gtboxes:(batch_idx,x1,y1,x2,y2,cls)blob_names+=[\\'roidb\\']ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#SameformatasRPNblobs,butoneperFPNlevelforlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):blob_names+=[\\'rpn_labels_int32_wide_fpn\\'+str(lvl),\\'rpn_bbox_targets_wide_fpn\\'+str(lvl),\\'rpn_bbox_inside_weights_wide_fpn\\'+str(lvl),\\'rpn_bbox_outside_weights_wide_fpn\\'+str(lvl)]else:#SinglelevelRPNblobsblob_names+=[\\'rpn_labels_int32_wide\\',\\'rpn_bbox_targets_wide\\',\\'rpn_bbox_inside_weights_wide\\',\\'rpn_bbox_outside_weights_wide\\']returnblob_namesdefadd_rpn_blobs(blobs,im_scales,roidb):\"\"\"AddblobsneededtrainingRPN-onlyandend-to-endFasterR-CNNmodels.\"\"\"ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELfoas=[]forlvlinrange(k_min,k_max+1):field_stride=2.**lvlanchor_sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),)anchor_aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOSfoa=data_utils.get_field_of_anchors(field_stride,anchor_sizes,anchor_aspect_ratios)foas.append(foa)all_anchors=np.concatenate([f.field_of_anchorsforfinfoas])else:foa=data_utils.get_field_of_anchors(cfg.RPN.STRIDE,cfg.RPN.SIZES,cfg.RPN.ASPECT_RATIOS)all_anchors=foa.field_of_anchorsforim_i,entryinenumerate(roidb):scale=im_scales[im_i]im_height=np.round(entry[\\'height\\']*scale)im_width=np.round(entry[\\'width\\']*scale)gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_rois=entry[\\'boxes\\'][gt_inds,:]*scaleim_info=np.array([[im_height,im_width,scale]],dtype=np.float32)blobs[\\'im_info\\'].append(im_info)#AddRPNtargetsifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:#RPNappliedtomanyfeaturelevels,asintheFPNpaperrpn_blobs=_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_rois)fori,lvlinenumerate(range(k_min,k_max+1)):fork,vinrpn_blobs[i].items():blobs[k+\\'_fpn\\'+str(lvl)].append(v)else:#ClassicalRPN,appliedtoasinglefeaturelevelrpn_blobs=_get_rpn_blobs(im_height,im_width,[foa],all_anchors,gt_rois)fork,vinrpn_blobs.items():blobs[k].append(v)fork,vinblobs.items():ifisinstance(v,list)andlen(v)>0:blobs[k]=np.concatenate(v)valid_keys=[\\'has_visible_keypoints\\',\\'boxes\\',\\'segms\\',\\'seg_areas\\',\\'gt_classes\\',\\'gt_overlaps\\',\\'is_crowd\\',\\'box_to_gt_ind_map\\',\\'gt_keypoints\\']minimal_roidb=[{}for_inrange(len(roidb))]fori,einenumerate(roidb):forkinvalid_keys:ifkine:minimal_roidb[i][k]=e[k]blobs[\\'roidb\\']=blob_utils.serialize(minimal_roidb)#Alwaysreturnvalid=True,sinceRPNminibatchesarevalidbydesignreturnTruedef_get_rpn_blobs(im_height,im_width,foas,all_anchors,gt_boxes):total_anchors=all_anchors.shape[0]straddle_thresh=cfg.TRAIN.RPN_STRADDLE_THRESHifstraddle_thresh>=0:#Onlykeepanchorsinsidetheimagebyamarginofstraddle_thresh#SetTRAIN.RPN_STRADDLE_THRESHto-1(oralargevalue)tokeepall#anchorsinds_inside=np.where((all_anchors[:,0]>=-straddle_thresh)&(all_anchors[:,1]>=-straddle_thresh)&(all_anchors[:,2]<im_width+straddle_thresh)&(all_anchors[:,3]<im_height+straddle_thresh))[0]#keeponlyinsideanchorsanchors=all_anchors[inds_inside,:]else:inds_inside=np.arange(all_anchors.shape[0])anchors=all_anchorsnum_inside=len(inds_inside)logger.debug(\\'total_anchors:{}\\'.format(total_anchors))logger.debug(\\'inds_inside:{}\\'.format(num_inside))logger.debug(\\'anchors.shape:{}\\'.format(anchors.shape))#Computeanchorlabels:#label=1ispositive,0isnegative,-1isdon\\'tcare(ignore)labels=np.empty((num_inside,),dtype=np.int32)labels.fill(-1)iflen(gt_boxes)>0:#Computeoverlapsbetweentheanchorsandthegtboxesoverlapsanchor_by_gt_overlap=box_utils.bbox_overlaps(anchors,gt_boxes)#Mapfromanchortogtboxthathashighestoverlapanchor_to_gt_argmax=anchor_by_gt_overlap.argmax(axis=1)#Foreachanchor,amountofoverlapwithmostoverlappinggtboxanchor_to_gt_max=anchor_by_gt_overlap[np.arange(num_inside),anchor_to_gt_argmax]#Mapfromgtboxtoananchorthathashighestoverlapgt_to_anchor_argmax=anchor_by_gt_overlap.argmax(axis=0)#Foreachgtbox,amountofoverlapwithmostoverlappinganchorgt_to_anchor_max=anchor_by_gt_overlap[gt_to_anchor_argmax,np.arange(anchor_by_gt_overlap.shape[1])]#Findallanchorsthatsharethemaxoverlapamount#(thisincludesmanyties)anchors_with_max_overlap=np.where(anchor_by_gt_overlap==gt_to_anchor_max)[0]#Fglabel:foreachgtuseanchorswithhighestoverlap#(includingties)labels[anchors_with_max_overlap]=1#Fglabel:abovethresholdIOUlabels[anchor_to_gt_max>=cfg.TRAIN.RPN_POSITIVE_OVERLAP]=1#subsamplepositivelabelsifwehavetoomanynum_fg=int(cfg.TRAIN.RPN_FG_FRACTION*cfg.TRAIN.RPN_BATCH_SIZE_PER_IM)fg_inds=np.where(labels==1)[0]iflen(fg_inds)>num_fg:disable_inds=npr.choice(fg_inds,size=(len(fg_inds)-num_fg),replace=False)labels[disable_inds]=-1fg_inds=np.where(labels==1)[0]#subsamplenegativelabelsifwehavetoomany#(sampleswithreplacement,butsincethesetofbgindsislargemost#sampleswillnothaverepeats)num_bg=cfg.TRAIN.RPN_BATCH_SIZE_PER_IM-np.sum(labels==1)bg_inds=np.where(anchor_to_gt_max<cfg.TRAIN.RPN_NEGATIVE_OVERLAP)[0]iflen(bg_inds)>num_bg:enable_inds=bg_inds[npr.randint(len(bg_inds),size=num_bg)]else:enable_inds=bg_indslabels[enable_inds]=0bg_inds=np.where(labels==0)[0]bbox_targets=np.zeros((num_inside,4),dtype=np.float32)bbox_targets[fg_inds,:]=data_utils.compute_targets(anchors[fg_inds,:],gt_boxes[anchor_to_gt_argmax[fg_inds],:])#Bboxregressionlosshastheform:#loss(x)=weight_outside*L(weight_inside*x)#Insideweightsallowustosetzerolossonanelement-wisebasis#Bboxregressionisonlytrainedonpositiveexamplessowesettheir#weightsto1.0(orotherwiseifconfigisdifferent)and0otherwisebbox_inside_weights=np.zeros((num_inside,4),dtype=np.float32)bbox_inside_weights[labels==1,:]=(1.0,1.0,1.0,1.0)#Thebboxregressionlossonlyaveragesbythenumberofimagesinthe#mini-batch,whereasweneedtoaveragebythetotalnumberofexample#anchorsselected#Outsideweightsareusedtoscaleeachelement-wiselosssothefinal#averageoverthemini-batchiscorrectbbox_outside_weights=np.zeros((num_inside,4),dtype=np.float32)#uniformweightingofexamples(givennon-uniformsampling)num_examples=np.sum(labels>=0)bbox_outside_weights[labels==1,:]=1.0/num_examplesbbox_outside_weights[labels==0,:]=1.0/num_examples#Mapuptooriginalsetofanchorslabels=data_utils.unmap(labels,total_anchors,inds_inside,fill=-1)bbox_targets=data_utils.unmap(bbox_targets,total_anchors,inds_inside,fill=0)bbox_inside_weights=data_utils.unmap(bbox_inside_weights,total_anchors,inds_inside,fill=0)bbox_outside_weights=data_utils.unmap(bbox_outside_weights,total_anchors,inds_inside,fill=0)#Splitthegeneratedlabels,etc.intolabelspereachfieldofanchorsblobs_out=[]start_idx=0forfoainfoas:H=foa.field_sizeW=foa.field_sizeA=foa.num_cell_anchorsend_idx=start_idx+H*W*A_labels=labels[start_idx:end_idx]_bbox_targets=bbox_targets[start_idx:end_idx,:]_bbox_inside_weights=bbox_inside_weights[start_idx:end_idx,:]_bbox_outside_weights=bbox_outside_weights[start_idx:end_idx,:]start_idx=end_idx#labelsoutputwithshape(1,A,height,width)_labels=_labels.reshape((1,H,W,A)).transpose(0,3,1,2)#bbox_targetsoutputwithshape(1,4*A,height,width)_bbox_targets=_bbox_targets.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_inside_weightsoutputwithshape(1,4*A,height,width)_bbox_inside_weights=_bbox_inside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)#bbox_outside_weightsoutputwithshape(1,4*A,height,width)_bbox_outside_weights=_bbox_outside_weights.reshape((1,H,W,A*4)).transpose(0,3,1,2)blobs_out.append(dict(rpn_labels_int32_wide=_labels,rpn_bbox_targets_wide=_bbox_targets,rpn_bbox_inside_weights_wide=_bbox_inside_weights,rpn_bbox_outside_weights_wide=_bbox_outside_weights))returnblobs_out[0]iflen(blobs_out)==1elseblobs_out#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ConstructminibatchesforMaskR-CNNtrainingwhenkeypointsareenabled.HandlestheminibatchblobsthatarespecifictotrainingMaskR-CNNforkeypointdetection.OtherblobsthataregenerictoRPNorFast/erR-CNNarehandledbytheirrespecitiveroi_datamodules.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defadd_keypoint_rcnn_blobs(blobs,roidb,fg_rois_per_image,fg_inds,im_scale,batch_idx):\"\"\"AddMaskR-CNNkeypointspecificblobstothegivenblobsdictionary.\"\"\"#Note:gt_indsmustmatchhowthey\\'recomputedin#datasets.json_dataset._merge_proposal_boxes_into_roidbgt_inds=np.where(roidb[\\'gt_classes\\']>0)[0]max_overlaps=roidb[\\'max_overlaps\\']gt_keypoints=roidb[\\'gt_keypoints\\']ind_kp=gt_inds[roidb[\\'box_to_gt_ind_map\\']]within_box=_within_box(gt_keypoints[ind_kp,:,:],roidb[\\'boxes\\'])vis_kp=gt_keypoints[ind_kp,2,:]>0is_visible=np.sum(np.logical_and(vis_kp,within_box),axis=1)>0kp_fg_inds=np.where(np.logical_and(max_overlaps>=cfg.TRAIN.FG_THRESH,is_visible))[0]kp_fg_rois_per_this_image=np.minimum(fg_rois_per_image,kp_fg_inds.size)ifkp_fg_inds.size>kp_fg_rois_per_this_image:kp_fg_inds=np.random.choice(kp_fg_inds,size=kp_fg_rois_per_this_image,replace=False)sampled_fg_rois=roidb[\\'boxes\\'][kp_fg_inds]box_to_gt_ind_map=roidb[\\'box_to_gt_ind_map\\'][kp_fg_inds]num_keypoints=gt_keypoints.shape[2]sampled_keypoints=-np.ones((len(sampled_fg_rois),gt_keypoints.shape[1],num_keypoints),dtype=gt_keypoints.dtype)foriiinrange(len(sampled_fg_rois)):ind=box_to_gt_ind_map[ii]ifind>=0:sampled_keypoints[ii,:,:]=gt_keypoints[gt_inds[ind],:,:]assertnp.sum(sampled_keypoints[ii,2,:])>0heats,weights=keypoint_utils.keypoints_to_heatmap_labels(sampled_keypoints,sampled_fg_rois)shape=(sampled_fg_rois.shape[0]*cfg.KRCNN.NUM_KEYPOINTS,1)heats=heats.reshape(shape)weights=weights.reshape(shape)sampled_fg_rois*=im_scalerepeated_batch_idx=batch_idx*blob_utils.ones((sampled_fg_rois.shape[0],1))sampled_fg_rois=np.hstack((repeated_batch_idx,sampled_fg_rois))blobs[\\'keypoint_rois\\']=sampled_fg_roisblobs[\\'keypoint_locations_int32\\']=heats.astype(np.int32,copy=False)blobs[\\'keypoint_weights\\']=weightsdeffinalize_keypoint_minibatch(blobs,valid):\"\"\"Finalizetheminibatchafterblobsforallminibatchimageshavebeencollated.\"\"\"min_count=cfg.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCHnum_visible_keypoints=np.sum(blobs[\\'keypoint_weights\\'])valid=(validandlen(blobs[\\'keypoint_weights\\'])>0andnum_visible_keypoints>min_count)#Normalizertouseifcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse.#Seemodeling.model_builder.add_keypoint_lossesnorm=num_visible_keypoints/(cfg.TRAIN.IMS_PER_BATCH*cfg.TRAIN.BATCH_SIZE_PER_IM*cfg.TRAIN.FG_FRACTION*cfg.KRCNN.NUM_KEYPOINTS)blobs[\\'keypoint_loss_normalizer\\']=np.array(norm,dtype=np.float32)returnvaliddef_within_box(points,boxes):\"\"\"Validatewhichkeypointsarecontainedinsideagivenbox.points:Nx2xKboxes:Nx4output:NxK\"\"\"x_within=np.logical_and(points[:,0,:]>=np.expand_dims(boxes[:,0],axis=1),points[:,0,:]<=np.expand_dims(boxes[:,2],axis=1))y_within=np.logical_and(points[:,1,:]>=np.expand_dims(boxes[:,1],axis=1),points[:,1,:]<=np.expand_dims(boxes[:,3],axis=1))returnnp.logical_and(x_within,y_within)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSmoothL1LossTest(unittest.TestCase):deftest_forward_and_gradient(self):Y=np.random.randn(128,4*21).astype(np.float32)Y_hat=np.random.randn(128,4*21).astype(np.float32)inside_weights=np.random.randn(128,4*21).astype(np.float32)inside_weights[inside_weights<0]=0outside_weights=np.random.randn(128,4*21).astype(np.float32)outside_weights[outside_weights<0]=0scale=np.random.random()beta=np.random.random()op=core.CreateOperator(\\'SmoothL1Loss\\',[\\'Y_hat\\',\\'Y\\',\\'inside_weights\\',\\'outside_weights\\'],[\\'loss\\'],scale=scale,beta=beta)gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[Y_hat,Y,inside_weights,outside_weights],0,[0])self.assertTrue(grad.shape==grad_estimated.shape,\\'Failcheck:grad.shape!=grad_estimated.shape\\')#Toinspectthegradientandestimatedgradient:#np.set_printoptions(precision=3,suppress=True)#print(\\'grad:\\')#print(grad)#print(\\'grad_estimated:\\')#print(grad_estimated)self.assertTrue(res)if__name__==\\'__main__\\':c2_utils.import_detectron_ops()assert\\'SmoothL1Loss\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfrompycocotoolsimportmaskasCOCOmaskimportdetectron.utils.boxesasbox_utilsdefrandom_boxes(mean_box,stdev,N):boxes=np.random.randn(N,4)*stdev+mean_boxreturnboxes.astype(dtype=np.float32)classTestBboxTransform(unittest.TestCase):deftest_bbox_transform_and_inverse(self):weights=(5,5,10,10)src_boxes=random_boxes([10,10,20,20],1,10)dst_boxes=random_boxes([10,10,20,20],1,10)deltas=box_utils.bbox_transform_inv(src_boxes,dst_boxes,weights=weights)dst_boxes_reconstructed=box_utils.bbox_transform(src_boxes,deltas,weights=weights)np.testing.assert_array_almost_equal(dst_boxes,dst_boxes_reconstructed,decimal=5)deftest_bbox_dataset_to_prediction_roundtrip(self):\"\"\"Simulatetheprocessofreadingaground-truthboxfromadataset,makepredictionsfromproposals,convertthepredictionsbacktothedatasetformat,andthenusetheCOCOAPItocomputeIoUoverlapbetweenthegtboxandthepredictions.TheseshouldhaveIoUof1.\"\"\"weights=(5,5,10,10)#1/\"read\"aboxfromadatasetinthedefault(x1,y1,w,h)formatgt_xywh_box=[10,20,100,150]#2/convertittoourinternal(x1,y1,x2,y2)formatgt_xyxy_box=box_utils.xywh_to_xyxy(gt_xywh_box)#3/considernearbyproposalboxesprop_xyxy_boxes=random_boxes(gt_xyxy_box,10,10)#4/computeproposal-to-gttransformationdeltasdeltas=box_utils.bbox_transform_inv(prop_xyxy_boxes,np.array([gt_xyxy_box]),weights=weights)#5/usedeltastotransformproposalstoxyxypredictedboxpred_xyxy_boxes=box_utils.bbox_transform(prop_xyxy_boxes,deltas,weights=weights)#6/convertxyxypredictedboxtoxywhpredictedboxpred_xywh_boxes=box_utils.xyxy_to_xywh(pred_xyxy_boxes)#7/useCOCOAPItocomputeIoUnot_crowd=[int(False)]*pred_xywh_boxes.shape[0]ious=COCOmask.iou(pred_xywh_boxes,np.array([gt_xywh_box]),not_crowd)np.testing.assert_array_almost_equal(ious,np.ones(ious.shape))deftest_cython_bbox_iou_against_coco_api_bbox_iou(self):\"\"\"CheckthatourcythonimplementationofboundingboxIoUoverlapmatchestheCOCOAPIimplementation.\"\"\"def_do_test(b1,b2):#ComputeIoUoverlapwiththecythonimplementationcython_iou=box_utils.bbox_overlaps(b1,b2)#ComputeIoUoverlapwiththeCOCOAPIimplementation#(requiresconvertingboxesfromxyxytoxywhformat)xywh_b1=box_utils.xyxy_to_xywh(b1)xywh_b2=box_utils.xyxy_to_xywh(b2)not_crowd=[int(False)]*b2.shape[0]coco_ious=COCOmask.iou(xywh_b1,xywh_b2,not_crowd)#IoUsshouldbesimilarnp.testing.assert_array_almost_equal(cython_iou,coco_ious,decimal=5)#Testsmallboxesb1=random_boxes([10,10,20,20],5,10)b2=random_boxes([10,10,20,20],5,10)_do_test(b1,b2)#Testbiggerboxesb1=random_boxes([10,10,110,20],20,10)b2=random_boxes([10,10,110,20],20,10)_do_test(b1,b2)if__name__==\\'__main__\\':unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimporttempfilefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.netasnuc2_utils.import_detectron_ops()defget_params(model):blobs={}#gpu_0blobswithunscoped_nameaskeyall_blobs={}#allblobswithscopednameaskey#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)forparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)if\\'gpu_0\\'inscoped_name:blobs[unscoped_name]=workspace.FetchBlob(scoped_name)all_blobs[scoped_name]=workspace.FetchBlob(scoped_name)returnblobs,all_blobsdefadd_momentum_init_ops(model):forparaminmodel.TrainableParams(gpu_id=0):model.param_init_net.GaussianFill([param+\\'_momentum\\'],param+\\'_momentum\\',mean=0.0,std=1.0)definit_weights(model):#initweightsingpu_id=0andthenbroadcastworkspace.RunNetOnce(model.param_init_net)nu.broadcast_parameters(model)deftest_restore_checkpoint():#CreateModelmodel=model_builder.create(cfg.MODEL.TYPE,train=True)add_momentum_init_ops(model)init_weights(model)#Fillinputblobsroidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)model_builder.add_training_inputs(model,roidb=roidb)workspace.CreateNet(model.net)#Bookkeepingforcheckpointcreationiter_num=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)chk_file_path=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(iter_num))checkpoints[iter_num]=chk_file_path#Savemodelweightsnu.save_model_to_weights_file(checkpoints[iter_num],model)orig_gpu_0_params,orig_all_params=get_params(model)#Changethemodelweightsinit_weights(model)#Reloadtheweightsinthemodelnu.initialize_gpu_from_weights_file(model,chk_file_path,gpu_id=0)nu.broadcast_parameters(model)shutil.rmtree(cfg.OUTPUT_DIR)_,restored_all_params=get_params(model)#Checkifallparamsareloadedcorrectlyforscoped_name,blobinorig_all_params.items():np.testing.assert_array_equal(blob,restored_all_params[scoped_name])#Checkifbroadcast_parametersworksforscoped_name,blobinrestored_all_params.items():unscoped_name=c2_utils.UnscopeName(scoped_name)np.testing.assert_array_equal(blob,orig_gpu_0_params[unscoped_name])if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)output_dir=tempfile.mkdtemp()#Generateconfigfortestcfg.MODEL.TYPE=\\'generalized_rcnn\\'cfg.MODEL.CONV_BODY=\\'FPN.add_fpn_ResNet50_conv5_body\\'cfg.MODEL.NUM_CLASSES=81cfg.MODEL.FASTER_RCNN=Truecfg.FPN.FPN_ON=Truecfg.FPN.MULTILEVEL_ROIS=Truecfg.FPN.MULTILEVEL_RPN=Truecfg.FAST_RCNN.ROI_BOX_HEAD=\\'fast_rcnn_heads.add_roi_2mlp_head\\'cfg.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'cfg.OUTPUT_DIR=output_dircfg.TRAIN.DATASETS=(\\'coco_2014_minival\\',)cfg.TRAIN.WEIGHTS=b\\'\\'fornum_gpuinrange(workspace.NumCudaDevices()):cfg.immutable(False)cfg.NUM_GPUS=num_gpu+1assert_and_infer_cfg()test_restore_checkpoint()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsclassZeroEvenOpTest(unittest.TestCase):def_run_zero_even_op(self,X):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdef_run_zero_even_op_gpu(self,X):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'ZeroEven\\',[\\'X\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')returnYdeftest_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op(X)deftest_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_throws_on_non_1D_arrays(self):X=np.zeros((2,2),dtype=np.float32)withself.assertRaisesRegex(RuntimeError,\\'X\\\\.ndim\\\\(\\\\)==1\\'):self._run_zero_even_op_gpu(X)deftest_gpu_handles_empty_arrays(self):X=np.array([],dtype=np.float32)Y_exp=np.copy(X)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_sets_vals_at_even_inds_to_zero(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[0::2],Y_exp[0::2])deftest_gpu_preserves_vals_at_odd_inds(self):X=np.array([0,1,2,3,4],dtype=np.float32)Y_exp=np.array([0,1,0,3,0],dtype=np.float32)Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act[1::2],Y_exp[1::2])deftest_gpu_handles_even_length_arrays(self):X=np.random.rand(64).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)deftest_gpu_handles_odd_length_arrays(self):X=np.random.randn(77).astype(np.float32)Y_exp=np.copy(X)Y_exp[0::2]=0.0Y_act=self._run_zero_even_op_gpu(X)np.testing.assert_allclose(Y_act,Y_exp)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_custom_ops()assert\\'ZeroEven\\'inworkspace.RegisteredOperators()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.loggingaslogging_utilsimportdetectron.utils.c2asc2_utilsclassBatchPermutationOpTest(unittest.TestCase):def_run_op_test(self,X,I,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'BatchPermutation\\',[\\'X\\',\\'I\\'],[\\'Y\\'])workspace.FeedBlob(\\'X\\',X)workspace.FeedBlob(\\'I\\',I)workspace.RunOperatorOnce(op)Y=workspace.FetchBlob(\\'Y\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.1,threshold=0.001,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[X,I],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')Y_ref=X[I]np.testing.assert_allclose(Y,Y_ref,rtol=1e-5,atol=1e-08)def_run_speed_test(self,iters=5,N=1024):\"\"\"ThisfunctionprovidesanexampleofhowtobenchmarkcustomoperatorsusingtheCaffe2\\'prof_dag\\'networkexecutiontype.Pleasenotethatfor\\'prof_dag\\'towork,Caffe2mustbecompiledwithprofilingsupportusingthe`-DUSE_PROF=ON`optionpassedto`cmake`whenbuildingCaffe2.\"\"\"net=core.Net(\\'test\\')net.Proto().type=\\'prof_dag\\'net.Proto().num_workers=2Y=net.BatchPermutation([\\'X\\',\\'I\\'],\\'Y\\')Y_flat=net.FlattenToVec([Y],\\'Y_flat\\')loss=net.AveragedLoss([Y_flat],\\'loss\\')net.AddGradientOperators([loss])workspace.CreateNet(net)X=np.random.randn(N,256,14,14)for_iinrange(iters):I=np.random.permutation(N)workspace.FeedBlob(\\'X\\',X.astype(np.float32))workspace.FeedBlob(\\'I\\',I.astype(np.int32))workspace.RunNet(net.Proto().name)np.testing.assert_allclose(workspace.FetchBlob(\\'Y\\'),X[I],rtol=1e-5,atol=1e-08)deftest_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([0,1],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)I=np.array([1,0],dtype=np.int32)self._run_op_test(A,I,check_grad=True)A=np.random.randn(10,3,5,7).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)self._run_op_test(A,I,check_grad=True)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)I=np.array(np.random.permutation(10),dtype=np.int32)withself.assertRaises(RuntimeError):self._run_op_test(A,I)#Seedocstringin_run_speed_test#deftest_perf(self):#withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):#self._run_speed_test()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'BatchPermutation\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingimportunittestimportunittest.mockasmockfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.utils.loggingaslogging_utilsdefget_roidb_blobs(roidb):blobs={}blobs[\\'data\\']=np.stack([entry[\\'data\\']forentryinroidb])returnblobs,Truedefget_net(data_loader,name):logger=logging.getLogger(__name__)blob_names=data_loader.get_output_names()net=core.Net(name)net.type=\\'dag\\'forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)workspace.CreateBlob(blob)net.DequeueBlobs(data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))returnnetdefget_roidb_sample_data(sample_data):roidb=[]for_inrange(np.random.randint(4,10)):roidb.append({\\'data\\':sample_data})returnroidbdefcreate_loader_and_network(sample_data,name):roidb=get_roidb_sample_data(sample_data)loader=RoIDataLoader(roidb)net=get_net(loader,\\'dequeue_net_train\\')loader.register_sigint_handler()loader.start(prefill=False)returnloader,netdefrun_net(net):workspace.RunNetOnce(net)gpu_dev=core.DeviceOption(caffe2_pb2.CUDA,0)name_scope=\\'gpu_{}\\'.format(0)withcore.NameScope(name_scope):withcore.DeviceScope(gpu_dev):data=workspace.FetchBlob(core.ScopedName(\\'data\\'))returndataclassTestRoIDataLoader(unittest.TestCase):@mock.patch(\\'detectron.roi_data.loader.get_minibatch_blob_names\\',return_value=[u\\'data\\'])@mock.patch(\\'detectron.roi_data.loader.get_minibatch\\',side_effect=get_roidb_blobs)deftest_two_parallel_loaders(self,_1,_2):train_data=np.random.rand(2,3,3).astype(np.float32)train_loader,train_net=create_loader_and_network(train_data,\\'dequeue_net_train\\')test_data=np.random.rand(2,4,4).astype(np.float32)test_loader,test_net=create_loader_and_network(test_data,\\'dequeue_net_test\\')for_inrange(5):data=run_net(train_net)self.assertEqual(data[0].tolist(),train_data.tolist())data=run_net(test_net)self.assertEqual(data[0].tolist(),test_data.tolist())test_loader.shutdown()train_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=logging_utils.setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)cfg.TRAIN.ASPECT_GROUPING=Falsecfg.NUM_GPUS=2assert_and_infer_cfg()unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Exampleusage:#data_loader_benchmark.par\\\\#NUM_GPUS2\\\\#TRAIN.DATASETS\"(\\'voc_2007_trainval\\',)\"\\\\#TRAIN.PROPOSAL_FILES/path/to/voc_2007_trainval/proposals.pkl\\\\#DATA_LOADER.NUM_THREADS4\\\\#DATA_LOADER.MINIBATCH_QUEUE_SIZE64\\\\#DATA_LOADER.BLOBS_QUEUE_CAPACITY8from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportloggingimportnumpyasnpimportpprintimportsysimporttimefromcaffe2.pythonimportcorefromcaffe2.pythonimportmujifromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.roi_data.loaderimportRoIDataLoaderfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--num-batches\\',dest=\\'num_batches\\',help=\\'Numberofminibatchestorun\\',default=200,type=int)parser.add_argument(\\'--sleep\\',dest=\\'sleep_time\\',help=\\'Secondssleeptoemulateanetworkrunning\\',default=0.1,type=float)parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--x-factor\\',dest=\\'x_factor\\',help=\\'simulatesx-factormoreGPUs\\',default=1,type=int)parser.add_argument(\\'--profiler\\',dest=\\'profiler\\',help=\\'profileminibatchloadtime\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefloader_loop(roi_data_loader):load_timer=Timer()iters=100foriinrange(iters):load_timer.tic()roi_data_loader.get_next_minibatch()load_timer.toc()print(\\'{:d}/{:d}:Averageget_next_minibatchtime:{:.3f}s\\'.format(i+1,iters,load_timer.average_time))defmain(opts):logger=logging.getLogger(__name__)roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)blob_names=roi_data_loader.get_output_names()net=core.Net(\\'dequeue_net\\')net.type=\\'dag\\'all_blobs=[]forgpu_idinrange(cfg.NUM_GPUS):withcore.NameScope(\\'gpu_{}\\'.format(gpu_id)):withcore.DeviceScope(muji.OnGPU(gpu_id)):forblob_nameinblob_names:blob=core.ScopedName(blob_name)all_blobs.append(blob)workspace.CreateBlob(blob)logger.info(\\'Creatingblob:{}\\'.format(blob))net.DequeueBlobs(roi_data_loader._blobs_queue_name,blob_names)logger.info(\"Protobuf:\\\\n\"+str(net.Proto()))ifopts.profiler:importcProfilecProfile.runctx(\\'loader_loop(roi_data_loader)\\',globals(),locals(),sort=\\'cumulative\\')else:loader_loop(roi_data_loader)roi_data_loader.register_sigint_handler()roi_data_loader.start(prefill=True)total_time=0foriinrange(opts.num_batches):start_t=time.time()for_inrange(opts.x_factor):workspace.RunNetOnce(net)total_time+=(time.time()-start_t)/opts.x_factorlogger.info(\\'{:d}/{:d}:Avergedequeuetime:{:.3f}s[{:d}/{:d}]\\'.format(i+1,opts.num_batches,total_time/(i+1),roi_data_loader._minibatch_queue.qsize(),cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE))#Sleeptosimulatethetimetakenbyrunningalittlenetworktime.sleep(opts.sleep_time)#Toinspect:#blobs=workspace.FetchBlobs(all_blobs)#fromIPythonimportembed;embed()logger.info(\\'Shuttingdowndataloader...\\')roi_data_loader.shutdown()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)logger.setLevel(logging.DEBUG)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)np.random.seed(cfg.RNG_SEED)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Runningwithconfig:\\')logger.info(pprint.pformat(cfg))main(args)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportunittestfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportgradient_checkerfromcaffe2.pythonimportworkspaceimportdetectron.utils.c2asc2_utilsimportdetectron.utils.loggingaslogging_utilsclassSpatialNarrowAsOpTest(unittest.TestCase):def_run_test(self,A,B,check_grad=False):withcore.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA,0)):op=core.CreateOperator(\\'SpatialNarrowAs\\',[\\'A\\',\\'B\\'],[\\'C\\'])workspace.FeedBlob(\\'A\\',A)workspace.FeedBlob(\\'B\\',B)workspace.RunOperatorOnce(op)C=workspace.FetchBlob(\\'C\\')ifcheck_grad:gc=gradient_checker.GradientChecker(stepsize=0.005,threshold=0.005,device_option=core.DeviceOption(caffe2_pb2.CUDA,0))res,grad,grad_estimated=gc.CheckSimple(op,[A,B],0,[0])self.assertTrue(res,\\'Gradcheckfailed\\')dims=C.shapeC_ref=A[:dims[0],:dims[1],:dims[2],:dims[3]]np.testing.assert_allclose(C,C_ref,rtol=1e-5,atol=1e-08)deftest_small_forward_and_gradient(self):A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,2,2).astype(np.float32)self._run_test(A,B,check_grad=True)A=np.random.randn(2,3,5,7).astype(np.float32)B=np.random.randn(2,3,5).astype(np.float32)self._run_test(A,B,check_grad=True)deftest_large_forward(self):A=np.random.randn(2,256,42,100).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)A=np.random.randn(2,256,42,87).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)self._run_test(A,B)deftest_size_exceptions(self):A=np.random.randn(2,256,42,86).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)A=np.random.randn(2,255,42,88).astype(np.float32)B=np.random.randn(2,256,35,87).astype(np.float32)withself.assertRaises(RuntimeError):self._run_test(A,B)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])c2_utils.import_detectron_ops()assert\\'SpatialNarrowAs\\'inworkspace.RegisteredOperators()logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimporttempfileimportunittestfromdetectron.core.configimportcfgfromdetectron.utils.collectionsimportAttrDictimportdetectron.core.configascore_configimportdetectron.utils.envasenvuimportdetectron.utils.loggingaslogging_utilsclassTestAttrDict(unittest.TestCase):deftest_immutability(self):#Toplevelimmutablea=AttrDict()a.foo=0a.immutable(True)withself.assertRaises(AttributeError):a.foo=1a.bar=1asserta.is_immutable()asserta.foo==0a.immutable(False)assertnota.is_immutable()a.foo=1asserta.foo==1#Recursivelyimmutablea.level1=AttrDict()a.level1.foo=0a.level1.level2=AttrDict()a.level1.level2.foo=0a.immutable(True)asserta.is_immutable()withself.assertRaises(AttributeError):a.level1.level2.foo=1a.level1.bar=1asserta.level1.level2.foo==0#Serializeimmutabilitystatea.immutable(True)a2=core_config.load_cfg(envu.yaml_dump(a))asserta.is_immutable()asserta2.is_immutable()classTestCfg(unittest.TestCase):deftest_copy_cfg(self):cfg2=copy.deepcopy(cfg)s=cfg.MODEL.TYPEcfg2.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_cfg(self):#Test:mergefromdeepcopys=\\'dummy0\\'cfg2=copy.deepcopy(cfg)cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergefromyamls=\\'dummy1\\'cfg2=core_config.load_cfg(envu.yaml_dump(cfg))cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithavalidkeys=\\'dummy2\\'cfg2=AttrDict()cfg2.MODEL=AttrDict()cfg2.MODEL.TYPE=score_config.merge_cfg_from_cfg(cfg2)assertcfg.MODEL.TYPE==s#Test:mergewithaninvalidkeys=\\'dummy3\\'cfg2=AttrDict()cfg2.FOO=AttrDict()cfg2.FOO.BAR=swithself.assertRaises(KeyError):core_config.merge_cfg_from_cfg(cfg2)#Test:mergewithconvertedtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=[1]core_config.merge_cfg_from_cfg(cfg2)asserttype(cfg.TRAIN.SCALES)istupleassertcfg.TRAIN.SCALES[0]==1#Test:mergewithinvalidtypecfg2=AttrDict()cfg2.TRAIN=AttrDict()cfg2.TRAIN.SCALES=1withself.assertRaises(ValueError):core_config.merge_cfg_from_cfg(cfg2)deftest_merge_cfg_from_file(self):withtempfile.NamedTemporaryFile()asf:envu.yaml_dump(cfg,f)s=cfg.MODEL.TYPEcfg.MODEL.TYPE=\\'dummy\\'assertcfg.MODEL.TYPE!=score_config.merge_cfg_from_file(f.name)assertcfg.MODEL.TYPE==sdeftest_merge_cfg_from_list(self):opts=[\\'TRAIN.SCALES\\',\\'(100,)\\',\\'MODEL.TYPE\\',u\\'foobar\\',\\'NUM_GPUS\\',2]assertlen(cfg.TRAIN.SCALES)>0assertcfg.TRAIN.SCALES[0]!=100assertcfg.MODEL.TYPE!=\\'foobar\\'assertcfg.NUM_GPUS!=2core_config.merge_cfg_from_list(opts)asserttype(cfg.TRAIN.SCALES)istupleassertlen(cfg.TRAIN.SCALES)==1assertcfg.TRAIN.SCALES[0]==100assertcfg.MODEL.TYPE==\\'foobar\\'assertcfg.NUM_GPUS==2deftest_deprecated_key_from_list(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"opts=[\\'FINAL_MSG\\',\\'foobar\\',\\'MODEL.DILATION\\',2]withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_list(opts)withself.assertRaises(AttributeError):_=cfg.FINAL_MSG#noqawithself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_deprecated_key_from_file(self):#Youshouldseeloggermessageslike:#\"Deprecatedconfigkey(ignoring):MODEL.DILATION\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.MODEL.DILATION=2envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqacore_config.merge_cfg_from_file(f.name)withself.assertRaises(AttributeError):_=cfg.MODEL.DILATION#noqadeftest_renamed_key_from_list(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"opts=[\\'EXAMPLE.RENAMED.KEY\\',\\'foobar\\']withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_list(opts)deftest_renamed_key_from_file(self):#Youshouldseeloggermessageslike:#\"KeyEXAMPLE.RENAMED.KEYwasrenamedtoEXAMPLE.KEY;#pleaseupdateyourconfig\"withtempfile.NamedTemporaryFile()asf:cfg2=copy.deepcopy(cfg)cfg2.EXAMPLE=AttrDict()cfg2.EXAMPLE.RENAMED=AttrDict()cfg2.EXAMPLE.RENAMED.KEY=\\'foobar\\'envu.yaml_dump(cfg2,f)withself.assertRaises(AttributeError):_=cfg.EXAMPLE.RENAMED.KEY#noqawithself.assertRaises(KeyError):core_config.merge_cfg_from_file(f.name)if__name__==\\'__main__\\':logging_utils.setup_logging(__name__)unittest.main()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Primitivesforrunningmultiplesingle-GPUjobsinparalleloversubrangesofdata.Theseareusedforrunningmulti-GPUinference.SubprocessesareusedtoavoidtheGILsinceinferencemayinvolvenon-trivialamountsofPythoncode.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportnumpyasnpimportsubprocessfromsix.movesimportshlex_quotefromdetectron.core.configimportcfgfromdetectron.utils.ioimportload_objectimportdetectron.utils.envasenvuimportlogginglogger=logging.getLogger(__name__)defprocess_in_parallel(tag,total_range_size,binary,output_dir,opts=\\'\\'):\"\"\"Runthespecifiedbinarycfg.NUM_GPUStimesinparallel,eachtimeasasubprocessthatusesoneGPU.Thebinarymustacceptthecommandlinearguments`--range{start}{end}`thatspecifyadataprocessingrange.\"\"\"#Snapshotthecurrentcfgstateinordertopasstotheinference#subprocessescfg_file=os.path.join(output_dir,\\'{}_range_config.yaml\\'.format(tag))withopen(cfg_file,\\'w\\')asf:envu.yaml_dump(cfg,stream=f)subprocess_env=os.environ.copy()processes=[]subinds=np.array_split(range(total_range_size),cfg.NUM_GPUS)#DetermineGPUstousecuda_visible_devices=os.environ.get(\\'CUDA_VISIBLE_DEVICES\\')ifcuda_visible_devices:gpu_inds=map(int,cuda_visible_devices.split(\\',\\'))assert-1notingpu_inds,\\\\\\'HidingGPUindicesusingthe\\\\\\'-1\\\\\\'indexisnotsupported\\'else:gpu_inds=range(cfg.NUM_GPUS)#Runthebinaryincfg.NUM_GPUSsubprocessesfori,gpu_indinenumerate(gpu_inds):start=subinds[i][0]end=subinds[i][-1]+1subprocess_env[\\'CUDA_VISIBLE_DEVICES\\']=str(gpu_ind)cmd=\\'{binary}--range{start}{end}--cfg{cfg_file}NUM_GPUS1{opts}\\'cmd=cmd.format(binary=shlex_quote(binary),start=int(start),end=int(end),cfg_file=shlex_quote(cfg_file),opts=\\'\\'.join([shlex_quote(opt)foroptinopts]))logger.info(\\'{}rangecommand{}:{}\\'.format(tag,i,cmd))ifi==0:subprocess_stdout=subprocess.PIPEelse:filename=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))subprocess_stdout=open(filename,\\'w\\')#NOQA(closebelow)p=subprocess.Popen(cmd,shell=True,env=subprocess_env,stdout=subprocess_stdout,stderr=subprocess.STDOUT,bufsize=1)processes.append((i,p,start,end,subprocess_stdout))#Logoutputfrominferenceprocessesandcollatetheirresultsoutputs=[]fori,p,start,end,subprocess_stdoutinprocesses:log_subprocess_output(i,p,output_dir,tag,start,end)ifi>0:subprocess_stdout.close()range_file=os.path.join(output_dir,\\'%s_range_%s_%s.pkl\\'%(tag,start,end))range_data=load_object(range_file)outputs.append(range_data)returnoutputsdeflog_subprocess_output(i,p,output_dir,tag,start,end):\"\"\"Capturetheoutputofeachsubprocessandlogitintheparentprocess.Thefirstsubprocess\\'soutputisloggedinrealtime.Theoutputfromtheothersubprocessesisbufferedandthenprintedallatonce(inorder)whensubprocessesfinish.\"\"\"outfile=os.path.join(output_dir,\\'%s_range_%s_%s.stdout\\'%(tag,start,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')logger.info(\\'stdoutofsubprocess%swithrange[%s,%s]\\'%(i,start+1,end))logger.info(\\'#\\'+\\'-\\'*76+\\'#\\')ifi==0:#Streamthepipedstdoutfromthefirstsubprocessinrealtimewithopen(outfile,\\'wb\\')asf:forlineiniter(p.stdout.readline,b\\'\\'):print(line.rstrip().decode(\"utf8\"))f.write(line)p.stdout.close()ret=p.wait()else:#Forsubprocesses>=1,waitanddumptheirlogfileret=p.wait()withopen(outfile,\\'r\\')asf:print(\\'\\'.join(f.readlines()))assertret==0,\\'Rangesubprocessfailed(exitcode:{})\\'.format(ret)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforinteractingwithsegmentationmasksintheCOCOformat.Thefollowingtermsareusedinthismodulemask:abinarymaskencodedasa2Dnumpyarraysegm:asegmentationmaskinoneofthetwoCOCOformats(polygonorRLE)polygon:COCO\\'spolygonformatRLE:COCO\\'srunlengthencodingformat\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportpycocotools.maskasmask_util#Typeusedforstoringmasksinpolygonformat_POLY_TYPE=list#TypeusedforstoringmasksinRLEformat_RLE_TYPE=dictdefis_poly(segm):\"\"\"Determineifsegmisapolygon.Validsegmexpected(polygonorRLE).\"\"\"assertisinstance(segm,(_POLY_TYPE,_RLE_TYPE)),\\\\\\'Invalidsegmtype:{}\\'.format(type(segm))returnisinstance(segm,_POLY_TYPE)defflip_segms(segms,height,width):\"\"\"Left/rightflipeachmaskinalistofmasks.\"\"\"def_flip_poly(poly,width):flipped_poly=np.array(poly)flipped_poly[0::2]=width-np.array(poly[0::2])-1returnflipped_poly.tolist()def_flip_rle(rle,height,width):if\\'counts\\'inrleandtype(rle[\\'counts\\'])==list:#MagicRLEformathandlingpainfullydiscoveredbylookingatthe#COCOAPIshowAnnsfunction.rle=mask_util.frPyObjects([rle],height,width)mask=mask_util.decode(rle)mask=mask[:,::-1,:]rle=mask_util.encode(np.array(mask,order=\\'F\\',dtype=np.uint8))returnrleflipped_segms=[]forsegminsegms:ifis_poly(segm):#Polygonformatflipped_segms.append([_flip_poly(poly,width)forpolyinsegm])else:#RLEformatflipped_segms.append(_flip_rle(segm,height,width))returnflipped_segmsdefpolys_to_mask(polygons,height,width):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.Thepolygonsegmentationisunderstoodtobeenclosedinsideaheightxwidthimage.Theresultingmaskisthereforeofshape(height,width).\"\"\"rle=mask_util.frPyObjects(polygons,height,width)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefmask_to_bbox(mask):\"\"\"Computethetightboundingboxofabinarymask.\"\"\"xs=np.where(np.sum(mask,axis=0)>0)[0]ys=np.where(np.sum(mask,axis=1)>0)[0]iflen(xs)==0orlen(ys)==0:returnNonex0=xs[0]x1=xs[-1]y0=ys[0]y1=ys[-1]returnnp.array((x0,y0,x1,y1),dtype=np.float32)defpolys_to_mask_wrt_box(polygons,box,M):\"\"\"ConvertfromtheCOCOpolygonsegmentationformattoabinarymaskencodedasa2Darrayofdatatypenumpy.float32.ThepolygonsegmentationisunderstoodtobeenclosedinthegivenboxandrasterizedtoanMxMmask.Theresultingmaskisthereforeofshape(M,M).\"\"\"w=box[2]-box[0]h=box[3]-box[1]w=np.maximum(w,1)h=np.maximum(h,1)polygons_norm=[]forpolyinpolygons:p=np.array(poly,dtype=np.float32)p[0::2]=(p[0::2]-box[0])*M/wp[1::2]=(p[1::2]-box[1])*M/hpolygons_norm.append(p)rle=mask_util.frPyObjects(polygons_norm,M,M)mask=np.array(mask_util.decode(rle),dtype=np.float32)#Flattenincasepolygonswasalistmask=np.sum(mask,axis=2)mask=np.array(mask>0,dtype=np.float32)returnmaskdefpolys_to_boxes(polys):\"\"\"Convertalistofpolygonsintoanarrayoftightboundingboxes.\"\"\"boxes_from_polys=np.zeros((len(polys),4),dtype=np.float32)foriinrange(len(polys)):poly=polys[i]x0=min(min(p[::2])forpinpoly)x1=max(max(p[::2])forpinpoly)y0=min(min(p[1::2])forpinpoly)y1=max(max(p[1::2])forpinpoly)boxes_from_polys[i,:]=[x0,y0,x1,y1]returnboxes_from_polysdefrle_mask_voting(top_masks,all_masks,all_dets,iou_thresh,binarize_thresh,method=\\'AVG\\'):\"\"\"Returnsnewmasks(incorrespondencewith`top_masks`)bycombiningmultipleoverlappingmaskscomingfromthepoolof`all_masks`.Twomethodsforcombiningmasksaresupported:\\'AVG\\'usesaweightedaverageofoverlappingmaskpixels;\\'UNION\\'takestheunionofallmaskpixels.\"\"\"iflen(top_masks)==0:returnall_not_crowd=[False]*len(all_masks)top_to_all_overlaps=mask_util.iou(top_masks,all_masks,all_not_crowd)decoded_all_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinall_masks]decoded_top_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleintop_masks]all_boxes=all_dets[:,:4].astype(np.int32)all_scores=all_dets[:,4]#Fillboxsupportwithweightsmask_shape=decoded_all_masks[0].shapemask_weights=np.zeros((len(all_masks),mask_shape[0],mask_shape[1]))forkinrange(len(all_masks)):ref_box=all_boxes[k]x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,mask_shape[1])y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,mask_shape[0])mask_weights[k,y_0:y_1,x_0:x_1]=all_scores[k]mask_weights=np.maximum(mask_weights,1e-5)top_segms_out=[]forkinrange(len(top_masks)):#Cornercaseofemptymaskifdecoded_top_masks[k].sum()==0:top_segms_out.append(top_masks[k])continueinds_to_vote=np.where(top_to_all_overlaps[k]>=iou_thresh)[0]#Onlymatchesitselfiflen(inds_to_vote)==1:top_segms_out.append(top_masks[k])continuemasks_to_vote=[decoded_all_masks[i]foriininds_to_vote]ifmethod==\\'AVG\\':ws=mask_weights[inds_to_vote]soft_mask=np.average(masks_to_vote,axis=0,weights=ws)mask=np.array(soft_mask>binarize_thresh,dtype=np.uint8)elifmethod==\\'UNION\\':#Anypixelthat\\'sonjoinsthemasksoft_mask=np.sum(masks_to_vote,axis=0)mask=np.array(soft_mask>1e-5,dtype=np.uint8)else:raiseNotImplementedError(\\'Method{}isunknown\\'.format(method))rle=mask_util.encode(np.array(mask[:,:,np.newaxis],order=\\'F\\'))[0]top_segms_out.append(rle)returntop_segms_outdefrle_mask_nms(masks,dets,thresh,mode=\\'IOU\\'):\"\"\"Performsgreedynon-maximumsuppressionbasedonanoverlapmeasurementbetweenmasks.Thetypeofmeasurementisdeterminedby`mode`andcanbeeither\\'IOU\\'(standardintersectionoverunion)or\\'IOMA\\'(intersectionovermininumarea).\"\"\"iflen(masks)==0:return[]iflen(masks)==1:return[0]ifmode==\\'IOU\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(union(m1,m2))all_not_crowds=[False]*len(masks)ious=mask_util.iou(masks,masks,all_not_crowds)elifmode==\\'IOMA\\':#Computesious[m1,m2]=area(intersect(m1,m2))/min(area(m1),area(m2))all_crowds=[True]*len(masks)#ious[m1,m2]=area(intersect(m1,m2))/area(m2)ious=mask_util.iou(masks,masks,all_crowds)#...=max(area(intersect(m1,m2))/area(m2),#area(intersect(m2,m1))/area(m1))ious=np.maximum(ious,ious.transpose())elifmode==\\'CONTAINMENT\\':#Computesious[m1,m2]=area(intersect(m1,m2))/area(m2)#Whichmeasureshowmuchm2iscontainedinsidem1all_crowds=[True]*len(masks)ious=mask_util.iou(masks,masks,all_crowds)else:raiseNotImplementedError(\\'Mode{}isunknown\\'.format(mode))scores=dets[:,4]order=np.argsort(-scores)keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=ious[i,order[1:]]inds_to_keep=np.where(ovr<=thresh)[0]order=order[inds_to_keep+1]returnkeepdefrle_masks_to_boxes(masks):\"\"\"ComputestheboundingboxofeachmaskinalistofRLEencodedmasks.\"\"\"iflen(masks)==0:return[]decoded_masks=[np.array(mask_util.decode(rle),dtype=np.float32)forrleinmasks]defget_bounds(flat_mask):inds=np.where(flat_mask>0)[0]returninds.min(),inds.max()boxes=np.zeros((len(decoded_masks),4))keep=[True]*len(decoded_masks)fori,maskinenumerate(decoded_masks):ifmask.sum()==0:keep[i]=Falsecontinueflat_mask=mask.sum(axis=0)x0,x1=get_bounds(flat_mask)flat_mask=mask.sum(axis=1)y0,y1=get_bounds(flat_mask)boxes[i,:]=(x0,y0,x1,y1)returnboxes,np.where(keep)[0]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Anawesomecolormapforreallyneatvisualizations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpdefcolormap(rgb=False):color_list=np.array([0.000,0.447,0.741,0.850,0.325,0.098,0.929,0.694,0.125,0.494,0.184,0.556,0.466,0.674,0.188,0.301,0.745,0.933,0.635,0.078,0.184,0.300,0.300,0.300,0.600,0.600,0.600,1.000,0.000,0.000,1.000,0.500,0.000,0.749,0.749,0.000,0.000,1.000,0.000,0.000,0.000,1.000,0.667,0.000,1.000,0.333,0.333,0.000,0.333,0.667,0.000,0.333,1.000,0.000,0.667,0.333,0.000,0.667,0.667,0.000,0.667,1.000,0.000,1.000,0.333,0.000,1.000,0.667,0.000,1.000,1.000,0.000,0.000,0.333,0.500,0.000,0.667,0.500,0.000,1.000,0.500,0.333,0.000,0.500,0.333,0.333,0.500,0.333,0.667,0.500,0.333,1.000,0.500,0.667,0.000,0.500,0.667,0.333,0.500,0.667,0.667,0.500,0.667,1.000,0.500,1.000,0.000,0.500,1.000,0.333,0.500,1.000,0.667,0.500,1.000,1.000,0.500,0.000,0.333,1.000,0.000,0.667,1.000,0.000,1.000,1.000,0.333,0.000,1.000,0.333,0.333,1.000,0.333,0.667,1.000,0.333,1.000,1.000,0.667,0.000,1.000,0.667,0.333,1.000,0.667,0.667,1.000,0.667,1.000,1.000,1.000,0.000,1.000,1.000,0.333,1.000,1.000,0.667,1.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.167,0.000,0.000,0.333,0.000,0.000,0.500,0.000,0.000,0.667,0.000,0.000,0.833,0.000,0.000,1.000,0.000,0.000,0.000,0.143,0.143,0.143,0.286,0.286,0.286,0.429,0.429,0.429,0.571,0.571,0.571,0.714,0.714,0.714,0.857,0.857,0.857,1.000,1.000,1.000]).astype(np.float32)color_list=color_list.reshape((-1,3))*255ifnotrgb:color_list=color_list[:,::-1]returncolor_list#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Environmenthelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportosimportsysimportyaml#DefaultvalueoftheCMakeinstallprefix_CMAKE_INSTALL_PREFIX=\\'/usr/local\\'#Detectronopslib_DETECTRON_OPS_LIB=\\'libcaffe2_detectron_ops_gpu.so\\'defget_runtime_dir():\"\"\"Retrievethepathtotheruntimedirectory.\"\"\"returnsys.path[0]defget_py_bin_ext():\"\"\"Retrievepythonbinaryextension.\"\"\"return\\'.py\\'defset_up_matplotlib():\"\"\"Setmatplotlibup.\"\"\"importmatplotlib#Useanon-interactivebackendmatplotlib.use(\\'Agg\\')defexit_on_error():\"\"\"Exitfromadetectrontoolwhenthere\\'sanerror.\"\"\"sys.exit(1)defimport_nccl_ops():\"\"\"ImportNCCLops.\"\"\"#ThereisnoneedtoloadNCCLopssincethe#NCCLdependencyisbuiltintotheCaffe2gpulibpassdefget_detectron_ops_lib():\"\"\"RetrieveDetectronopslibrary.\"\"\"#Candidateprefixesfordetectronopslibpathprefixes=[_CMAKE_INSTALL_PREFIX,sys.prefix,sys.exec_prefix]+sys.path#Candidatesubdirsfordetectronopslibsubdirs=[\\'lib\\',\\'torch/lib\\']#Trytofinddetectronopslibforprefixinprefixes:forsubdirinsubdirs:ops_path=os.path.join(prefix,subdir,_DETECTRON_OPS_LIB)ifos.path.exists(ops_path):print(\\'FoundDetectronopslib:{}\\'.format(ops_path))returnops_pathraiseException(\\'Detectronopslibnotfound\\')defget_custom_ops_lib():\"\"\"Retrievecustomopslibrary.\"\"\"det_dir,_=os.path.split(os.path.dirname(__file__))root_dir,_=os.path.split(det_dir)custom_ops_lib=os.path.join(root_dir,\\'build/libcaffe2_detectron_custom_ops_gpu.so\\')assertos.path.exists(custom_ops_lib),\\\\\\'Customopslibnotfoundat\\\\\\'{}\\\\\\'\\'.format(custom_ops_lib)returncustom_ops_lib#YAMLload/dumpfunctionaliasesyaml_load=yaml.loadyaml_dump=yaml.dump#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectionoutputvisualizationmodule.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpimportosimportpycocotools.maskasmask_utilfromdetectron.utils.colormapimportcolormapimportdetectron.utils.envasenvuimportdetectron.utils.keypointsaskeypoint_utils#Matplotlibrequirescertainadjustmentsinsomeenvironments#Musthappenbeforeimportingmatplotlibenvu.set_up_matplotlib()importmatplotlib.pyplotaspltfrommatplotlib.patchesimportPolygonplt.rcParams[\\'pdf.fonttype\\']=42#ForeditinginAdobeIllustrator_GRAY=(218,227,218)_GREEN=(18,127,15)_WHITE=(255,255,255)defkp_connections(keypoints):kp_lines=[[keypoints.index(\\'left_eye\\'),keypoints.index(\\'right_eye\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'nose\\')],[keypoints.index(\\'right_eye\\'),keypoints.index(\\'right_ear\\')],[keypoints.index(\\'left_eye\\'),keypoints.index(\\'left_ear\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'right_elbow\\')],[keypoints.index(\\'right_elbow\\'),keypoints.index(\\'right_wrist\\')],[keypoints.index(\\'left_shoulder\\'),keypoints.index(\\'left_elbow\\')],[keypoints.index(\\'left_elbow\\'),keypoints.index(\\'left_wrist\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'right_knee\\')],[keypoints.index(\\'right_knee\\'),keypoints.index(\\'right_ankle\\')],[keypoints.index(\\'left_hip\\'),keypoints.index(\\'left_knee\\')],[keypoints.index(\\'left_knee\\'),keypoints.index(\\'left_ankle\\')],[keypoints.index(\\'right_shoulder\\'),keypoints.index(\\'left_shoulder\\')],[keypoints.index(\\'right_hip\\'),keypoints.index(\\'left_hip\\')],]returnkp_linesdefconvert_from_cls_format(cls_boxes,cls_segms,cls_keyps):\"\"\"Convertfromtheclassboxes/segms/keypsformatgeneratedbythetestingcode.\"\"\"box_list=[bforbincls_boxesiflen(b)>0]iflen(box_list)>0:boxes=np.concatenate(box_list)else:boxes=Noneifcls_segmsisnotNone:segms=[sforslistincls_segmsforsinslist]else:segms=Noneifcls_keypsisnotNone:keyps=[kforklistincls_keypsforkinklist]else:keyps=Noneclasses=[]forjinrange(len(cls_boxes)):classes+=[j]*len(cls_boxes[j])returnboxes,segms,keyps,classesdefget_class_string(class_index,score,dataset):class_text=dataset.classes[class_index]ifdatasetisnotNoneelse\\\\\\'id{:d}\\'.format(class_index)returnclass_text+\\'{:0.2f}\\'.format(score).lstrip(\\'0\\')defvis_mask(img,mask,col,alpha=0.4,show_border=True,border_thick=1):\"\"\"Visualizesasinglebinarymask.\"\"\"img=img.astype(np.float32)idx=np.nonzero(mask)img[idx[0],idx[1],:]*=1.0-alphaimg[idx[0],idx[1],:]+=alpha*colifshow_border:contours=cv2.findContours(mask.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]cv2.drawContours(img,contours,-1,_WHITE,border_thick,cv2.LINE_AA)returnimg.astype(np.uint8)defvis_class(img,pos,class_str,font_scale=0.35):\"\"\"Visualizestheclass.\"\"\"img=img.astype(np.uint8)x0,y0=int(pos[0]),int(pos[1])#Computetextsize.txt=class_strfont=cv2.FONT_HERSHEY_SIMPLEX((txt_w,txt_h),_)=cv2.getTextSize(txt,font,font_scale,1)#Placetextbackground.back_tl=x0,y0-int(1.3*txt_h)back_br=x0+txt_w,y0cv2.rectangle(img,back_tl,back_br,_GREEN,-1)#Showtext.txt_tl=x0,y0-int(0.3*txt_h)cv2.putText(img,txt,txt_tl,font,font_scale,_GRAY,lineType=cv2.LINE_AA)returnimgdefvis_bbox(img,bbox,thick=1):\"\"\"Visualizesaboundingbox.\"\"\"img=img.astype(np.uint8)(x0,y0,w,h)=bboxx1,y1=int(x0+w),int(y0+h)x0,y0=int(x0),int(y0)cv2.rectangle(img,(x0,y0),(x1,y1),_GREEN,thickness=thick)returnimgdefvis_keypoints(img,kps,kp_thresh=2,alpha=0.7):\"\"\"Visualizeskeypoints(adaptedfromvis_one_image).kpshasshape(4,#keypoints)where4rowsare(x,y,logit,prob).\"\"\"dataset_keypoints,_=keypoint_utils.get_keypoints()kp_lines=kp_connections(dataset_keypoints)#Convertfromplt0-1RGBAcolorsto0-255BGRcolorsforopencv.cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]colors=[(c[2]*255,c[1]*255,c[0]*255)forcincolors]#Performthedrawingonacopyoftheimage,toallowforblending.kp_mask=np.copy(img)#Drawmidshoulder/midhipfirstforbettervisualization.mid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])nose_idx=dataset_keypoints.index(\\'nose\\')ifsc_mid_shoulder>kp_threshandkps[2,nose_idx]>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(kps[:2,nose_idx]),color=colors[len(kp_lines)],thickness=2,lineType=cv2.LINE_AA)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:cv2.line(kp_mask,tuple(mid_shoulder),tuple(mid_hip),color=colors[len(kp_lines)+1],thickness=2,lineType=cv2.LINE_AA)#Drawthekeypoints.forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]p1=kps[0,i1],kps[1,i1]p2=kps[0,i2],kps[1,i2]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:cv2.line(kp_mask,p1,p2,color=colors[l],thickness=2,lineType=cv2.LINE_AA)ifkps[2,i1]>kp_thresh:cv2.circle(kp_mask,p1,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)ifkps[2,i2]>kp_thresh:cv2.circle(kp_mask,p2,radius=3,color=colors[l],thickness=-1,lineType=cv2.LINE_AA)#Blendthekeypoints.returncv2.addWeighted(img,1.0-alpha,kp_mask,alpha,0)defvis_one_image_opencv(im,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,show_box=False,dataset=None,show_class=False):\"\"\"Constructsanumpyarraywiththedetectionsvisualized.\"\"\"ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)ifboxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh:returnimifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap()mask_color_id=0#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ifshow_box:im=vis_bbox(im,(bbox[0],bbox[1],bbox[2]-bbox[0],bbox[3]-bbox[1]))#showclass(offbydefault)ifshow_class:class_str=get_class_string(classes[i],score,dataset)im=vis_class(im,(bbox[0],bbox[1]-2),class_str)#showmaskifsegmsisnotNoneandlen(segms)>i:color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1im=vis_mask(im,masks[...,i],color_mask)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:im=vis_keypoints(im,keypoints[i],kp_thresh)returnimdefvis_one_image(im,im_name,output_dir,boxes,segms=None,keypoints=None,thresh=0.9,kp_thresh=2,dpi=200,box_alpha=0.0,dataset=None,show_class=False,ext=\\'pdf\\',out_when_no_box=False):\"\"\"Visualdebuggingofdetections.\"\"\"ifnotos.path.exists(output_dir):os.makedirs(output_dir)ifisinstance(boxes,list):boxes,segms,keypoints,classes=convert_from_cls_format(boxes,segms,keypoints)if(boxesisNoneorboxes.shape[0]==0ormax(boxes[:,4])<thresh)andnotout_when_no_box:returndataset_keypoints,_=keypoint_utils.get_keypoints()ifsegmsisnotNoneandlen(segms)>0:masks=mask_util.decode(segms)color_list=colormap(rgb=True)/255kp_lines=kp_connections(dataset_keypoints)cmap=plt.get_cmap(\\'rainbow\\')colors=[cmap(i)foriinnp.linspace(0,1,len(kp_lines)+2)]fig=plt.figure(frameon=False)fig.set_size_inches(im.shape[1]/dpi,im.shape[0]/dpi)ax=plt.Axes(fig,[0.,0.,1.,1.])ax.axis(\\'off\\')fig.add_axes(ax)ax.imshow(im)ifboxesisNone:sorted_inds=[]#avoidcrashwhen\\'boxes\\'isNoneelse:#Displayinlargesttosmallestordertoreduceocclusionareas=(boxes[:,2]-boxes[:,0])*(boxes[:,3]-boxes[:,1])sorted_inds=np.argsort(-areas)mask_color_id=0foriinsorted_inds:bbox=boxes[i,:4]score=boxes[i,-1]ifscore<thresh:continue#showbox(offbydefault)ax.add_patch(plt.Rectangle((bbox[0],bbox[1]),bbox[2]-bbox[0],bbox[3]-bbox[1],fill=False,edgecolor=\\'g\\',linewidth=0.5,alpha=box_alpha))ifshow_class:ax.text(bbox[0],bbox[1]-2,get_class_string(classes[i],score,dataset),fontsize=3,family=\\'serif\\',bbox=dict(facecolor=\\'g\\',alpha=0.4,pad=0,edgecolor=\\'none\\'),color=\\'white\\')#showmaskifsegmsisnotNoneandlen(segms)>i:img=np.ones(im.shape)color_mask=color_list[mask_color_id%len(color_list),0:3]mask_color_id+=1w_ratio=.4forcinrange(3):color_mask[c]=color_mask[c]*(1-w_ratio)+w_ratioforcinrange(3):img[:,:,c]=color_mask[c]e=masks[:,:,i]contour=cv2.findContours(e.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)[-2]forcincontour:polygon=Polygon(c.reshape((-1,2)),fill=True,facecolor=color_mask,edgecolor=\\'w\\',linewidth=1.2,alpha=0.5)ax.add_patch(polygon)#showkeypointsifkeypointsisnotNoneandlen(keypoints)>i:kps=keypoints[i]plt.autoscale(False)forlinrange(len(kp_lines)):i1=kp_lines[l][0]i2=kp_lines[l][1]ifkps[2,i1]>kp_threshandkps[2,i2]>kp_thresh:x=[kps[0,i1],kps[0,i2]]y=[kps[1,i1],kps[1,i2]]line=plt.plot(x,y)plt.setp(line,color=colors[l],linewidth=1.0,alpha=0.7)ifkps[2,i1]>kp_thresh:plt.plot(kps[0,i1],kps[1,i1],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)ifkps[2,i2]>kp_thresh:plt.plot(kps[0,i2],kps[1,i2],\\'.\\',color=colors[l],markersize=3.0,alpha=0.7)#addmidshoulder/midhipforbettervisualizationmid_shoulder=(kps[:2,dataset_keypoints.index(\\'right_shoulder\\')]+kps[:2,dataset_keypoints.index(\\'left_shoulder\\')])/2.0sc_mid_shoulder=np.minimum(kps[2,dataset_keypoints.index(\\'right_shoulder\\')],kps[2,dataset_keypoints.index(\\'left_shoulder\\')])mid_hip=(kps[:2,dataset_keypoints.index(\\'right_hip\\')]+kps[:2,dataset_keypoints.index(\\'left_hip\\')])/2.0sc_mid_hip=np.minimum(kps[2,dataset_keypoints.index(\\'right_hip\\')],kps[2,dataset_keypoints.index(\\'left_hip\\')])if(sc_mid_shoulder>kp_threshandkps[2,dataset_keypoints.index(\\'nose\\')]>kp_thresh):x=[mid_shoulder[0],kps[0,dataset_keypoints.index(\\'nose\\')]]y=[mid_shoulder[1],kps[1,dataset_keypoints.index(\\'nose\\')]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)],linewidth=1.0,alpha=0.7)ifsc_mid_shoulder>kp_threshandsc_mid_hip>kp_thresh:x=[mid_shoulder[0],mid_hip[0]]y=[mid_shoulder[1],mid_hip[1]]line=plt.plot(x,y)plt.setp(line,color=colors[len(kp_lines)+1],linewidth=1.0,alpha=0.7)output_name=os.path.basename(im_name)+\\'.\\'+extfig.savefig(os.path.join(output_dir,\\'{}\\'.format(output_name)),dpi=dpi)plt.close(\\'all\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelpfulutilitiesforworkingwithCaffe2.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromsiximportstring_typesimportcontextlibimportsubprocessfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcorefromcaffe2.pythonimportdyndepfromcaffe2.pythonimportscopefromcaffe2.pythonimportworkspaceimportdetectron.utils.envasenvudefimport_contrib_ops():\"\"\"ImportcontribopsneededbyDetectron.\"\"\"envu.import_nccl_ops()defimport_detectron_ops():\"\"\"ImportDetectronops.\"\"\"detectron_ops_lib=envu.get_detectron_ops_lib()dyndep.InitOpsLibrary(detectron_ops_lib)defimport_custom_ops():\"\"\"Importcustomops.\"\"\"custom_ops_lib=envu.get_custom_ops_lib()dyndep.InitOpsLibrary(custom_ops_lib)defSuffixNet(name,net,prefix_len,outputs):\"\"\"ReturnsanewNetfromthegivenNet(`net`)thatincludesonlytheopsafterremovingthefirst`prefix_len`numberofops.ThenewNetisthusasuffixof`net`.Blobslistedin`outputs`areregisteredasexternaloutputblobs.\"\"\"outputs=BlobReferenceList(outputs)foroutputinoutputs:assertnet.BlobIsDefined(output)new_net=net.Clone(name)delnew_net.Proto().op[:]delnew_net.Proto().external_input[:]delnew_net.Proto().external_output[:]#Addsuffixopsnew_net.Proto().op.extend(net.Proto().op[prefix_len:])#Addexternalinputblobs#Treatanyundefinedblobsasexternalinputsinput_names=[iforopinnew_net.Proto().opforiinop.inputifnotnew_net.BlobIsDefined(i)]new_net.Proto().external_input.extend(input_names)#Addexternaloutputblobsoutput_names=[str(o)foroinoutputs]new_net.Proto().external_output.extend(output_names)returnnew_net,[new_net.GetBlobRef(o)foroinoutput_names]defBlobReferenceList(blob_ref_or_list):\"\"\"EnsurethattheargumentisreturnedasalistofBlobReferences.\"\"\"ifisinstance(blob_ref_or_list,core.BlobReference):return[blob_ref_or_list]eliftype(blob_ref_or_list)in(list,tuple):forbinblob_ref_or_list:assertisinstance(b,core.BlobReference)returnblob_ref_or_listelse:raiseTypeError(\\'blob_ref_or_listmustbeaBlobReferenceoralist/tupleof\\'\\'BlobReferences\\')defUnscopeName(possibly_scoped_name):\"\"\"Removeanynamescopingfroma(possibly)scopedname.Forexample,convertthename\\'gpu_0/foo\\'to\\'foo\\'.\"\"\"assertisinstance(possibly_scoped_name,string_types)returnpossibly_scoped_name[possibly_scoped_name.rfind(scope._NAMESCOPE_SEPARATOR)+1:]@contextlib.contextmanagerdefNamedCudaScope(gpu_id):\"\"\"CreatesaGPUnamescopeandCUDAdevicescope.Thisfunctionisprovidedtoreduce`with...`nestinglevels.\"\"\"withGpuNameScope(gpu_id):withCudaScope(gpu_id):yield@contextlib.contextmanagerdefGpuNameScope(gpu_id):\"\"\"CreateanamescopeforGPUdevice`gpu_id`.\"\"\"withcore.NameScope(\\'gpu_{:d}\\'.format(gpu_id)):yield@contextlib.contextmanagerdefCudaScope(gpu_id):\"\"\"CreateaCUDAdevicescopeforGPUdevice`gpu_id`.\"\"\"gpu_dev=CudaDevice(gpu_id)withcore.DeviceScope(gpu_dev):yield@contextlib.contextmanagerdefCpuScope():\"\"\"CreateaCPUdevicescope.\"\"\"cpu_dev=core.DeviceOption(caffe2_pb2.CPU)withcore.DeviceScope(cpu_dev):yielddefCudaDevice(gpu_id):\"\"\"CreateaCudadevice.\"\"\"returncore.DeviceOption(caffe2_pb2.CUDA,gpu_id)defgauss_fill(std):\"\"\"Gaussianfillhelpertoreduceverbosity.\"\"\"return(\\'GaussianFill\\',{\\'std\\':std})defconst_fill(value):\"\"\"Constantfillhelpertoreduceverbosity.\"\"\"return(\\'ConstantFill\\',{\\'value\\':value})defget_nvidia_info():return(get_nvidia_smi_output(),workspace.GetCUDAVersion(),workspace.GetCuDNNVersion(),)defget_nvidia_smi_output():try:info=subprocess.check_output([\"nvidia-smi\"],stderr=subprocess.STDOUT)info=info.decode(\"utf8\")exceptExceptionase:info=\"Executingnvidia-smifailed:\"+str(e)returninfo.strip()#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"HelperfunctionsforworkingwithCaffe2networks(i.e.,operatorgraphs).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportnumpyasnpimportosimportpprintfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvulogger=logging.getLogger(__name__)logger.setLevel(logging.INFO)definitialize_from_weights_file(model,weights_file,broadcast=True):\"\"\"Initializeamodelfromweightsstoredinapickleddictionary.IfmultipleGPUsareused,theloadedweightsaresynchronizedonallGPUs,unless\\'broadcast\\'isFalse.\"\"\"initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)ifbroadcast:broadcast_parameters(model)definitialize_gpu_from_weights_file(model,weights_file,gpu_id=0):\"\"\"InitializeanetworkwithopsonaspecificGPU.IfyouuseCUDA_VISIBLE_DEVICEStotargetspecificGPUs,Caffe2willautomaticallymaplogicalGPUids(startingfrom0)tothephysicalGPUsspecifiedinCUDA_VISIBLE_DEVICES.\"\"\"logger.info(\\'Loadingweightsfrom:{}\\'.format(weights_file))ws_blobs=workspace.Blobs()src_blobs=load_object(weights_file)if\\'cfg\\'insrc_blobs:saved_cfg=load_cfg(src_blobs[\\'cfg\\'])configure_bbox_reg_weights(model,saved_cfg)if\\'blobs\\'insrc_blobs:#Backwardscompat--dictionaryusedtobeonlyblobs,nowtheyare#storedunderthe\\'blobs\\'keysrc_blobs=src_blobs[\\'blobs\\']#InitializeweightsonGPUgpu_idonlyunscoped_param_names=OrderedDict()#Printtheseoutinmodelorderforblobinmodel.params:unscoped_param_names[c2_utils.UnscopeName(str(blob))]=Truewithc2_utils.NamedCudaScope(gpu_id):forunscoped_param_nameinunscoped_param_names.keys():if(unscoped_param_name.find(\\']_\\')>=0andunscoped_param_namenotinsrc_blobs):#Specialcaseforsharinginitializationfromapretrained#model:#Ifablobnamed\\'_[xyz]_foo\\'isinmodel.paramsandnotin#theinitializationblobdictionary,thenloadsourceblob#\\'foo\\'intodestinationblob\\'_[xyz]_foo\\'src_name=unscoped_param_name[unscoped_param_name.find(\\']_\\')+2:]else:src_name=unscoped_param_nameifsrc_namenotinsrc_blobs:logger.info(\\'{:s}notfound\\'.format(src_name))continuedst_name=core.ScopedName(unscoped_param_name)has_momentum=src_name+\\'_momentum\\'insrc_blobshas_momentum_str=\\'[+momentum]\\'ifhas_momentumelse\\'\\'logger.info(\\'{:s}{:}loadedfromweightsfileinto{:s}:{}\\'.format(src_name,has_momentum_str,dst_name,src_blobs[src_name].shape))ifdst_nameinws_blobs:#Iftheblobisalreadyintheworkspace,makesurethatit#matchestheshapeoftheloadedblobws_blob=workspace.FetchBlob(dst_name)assertws_blob.shape==src_blobs[src_name].shape,\\\\(\\'Workspaceblob{}withshape{}doesnotmatch\\'\\'weightsfileshape{}\\').format(src_name,ws_blob.shape,src_blobs[src_name].shape)workspace.FeedBlob(dst_name,src_blobs[src_name].astype(np.float32,copy=False))ifhas_momentum:workspace.FeedBlob(dst_name+\\'_momentum\\',src_blobs[src_name+\\'_momentum\\'].astype(np.float32,copy=False))#Wepreserveblobsthatareintheweightsfilebutnotusedbythecurrent#model.WeloadtheseintoCPUmemoryunderthe\\'__preserve__/\\'namescope.#Theseblobswillbestoredwhensavingamodeltoaweightsfile.This#featureallowsforalternatingoptimizationofFasterR-CNNinwhichblobs#unusedbyonestepcanstillbepreservedforwardandusedtoinitialize#anotherstep.forsrc_nameinsrc_blobs.keys():if(src_namenotinunscoped_param_namesandnotsrc_name.endswith(\\'_momentum\\')andsrc_blobs[src_name]isnotNone):withc2_utils.CpuScope():workspace.FeedBlob(\\'__preserve__/{:s}\\'.format(src_name),src_blobs[src_name])logger.info(\\'{:s}preservedinworkspace(unused)\\'.format(src_name))defsave_model_to_weights_file(weights_file,model):\"\"\"Stashmodelweightsinadictionaryandpicklethemtoafile.WemapGPUdevicescopednamestounscopednames(e.g.,\\'gpu_0/conv1_w\\'->\\'conv1_w\\').\"\"\"logger.info(\\'Savingparametersandmomentumto{}\\'.format(os.path.abspath(weights_file)))blobs={}#Saveallparametersforparaminmodel.params:scoped_name=str(param)unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savemomentumforparaminmodel.TrainableParams():scoped_name=str(param)+\\'_momentum\\'unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)#Savepreservedblobsforscoped_nameinworkspace.Blobs():ifscoped_name.startswith(\\'__preserve__/\\'):unscoped_name=c2_utils.UnscopeName(scoped_name)ifunscoped_namenotinblobs:logger.debug(\\'{:s}->{:s}(preserved)\\'.format(scoped_name,unscoped_name))blobs[unscoped_name]=workspace.FetchBlob(scoped_name)cfg_yaml=envu.yaml_dump(cfg)save_object(dict(blobs=blobs,cfg=cfg_yaml),weights_file)defbroadcast_parameters(model):\"\"\"CopyparameterblobsfromGPU0overthecorrespondingparameterblobsonGPUs1throughcfg.NUM_GPUS-1.\"\"\"ifcfg.NUM_GPUS==1:#no-opifonlyrunningonasingleGPUreturndef_do_broadcast(all_blobs):assertlen(all_blobs)%cfg.NUM_GPUS==0,\\\\(\\'UnexpectedvalueforNUM_GPUS.Makesureyouarenot\\'\\'runningsingle-GPUinferencewithNUM_GPUS>1.\\')blobs_per_gpu=int(len(all_blobs)/cfg.NUM_GPUS)foriinrange(blobs_per_gpu):blobs=[pforpinall_blobs[i::blobs_per_gpu]]data=workspace.FetchBlob(blobs[0])logger.debug(\\'Broadcasting{}to\\'.format(str(blobs[0])))fori,pinenumerate(blobs[1:]):logger.debug(\\'|->{}\\'.format(str(p)))withc2_utils.CudaScope(i+1):workspace.FeedBlob(p,data)_do_broadcast(model.params)_do_broadcast([b+\\'_momentum\\'forbinmodel.TrainableParams()])defsum_multi_gpu_blob(blob_name):\"\"\"ReturnthesumofascalarblobheldonmultipleGPUs.\"\"\"val=0foriinrange(cfg.NUM_GPUS):val+=float(workspace.FetchBlob(\\'gpu_{}/{}\\'.format(i,blob_name)))returnvaldefaverage_multi_gpu_blob(blob_name):\"\"\"ReturntheaverageofascalarblobheldonmultipleGPUs.\"\"\"returnsum_multi_gpu_blob(blob_name)/cfg.NUM_GPUSdefprint_net(model,namescope=\\'gpu_0\\'):\"\"\"Printthemodelnetwork.\"\"\"logger.info(\\'Printingmodel:{}\\'.format(model.net.Name()))op_list=model.net.Proto().opforopinop_list:input_name=op.input#Forsimplicity:onlyprintthefirstoutput#Notrecommendediftherearesplitlayersoutput_name=str(op.output[0])op_type=op.typeop_name=op.nameifnamescopeisNoneoroutput_name.startswith(namescope):#Onlyprinttheforwardpassnetworkifoutput_name.find(\\'grad\\')>=0oroutput_name.find(\\'__m\\')>=0:continuetry:#Undersomeconditions(e.g.,dynamicmemoryoptimization)#itispossiblethatthenetworkfreessomeblobswhentheyare#nolongerneeded.Handlethiscase...output_shape=workspace.FetchBlob(output_name).shapeexceptBaseException:output_shape=\\'\\'first_blob=Trueop_label=op_type+(op_nameifop_name==\\'\\'else\\':\\'+op_name)suffix=\\'-------(op:{})\\'.format(op_label)forjinrange(len(input_name)):ifinput_name[j]inmodel.params:continueinput_blob=workspace.FetchBlob(input_name[j])ifisinstance(input_blob,np.ndarray):input_shape=input_blob.shapelogger.info(\\'{:28s}:{:20s}=>{:28s}:{:20s}{}\\'.format(c2_utils.UnscopeName(str(input_name[j])),\\'{}\\'.format(input_shape),c2_utils.UnscopeName(str(output_name)),\\'{}\\'.format(output_shape),suffix))iffirst_blob:first_blob=Falsesuffix=\\'------|\\'logger.info(\\'Endofmodel:{}\\'.format(model.net.Name()))defconfigure_bbox_reg_weights(model,saved_cfg):\"\"\"Compatibilityforoldmodelstrainedwithboundingboxregressionmean/stdnormalization(insteadoffixedweights).\"\"\"if\\'MODEL\\'notinsaved_cfgor\\'BBOX_REG_WEIGHTS\\'notinsaved_cfg.MODEL:logger.warning(\\'Modelfromweightsfilewastrainedbeforeconfigkey\\'\\'MODEL.BBOX_REG_WEIGHTSwasadded.Forcing\\'\\'MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)toensure\\'\\'correct**inference**behavior.\\')#Generallywedon\\'tallowmodifyingtheconfig,butthisisaone-off#hacktosupportsomeveryoldmodelsis_immutable=cfg.is_immutable()cfg.immutable(False)cfg.MODEL.BBOX_REG_WEIGHTS=(1.,1.,1.,1.)cfg.immutable(is_immutable)logger.info(\\'Newconfig:\\')logger.info(pprint.pformat(cfg))assertnotmodel.train,(\\'Thismodelwastrainedwithanolderversionofthecodethat\\'\\'usedboundingboxregressionmean/stdnormalization.Itcanno\\'\\'longerbeusedfortraining.Toupgradeittoatrainablemodel\\'\\'pleaseusefb/compat/convert_bbox_reg_normalized_model.py.\\')defget_group_gn(dim):\"\"\"getnumberofgroupsusedbyGroupNorm,basedonnumberofchannels\"\"\"dim_per_gp=cfg.GROUP_NORM.DIM_PER_GPnum_groups=cfg.GROUP_NORM.NUM_GROUPSassertdim_per_gp==-1ornum_groups==-1,\\\\\"GroupNorm:canonlyspecifyGorC/G.\"ifdim_per_gp>0:assertdim%dim_per_gp==0group_gn=dim//dim_per_gpelse:assertdim%num_groups==0group_gn=num_groupsreturngroup_gn#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesfortraining.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportdatetimeimportnumpyasnpfromcaffe2.pythonimportutilsasc2_py_utilsfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportlog_json_statsfromdetectron.utils.loggingimportSmoothedValuefromdetectron.utils.timerimportTimerimportdetectron.utils.netasnuclassTrainingStats:\"\"\"Trackvitaltrainingstatistics.\"\"\"def__init__(self,model):#Windowsizeforsmoothingtrackedvalues(withmedianfiltering)self.WIN_SZ=20#OutputloggingperiodinSGDiterationsself.LOG_PERIOD=20self.smoothed_losses_and_metrics={key:SmoothedValue(self.WIN_SZ)forkeyinmodel.losses+model.metrics}self.losses_and_metrics={key:0forkeyinmodel.losses+model.metrics}self.smoothed_total_loss=SmoothedValue(self.WIN_SZ)self.smoothed_mb_qsize=SmoothedValue(self.WIN_SZ)self.iter_total_loss=np.nanself.iter_timer=Timer()self.model=modeldefIterTic(self):self.iter_timer.tic()defIterToc(self):returnself.iter_timer.toc(average=False)defResetIterTimer(self):self.iter_timer.reset()defUpdateIterStats(self):\"\"\"Updatetrackediterationstatistics.\"\"\"forkinself.losses_and_metrics.keys():ifkinself.model.losses:self.losses_and_metrics[k]=nu.sum_multi_gpu_blob(k)else:self.losses_and_metrics[k]=nu.average_multi_gpu_blob(k)fork,vinself.smoothed_losses_and_metrics.items():v.AddValue(self.losses_and_metrics[k])self.iter_total_loss=np.sum(np.array([self.losses_and_metrics[k]forkinself.model.losses]))self.smoothed_total_loss.AddValue(self.iter_total_loss)self.smoothed_mb_qsize.AddValue(self.model.roi_data_loader._minibatch_queue.qsize())defLogIterStats(self,cur_iter,lr):\"\"\"Logthetrackedstatistics.\"\"\"if(cur_iter%self.LOG_PERIOD==0orcur_iter==cfg.SOLVER.MAX_ITER-1):stats=self.GetStats(cur_iter,lr)log_json_stats(stats)defGetStats(self,cur_iter,lr):eta_seconds=self.iter_timer.average_time*(cfg.SOLVER.MAX_ITER-cur_iter)eta=str(datetime.timedelta(seconds=int(eta_seconds)))mem_stats=c2_py_utils.GetGPUMemoryUsageStats()mem_usage=np.max(mem_stats[\\'max_by_gpu\\'][:cfg.NUM_GPUS])stats=dict(iter=cur_iter,lr=float(lr),time=self.iter_timer.average_time,loss=self.smoothed_total_loss.GetMedianValue(),eta=eta,mb_qsize=int(np.round(self.smoothed_mb_qsize.GetMedianValue())),mem=int(np.ceil(mem_usage/1024/1024)))fork,vinself.smoothed_losses_and_metrics.items():stats[k]=v.GetMedianValue()returnstats#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\\'\\'\\'Helperfunctionsformodelconversiontopb\\'\\'\\'from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromfunctoolsimportwrapsimportcopyimportnumpyasnpfromcaffe2.pythonimportcore,workspacefromcaffe2.protoimportcaffe2_pb2classOpFilter:def__init__(self,**kwargs):self.type=Noneself.type_in=Noneself.inputs=Noneself.outputs=Noneself.input_has=Noneself.output_has=Noneself.cond=Noneself.reverse=Falseassertall([xinself.__dict__forxinkwargs])self.__dict__.update(kwargs)defcheck(self,op):ret=self.reverseifself.typeandop.type!=self.type:returnretifself.type_inandop.typenotinself.type_in:returnretifself.inputsandset(op.input)!=set(self.inputs):returnretifself.outputsandset(op.output)!=set(self.outputs):returnretifself.input_hasandself.input_hasnotinop.input:returnretifself.output_hasandself.output_hasnotinop.output:returnretifself.condisnotNoneandnotself.cond:returnretreturnnotretdeffilter_op(op,**kwargs):\\'\\'\\'Returnstrueifpassedallchecks\\'\\'\\'returnOpFilter(**kwargs).check(op)defop_filter(**filter_args):\\'\\'\\'ReturnsNoneifnoconditionissatisfied\\'\\'\\'defactual_decorator(f):@wraps(f)defwrapper(op,**params):ifnotfilter_op(op,**filter_args):returnNonereturnf(op,**params)returnwrapperreturnactual_decoratordefop_func_chain(convert_func_list):\\'\\'\\'RunfuncsonebyoneuntilfuncreturnisnotNone\\'\\'\\'assertisinstance(convert_func_list,list)def_chain(op):forxinconvert_func_list:ret=x(op)ifretisnotNone:returnretreturnNonereturn_chaindefconvert_op_in_ops(ops_ref,func_or_list):func=func_or_listifisinstance(func_or_list,list):func=op_func_chain(func_or_list)ops=[opforopinops_ref]converted_ops=[]foropinops:new_ops=func(op)ifnew_opsisnotNoneandnotisinstance(new_ops,list):new_ops=[new_ops]converted_ops.extend(new_opsifnew_opsisnotNoneelse[op])delops_ref[:]#ops_refmaybeoftypeRepeatedCompositeFieldContainer#whichdoesnothaveappend()ops_ref.extend(converted_ops)defconvert_op_in_proto(proto,func_or_list):convert_op_in_ops(proto.op,func_or_list)defget_op_arg(op,arg_name):forxinop.arg:ifx.name==arg_name:returnxreturnNonedefget_op_arg_valf(op,arg_name,default_val):arg=get_op_arg(op,arg_name)returnarg.fifargisnotNoneelsedefault_valdefupdate_mobile_engines(net):foropinnet.op:ifop.type==\"Conv\":op.engine=\"NNPACK\"ifop.type==\"ConvTranspose\":op.engine=\"BLOCK\"defpairwise(iterable):\"s->(s0,s1),(s1,s2),(s2,s3),...\"fromitertoolsimportteea,b=tee(iterable)next(b,None)returnzip(a,b)defblob_uses(net,blob):u=[]fori,opinenumerate(net.op):ifblobinop.inputorblobinop.control_input:u.append(i)returnudeffuse_first_affine(net,params,removed_tensors):net=copy.deepcopy(net)params=copy.deepcopy(params)for((i,current),(j,next_))inpairwise(enumerate(net.op)):ifnext_.input[0]!=current.output[0]:continueifcurrent.typenotin(\"Conv\",\"ConvTranspose\")\\\\ornext_.type!=\"AffineChannel\":continueifcurrent.output[0]!=next_.output[0]and\\\\len(blob_uses(net,current.output[0]))!=1:#Can\\'tfuseifmorethanoneuserunlessAffineChannelisinplacecontinue#else,canfuseconv=currentaffine=next_fused_conv=copy.deepcopy(conv)fused_conv.output[0]=affine.output[0]conv_weight=params[conv.input[1]]conv_has_bias=len(conv.input)>2conv_bias=params[conv.input[2]]ifconv_has_biaselse0A=params[affine.input[1]]B=params[affine.input[2]]#Thus,canjusthavetheaffinetransform#X*A+B#where#A=bn_scale*1.0/(sqrt(running_var+eps))#B=(bias-running_mean*(1.0/sqrt(running_var+eps))#*bn_scale)#Thisidentifyshouldholdifwehavecorrectlyfused#np.testing.assert_array_equal(#params[conv.output[0]]*A+B,#params[bn.output[0]])#Now,wehavethatthecomputationmadeisthefollowing:#((X`conv`W)+b)*A+B#Then,wecansimplyfusethisasfollows:#(X`conv`(W*A))+b*A+B#whichissimply#(X`conv`Q)+C#where#Q=W*A#C=b*A+B#ForConvTranspose,fromtheviewofconvolutionsasa#Toepelizmultiplication,wehaveW_=W^T,sotheweights#arelaidoutas(R,S,K,K)(vs(S,R,K,K)foraConv),#sotheweightsbroadcastslightlydifferently.Remember,our#BNscale\\'B\\'isofsize(S,)A_=A.reshape(-1,1,1,1)ifconv.type==\"Conv\"else\\\\A.reshape(1,-1,1,1)C=conv_bias*A+BQ=conv_weight*A_assertparams[conv.input[1]].shape==Q.shapeparams[conv.input[1]]=Qifconv_has_bias:assertparams[conv.input[2]].shape==C.shapeparams[conv.input[2]]=Celse:#makeaf_biastobebiasoftheconvlayerfused_conv.input.append(affine.input[2])params[affine.input[2]]=Bnew_ops=net.op[:i]+[fused_conv]+net.op[j+1:]delnet.op[:]ifconv_has_bias:delparams[affine.input[2]]removed_tensors.append(affine.input[2])removed_tensors.append(affine.input[1])delparams[affine.input[1]]net.op.extend(new_ops)breakreturnnet,params,removed_tensorsdeffuse_affine(net,params,ignore_failure):#Rununtilwehitafixedpointremoved_tensors=[]whileTrue:(next_net,next_params,removed_tensors)=\\\\fuse_first_affine(net,params,removed_tensors)iflen(next_net.op)==len(net.op):if(any(op.type==\"AffineChannel\"foropinnext_net.op)andnotignore_failure):raiseException(\"ModelcontainsAffineChannelopafterfusion:%s\",next_net)return(next_net,next_params,removed_tensors)net,params,removed_tensors=(next_net,next_params,removed_tensors)deffuse_net(fuse_func,net,blobs,ignore_failure=False):is_core_net=isinstance(net,core.Net)ifis_core_net:net=net.Proto()net,params,removed_tensors=fuse_func(net,blobs,ignore_failure)forrtinremoved_tensors:net.external_input.remove(rt)ifis_core_net:net=core.Net(net)returnnet,paramsdeffuse_net_affine(net,blobs):returnfuse_net(fuse_affine,net,blobs)defadd_tensor(net,name,blob):\\'\\'\\'Createanoperatortostorethetensor\\'blob\\',runtheoperatortoputtheblobtoworkspace.uint8isstoredasanarrayofstringwithoneelement.\\'\\'\\'kTypeNameMapper={np.dtype(\\'float32\\'):\"GivenTensorFill\",np.dtype(\\'int32\\'):\"GivenTensorIntFill\",np.dtype(\\'int64\\'):\"GivenTensorInt64Fill\",np.dtype(\\'uint8\\'):\"GivenTensorStringFill\",}shape=blob.shapevalues=blob#passarrayofuint8asastringtosavestorage#storinguint8_thasalargeoverheadfornowifblob.dtype==np.dtype(\\'uint8\\'):shape=[1]values=[str(blob.data)]op=core.CreateOperator(kTypeNameMapper[blob.dtype],[],[name],shape=shape,values=values,#arg=[#putils.MakeArgument(\"shape\",shape),#putils.MakeArgument(\"values\",values),#])net.op.extend([op])defgen_init_net_from_blobs(blobs,blobs_to_use=None,excluded_blobs=None):\\'\\'\\'Generateaninitializationnetbasedonablobdict\\'\\'\\'ret=caffe2_pb2.NetDef()ifblobs_to_useisNone:blobs_to_use={xforxinblobs}else:blobs_to_use=copy.deepcopy(blobs_to_use)ifexcluded_blobsisnotNone:blobs_to_use=[xforxinblobs_to_useifxnotinexcluded_blobs]fornameinblobs_to_use:blob=blobs[name]ifisinstance(blob,str):print(\\'Blob{}withtype{}isnots'],\n",
       " ['<|begin_of_text|>upportedingeneratinginitnet,\\'\\'skipped.\\'.format(name,type(blob)))continueadd_tensor(ret,name,blob)returnretdefget_ws_blobs(blob_names=None):\\'\\'\\'Getblobsin\\'blob_names\\'inthedefaultworkspace,getallblobsifblob_namesisNone\\'\\'\\'blobs={}ifblob_namesisNone:blob_names=workspace.Blobs()blobs={x:workspace.FetchBlob(x)forxinblob_names}returnblobsdefget_device_option_cpu():device_option=core.DeviceOption(caffe2_pb2.CPU)returndevice_optiondefget_device_option_cuda(gpu_id=0):device_option=caffe2_pb2.DeviceOption()device_option.device_type=caffe2_pb2.CUDAdevice_option.device_id=gpu_idreturndevice_optiondefcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)defcompare_model(model1_func,model2_func,test_image,check_blobs):\\'\\'\\'model_func(test_image,check_blobs)\\'\\'\\'cb1,cb2=check_blobs,check_blobsifisinstance(check_blobs,dict):cb1=check_blobs.keys()cb2=check_blobs.values()print(\\'Runningthefirstmodel...\\')res1=model1_func(test_image,check_blobs)print(\\'Runningthesecondmodel...\\')res2=model2_func(test_image,check_blobs)foridxinrange(len(cb1)):print(\\'Checking{}->{}...\\'.format(cb1[idx],cb2[idx]))n1,n2=cb1[idx],cb2[idx]r1=res1[n1]ifn1inres1elseNoner2=res2[n2]ifn2inres2elseNoneassertr1isnotNoneorr2isNone,\\\\\"Blob{}inmodel1isNone\".format(n1)assertr2isnotNoneorr1isNone,\\\\\"Blob{}inmodel2isNone\".format(n2)assertr1.shape==r2.shape,\\\\\"Blob{}and{}shapemismatched:{}vs{}\".format(n1,n2,r1.shape,r2.shape)np.testing.assert_array_almost_equal(r1,r2,decimal=3,err_msg=\\'{}and{}notmatched.Maxdiff:{}\\'.format(n1,n2,np.amax(np.absolute(r1-r2))))returnTrue#graph_namecouldnotcontainword\\'graph\\'defsave_graph(net,file_name,graph_name=\"net\",op_only=True):fromcaffe2.pythonimportnet_drawergraph=Noneops=net.opifnotop_only:graph=net_drawer.GetPydotGraph(ops,graph_name,rankdir=\"TB\")else:graph=net_drawer.GetPydotGraphMinimal(ops,graph_name,rankdir=\"TB\",minimal_dependency=True)try:graph.write_png(file_name)exceptExceptionase:print(\\'Errorwhenwritinggraphtoimage{}\\'.format(e))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Caffe2blobhelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromsix.movesimportcPickleaspicklefromcaffe2.protoimportcaffe2_pb2fromdetectron.core.configimportcfgdefget_image_blob(im,target_scale,target_max_size):\"\"\"Convertanimageintoanetworkinput.Arguments:im(ndarray):acolorimageinBGRorderReturns:blob(ndarray):adatablobholdinganimagepyramidim_scale(float):imagescale(targetsize)/(originalsize)im_info(ndarray)\"\"\"processed_im,im_scale=prep_im_for_blob(im,cfg.PIXEL_MEANS,target_scale,target_max_size)blob=im_list_to_blob(processed_im)#NOTE:thisheightandwidthmaybelargerthanactualscaledinputimage#duetotheFPN.COARSEST_STRIDErelatedpaddinginim_list_to_blob.Weare#maintainingthisbehaviorfornowtomakeexistingresultsexactly#reproducible(inpracticeusingthetrueinputimageheightandwidth#yieldsnearlythesameresults,buttheyaresometimesslightlydifferent#becausepredictionsneartheedgeoftheimagewillbeprunedmore#aggressively).height,width=blob.shape[2],blob.shape[3]im_info=np.hstack((height,width,im_scale))[np.newaxis,:]returnblob,im_scale,im_info.astype(np.float32)defim_list_to_blob(ims):\"\"\"Convertalistofimagesintoanetworkinput.Assumesimageswerepreparedusingprep_im_for_bloborequivalent:i.e.-BGRchannelorder-pixelmeanssubtracted-resizedtothedesiredinputsize-float32numpyndarrayformatOutputisa4DHCHWtensoroftheimagesconcatenatedalongaxis0withshape.\"\"\"ifnotisinstance(ims,list):ims=[ims]max_shape=np.array([im.shapeforiminims]).max(axis=0)#Padtheimagesotheycanbedivisiblebyastrideifcfg.FPN.FPN_ON:stride=float(cfg.FPN.COARSEST_STRIDE)max_shape[0]=int(np.ceil(max_shape[0]/stride)*stride)max_shape[1]=int(np.ceil(max_shape[1]/stride)*stride)num_images=len(ims)blob=np.zeros((num_images,max_shape[0],max_shape[1],3),dtype=np.float32)foriinrange(num_images):im=ims[i]blob[i,0:im.shape[0],0:im.shape[1],:]=im#Movechannels(axis3)toaxis1#Axisorderwillbecome:(batchelem,channel,height,width)channel_swap=(0,3,1,2)blob=blob.transpose(channel_swap)returnblobdefprep_im_for_blob(im,pixel_means,target_size,max_size):\"\"\"Prepareanimageforuseasanetworkinputblob.Specially:-Subtractper-channelpixelmean-Converttofloat32-Rescaletoeachofthespecifiedtargetsize(cappedatmax_size)Returnsalistoftransformedimages,oneforeachtargetsize.Alsoreturnsthescalefactorsthatwereusedtocomputeeachreturnedimage.\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)#Preventthebiggestaxisfrombeingmorethanmax_sizeifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)returnim,im_scaledefzeros(shape,int32=False):\"\"\"Returnablobofallzerosofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.zeros(shape,dtype=np.int32ifint32elsenp.float32)defones(shape,int32=False):\"\"\"Returnablobofallonesofthegivenshapewiththecorrectfloatorintdatatype.\"\"\"returnnp.ones(shape,dtype=np.int32ifint32elsenp.float32)defpy_op_copy_blob(blob_in,blob_out):\"\"\"Copyanumpyndarraygivenasblob_inintotheCaffe2CPUTensorblobgivenasblob_out.Supportsfloat32andint32blobdatatypes.ThisfunctionisintendedforcopyingnumpydataintoaCaffe2blobinPythonOps.\"\"\"#SomeawkwardvoodoorequiredbyCaffe2tosupportint32blobsneeds_int32_init=Falsetry:_=blob.data.dtype#noqaexceptException:needs_int32_init=blob_in.dtype==np.int32ifneeds_int32_init:#initcanonlytakealist(failedontuple)blob_out.init(list(blob_in.shape),caffe2_pb2.TensorProto.INT32)else:blob_out.reshape(blob_in.shape)blob_out.data[...]=blob_indefget_loss_gradients(model,loss_blobs):\"\"\"Generateagradientof1foreachlossspecifiedin\\'loss_blobs\\'\"\"\"loss_gradients={}forbinloss_blobs:loss_grad=model.net.ConstantFill(b,[b+\\'_grad\\'],value=1.0)loss_gradients[str(b)]=str(loss_grad)returnloss_gradientsdefserialize(obj):\"\"\"SerializeaPythonobjectusingpickleandencodeitasanarrayoffloat32valuessothatitcanbefeedintotheworkspace.Seedeserialize().\"\"\"returnnp.fromstring(pickle.dumps(obj),dtype=np.uint8).astype(np.float32)defdeserialize(arr):\"\"\"UnserializeaPythonobjectfromanarrayoffloat32valuesfetchedfromaworkspace.Seeserialize().\"\"\"returnpickle.loads(arr.astype(np.uint8).tobytes())#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Asimpleattributedictionaryusedforrepresentingconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsclassAttrDict(dict):IMMUTABLE=\\'__immutable__\\'def__init__(self,*args,**kwargs):super(AttrDict,self).__init__(*args,**kwargs)self.__dict__[AttrDict.IMMUTABLE]=Falsedef__getattr__(self,name):ifnameinself.__dict__:returnself.__dict__[name]elifnameinself:returnself[name]else:raiseAttributeError(name)def__setattr__(self,name,value):ifnotself.__dict__[AttrDict.IMMUTABLE]:ifnameinself.__dict__:self.__dict__[name]=valueelse:self[name]=valueelse:raiseAttributeError(\\'Attemptedtoset\"{}\"to\"{}\",butAttrDictisimmutable\\'.format(name,value))defimmutable(self,is_immutable):\"\"\"Setimmutabilitytois_immutableandrecursivelyapplythesettingtoallnestedAttrDicts.\"\"\"self.__dict__[AttrDict.IMMUTABLE]=is_immutable#Recursivelysetimmutablestateforvinself.__dict__.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)forvinself.values():ifisinstance(v,AttrDict):v.immutable(is_immutable)defis_immutable(self):returnself.__dict__[AttrDict.IMMUTABLE]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Boxmanipulationfunctions.TheinternalDetectronboxformatis[x1,y1,x2,y2]where(x1,y1)specifythetop-leftboxcornerand(x2,y2)specifythebottom-rightboxcorner.Boxesfromexternalsources,e.g.,datasets,maybeinotherformats(suchas[x,y,w,h])andrequireconversion.Thismoduleusesaconventionthatmayseemstrangeatfirst:thewidthofaboxiscomputedasx2-x1+1(likewiseforheight).The\"+1\"datesbacktooldobjectdetectiondayswhenthecoordinateswereintegerpixelindices,ratherthanfloatingpointcoordinatesinasubpixelcoordinateframe.Aboxwithx2=x1andy2=y1wastakentoincludeasinglepixel,havingawidthof1,andhencerequiringthe\"+1\".Now,mostdatasetswilllikelyprovideboxeswithfloatingpointcoordinatesandthewidthshouldbemorereasonablycomputedasx2-x1.Inpractice,aslongasamodelistrainedandtestedwithaconsistentconventioneitherdecisionseemstobeok(atleastinourexperienceonCOCO).Sincewehavealonghistoryoftrainingmodelswiththe\"+1\"convention,wearereluctanttochangeitevenifourmoderntastesprefernottouseit.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.cython_bboxascython_bboximportdetectron.utils.cython_nmsascython_nmsbbox_overlaps=cython_bbox.bbox_overlapsdefboxes_area(boxes):\"\"\"Computetheareaofanarrayofboxes.\"\"\"w=(boxes[:,2]-boxes[:,0]+1)h=(boxes[:,3]-boxes[:,1]+1)areas=w*hassertnp.all(areas>=0),\\'Negativeareasfounds\\'returnareasdefunique_boxes(boxes,scale=1.0):\"\"\"Returnindicesofuniqueboxes.\"\"\"v=np.array([1,1e3,1e6,1e9])hashes=np.round(boxes*scale).dot(v)_,index=np.unique(hashes,return_index=True)returnnp.sort(index)defxywh_to_xyxy(xywh):\"\"\"Convert[x1y1wh]boxformatto[x1y1x2y2]format.\"\"\"ifisinstance(xywh,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xywh)==4x1,y1=xywh[0],xywh[1]x2=x1+np.maximum(0.,xywh[2]-1.)y2=y1+np.maximum(0.,xywh[3]-1.)return(x1,y1,x2,y2)elifisinstance(xywh,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xywh[:,0:2],xywh[:,0:2]+np.maximum(0,xywh[:,2:4]-1)))else:raiseTypeError(\\'Argumentxywhmustbealist,tuple,ornumpyarray.\\')defxyxy_to_xywh(xyxy):\"\"\"Convert[x1y1x2y2]boxformatto[x1y1wh]format.\"\"\"ifisinstance(xyxy,(list,tuple)):#Singleboxgivenasalistofcoordinatesassertlen(xyxy)==4x1,y1=xyxy[0],xyxy[1]w=xyxy[2]-x1+1h=xyxy[3]-y1+1return(x1,y1,w,h)elifisinstance(xyxy,np.ndarray):#Multipleboxesgivenasa2Dndarrayreturnnp.hstack((xyxy[:,0:2],xyxy[:,2:4]-xyxy[:,0:2]+1))else:raiseTypeError(\\'Argumentxyxymustbealist,tuple,ornumpyarray.\\')deffilter_small_boxes(boxes,min_size):\"\"\"Keepboxeswithwidthandheightbothgreaterthanmin_size.\"\"\"w=boxes[:,2]-boxes[:,0]+1h=boxes[:,3]-boxes[:,1]+1keep=np.where((w>min_size)&(h>min_size))[0]returnkeepdefclip_boxes_to_image(boxes,height,width):\"\"\"Clipanarrayofboxestoanimagewiththegivenheightandwidth.\"\"\"boxes[:,[0,2]]=np.minimum(width-1.,np.maximum(0.,boxes[:,[0,2]]))boxes[:,[1,3]]=np.minimum(height-1.,np.maximum(0.,boxes[:,[1,3]]))returnboxesdefclip_xyxy_to_image(x1,y1,x2,y2,height,width):\"\"\"Clipcoordinatestoanimagewiththegivenheightandwidth.\"\"\"x1=np.minimum(width-1.,np.maximum(0.,x1))y1=np.minimum(height-1.,np.maximum(0.,y1))x2=np.minimum(width-1.,np.maximum(0.,x2))y2=np.minimum(height-1.,np.maximum(0.,y2))returnx1,y1,x2,y2defclip_tiled_boxes(boxes,im_shape):\"\"\"Clipboxestoimageboundaries.im_shapeis[height,width]andboxeshasshape(N,4*num_tiled_boxes).\"\"\"assertboxes.shape[1]%4==0,\\\\\\'boxes.shape[1]is{:d},butmustbedivisibleby4.\\'.format(boxes.shape[1])#x1>=0boxes[:,0::4]=np.maximum(np.minimum(boxes[:,0::4],im_shape[1]-1),0)#y1>=0boxes[:,1::4]=np.maximum(np.minimum(boxes[:,1::4],im_shape[0]-1),0)#x2<im_shape[1]boxes[:,2::4]=np.maximum(np.minimum(boxes[:,2::4],im_shape[1]-1),0)#y2<im_shape[0]boxes[:,3::4]=np.maximum(np.minimum(boxes[:,3::4],im_shape[0]-1),0)returnboxesdefbbox_transform(boxes,deltas,weights=(1.0,1.0,1.0,1.0)):\"\"\"Forwardtransformthatmapsproposalboxestopredictedground-truthboxesusingbounding-boxregressiondeltas.Seebbox_transform_invforadescriptionoftheweightsargument.\"\"\"ifboxes.shape[0]==0:returnnp.zeros((0,deltas.shape[1]),dtype=deltas.dtype)boxes=boxes.astype(deltas.dtype,copy=False)widths=boxes[:,2]-boxes[:,0]+1.0heights=boxes[:,3]-boxes[:,1]+1.0ctr_x=boxes[:,0]+0.5*widthsctr_y=boxes[:,1]+0.5*heightswx,wy,ww,wh=weightsdx=deltas[:,0::4]/wxdy=deltas[:,1::4]/wydw=deltas[:,2::4]/wwdh=deltas[:,3::4]/wh#Preventsendingtoolargevaluesintonp.exp()dw=np.minimum(dw,cfg.BBOX_XFORM_CLIP)dh=np.minimum(dh,cfg.BBOX_XFORM_CLIP)pred_ctr_x=dx*widths[:,np.newaxis]+ctr_x[:,np.newaxis]pred_ctr_y=dy*heights[:,np.newaxis]+ctr_y[:,np.newaxis]pred_w=np.exp(dw)*widths[:,np.newaxis]pred_h=np.exp(dh)*heights[:,np.newaxis]pred_boxes=np.zeros(deltas.shape,dtype=deltas.dtype)#x1pred_boxes[:,0::4]=pred_ctr_x-0.5*pred_w#y1pred_boxes[:,1::4]=pred_ctr_y-0.5*pred_h#x2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,2::4]=pred_ctr_x+0.5*pred_w-1#y2(note:\"-1\"iscorrect;don\\'tbefooledbytheasymmetry)pred_boxes[:,3::4]=pred_ctr_y+0.5*pred_h-1returnpred_boxesdefbbox_transform_inv(boxes,gt_boxes,weights=(1.0,1.0,1.0,1.0)):\"\"\"Inversetransformthatcomputestargetbounding-boxregressiondeltasgivenproposalboxesandground-truthboxes.Theweightsargumentshouldbea4-tupleofmultiplicativeweightsthatareappliedtotheregressiontarget.Inolderversionsofthiscode(andinpy-faster-rcnn),theweightsweresetsuchthattheregressiondeltaswouldhaveunitstandarddeviationonthetrainingdataset.Presently,ratherthancomputingthesestatisticsexactly,weuseafixedsetofweights(10.,10.,5.,5.)bydefault.TheseareapproximatelytheweightsonewouldgetfromCOCOusingthepreviousunitstdevheuristic.\"\"\"ex_widths=boxes[:,2]-boxes[:,0]+1.0ex_heights=boxes[:,3]-boxes[:,1]+1.0ex_ctr_x=boxes[:,0]+0.5*ex_widthsex_ctr_y=boxes[:,1]+0.5*ex_heightsgt_widths=gt_boxes[:,2]-gt_boxes[:,0]+1.0gt_heights=gt_boxes[:,3]-gt_boxes[:,1]+1.0gt_ctr_x=gt_boxes[:,0]+0.5*gt_widthsgt_ctr_y=gt_boxes[:,1]+0.5*gt_heightswx,wy,ww,wh=weightstargets_dx=wx*(gt_ctr_x-ex_ctr_x)/ex_widthstargets_dy=wy*(gt_ctr_y-ex_ctr_y)/ex_heightstargets_dw=ww*np.log(gt_widths/ex_widths)targets_dh=wh*np.log(gt_heights/ex_heights)targets=np.vstack((targets_dx,targets_dy,targets_dw,targets_dh)).transpose()returntargetsdefexpand_boxes(boxes,scale):\"\"\"Expandanarrayofboxesbyagivenscale.\"\"\"w_half=(boxes[:,2]-boxes[:,0])*.5h_half=(boxes[:,3]-boxes[:,1])*.5x_c=(boxes[:,2]+boxes[:,0])*.5y_c=(boxes[:,3]+boxes[:,1])*.5w_half*=scaleh_half*=scaleboxes_exp=np.zeros(boxes.shape)boxes_exp[:,0]=x_c-w_halfboxes_exp[:,2]=x_c+w_halfboxes_exp[:,1]=y_c-h_halfboxes_exp[:,3]=y_c+h_halfreturnboxes_expdefflip_boxes(boxes,im_width):\"\"\"Flipboxeshorizontally.\"\"\"boxes_flipped=boxes.copy()boxes_flipped[:,0::4]=im_width-boxes[:,2::4]-1boxes_flipped[:,2::4]=im_width-boxes[:,0::4]-1returnboxes_flippeddefaspect_ratio(boxes,aspect_ratio):\"\"\"Performwidth-relativeaspectratiotransformation.\"\"\"boxes_ar=boxes.copy()boxes_ar[:,0::4]=aspect_ratio*boxes[:,0::4]boxes_ar[:,2::4]=aspect_ratio*boxes[:,2::4]returnboxes_ardefbox_voting(top_dets,all_dets,thresh,scoring_method=\\'ID\\',beta=1.0):\"\"\"Applybounding-boxvotingtorefine`top_dets`byvotingwith`all_dets`.See:Optionalscoreaveraging(notinthereferencedpaper)canbeappliedbysetting`scoring_method`appropriately.\"\"\"#top_detsis[N,5]eachrowis[x1y1x2y2,sore]#all_detsis[N,5]eachrowis[x1y1x2y2,sore]top_dets_out=top_dets.copy()top_boxes=top_dets[:,:4]all_boxes=all_dets[:,:4]all_scores=all_dets[:,4]top_to_all_overlaps=bbox_overlaps(top_boxes,all_boxes)forkinrange(top_dets_out.shape[0]):inds_to_vote=np.where(top_to_all_overlaps[k]>=thresh)[0]boxes_to_vote=all_boxes[inds_to_vote,:]ws=all_scores[inds_to_vote]top_dets_out[k,:4]=np.average(boxes_to_vote,axis=0,weights=ws)ifscoring_method==\\'ID\\':#Identity,nothingtodopasselifscoring_method==\\'TEMP_AVG\\':#Averageprobabilities(consideredasP(detectedclass)vs.#P(notthedetectedclass))aftersmoothingwithatemperature#hyperparameter.P=np.vstack((ws,1.0-ws))P_max=np.max(P,axis=0)X=np.log(P/P_max)X_exp=np.exp(X/beta)P_temp=X_exp/np.sum(X_exp,axis=0)P_avg=P_temp[0].mean()top_dets_out[k,4]=P_avgelifscoring_method==\\'AVG\\':#Combinenewprobsfromoverlappingboxestop_dets_out[k,4]=ws.mean()elifscoring_method==\\'IOU_AVG\\':P=wsws=top_to_all_overlaps[k,inds_to_vote]P_avg=np.average(P,weights=ws)top_dets_out[k,4]=P_avgelifscoring_method==\\'GENERALIZED_AVG\\':P_avg=np.mean(ws**beta)**(1.0/beta)top_dets_out[k,4]=P_avgelifscoring_method==\\'QUASI_SUM\\':top_dets_out[k,4]=ws.sum()/float(len(ws))**betaelse:raiseNotImplementedError(\\'Unknownscoringmethod{}\\'.format(scoring_method))returntop_dets_outdefnms(dets,thresh):\"\"\"ApplyclassicDPM-stylegreedyNMS.\"\"\"ifdets.shape[0]==0:return[]returncython_nms.nms(dets,thresh)defsoft_nms(dets,sigma=0.5,overlap_thresh=0.3,score_thresh=0.001,method=\\'linear\\'):\"\"\"ApplythesoftNMSalgorithmfrom\"\"\"ifdets.shape[0]==0:returndets,[]methods={\\'hard\\':0,\\'linear\\':1,\\'gaussian\\':2}assertmethodinmethods,\\'Unknownsoft_nmsmethod:{}\\'.format(method)dets,keep=cython_nms.soft_nms(np.ascontiguousarray(dets,dtype=np.float32),np.float32(sigma),np.float32(overlap_thresh),np.float32(score_thresh),np.uint8(methods[method]))returndets,keep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Utilitiesforlogging.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdequefromemail.mime.textimportMIMETextimportjsonimportloggingimportnumpyasnpimportsmtplibimportsysdeflog_json_stats(stats,sort_keys=True):#hacktocontrolprecisionoftop-levelfloatsstats={k:\\'{:.6f}\\'.format(v)ifisinstance(v,float)elsevfork,vinstats.items()}print(\\'json_stats:{:s}\\'.format(json.dumps(stats,sort_keys=sort_keys)))classSmoothedValue:\"\"\"Trackaseriesofvaluesandprovideaccesstosmoothedvaluesoverawindowortheglobalseriesaverage.\"\"\"def__init__(self,window_size):self.deque=deque(maxlen=window_size)self.series=[]self.total=0.0self.count=0defAddValue(self,value):self.deque.append(value)self.series.append(value)self.count+=1self.total+=valuedefGetMedianValue(self):returnnp.median(self.deque)defGetAverageValue(self):returnnp.mean(self.deque)defGetGlobalAverageValue(self):returnself.total/self.countdefsend_email(subject,body,to):s=smtplib.SMTP(\\'localhost\\')mime=MIMEText(body)mime[\\'Subject\\']=subjectmime[\\'To\\']=tos.sendmail(\\'detectron\\',to,mime.as_string())defsetup_logging(name):FORMAT=\\'%(levelname)s%(filename)s:%(lineno)4d:%(message)s\\'#Manuallyclearrootloggerstopreventanymodulethatmayhavecalled#logging.basicConfig()fromblockingourloggingsetuplogging.root.handlers=[]logging.basicConfig(level=logging.INFO,format=FORMAT,stream=sys.stdout)logger=logging.getLogger(name)returnlogger#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Imagehelperfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpdefaspect_ratio_rel(im,aspect_ratio):\"\"\"Performswidth-relativeaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_ar_w=int(round(aspect_ratio*im_w))im_ar=cv2.resize(im,dsize=(im_ar_w,im_h))returnim_ardefaspect_ratio_abs(im,aspect_ratio):\"\"\"Performsabsoluteaspectratiotransformation.\"\"\"im_h,im_w=im.shape[:2]im_area=im_h*im_wim_ar_w=np.sqrt(im_area*aspect_ratio)im_ar_h=np.sqrt(im_area/aspect_ratio)assertnp.isclose(im_ar_w/im_ar_h,aspect_ratio)im_ar=cv2.resize(im,dsize=(int(im_ar_w),int(im_ar_h)))returnim_ar#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Learningratepolicies.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgdefget_lr_at_iter(it):\"\"\"Getthelearningrateatiterationitaccordingtothecfg.SOLVERsettings.\"\"\"lr=get_lr_func()(it)ifit<cfg.SOLVER.WARM_UP_ITERS:method=cfg.SOLVER.WARM_UP_METHODifmethod==\\'constant\\':warmup_factor=cfg.SOLVER.WARM_UP_FACTORelifmethod==\\'linear\\':alpha=it/cfg.SOLVER.WARM_UP_ITERSwarmup_factor=cfg.SOLVER.WARM_UP_FACTOR*(1-alpha)+alphaelse:raiseKeyError(\\'UnknownSOLVER.WARM_UP_METHOD:{}\\'.format(method))lr*=warmup_factorreturnnp.float32(lr)#----------------------------------------------------------------------------##Learningratepolicyfunctions#----------------------------------------------------------------------------#deflr_func_steps_with_lrs(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_lrs\\'Changethelearningratetospecifiedvaluesatspecifiediterations.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.LRS:[0.02,0.002,0.0002]forcur_iterin[0,59]use0.02in[60,79]use0.002in[80,inf]use0.0002\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.LRS[ind]deflr_func_steps_with_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'steps_with_decay\\'Changethelearningratespecifiediterationsbasedontheformulalr=base_lr*gamma**lr_step_count.Example:cfg.SOLVER.MAX_ITER:90cfg.SOLVER.STEPS:[0,60,80]cfg.SOLVER.BASE_LR:0.02cfg.SOLVER.GAMMA:0.1forcur_iterin[0,59]use0.02=0.02*0.1**0in[60,79]use0.002=0.02*0.1**1in[80,inf]use0.0002=0.02*0.1**2\"\"\"ind=get_step_index(cur_iter)returncfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**inddeflr_func_step(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'step\\'\"\"\"return(cfg.SOLVER.BASE_LR*cfg.SOLVER.GAMMA**(cur_iter//cfg.SOLVER.STEP_SIZE))deflr_func_cosine_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'cosine_decay\\'\"\"\"iter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERcos_frac=0.5*(np.cos(np.pi*iter_frac)+1)returncfg.SOLVER.BASE_LR*cos_fracdeflr_func_exp_decay(cur_iter):\"\"\"Forcfg.SOLVER.LR_POLICY=\\'exp_decay\\'\"\"\"#GAMMAisfinal/initiallearningrateratioiter_frac=float(cur_iter)/cfg.SOLVER.MAX_ITERexp_frac=np.exp(iter_frac*np.log(cfg.SOLVER.GAMMA))returncfg.SOLVER.BASE_LR*exp_frac#----------------------------------------------------------------------------##Helpers#----------------------------------------------------------------------------#defget_step_index(cur_iter):\"\"\"Givenaniteration,findwhichlearningratestepwe\\'reat.\"\"\"assertcfg.SOLVER.STEPS[0]==0,\\'Thefirststepshouldalwaysstartat0.\\'steps=cfg.SOLVER.STEPS+[cfg.SOLVER.MAX_ITER]forind,stepinenumerate(steps):#NoQAifcur_iter<step:breakreturnind-1defget_lr_func():policy=\\'lr_func_\\'+cfg.SOLVER.LR_POLICYifpolicynotinglobals():raiseNotImplementedError(\\'UnknownLRpolicy:{}\\'.format(cfg.SOLVER.LR_POLICY))else:returnglobals()[policy]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Timingrelatedfunctions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporttimeclassTimer:\"\"\"Asimpletimer.\"\"\"def__init__(self):self.reset()deftic(self):#usingtime.timeinsteadoftime.clockbecausetimetime.clock#doesnotnormalizeformultithreadingself.start_time=time.time()deftoc(self,average=True):self.diff=time.time()-self.start_timeself.total_time+=self.diffself.calls+=1self.average_time=self.total_time/self.callsifaverage:returnself.average_timeelse:returnself.diffdefreset(self):self.total_time=0.self.calls=0self.start_time=0.self.diff=0.self.average_time=0.#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Coordinatedaccesstoasharedmultithreading/processingqueue.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcontextlibimportloggingimportthreadingimporttracebackfromsix.movesimportqueueasQueuelog=logging.getLogger(__name__)classCoordinator:def__init__(self):self._event=threading.Event()defrequest_stop(self):log.debug(\\'Coordinatorstopping\\')self._event.set()defshould_stop(self):returnself._event.is_set()defwait_for_stop(self):returnself._event.wait()@contextlib.contextmanagerdefstop_on_exception(self):try:yieldexceptException:ifnotself.should_stop():traceback.print_exc()self.request_stop()defcoordinated_get(coordinator,queue):whilenotcoordinator.should_stop():try:returnqueue.get(block=True,timeout=1.0)exceptQueue.Empty:continueraiseException(\\'Coordinatorstoppedduringget()\\')defcoordinated_put(coordinator,queue,element):whilenotcoordinator.should_stop():try:queue.put(element,block=True,timeout=1.0)returnexceptQueue.Full:continueraiseException(\\'Coordinatorstoppedduringput()\\')#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Utilitiesdrivingthetrain_netbinary\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromshutilimportcopyfileimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportosimportrefromcaffe2.pythonimportmemongerfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.datasets.roidbimportcombined_roidb_for_trainingfromdetectron.modelingimportmodel_builderfromdetectron.utilsimportlr_policyfromdetectron.utils.training_statsimportTrainingStatsimportdetectron.utils.envasenvuimportdetectron.utils.netasnudeftrain_model():\"\"\"Modeltrainingloop.\"\"\"model,weights_file,start_iter,checkpoints,output_dir=create_model()if\\'final\\'incheckpoints:#Thefinalmodelwasfoundintheoutputdirectory,sonothingtodoreturncheckpointssetup_model_for_training(model,weights_file,output_dir)training_stats=TrainingStats(model)CHECKPOINT_PERIOD=int(cfg.TRAIN.SNAPSHOT_ITERS/cfg.NUM_GPUS)forcur_iterinrange(start_iter,cfg.SOLVER.MAX_ITER):ifmodel.roi_data_loader.has_stopped():handle_critical_error(model,\\'roi_data_loaderfailed\\')training_stats.IterTic()lr=model.UpdateWorkspaceLr(cur_iter,lr_policy.get_lr_at_iter(cur_iter))workspace.RunNet(model.net.Proto().name)ifcur_iter==start_iter:nu.print_net(model)training_stats.IterToc()training_stats.UpdateIterStats()training_stats.LogIterStats(cur_iter,lr)if(cur_iter+1)%CHECKPOINT_PERIOD==0andcur_iter>start_iter:checkpoints[cur_iter]=os.path.join(output_dir,\\'model_iter{}.pkl\\'.format(cur_iter))nu.save_model_to_weights_file(checkpoints[cur_iter],model)ifcur_iter==start_iter+training_stats.LOG_PERIOD:#Resettheiterationtimertoremoveoutliersfromthefirstfew#SGDiterationstraining_stats.ResetIterTimer()ifnp.isnan(training_stats.iter_total_loss):handle_critical_error(model,\\'LossisNaN\\')#Savethefinalmodelcheckpoints[\\'final\\']=os.path.join(output_dir,\\'model_final.pkl\\')nu.save_model_to_weights_file(checkpoints[\\'final\\'],model)#Shutdowndataloadingthreadsmodel.roi_data_loader.shutdown()returncheckpointsdefhandle_critical_error(model,msg):logger=logging.getLogger(__name__)logger.critical(msg)model.roi_data_loader.shutdown()raiseException(msg)defcreate_model():\"\"\"Buildthemodelandlookforsavedmodelcheckpointsincasewecanresumefromone.\"\"\"logger=logging.getLogger(__name__)start_iter=0checkpoints={}output_dir=get_output_dir(cfg.TRAIN.DATASETS,training=True)weights_file=cfg.TRAIN.WEIGHTSifcfg.TRAIN.AUTO_RESUME:#Checkforthefinalmodel(indicatestrainingalreadyfinished)final_path=os.path.join(output_dir,\\'model_final.pkl\\')ifos.path.exists(final_path):logger.info(\\'model_final.pklexists;noneedtotrain!\\')returnNone,None,None,{\\'final\\':final_path},output_dirifcfg.TRAIN.COPY_WEIGHTS:copyfile(weights_file,os.path.join(output_dir,os.path.basename(weights_file)))logger.info(\\'Copy{}to{}\\'.format(weights_file,output_dir))#Findthemostrecentcheckpoint(highestiterationnumber)files=os.listdir(output_dir)forfinfiles:iter_string=re.findall(r\\'(?<=model_iter)\\\\d+(?=\\\\.pkl)\\',f)iflen(iter_string)>0:checkpoint_iter=int(iter_string[0])ifcheckpoint_iter>start_iter:#Startoneiterationimmediatelyafterthecheckpointiterstart_iter=checkpoint_iter+1resume_weights_file=fifstart_iter>0:#Overridetheinitializationweightswiththefoundcheckpointweights_file=os.path.join(output_dir,resume_weights_file)logger.info(\\'========>Resumingfromcheckpoint{}atstartiter{}\\'.format(weights_file,start_iter))logger.info(\\'Buildingmodel:{}\\'.format(cfg.MODEL.TYPE))model=model_builder.create(cfg.MODEL.TYPE,train=True)ifcfg.MEMONGER:optimize_memory(model)#Performsrandomweightinitializationasdefinedbythemodelworkspace.RunNetOnce(model.param_init_net)returnmodel,weights_file,start_iter,checkpoints,output_dirdefoptimize_memory(model):\"\"\"SaveGPUmemorythroughblobsharing.\"\"\"fordeviceinrange(cfg.NUM_GPUS):namescope=\\'gpu_{}/\\'.format(device)losses=[namescope+lforlinmodel.losses]model.net._net=memonger.share_grad_blobs(model.net,losses,set(model.param_to_grad.values()),namescope,share_activations=cfg.MEMONGER_SHARE_ACTIVATIONS)defsetup_model_for_training(model,weights_file,output_dir):\"\"\"LoadedsavedweightsandcreatethenetworkintheC2workspace.\"\"\"logger=logging.getLogger(__name__)add_model_training_inputs(model)ifweights_file:#Overriderandomweightinitializationwithweightsfromasavedmodelnu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=0)#Evenifwe\\'rerandomlyinitializingwestillneedtosynchronize#parametersacrossGPUsnu.broadcast_parameters(model)workspace.CreateNet(model.net)logger.info(\\'Outputssavedto:{:s}\\'.format(os.path.abspath(output_dir)))dump_proto_files(model,output_dir)#Startloadingmini-batchesandenqueuingblobsmodel.roi_data_loader.register_sigint_handler()model.roi_data_loader.start(prefill=True)returnoutput_dirdefadd_model_training_inputs(model):\"\"\"Loadthetrainingdatasetandattachthetraininginputstothemodel.\"\"\"logger=logging.getLogger(__name__)logger.info(\\'Loadingdataset:{}\\'.format(cfg.TRAIN.DATASETS))roidb=combined_roidb_for_training(cfg.TRAIN.DATASETS,cfg.TRAIN.PROPOSAL_FILES)logger.info(\\'{:d}roidbentries\\'.format(len(roidb)))model_builder.add_training_inputs(model,roidb=roidb)defdump_proto_files(model,output_dir):\"\"\"Saveprototxtdescriptionsofthetrainingnetworkandparameterinitializationnetwork.\"\"\"withopen(os.path.join(output_dir,\\'net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.net.Proto()))withopen(os.path.join(output_dir,\\'param_init_net.pbtxt\\'),\\'w\\')asfid:fid.write(str(model.param_init_net.Proto()))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"IOutilities.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimporterrnoimporthashlibimportloggingimportosimportreimportsiximportsysfromsix.movesimportcPickleaspicklefromsix.movesimporturllibfromuuidimportuuid4logger=logging.getLogger(__name__)_DETECTRON_S3_BASE_URL=\\'defsave_object(obj,file_name,pickle_format=2):\"\"\"SaveaPythonobjectbypicklingit.Unlessspecificallyoverridden,wewanttosaveitinPickleformat=2sincethiswillallowotherPython2executablestoloadtheresultingPickle.WhenwewanttocompletelyremovePython2backward-compatibility,wecanbumpitupto3.Weshouldneverusepickle.HIGHEST_PROTOCOLasfaraspossibleiftheresultingfileismanifestedorused,externaltothesystem.\"\"\"file_name=os.path.abspath(file_name)#Avoidfilesystemraceconditions(particularlyonnetworkfilesystems)#bysavingtoarandomtmpfileonthesamefilesystem,andthen#atomicallyrenametothetargetfilename.tmp_file_name=file_name+\".tmp.\"+uuid4().hextry:withopen(tmp_file_name,\\'wb\\')asf:pickle.dump(obj,f,pickle_format)f.flush()#makesureit\\'swrittentodiskos.fsync(f.fileno())os.rename(tmp_file_name,file_name)finally:#Cleanupthetempfileonfailure.Ratherthanusingos.path.exists(),#whichcanbeunreliableonnetworkfilesystems,attempttodeleteand#ignoreoserrors.try:os.remove(tmp_file_name)exceptEnvironmentErrorase:#parentclassofIOError,OSErrorifgetattr(e,\\'errno\\',None)!=errno.ENOENT:#WeexpectENOENTlogger.info(\"Couldnotdeletetempfile%r\",tmp_file_name,exc_info=True)#passthroughsincewedon\\'twantthejobtocrashdefload_object(file_name):withopen(file_name,\\'rb\\')asf:#Thedefaultencodingusedwhileunpicklingis7-bit(ASCII.)However,#theblobsarearbitrary8-bitbyteswhichdon\\'tagree.Theabsolute#correctwaytodothisistouse`encoding=\"bytes\"`andtheninterpret#theblobnameseitherasASCII,orbetter,asunicodeutf-8.A#reasonablefix,however,istotreatittheencodingas8-bitlatin1#(whichagreeswiththefirst256charactersofUnicodeanyway.)ifsix.PY2:returnpickle.load(f)else:returnpickle.load(f,encoding=\\'latin1\\')defcache_url(url_or_file,cache_dir):\"\"\"DownloadthefilespecifiedbytheURLtothecache_dirandreturnthepathtothecachedfile.IftheargumentisnotaURL,simplyreturnitasis.\"\"\"is_url=re.match(r\\'^(?:http)s?://\\',url_or_file,re.IGNORECASE)isnotNoneifnotis_url:returnurl_or_fileurl=url_or_fileasserturl.startswith(_DETECTRON_S3_BASE_URL),\\\\(\\'DetectrononlyautomaticallycachesURLsintheDetectronS3\\'\\'bucket:{}\\').format(_DETECTRON_S3_BASE_URL)cache_file_path=url.replace(_DETECTRON_S3_BASE_URL,cache_dir)ifos.path.exists(cache_file_path):assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathcache_file_dir=os.path.dirname(cache_file_path)ifnotos.path.exists(cache_file_dir):os.makedirs(cache_file_dir)logger.info(\\'Downloadingremotefile{}to{}\\'.format(url,cache_file_path))download_url(url,cache_file_path)assert_cache_file_is_ok(url,cache_file_path)returncache_file_pathdefassert_cache_file_is_ok(url,file_path):\"\"\"Checkthatcachefilehasthecorrecthash.\"\"\"#Fileisalreadyinthecache,verifythatthemd5summatchesand#returnlocalpathcache_file_md5sum=_get_file_md5sum(file_path)ref_md5sum=_get_reference_md5sum(url)assertcache_file_md5sum==ref_md5sum,\\\\(\\'TargetURL{}appearstobedownloadedtothelocalcachefile\\'\\'{},butthemd5hashofthelocalfiledoesnotmatchthe\\'\\'reference(actual:{}vs.expected:{}).Youmaywishtodelete\\'\\'thecachedfileandtryagaintotriggerautomatic\\'\\'download.\\').format(url,file_path,cache_file_md5sum,ref_md5sum)def_progress_bar(count,total):\"\"\"Reportdownloadprogress.Credit:\"\"\"bar_len=60filled_len=int(round(bar_len*count/float(total)))percents=round(100.0*count/float(total),1)bar=\\'=\\'*filled_len+\\'-\\'*(bar_len-filled_len)sys.stdout.write(\\'[{}]{}%of{:.1f}MBfile\\\\r\\'.format(bar,percents,total/1024/1024))sys.stdout.flush()ifcount>=total:sys.stdout.write(\\'\\\\n\\')defdownload_url(url,dst_file_path,chunk_size=8192,progress_hook=_progress_bar):\"\"\"Downloadurlandwriteittodst_file_path.Credit:\"\"\"response=urllib.request.urlopen(url)ifsix.PY2:total_size=response.info().getheader(\\'Content-Length\\').strip()else:total_size=response.info().get(\\'Content-Length\\').strip()total_size=int(total_size)bytes_so_far=0withopen(dst_file_path,\\'wb\\')asf:while1:chunk=response.read(chunk_size)bytes_so_far+=len(chunk)ifnotchunk:breakifprogress_hook:progress_hook(bytes_so_far,total_size)f.write(chunk)returnbytes_so_fardef_get_file_md5sum(file_name):\"\"\"Computethemd5hashofafile.\"\"\"hash_obj=hashlib.md5()withopen(file_name,\\'rb\\')asf:hash_obj.update(f.read())returnhash_obj.hexdigest().encode(\\'utf-8\\')def_get_reference_md5sum(url):\"\"\"Byconventionthemd5hashforurlisstoredinurl+\\'.md5sum\\'.\"\"\"url_md5sum=url+\\'.md5sum\\'md5sum=urllib.request.urlopen(url_md5sum).read().strip()returnmd5sum#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Keypointutilities(somewhatspecifictoCOCOkeypoints).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_keypoints():\"\"\"GettheCOCOkeypointsandtheirleft/rightflipcoorespondencemap.\"\"\"#KeypointsarenotavailableintheCOCOjsonforthetestsplit,sowe#providethemhere.keypoints=[\\'nose\\',\\'left_eye\\',\\'right_eye\\',\\'left_ear\\',\\'right_ear\\',\\'left_shoulder\\',\\'right_shoulder\\',\\'left_elbow\\',\\'right_elbow\\',\\'left_wrist\\',\\'right_wrist\\',\\'left_hip\\',\\'right_hip\\',\\'left_knee\\',\\'right_knee\\',\\'left_ankle\\',\\'right_ankle\\']keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}returnkeypoints,keypoint_flip_mapdefget_person_class_index():\"\"\"IndexofthepersonclassinCOCO.\"\"\"return1defflip_keypoints(keypoints,keypoint_flip_map,keypoint_coords,width):\"\"\"Left/rightflipkeypoint_coords.keypointsandkeypoint_flip_mapareaccessiblefromget_keypoints().\"\"\"flipped_kps=keypoint_coords.copy()forlkp,rkpinkeypoint_flip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)flipped_kps[:,:,lid]=keypoint_coords[:,:,rid]flipped_kps[:,:,rid]=keypoint_coords[:,:,lid]#Flipxcoordinatesflipped_kps[:,0,:]=width-flipped_kps[:,0,:]-1#MaintainCOCOconventionthatifvisibility==0,thenx,y=0inds=np.where(flipped_kps[:,2,:]==0)flipped_kps[inds[0],0,inds[1]]=0returnflipped_kpsdefflip_heatmaps(heatmaps):\"\"\"Flipheatmapshorizontally.\"\"\"keypoints,flip_map=get_keypoints()heatmaps_flipped=heatmaps.copy()forlkp,rkpinflip_map.items():lid=keypoints.index(lkp)rid=keypoints.index(rkp)heatmaps_flipped[:,rid,:,:]=heatmaps[:,lid,:,:]heatmaps_flipped[:,lid,:,:]=heatmaps[:,rid,:,:]heatmaps_flipped=heatmaps_flipped[:,:,:,::-1]returnheatmaps_flippeddefheatmaps_to_keypoints(maps,rois):\"\"\"Extractpredictedkeypointlocationsfromheatmaps.Outputhasshape(#rois,4,#keypoints)withthe4rowscorrespondingto(x,y,logit,prob)foreachkeypoint.\"\"\"#ThisfunctionconvertsadiscreteimagecoordinateinaHEATMAP_SIZEx#HEATMAP_SIZEimagetoacontinuouskeypointcoordinate.Wemaintain#consistencywithkeypoints_to_heatmap_labelsbyusingtheconversionfrom#Heckbert1990:c=d+0.5,wheredisadiscretecoordinateandcisa#continuouscoordinate.offset_x=rois[:,0]offset_y=rois[:,1]widths=rois[:,2]-rois[:,0]heights=rois[:,3]-rois[:,1]widths=np.maximum(widths,1)heights=np.maximum(heights,1)widths_ceil=np.ceil(widths)heights_ceil=np.ceil(heights)#NCHWtoNHWCforusewithOpenCVmaps=np.transpose(maps,[0,2,3,1])min_size=cfg.KRCNN.INFERENCE_MIN_SIZExy_preds=np.zeros((len(rois),4,cfg.KRCNN.NUM_KEYPOINTS),dtype=np.float32)foriinrange(len(rois)):ifmin_size>0:roi_map_width=int(np.maximum(widths_ceil[i],min_size))roi_map_height=int(np.maximum(heights_ceil[i],min_size))else:roi_map_width=widths_ceil[i]roi_map_height=heights_ceil[i]width_correction=widths[i]/roi_map_widthheight_correction=heights[i]/roi_map_heightroi_map=cv2.resize(maps[i],(roi_map_width,roi_map_height),interpolation=cv2.INTER_CUBIC)#BringbacktoCHWroi_map=np.transpose(roi_map,[2,0,1])roi_map_probs=scores_to_probs(roi_map.copy())w=roi_map.shape[2]forkinrange(cfg.KRCNN.NUM_KEYPOINTS):pos=roi_map[k,:,:].argmax()x_int=pos%wy_int=(pos-x_int)//wassert(roi_map_probs[k,y_int,x_int]==roi_map_probs[k,:,:].max())x=(x_int+0.5)*width_correctiony=(y_int+0.5)*height_correctionxy_preds[i,0,k]=x+offset_x[i]xy_preds[i,1,k]=y+offset_y[i]xy_preds[i,2,k]=roi_map[k,y_int,x_int]xy_preds[i,3,k]=roi_map_probs[k,y_int,x_int]returnxy_predsdefkeypoints_to_heatmap_labels(keypoints,rois):\"\"\"EncodekeypointlocationinthetargetheatmapforuseinSoftmaxWithLoss.\"\"\"#Mapskeypointsfromthehalf-openinterval[x1,x2)oncontinuousimage#coordinatestotheclosedinterval[0,HEATMAP_SIZE-1]ondiscreteimage#coordinates.WeusethecontinuousdiscreteconversionfromHeckbert#1990(\"Whatisthecoordinateofapixel?\"):d=floor(c)andc=d+0.5,#wheredisadiscretecoordinateandcisacontinuouscoordinate.assertkeypoints.shape[2]==cfg.KRCNN.NUM_KEYPOINTSshape=(len(rois),cfg.KRCNN.NUM_KEYPOINTS)heatmaps=blob_utils.zeros(shape)weights=blob_utils.zeros(shape)offset_x=rois[:,0]offset_y=rois[:,1]scale_x=cfg.KRCNN.HEATMAP_SIZE/(rois[:,2]-rois[:,0])scale_y=cfg.KRCNN.HEATMAP_SIZE/(rois[:,3]-rois[:,1])forkpinrange(keypoints.shape[2]):vis=keypoints[:,2,kp]>0x=keypoints[:,0,kp].astype(np.float32)y=keypoints[:,1,kp].astype(np.float32)#Sinceweusefloorbelow,ifakeypointisexactlyontheroi\\'sright#orbottomboundary,weshiftitinbyeps(conceptually)tokeepitin#thegroundtruthheatmap.x_boundary_inds=np.where(x==rois[:,2])[0]y_boundary_inds=np.where(y==rois[:,3])[0]x=(x-offset_x)*scale_xx=np.floor(x)iflen(x_boundary_inds)>0:x[x_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1y=(y-offset_y)*scale_yy=np.floor(y)iflen(y_boundary_inds)>0:y[y_boundary_inds]=cfg.KRCNN.HEATMAP_SIZE-1valid_loc=np.logical_and(np.logical_and(x>=0,y>=0),np.logical_and(x<cfg.KRCNN.HEATMAP_SIZE,y<cfg.KRCNN.HEATMAP_SIZE))valid=np.logical_and(valid_loc,vis)valid=valid.astype(np.int32)lin_ind=y*cfg.KRCNN.HEATMAP_SIZE+xheatmaps[:,kp]=lin_ind*validweights[:,kp]=validreturnheatmaps,weightsdefscores_to_probs(scores):\"\"\"TransformsCxHxWofscorestoprobabilitiesspatially.\"\"\"channels=scores.shape[0]forcinrange(channels):temp=scores[c,:,:]max_score=temp.max()temp=np.exp(temp-max_score)/np.sum(np.exp(temp-max_score))scores[c,:,:]=tempreturnscoresdefnms_oks(kp_predictions,rois,thresh):\"\"\"Nmsbasedonkppredictions.\"\"\"scores=np.mean(kp_predictions[:,2,:],axis=1)order=scores.argsort()[::-1]keep=[]whileorder.size>0:i=order[0]keep.append(i)ovr=compute_oks(kp_predictions[i],rois[i],kp_predictions[order[1:]],rois[order[1:]])inds=np.where(ovr<=thresh)[0]order=order[inds+1]returnkeepdefcompute_oks(src_keypoints,src_roi,dst_keypoints,dst_roi):\"\"\"ComputeOKSforpredictedkeypointswrtgt_keypoints.src_keypoints:4xKsrc_roi:4x1dst_keypoints:Nx4xKdst_roi:Nx4\"\"\"sigmas=np.array([.26,.25,.25,.35,.35,.79,.79,.72,.72,.62,.62,1.07,1.07,.87,.87,.89,.89])/10.0vars=(sigmas*2)**2#areasrc_area=(src_roi[2]-src_roi[0]+1)*(src_roi[3]-src_roi[1]+1)#measuretheper-keypointdistanceifkeypointsvisibledx=dst_keypoints[:,0,:]-src_keypoints[0,:]dy=dst_keypoints[:,1,:]-src_keypoints[1,:]e=(dx**2+dy**2)/vars/(src_area+np.spacing(1))/2e=np.sum(np.exp(-e),axis=1)/e.shape[1]returne#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fill#----------------------------------------------------------------------------##R-FCNoutputsandlosses#----------------------------------------------------------------------------#defadd_rfcn_outputs(model,blob_in,dim_in,dim_reduce,spatial_scale):ifdim_reduceisnotNone:#Optionaldimreductionblob_in=model.Conv(blob_in,\\'conv_dim_reduce\\',dim_in,dim_reduce,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))blob_in=model.Relu(blob_in,blob_in)dim_in=dim_reduce#Classificationconvmodel.Conv(blob_in,\\'conv_cls\\',dim_in,model.num_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Bounding-boxregressionconvnum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.Conv(blob_in,\\'conv_bbox_pred\\',dim_in,4*num_bbox_reg_classes*cfg.RFCN.PS_GRID_SIZE**2,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#ClassificationPSRoIpoolingmodel.net.PSRoIPool([\\'conv_cls\\',\\'rois\\'],[\\'psroipooled_cls\\',\\'_mapping_channel_cls\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=model.num_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_cls\\',\\'cls_score_4d\\',kernel=cfg.RFCN.PS_GRID_SIZE)model.net.Reshape(\\'cls_score_4d\\',[\\'cls_score\\',\\'_cls_scores_shape\\'],shape=(-1,cfg.MODEL.NUM_CLASSES))ifnotmodel.train:model.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#BboxregressionPSRoIpoolingmodel.net.PSRoIPool([\\'conv_bbox_pred\\',\\'rois\\'],[\\'psroipooled_bbox\\',\\'_mapping_channel_bbox\\'],group_size=cfg.RFCN.PS_GRID_SIZE,output_dim=4*num_bbox_reg_classes,spatial_scale=spatial_scale)model.AveragePool(\\'psroipooled_bbox\\',\\'bbox_pred\\',kernel=cfg.RFCN.PS_GRID_SIZE)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ImplementsResNetandResNeXt.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.netimportget_group_gn#----------------------------------------------------------------------------##Bitsforspecificarchitectures(ResNet50,ResNet101,...)#----------------------------------------------------------------------------#defadd_ResNet50_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,6))defadd_ResNet50_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,6,3))defadd_ResNet101_conv4_body(model):returnadd_ResNet_convX_body(model,(3,4,23))defadd_ResNet101_conv5_body(model):returnadd_ResNet_convX_body(model,(3,4,23,3))defadd_ResNet152_conv5_body(model):returnadd_ResNet_convX_body(model,(3,8,36,3))#----------------------------------------------------------------------------##GenericResNetcomponents#----------------------------------------------------------------------------#defadd_stage(model,prefix,blob_in,n,dim_in,dim_out,dim_inner,dilation,stride_init=2):\"\"\"AddaResNetstagetothemodelbystackingnresidualblocks.\"\"\"#e.g.,prefix=res2foriinrange(n):blob_in=add_residual_block(model,\\'{}_{}\\'.format(prefix,i),blob_in,dim_in,dim_out,dim_inner,dilation,stride_init,#Notusinginplaceforthelastblock;#itmaybefetchedexternallyorusedbyFPNinplace_sum=i<n-1)dim_in=dim_outreturnblob_in,dim_indefadd_ResNet_convX_body(model,block_counts):\"\"\"AddaResNetbodyfrominputdataupthroughtheres5(akaconv5)stage.Thefinalres5/conv5stagemaybeoptionallyexcluded(henceconvX,whereX=4or5).\"\"\"freeze_at=cfg.TRAIN.FREEZE_ATassertfreeze_atin[0,2,3,4,5]#addthestem(bydefault,conv1andpool1withbn;cansupportgn)p,dim_in=globals()[cfg.RESNETS.STEM_FUNC](model,\\'data\\')dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUP(n1,n2,n3)=block_counts[:3]s,dim_in=add_stage(model,\\'res2\\',p,n1,dim_in,256,dim_bottleneck,1)iffreeze_at==2:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res3\\',s,n2,dim_in,512,dim_bottleneck*2,1)iffreeze_at==3:model.StopGradient(s,s)s,dim_in=add_stage(model,\\'res4\\',s,n3,dim_in,1024,dim_bottleneck*4,1)iffreeze_at==4:model.StopGradient(s,s)iflen(block_counts)==4:n4=block_counts[3]s,dim_in=add_stage(model,\\'res5\\',s,n4,dim_in,2048,dim_bottleneck*8,cfg.RESNETS.RES5_DILATION)iffreeze_at==5:model.StopGradient(s,s)returns,dim_in,1./32.*cfg.RESNETS.RES5_DILATIONelse:returns,dim_in,1./16.defadd_ResNet_roi_conv5_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddsanRoIfeaturetransformation(e.g.,RoIpooling)followedbyares5/conv5headappliedtoeachRoI.\"\"\"#TODO(rbg):ThiscontainsFastR-CNNspecificconfigoptionsmakingitnon-#reusable;makethismoregenericwithmodel-specificwrappersmodel.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=cfg.FAST_RCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dim_bottleneck=cfg.RESNETS.NUM_GROUPS*cfg.RESNETS.WIDTH_PER_GROUPstride_init=int(cfg.FAST_RCNN.ROI_XFORM_RESOLUTION/7)s,dim_in=add_stage(model,\\'res5\\',\\'pool5\\',3,dim_in,2048,dim_bottleneck*8,1,stride_init)s=model.AveragePool(s,\\'res5_pool\\',kernel=7)returns,2048defadd_residual_block(model,prefix,blob_in,dim_in,dim_out,dim_inner,dilation,stride_init=2,inplace_sum=False):\"\"\"Addaresidualblocktothemodel.\"\"\"#prefix=res_,e.g.,res2_3#Maxpoolingisperformedpriortothefirststage(whichisuniquely#distinguishedbydim_in=64),thuswekeepstride=1forthefirststagestride=stride_initif(dim_in!=dim_outanddim_in!=64anddilation==1)else1#transformationblobtr=globals()[cfg.RESNETS.TRANS_FUNC](model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,group=cfg.RESNETS.NUM_GROUPS,dilation=dilation)#sum->ReLU#shortcutfunction:bydefaultusingbn;supportgnadd_shortcut=globals()[cfg.RESNETS.SHORTCUT_FUNC]sc=add_shortcut(model,prefix,blob_in,dim_in,dim_out,stride)ifinplace_sum:s=model.net.Sum([tr,sc],tr)else:s=model.net.Sum([tr,sc],prefix+\\'_sum\\')returnmodel.Relu(s,s)#------------------------------------------------------------------------------#variousshortcuts(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):\"\"\"Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"ifdim_in==dim_out:returnblob_inc=model.Conv(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,stride=stride,no_bias=1)returnmodel.AffineChannel(c,prefix+\\'_branch1_bn\\',dim=dim_out)defbasic_gn_shortcut(model,prefix,blob_in,dim_in,dim_out,stride):ifdim_in==dim_out:returnblob_in#outputnameisprefix+\\'_branch1_gn\\'returnmodel.ConvGN(blob_in,prefix+\\'_branch1\\',dim_in,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=stride,pad=0,group=1,)#------------------------------------------------------------------------------#variousstems(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbasic_bn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem.Forapre-trainednetworkthatusedBN.AnAffineChannelopreplacesBNduringfine-tuning.\"\"\"dim=64p=model.Conv(data,\\'conv1\\',3,dim,7,pad=3,stride=2,no_bias=1)p=model.AffineChannel(p,\\'res_conv1_bn\\',dim=dim,inplace=True)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dimdefbasic_gn_stem(model,data,**kwargs):\"\"\"AddabasicResNetstem(usingGN)\"\"\"dim=64p=model.ConvGN(data,\\'conv1\\',3,dim,7,group_gn=get_group_gn(dim),pad=3,stride=2)p=model.Relu(p,p)p=model.MaxPool(p,\\'pool1\\',kernel=3,pad=1,stride=2)returnp,dim#------------------------------------------------------------------------------#varioustransformations(mayexpandandmayconsideranewhelper)#------------------------------------------------------------------------------defbottleneck_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"Addabottlenecktransformationtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->BN->ReLUcur=model.ConvAffine(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,stride=str1x1,pad=0,inplace=True)cur=model.Relu(cur,cur)#conv3x3->BN->ReLUcur=model.ConvAffine(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,stride=str3x3,pad=1*dilation,dilation=dilation,group=group,inplace=True)cur=model.Relu(cur,cur)#conv1x1->BN(noReLU)#NB:fornowthisAffineChannelopcannotbein-placeduetoabuginC2#gradientcomputationforgraphslikethiscur=model.ConvAffine(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,stride=1,pad=0,inplace=False)returncurdefbottleneck_gn_transformation(model,blob_in,dim_in,dim_out,stride,prefix,dim_inner,dilation=1,group=1):\"\"\"AddabottlenecktransformationwithGroupNormtothemodel.\"\"\"#Inoriginalresnet,stride=2ison1x1.#Infb.torchresnet,stride=2ison3x3.(str1x1,str3x3)=(stride,1)ifcfg.RESNETS.STRIDE_1X1else(1,stride)#conv1x1->GN->ReLUcur=model.ConvGN(blob_in,prefix+\\'_branch2a\\',dim_in,dim_inner,kernel=1,group_gn=get_group_gn(dim_inner),stride=str1x1,pad=0,)cur=model.Relu(cur,cur)#conv3x3->GN->ReLUcur=model.ConvGN(cur,prefix+\\'_branch2b\\',dim_inner,dim_inner,kernel=3,group_gn=get_group_gn(dim_inner),stride=str3x3,pad=1*dilation,dilation=dilation,group=group,)cur=model.Relu(cur,cur)#conv1x1->GN(noReLU)cur=model.ConvGN(cur,prefix+\\'_branch2c\\',dim_inner,dim_out,kernel=1,group_gn=get_group_gn(dim_out),stride=1,pad=0,)returncur#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingkeypointsinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->keypointhead->keypointoutput->loss...->Feature/MapThekeypointheadproducesafeaturerepresentationoftheRoIforthepurposeofkeypointprediction.Thekeypointoutputmoduleconvertsthefeaturerepresentationintokeypointheatmaps.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##KeypointR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_keypoint_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNkeypointspecificoutputs:keypointheatmaps.\"\"\"#NxKxHxWupsample_heatmap=(cfg.KRCNN.UP_SCALE>1)ifcfg.KRCNN.USE_DECONV:#ApplyConvTransposetothefeaturerepresentation;resultsin2x#upsamplingblob_in=model.ConvTranspose(blob_in,\\'kps_deconv\\',dim,cfg.KRCNN.DECONV_DIM,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'kps_deconv\\',\\'kps_deconv\\')dim=cfg.KRCNN.DECONV_DIMifupsample_heatmap:blob_name=\\'kps_score_lowres\\'else:blob_name=\\'kps_score\\'ifcfg.KRCNN.USE_DECONV_OUTPUT:#UseConvTransposetopredictheatmaps;resultsin2xupsamplingblob_out=model.ConvTranspose(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=cfg.KRCNN.DECONV_KERNEL,pad=int(cfg.KRCNN.DECONV_KERNEL/2-1),stride=2,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))else:#UseConvtopredictheatmaps;doesnoupsamplingblob_out=model.Conv(blob_in,blob_name,dim,cfg.KRCNN.NUM_KEYPOINTS,kernel=1,pad=0,stride=1,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifupsample_heatmap:#Increaseheatmapoutputsizeviabilinearupsamplingblob_out=model.BilinearInterpolation(blob_out,\\'kps_score\\',cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.NUM_KEYPOINTS,cfg.KRCNN.UP_SCALE)returnblob_outdefadd_keypoint_losses(model):\"\"\"AddMaskR-CNNkeypointspecificlosses.\"\"\"#Reshapeinputfrom(N,K,H,W)to(NK,HW)model.net.Reshape([\\'kps_score\\'],[\\'kps_score_reshaped\\',\\'_kps_score_old_shape\\'],shape=(-1,cfg.KRCNN.HEATMAP_SIZE*cfg.KRCNN.HEATMAP_SIZE))#Softmaxacross**space**(woahh....space!)#Note:thisisnotwhatiscommonlycalled\"spatialsoftmax\"#(i.e.,softmaxappliedalongthechanneldimensionateachspatial#location);Thisissoftmaxappliedoverasetofspatiallocations(i.e.,#eachspatiallocationisa\"class\").kps_prob,loss_kps=model.net.SoftmaxWithLoss([\\'kps_score_reshaped\\',\\'keypoint_locations_int32\\',\\'keypoint_weights\\'],[\\'kps_prob\\',\\'loss_kps\\'],scale=cfg.KRCNN.LOSS_WEIGHT/cfg.NUM_GPUS,spatial=0)ifnotcfg.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS:#Discussion:thesoftmaxlossabovewillaveragethelossbythesumof#keypoint_weights,i.e.thetotalnumberofvisiblekeypoints.Since#thenumberofvisiblekeypointscanvarysignificantlybetween#minibatches,thishastheeffectofup-weightingtheimportanceof#minibatcheswithfewvisiblekeypoints.(Imaginetheextremecaseof#onlyonevisiblekeypointversusN:inthecaseofN,eachone#contributes1/Ntothegradientcomparedtothesinglekeypoint#determiningthegradientdirection).Instead,wecannormalizethe#lossbythetotalnumberofkeypoints,ifitwerethecasethatall#keypointswerevisibleinafullminibatch.(Returningtotheexample,#thismeansthattheonevisiblekeypointcontributesasmuchaseach#oftheNkeypoints.)model.StopGradient(\\'keypoint_loss_normalizer\\',\\'keypoint_loss_normalizer\\')loss_kps=model.net.Mul([\\'loss_kps\\',\\'keypoint_loss_normalizer\\'],\\'loss_kps_normalized\\')loss_gradients=blob_utils.get_loss_gradients(model,[loss_kps])model.AddLosses(loss_kps)returnloss_gradients#----------------------------------------------------------------------------##Keypointheads#----------------------------------------------------------------------------#defadd_ResNet_roi_conv5_head_for_keypoints(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforMaskR-CNNkeypointprediction.\"\"\"model.RoIFeatureTransform(blob_in,\\'_[pose]_pool5\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)#Usingtheprefix\\'_[pose]_\\'to\\'res5\\'enablesinitializingthehead\\'s#parametersusingpretrained\\'res5\\'parametersifgiven(see#utils.net.initialize_from_weights_file)s,dim_in=ResNet.add_stage(model,\\'_[pose]_res5\\',\\'_[pose]_pool5\\',3,dim_in,2048,512,cfg.KRCNN.DILATION,stride_init=int(cfg.KRCNN.ROI_XFORM_RESOLUTION/7))returns,2048defadd_roi_pose_head_v1convX(model,blob_in,dim_in,spatial_scale):\"\"\"AddaMaskR-CNNkeypointhead.v1convXdesign:X*(conv).\"\"\"hidden_dim=cfg.KRCNN.CONV_HEAD_DIMkernel_size=cfg.KRCNN.CONV_HEAD_KERNELpad_size=kernel_size//2current=model.RoIFeatureTransform(blob_in,\\'_[pose]_roi_feat\\',blob_rois=\\'keypoint_rois\\',method=cfg.KRCNN.ROI_XFORM_METHOD,resolution=cfg.KRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.KRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)foriinrange(cfg.KRCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'conv_fcn\\'+str(i+1),dim_in,hidden_dim,kernel_size,stride=1,pad=pad_size,weight_init=(cfg.KRCNN.CONV_INIT,{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimreturncurrent,hidden_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Detectronmodelconstructionfunctions.Detectronsupportsalargenumberofmodeltypes.Theconfigurationspaceislarge.Togetasense,agivenmodelisinelementinthecartesianproductof:-backbone(e.g.,VGG16,ResNet,ResNeXt)-FPN(onoroff)-RPNonly(justproposals)-FixedproposalsforFastR-CNN,RFCN,MaskR-CNN(withorwithoutkeypoints)-End-to-endmodelwithRPN+FastR-CNN(i.e.,FasterR-CNN),MaskR-CNN,...-Different\"head\"choicesforthemodel-...manyconfigurationoptions...Agivenmodelismadebycombiningmanybasiccomponents.Theresultisflexiblethoughsomewhatcomplextounderstandatfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportimportlibimportloggingfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.modeling.detectorimportDetectionModelHelperfromdetectron.roi_data.loaderimportRoIDataLoaderimportdetectron.modeling.fast_rcnn_headsasfast_rcnn_headsimportdetectron.modeling.keypoint_rcnn_headsaskeypoint_rcnn_headsimportdetectron.modeling.mask_rcnn_headsasmask_rcnn_headsimportdetectron.modeling.name_compatasname_compatimportdetectron.modeling.optimizerasoptimimportdetectron.modeling.retinanet_headsasretinanet_headsimportdetectron.modeling.rfcn_headsasrfcn_headsimportdetectron.modeling.rpn_headsasrpn_headsimportdetectron.roi_data.minibatchasroi_data_minibatchimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)#----------------------------------------------------------------------------##Genericrecomposablemodelbuilders##Forexample,youcancreateaFastR-CNNmodelwiththeResNet-50-C4backbone#withtheconfiguration:##MODEL:#TYPE:generalized_rcnn#CONV_BODY:ResNet.add_ResNet50_conv4_body#ROI_HEAD:ResNet.add_ResNet_roi_conv5_head#----------------------------------------------------------------------------#defgeneralized_rcnn(model):\"\"\"Thismodeltypehandles:-FastR-CNN-RPNonly(notintegratedwithFastR-CNN)-FasterR-CNN(stagewisetrainingfromNIPSpaper)-FasterR-CNN(end-to-endjointtraining)-MaskR-CNN(stagewisetrainingfromNIPSpaper)-MaskR-CNN(end-to-endjointtraining)\"\"\"returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=cfg.TRAIN.FREEZE_CONV_BODY)defrfcn(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_rfcn_model(model,get_func(cfg.MODEL.CONV_BODY))defretinanet(model):#TODO(rbg):foldintobuild_generic_detection_modelreturnbuild_generic_retinanet_model(model,get_func(cfg.MODEL.CONV_BODY))#----------------------------------------------------------------------------##Helperfunctionsforbuildingvariousre-usablenetworkbits#----------------------------------------------------------------------------#defcreate(model_type_func,train=False,gpu_id=0):\"\"\"Genericmodelcreationfunctionthatdispatchestospecificmodelbuildingfunctions.Bydefault,thisfunctionwillgenerateadataparallelmodelconfiguredtorunoncfg.NUM_GPUSdevices.However,youcanrestrictittobuildamodeltargetedtoaspecificGPUbyspecifyinggpu_id.Thisisusedbyoptimizer.build_data_parallel_model()duringtesttime.\"\"\"model=DetectionModelHelper(name=model_type_func,train=train,num_classes=cfg.MODEL.NUM_CLASSES,init_params=train)model.only_build_forward_pass=Falsemodel.target_gpu_id=gpu_idreturnget_func(model_type_func)(model)defget_func(func_name):\"\"\"Helpertoreturnafunctionobjectbyname.func_namemustidentifyafunctioninthismoduleorthepathtoafunctionrelativetothebase\\'modeling\\'module.\"\"\"iffunc_name==\\'\\':returnNonenew_func_name=name_compat.get_new_name(func_name)ifnew_func_name!=func_name:logger.warn(\\'Remappingoldfunctionname:{}->{}\\'.format(func_name,new_func_name))func_name=new_func_nametry:parts=func_name.split(\\'.\\')#Referstoafunctioninthismoduleiflen(parts)==1:returnglobals()[parts[0]]#Otherwise,assumewe\\'rereferencingamoduleundermodelingmodule_name=\\'detectron.modeling.\\'+\\'.\\'.join(parts[:-1])module=importlib.import_module(module_name)returngetattr(module,parts[-1])exceptException:logger.error(\\'Failedtofindfunction:{}\\'.format(func_name))raisedefbuild_generic_detection_model(model,add_conv_body_func,add_roi_box_head_func=None,add_roi_mask_head_func=None,add_roi_keypoint_head_func=None,freeze_conv_body=False):def_single_gpu_build_func(model):\"\"\"BuildthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"#Addtheconvbody(called\"backbonearchitecture\"inpapers)#E.g.,ResNet-50,ResNet-50-FPN,ResNeXt-101-FPN,etc.blob_conv,dim_conv,spatial_scale_conv=add_conv_body_func(model)iffreeze_conv_body:forbinc2_utils.BlobReferenceList(blob_conv):model.StopGradient(b,b)ifnotmodel.train:#==inference#Createanetthatcanbeusedtoexecutetheconvbodyonanimage#(withoutalsoexecutingRPNoranyothernetworkheads)model.conv_body_net=model.net.Clone(\\'conv_body_net\\')head_loss_gradients={\\'rpn\\':None,\\'box\\':None,\\'mask\\':None,\\'keypoints\\':None,}ifcfg.RPN.RPN_ON:#AddtheRPNheadhead_loss_gradients[\\'rpn\\']=rpn_heads.add_generic_rpn_outputs(model,blob_conv,dim_conv,spatial_scale_conv)ifcfg.FPN.FPN_ON:#AfteraddingtheRPNhead,restrictFPNblobsandscalesto#thoseusedintheRoIheadsblob_conv,spatial_scale_conv=_narrow_to_fpn_roi_levels(blob_conv,spatial_scale_conv)ifnotcfg.MODEL.RPN_ONLY:#AddtheFastR-CNNheadhead_loss_gradients[\\'box\\']=_add_fast_rcnn_head(model,add_roi_box_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.MASK_ON:#Addthemaskheadhead_loss_gradients[\\'mask\\']=_add_roi_mask_head(model,add_roi_mask_head_func,blob_conv,dim_conv,spatial_scale_conv)ifcfg.MODEL.KEYPOINTS_ON:#Addthekeypointheadhead_loss_gradients[\\'keypoint\\']=_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_conv,dim_conv,spatial_scale_conv)ifmodel.train:loss_gradients={}forlginhead_loss_gradients.values():iflgisnotNone:loss_gradients.update(lg)returnloss_gradientselse:returnNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldef_narrow_to_fpn_roi_levels(blobs,spatial_scales):\"\"\"ReturnonlytheblobsandspatialscalesthatwillbeusedforRoIheads.Inputs`blobs`and`spatial_scales`mayincludeextrablobsandscalesthatareusedforRPNproposals,butnotforRoIheads.\"\"\"#CodeonlysupportscasewhenRPNandROIminlevelsarethesameassertcfg.FPN.RPN_MIN_LEVEL==cfg.FPN.ROI_MIN_LEVEL#RPNmaxlevelcanbe>=toROImaxlevelassertcfg.FPN.RPN_MAX_LEVEL>=cfg.FPN.ROI_MAX_LEVEL#FPNRPNmaxlevelmightbe>FPNROImaxlevelinwhichcasewe#needtodiscardsomeleadingconvblobs(blobsareorderedfrom#max/coarsestleveltomin/finestlevel)num_roi_levels=cfg.FPN.ROI_MAX_LEVEL-cfg.FPN.ROI_MIN_LEVEL+1returnblobs[-num_roi_levels:],spatial_scales[-num_roi_levels:]def_add_fast_rcnn_head(model,add_roi_box_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"AddaFastR-CNNheadtothemodel.\"\"\"blob_frcn,dim_frcn=add_roi_box_head_func(model,blob_in,dim_in,spatial_scale_in)fast_rcnn_heads.add_fast_rcnn_outputs(model,blob_frcn,dim_frcn)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)else:loss_gradients=Nonereturnloss_gradientsdef_add_roi_mask_head(model,add_roi_mask_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addamaskpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthemaskheadblob_mask_head,dim_mask_head=add_roi_mask_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthemaskoutputblob_mask=mask_rcnn_heads.add_mask_rcnn_outputs(model,blob_mask_head,dim_mask_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenmaskpredictions.#Thisrequiresseparatenetsforboxandmaskprediction.#Soweextractthemaskpredictionnet,storeitasitsownnetwork,#thenrestoremodel.nettobethebbox-onlynetworkmodel.mask_net,blob_mask=c2_utils.SuffixNet(\\'mask_net\\',model.net,len(bbox_net.op),blob_mask)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=mask_rcnn_heads.add_mask_rcnn_losses(model,blob_mask)returnloss_gradientsdef_add_roi_keypoint_head(model,add_roi_keypoint_head_func,blob_in,dim_in,spatial_scale_in):\"\"\"Addakeypointpredictionheadtothemodel.\"\"\"#Capturemodelgraphbeforeaddingthemaskheadbbox_net=copy.deepcopy(model.net.Proto())#Addthekeypointheadblob_keypoint_head,dim_keypoint_head=add_roi_keypoint_head_func(model,blob_in,dim_in,spatial_scale_in)#Addthekeypointoutputblob_keypoint=keypoint_rcnn_heads.add_keypoint_outputs(model,blob_keypoint_head,dim_keypoint_head)ifnotmodel.train:#==inference#Inferenceusesacascadeofboxpredictions,thenkeypointpredictions#Thisrequiresseparatenetsforboxandkeypointprediction.#Soweextractthekeypointpredictionnet,storeitasitsown#network,thenrestoremodel.nettobethebbox-onlynetworkmodel.keypoint_net,keypoint_blob_out=c2_utils.SuffixNet(\\'keypoint_net\\',model.net,len(bbox_net.op),blob_keypoint)model.net._net=bbox_netloss_gradients=Noneelse:loss_gradients=keypoint_rcnn_heads.add_keypoint_losses(model)returnloss_gradientsdefbuild_generic_rfcn_model(model,add_conv_body_func,dim_reduce=None):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blob,dim,spatial_scale=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')rfcn_heads.add_rfcn_outputs(model,blob,dim,dim_reduce,spatial_scale)ifmodel.train:loss_gradients=fast_rcnn_heads.add_fast_rcnn_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodeldefbuild_generic_retinanet_model(model,add_conv_body_func,freeze_conv_body=False):#TODO(rbg):foldthisfunctionintobuild_generic_detection_modeldef_single_gpu_build_func(model):\"\"\"BuildsthemodelonasingleGPU.CanbecalledinaloopoverGPUswithnameanddevicescopingtocreateadataparallelmodel.\"\"\"blobs,dim,spatial_scales=add_conv_body_func(model)ifnotmodel.train:model.conv_body_net=model.net.Clone(\\'conv_body_net\\')retinanet_heads.add_fpn_retinanet_outputs(model,blobs,dim,spatial_scales)ifmodel.train:loss_gradients=retinanet_heads.add_fpn_retinanet_losses(model)returnloss_gradientsifmodel.trainelseNoneoptim.build_data_parallel_model(model,_single_gpu_build_func)returnmodel#----------------------------------------------------------------------------##Networkinputs#----------------------------------------------------------------------------#defadd_training_inputs(model,roidb=None):\"\"\"Createnetworkinputopsandblobsusedfortraining.Tobecalled*after*model_builder.create().\"\"\"#Implementationnotes:#Typically,onewouldcreatetheinputopsandthentherestofthenet.#However,creatingtheinputopsdependsonloadingthedataset,which#cantakeafewminutesforCOCO.#Weprefertoavoidwaitingsodebuggingcanfailfast.#Thus,wecreatethenet*withoutinputops*priortoloadingthe#dataset,andthenaddtheinputopsafterloadingthedataset.#Sincewedeferinputopcreation,weneedtodoalittlebitofsurgery#toplacetheinputopsatthestartofthenetworkoplist.assertmodel.train,\\'Traininginputscanonlybeaddedtoatrainablemodel\\'ifroidbisnotNone:#Tomakedebuggingeasieryoucansetcfg.DATA_LOADER.NUM_THREADS=1model.roi_data_loader=RoIDataLoader(roidb,num_loaders=cfg.DATA_LOADER.NUM_THREADS,minibatch_queue_size=cfg.DATA_LOADER.MINIBATCH_QUEUE_SIZE,blobs_queue_capacity=cfg.DATA_LOADER.BLOBS_QUEUE_CAPACITY)orig_num_op=len(model.net._net.op)blob_names=roi_data_minibatch.get_minibatch_blob_names(is_training=True)forgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):forblob_nameinblob_names:workspace.CreateBlob(core.ScopedName(blob_name))model.net.DequeueBlobs(model.roi_data_loader._blobs_queue_name,blob_names)#Alittleopsurgerytomoveinputopstothestartofthenetdiff=len(model.net._net.op)-orig_num_opnew_op=model.net._net.op[-diff:]+model.net._net.op[:-diff]delmodel.net._net.op[:]model.net._net.op.extend(new_op)defadd_inference_inputs(model):\"\"\"Createnetworkinputblobsusedforinference.\"\"\"defcreate_input_blobs_for_net(net_def):foropinnet_def.op:forblob_ininop.input:ifnotworkspace.HasBlob(blob_in):workspace.CreateBlob(blob_in)create_input_blobs_for_net(model.net.Proto())ifcfg.MODEL.MASK_ON:create_input_blobs_for_net(model.mask_net.Proto())ifcfg.MODEL.KEYPOINTS_ON:create_input_blobs_for_net(model.keypoint_net.Proto())#----------------------------------------------------------------------------##**********************DEPRECATEDFUNCTIONALITYBELOW**********************##----------------------------------------------------------------------------##----------------------------------------------------------------------------##Hardcodedfunctionstocreatevarioustypesofcommonmodels##***Thistypeofmodeldefinitionisdeprecated***#***Usethegenericcomposableversionsinstead***##----------------------------------------------------------------------------#importdetectron.modeling.ResNetasResNetimportdetectron.modeling.VGG16asVGG16importdetectron.modeling.VGG_CNN_M_1024asVGG_CNN_M_1024deffast_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`.\\')returngeneralized_rcnn(model)defmask_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:True`\\')returngeneralized_rcnn(model)defkeypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defmask_and_keypoint_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.MASK_ON:Trueand``MODEL.KEYPOINTS_ON:True`\\')returngeneralized_rcnn(model)defrpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`\\')returngeneralized_rcnn(model)deffpn_rpn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.RPN_ONLY:True`andFPNenabledviaconfigs\\')returngeneralized_rcnn(model)deffaster_rcnn(model):logger.warn(\\'Deprecated:use`MODEL.TYPE:generalized_rcnn`with\\'\\'`MODEL.FASTER_RCNN:True`\\')returngeneralized_rcnn(model)deffast_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),freeze_conv_body=True)defrpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)deffpn_rpn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),freeze_conv_body=True)defmask_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_mask_head_func=get_func(cfg.MRCNN.ROI_MASK_HEAD),freeze_conv_body=True)defkeypoint_rcnn_frozen_features(model):logger.warn(\\'Deprecated:use`TRAIN.FREEZE_CONV_BODY:True`instead\\')returnbuild_generic_detection_model(model,get_func(cfg.MODEL.CONV_BODY),add_roi_box_head_func=get_func(cfg.FAST_RCNN.ROI_BOX_HEAD),add_roi_keypoint_head_func=get_func(cfg.KRCNN.ROI_KEYPOINTS_HEAD),freeze_conv_body=True)#----------------------------------------------------------------------------##FastR-CNNmodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,VGG_CNN_M_1024.add_VGG_CNN_M_1024_roi_fc_head)defVGG16_fast_rcnn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_fast_rcnn(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet50_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)defResNet101_fast_rcnn_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head,freeze_conv_body=True)#----------------------------------------------------------------------------##RPN-onlymodels#----------------------------------------------------------------------------#defVGG_CNN_M_1024_rpn(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body)defVGG16_rpn(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body)defResNet50_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body)defResNet101_rpn_conv4(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body)defVGG_CNN_M_1024_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG_CNN_M_1024.add_VGG_CNN_M_1024_conv5_body,freeze_conv_body=True)defVGG16_rpn_frozen_features(model):returnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,freeze_conv_body=True)defResNet50_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,freeze_conv_body=True)defResNet101_rpn_conv4_frozen_features(model):returnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,freeze_conv_body=True)#----------------------------------------------------------------------------##FasterR-CNNmodels#----------------------------------------------------------------------------#defVGG16_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,VGG16.add_VGG16_conv5_body,VGG16.add_VGG16_roi_fc_head)defResNet50_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet50_conv4_body,ResNet.add_ResNet_roi_conv5_head)defResNet101_faster_rcnn(model):assertcfg.MODEL.FASTER_RCNNreturnbuild_generic_detection_model(model,ResNet.add_ResNet101_conv4_body,ResNet.add_ResNet_roi_conv5_head)#----------------------------------------------------------------------------##R-FCNmodels#----------------------------------------------------------------------------#defResNet50_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet50_conv5_body,dim_reduce=1024)defResNet101_rfcn(model):returnbuild_generic_rfcn_model(model,ResNet.add_ResNet101_conv5_body,dim_reduce=1024)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforusingaFeaturePyramidNetwork(FPN).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcollectionsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utils#Lowestandhighestpyramidlevelsinthebackbonenetwork.ForFPN,weassume#thatallnetworkshave5spatialreductions,eachbyafactorof2.Level1#wouldcorrespondtotheinputimage,henceitdoesnotmakesensetouseit.LOWEST_BACKBONE_LVL=2#E.g.,\"conv2\"-likelevelHIGHEST_BACKBONE_LVL=5#E.g.,\"conv5\"-likelevel#----------------------------------------------------------------------------##FPNwithResNet#----------------------------------------------------------------------------#defadd_fpn_ResNet50_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5)defadd_fpn_ResNet50_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet50_conv5_body,fpn_level_info_ResNet50_conv5,P2only=True)defadd_fpn_ResNet101_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5)defadd_fpn_ResNet101_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet101_conv5_body,fpn_level_info_ResNet101_conv5,P2only=True)defadd_fpn_ResNet152_conv5_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5)defadd_fpn_ResNet152_conv5_P2only_body(model):returnadd_fpn_onto_conv_body(model,ResNet.add_ResNet152_conv5_body,fpn_level_info_ResNet152_conv5,P2only=True)#----------------------------------------------------------------------------##FunctionsforboltingFPNontoabackbonearchitectures#----------------------------------------------------------------------------#defadd_fpn_onto_conv_body(model,conv_body_func,fpn_level_info_func,P2only=False):\"\"\"AddthespecifiedconvbodytothemodelandthenaddFPNlevelstoit.\"\"\"#Note:blobs_convisinrevsersedorder:[fpn5,fpn4,fpn3,fpn2]#similarlyfordims_conv:[2048,1024,512,256]#similarlyforspatial_scales_fpn:[1/32,1/16,1/8,1/4]conv_body_func(model)blobs_fpn,dim_fpn,spatial_scales_fpn=add_fpn(model,fpn_level_info_func())ifP2only:#useonlythefinestlevelreturnblobs_fpn[-1],dim_fpn,spatial_scales_fpn[-1]else:#usealllevelsreturnblobs_fpn,dim_fpn,spatial_scales_fpndefadd_fpn(model,fpn_level_info):\"\"\"AddFPNconnectionsbasedonthemodeldescribedintheFPNpaper.\"\"\"#FPNlevelsarebuiltstartingfromthehighest/coarestlevelofthe#backbone(usually\"conv5\").Firstwebuilddown,recursivelyconstructing#lower/finerresolutionFPNlevels.Thenwebuildup,constructinglevels#thatareevenhigher/coarserthanthestartinglevel.fpn_dim=cfg.FPN.DIMmin_level,max_level=get_min_max_levels()#CountthenumberofbackbonestagesthatwewillgenerateFPNlevelsfor#startingfromthecoarestbackbonestage(usuallythe\"conv5\"-likelevel)#E.g.,ifthebackbonelevelinfodefinesstages4stages:\"conv5\",#\"conv4\",...\"conv2\"andmin_level=2,thenweendupwith4-(2-2)=4#backbonestagestoaddFPNto.num_backbone_stages=(len(fpn_level_info.blobs)-(min_level-LOWEST_BACKBONE_LVL))lateral_input_blobs=fpn_level_info.blobs[:num_backbone_stages]output_blobs=[\\'fpn_inner_{}\\'.format(s)forsinfpn_level_info.blobs[:num_backbone_stages]]fpn_dim_lateral=fpn_level_info.dimsxavier_fill=(\\'XavierFill\\',{})#Forthecoarsestbackbonelevel:1x1convonlyseedsrecursionifcfg.FPN.USE_GN:#useGroupNormc=model.ConvGN(lateral_input_blobs[0],output_blobs[0],#note:thisisaprefixdim_in=fpn_dim_lateral[0],dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))output_blobs[0]=c#renameitelse:model.Conv(lateral_input_blobs[0],output_blobs[0],dim_in=fpn_dim_lateral[0],dim_out=fpn_dim,kernel=1,pad=0,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))##Step1:recursivelybuilddownstartingfromthecoarsestbackbonelevel##Forotherlevelsaddtop-downandlateralconnectionsforiinrange(num_backbone_stages-1):add_topdown_lateral_module(model,output_blobs[i],#top-downbloblateral_input_blobs[i+1],#lateralbloboutput_blobs[i+1],#nextoutputblobfpn_dim,#outputdimensionfpn_dim_lateral[i+1]#lateralinputdimension)#Post-hocscale-specific3x3convsblobs_fpn=[]spatial_scales=[]foriinrange(num_backbone_stages):ifcfg.FPN.USE_GN:#useGroupNormfpn_blob=model.ConvGN(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,group_gn=get_group_gn(fpn_dim),kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))else:fpn_blob=model.Conv(output_blobs[i],\\'fpn_{}\\'.format(fpn_level_info.blobs[i]),dim_in=fpn_dim,dim_out=fpn_dim,kernel=3,pad=1,stride=1,weight_init=xavier_fill,bias_init=const_fill(0.0))blobs_fpn+=[fpn_blob]spatial_scales+=[fpn_level_info.spatial_scales[i]]##Step2:buildupstartingfromthecoarsestbackbonelevel##CheckifweneedtheP6featuremapifnotcfg.FPN.EXTRA_CONV_LEVELSandmax_level==HIGHEST_BACKBONE_LVL+1:#OriginalFPNP6levelimplementationfromourCVPR\\'17FPNpaperP6_blob_in=blobs_fpn[0]P6_name=P6_blob_in+\\'_subsampled_2x\\'#Usemaxpoolingtosimulatestride2subsamplingP6_blob=model.MaxPool(P6_blob_in,P6_name,kernel=1,pad=0,stride=2)blobs_fpn.insert(0,P6_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)#CoarserFPNlevelsintroducedforRetinaNetifcfg.FPN.EXTRA_CONV_LEVELSandmax_level>HIGHEST_BACKBONE_LVL:fpn_blob=fpn_level_info.blobs[0]dim_in=fpn_level_info.dims[0]foriinrange(HIGHEST_BACKBONE_LVL+1,max_level+1):fpn_blob_in=fpn_blobifi>HIGHEST_BACKBONE_LVL+1:fpn_blob_in=model.Relu(fpn_blob,fpn_blob+\\'_relu\\')fpn_blob=model.Conv(fpn_blob_in,\\'fpn_\\'+str(i),dim_in=dim_in,dim_out=fpn_dim,kernel=3,pad=1,stride=2,weight_init=xavier_fill,bias_init=const_fill(0.0))dim_in=fpn_dimblobs_fpn.insert(0,fpn_blob)spatial_scales.insert(0,spatial_scales[0]*0.5)returnblobs_fpn,fpn_dim,spatial_scalesdefadd_topdown_lateral_module(model,fpn_top,fpn_lateral,fpn_bottom,dim_top,dim_lateral):\"\"\"Addatop-downlateralmodule.\"\"\"#Lateral1x1convifcfg.FPN.USE_GN:#useGroupNormlat=model.ConvGN(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,group_gn=get_group_gn(dim_top),kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))else:lat=model.Conv(fpn_lateral,fpn_bottom+\\'_lateral\\',dim_in=dim_lateral,dim_out=dim_top,kernel=1,pad=0,stride=1,weight_init=(const_fill(0.0)ifcfg.FPN.ZERO_INIT_LATERALelse(\\'XavierFill\\',{})),bias_init=const_fill(0.0))#Top-down2xupsamplingtd=model.net.UpsampleNearest(fpn_top,fpn_bottom+\\'_topdown\\',scale=2)#Sumlateralandtop-downmodel.net.Sum([lat,td],fpn_bottom)defget_min_max_levels():\"\"\"TheminandmaxFPNlevelsrequiredforsupportingRPNand/orRoItransformoperationsonmultipleFPNlevels.\"\"\"min_level=LOWEST_BACKBONE_LVLmax_level=HIGHEST_BACKBONE_LVLifcfg.FPN.MULTILEVEL_RPNandnotcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.RPN_MAX_LEVELmin_level=cfg.FPN.RPN_MIN_LEVELifnotcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=cfg.FPN.ROI_MAX_LEVELmin_level=cfg.FPN.ROI_MIN_LEVELifcfg.FPN.MULTILEVEL_RPNandcfg.FPN.MULTILEVEL_ROIS:max_level=max(cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.ROI_MAX_LEVEL)min_level=min(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.ROI_MIN_LEVEL)returnmin_level,max_level#----------------------------------------------------------------------------##RPNwithanFPNbackbone#----------------------------------------------------------------------------#defadd_fpn_rpn_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"AddRPNonFPNspecificoutputs.\"\"\"num_anchors=len(cfg.FPN.RPN_ASPECT_RATIOS)dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scales[k_max-lvl]#inreversedorderslvl=str(lvl)iflvl==k_min:#Createconvopswithrandomlyinitializedweightsand#zeroedbiasesforthefirstFPNlevel;thesewillbesharedby#allotherFPNlevels#RPNhiddenrepresentationconv_rpn_fpn=model.Conv(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.Conv(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.Conv(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))else:#Shareweightsandbiasessk_min=str(k_min)#RPNhiddenrepresentationconv_rpn_fpn=model.ConvShared(bl_in,\\'conv_rpn_fpn\\'+slvl,dim_in,dim_out,kernel=3,pad=1,stride=1,weight=\\'conv_rpn_fpn\\'+sk_min+\\'_w\\',bias=\\'conv_rpn_fpn\\'+sk_min+\\'_b\\')model.Relu(conv_rpn_fpn,conv_rpn_fpn)#Proposalclassificationscoresrpn_cls_logits_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_cls_logits_fpn\\'+slvl,dim_in,num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_cls_logits_fpn\\'+sk_min+\\'_b\\')#Proposalbboxregressiondeltasrpn_bbox_pred_fpn=model.ConvShared(conv_rpn_fpn,\\'rpn_bbox_pred_fpn\\'+slvl,dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_w\\',bias=\\'rpn_bbox_pred_fpn\\'+sk_min+\\'_b\\')ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededlvl_anchors=generate_anchors(stride=2.**lvl,sizes=(cfg.FPN.RPN_ANCHOR_START_SIZE*2.**(lvl-k_min),),aspect_ratios=cfg.FPN.RPN_ASPECT_RATIOS)rpn_cls_probs_fpn=model.net.Sigmoid(rpn_cls_logits_fpn,\\'rpn_cls_probs_fpn\\'+slvl)model.GenerateProposals([rpn_cls_probs_fpn,rpn_bbox_pred_fpn,\\'im_info\\'],[\\'rpn_rois_fpn\\'+slvl,\\'rpn_roi_probs_fpn\\'+slvl],anchors=lvl_anchors,spatial_scale=sc)defadd_fpn_rpn_losses(model):\"\"\"AddRPNonFPNspecificlosses.\"\"\"loss_gradients={}forlvlinrange(cfg.FPN.RPN_MIN_LEVEL,cfg.FPN.RPN_MAX_LEVEL+1):slvl=str(lvl)#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide_fpn\\'+slvl,\\'rpn_cls_logits_fpn\\'+slvl],\\'rpn_labels_int32_fpn\\'+slvl)forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide_fpn\\'+slvl,\\'rpn_bbox_pred_fpn\\'+slvl],\\'rpn_bbox_\\'+key+\\'_fpn\\'+slvl)loss_rpn_cls_fpn=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits_fpn\\'+slvl,\\'rpn_labels_int32_fpn\\'+slvl],\\'loss_rpn_cls_fpn\\'+slvl,normalize=0,scale=(model.GetLossScale()/cfg.TRAIN.RPN_BATCH_SIZE_PER_IM/cfg.TRAIN.IMS_PER_BATCH))#Normalizationby(1)RPN_BATCH_SIZE_PER_IMand(2)IMS_PER_BATCHis#handledby(1)settingbboxoutsideweightsand(2)SmoothL1Loss#normalizesbyIMS_PER_BATCHloss_rpn_bbox_fpn=model.net.SmoothL1Loss([\\'rpn_bbox_pred_fpn\\'+slvl,\\'rpn_bbox_targets_fpn\\'+slvl,\\'rpn_bbox_inside_weights_fpn\\'+slvl,\\'rpn_bbox_outside_weights_fpn\\'+slvl],\\'loss_rpn_bbox_fpn\\'+slvl,beta=1./9.,scale=model.GetLossScale(),)loss_gradients.update(blob_utils.get_loss_gradients(model,[loss_rpn_cls_fpn,loss_rpn_bbox_fpn]))model.AddLosses([\\'loss_rpn_cls_fpn\\'+slvl,\\'loss_rpn_bbox_fpn\\'+slvl])returnloss_gradients#----------------------------------------------------------------------------##HelperfunctionsforworkingwithmultilevelFPNRoIs#----------------------------------------------------------------------------#defmap_rois_to_fpn_levels(rois,k_min,k_max):\"\"\"DeterminewhichFPNleveleachRoIinasetofRoIsshouldmaptobasedontheheuristicintheFPNpaper.\"\"\"#Computelevelidss=np.sqrt(box_utils.boxes_area(rois))s0=cfg.FPN.ROI_CANONICAL_SCALE#default:224lvl0=cfg.FPN.ROI_CANONICAL_LEVEL#default:4#Eqn.(1)inFPNpapertarget_lvls=np.floor(lvl0+np.log2(s/s0+1e-6))target_lvls=np.clip(target_lvls,k_min,k_max)returntarget_lvlsdefadd_multilevel_roi_blobs(blobs,blob_prefix,rois,target_lvls,lvl_min,lvl_max):\"\"\"AddRoIblobsformultipleFPNlevelstotheblobsdict.blobs:adictmappingfromblobnametonumpyndarrayblob_prefix:nameprefixtousefortheFPNblobsrois:thesourceroisasa2Dnumpyarrayofshape(N,5)whereeachrowisanroiandthecolumnsencode(batch_idx,x1,y1,x2,y2)target_lvls:numpyarrayofshape(N,)indicatingwhichFPNleveleachroiinroisshouldbeassignedtolvl_min:thefinest(highestresolution)FPNlevel(e.g.,2)lvl_max:thecoarest(lowestresolution)FPNlevel(e.g.,6)\"\"\"rois_idx_order=np.empty((0,))rois_stacked=np.zeros((0,5),dtype=np.float32)#forassertforlvlinrange(lvl_min,lvl_max+1):idx_lvl=np.where(target_lvls==lvl)[0]blobs[blob_prefix+\\'_fpn\\'+str(lvl)]=rois[idx_lvl,:]rois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_stacked=np.vstack([rois_stacked,blobs[blob_prefix+\\'_fpn\\'+str(lvl)]])rois_idx_restore=np.argsort(rois_idx_order).astype(np.int32,copy=False)blobs[blob_prefix+\\'_idx_restore_int32\\']=rois_idx_restore#Sanitycheckthatrestoreorderiscorrectassert(rois_stacked[rois_idx_restore]==rois).all()#----------------------------------------------------------------------------##FPNlevelinfoforstages5,4,3,2forselectmodels(morecanbeadded)#----------------------------------------------------------------------------#FpnLevelInfo=collections.namedtuple(\\'FpnLevelInfo\\',[\\'blobs\\',\\'dims\\',\\'spatial_scales\\'])deffpn_level_info_ResNet50_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_5_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet101_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_22_sum\\',\\'res3_3_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))deffpn_level_info_ResNet152_conv5():returnFpnLevelInfo(blobs=(\\'res5_2_sum\\',\\'res4_35_sum\\',\\'res3_7_sum\\',\\'res2_2_sum\\'),dims=(2048,1024,512,256),spatial_scales=(1./32.,1./16.,1./8.,1./4.))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forclassificationandboundingboxprediction.Thedesignisasfollows:...->RoI----\\\\/->boxclsoutput->clsloss->RoIFeatureXform->boxhead...->Feature/\\\\->boxregoutput->reglossMapTheFastR-CNNheadproducesafeaturerepresentationoftheRoIforthepurposeofboundingboxclassificationandregression.Theboxoutputmoduleconvertsthefeaturerepresentationintoclassificationandregressionpredictions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##FastR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_fast_rcnn_outputs(model,blob_in,dim):\"\"\"AddRoIclassificationandboundingboxregressionoutputops.\"\"\"#Boxclassificationlayermodel.FC(blob_in,\\'cls_score\\',dim,model.num_classes,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.train:#==iftest#Onlyaddsoftmaxwhentesting;duringtrainingthesoftmaxiscombined#withthelabelcrossentropylossfornumericalstabilitymodel.Softmax(\\'cls_score\\',\\'cls_prob\\',engine=\\'CUDNN\\')#Boxregressionlayernum_bbox_reg_classes=(2ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelsemodel.num_classes)model.FC(blob_in,\\'bbox_pred\\',dim,num_bbox_reg_classes*4,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))defadd_fast_rcnn_losses(model):\"\"\"AddlossesforRoIclassificationandboundingboxregression.\"\"\"cls_prob,loss_cls=model.net.SoftmaxWithLoss([\\'cls_score\\',\\'labels_int32\\'],[\\'cls_prob\\',\\'loss_cls\\'],scale=model.GetLossScale())loss_bbox=model.net.SmoothL1Loss([\\'bbox_pred\\',\\'bbox_targets\\',\\'bbox_inside_weights\\',\\'bbox_outside_weights\\'],\\'loss_bbox\\',scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_cls,loss_bbox])model.Accuracy([\\'cls_prob\\',\\'labels_int32\\'],\\'accuracy_cls\\')model.AddLosses([\\'loss_cls\\',\\'loss_bbox\\'])model.AddMetrics(\\'accuracy_cls\\')returnloss_gradients#----------------------------------------------------------------------------##Boxheads#----------------------------------------------------------------------------#defadd_roi_2mlp_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaReLUMLPwithtwohiddenlayers.\"\"\"hidden_dim=cfg.FAST_RCNN.MLP_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(roi_feat,\\'fc6\\',dim_in*roi_size*roi_size,hidden_dim)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',hidden_dim,hidden_dim)model.Relu(\\'fc7\\',\\'fc7\\')return\\'fc7\\',hidden_dimdefadd_roi_Xconv1fc_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,asareferenceifnotusingGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.Conv(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}),no_bias=0)current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dimdefadd_roi_Xconv1fc_gn_head(model,blob_in,dim_in,spatial_scale):\"\"\"AddaXconv+1fchead,withGroupNorm\"\"\"hidden_dim=cfg.FAST_RCNN.CONV_HEAD_DIMroi_size=cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONroi_feat=model.RoIFeatureTransform(blob_in,\\'roi_feat\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=roi_size,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)current=roi_featforiinrange(cfg.FAST_RCNN.NUM_STACKED_CONVS):current=model.ConvGN(current,\\'head_conv\\'+str(i+1),dim_in,hidden_dim,3,group_gn=get_group_gn(hidden_dim),stride=1,pad=1,weight_init=(\\'MSRAFill\\',{}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=hidden_dimfc_dim=cfg.FAST_RCNN.MLP_HEAD_DIMmodel.FC(current,\\'fc6\\',dim_in*roi_size*roi_size,fc_dim)model.Relu(\\'fc6\\',\\'fc6\\')return\\'fc6\\',fc_dim#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Variousnetwork\"heads\"forpredictingmasksinMaskR-CNN.Thedesignisasfollows:...->RoI----\\\\->RoIFeatureXform->maskhead->maskoutput->loss...->Feature/MapThemaskheadproducesafeaturerepresentationoftheRoIforthepurposeofmaskprediction.Themaskoutputmoduleconvertsthefeaturerepresentationintoreal-valued(soft)masks.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillfromdetectron.utils.netimportget_group_gnimportdetectron.modeling.ResNetasResNetimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##MaskR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_mask_rcnn_outputs(model,blob_in,dim):\"\"\"AddMaskR-CNNspecificoutputs:eithermasklogitsorprobs.\"\"\"num_cls=cfg.MODEL.NUM_CLASSESifcfg.MRCNN.CLS_SPECIFIC_MASKelse1ifcfg.MRCNN.USE_FC_OUTPUT:#Predictmaskswithafullyconnectedlayer(ignore\\'fcn\\'intheblob#name)dim_fc=int(dim*(cfg.MRCNN.RESOLUTION/cfg.MRCNN.UPSAMPLE_RATIO)**2)blob_out=model.FC(blob_in,\\'mask_fcn_logits\\',dim_fc,num_cls*cfg.MRCNN.RESOLUTION**2,weight_init=gauss_fill(0.001),bias_init=const_fill(0.0))else:#PredictmaskusingConv#UseGaussianFillforclass-agnosticmaskprediction;fillsbasedon#fan-incanbetoolargeinthiscaseandcausedivergencefill=(cfg.MRCNN.CONV_INITifcfg.MRCNN.CLS_SPECIFIC_MASKelse\\'GaussianFill\\')blob_out=model.Conv(blob_in,\\'mask_fcn_logits\\',dim,num_cls,kernel=1,pad=0,stride=1,weight_init=(fill,{\\'std\\':0.001}),bias_init=const_fill(0.0))ifcfg.MRCNN.UPSAMPLE_RATIO>1:blob_out=model.BilinearInterpolation(\\'mask_fcn_logits\\',\\'mask_fcn_logits_up\\',num_cls,num_cls,cfg.MRCNN.UPSAMPLE_RATIO)ifnotmodel.train:#==iftestblob_out=model.net.Sigmoid(blob_out,\\'mask_fcn_probs\\')returnblob_outdefadd_mask_rcnn_losses(model,blob_mask):\"\"\"AddMaskR-CNNspecificlosses.\"\"\"loss_mask=model.net.SigmoidCrossEntropyLoss([blob_mask,\\'masks_int32\\'],\\'loss_mask\\',scale=model.GetLossScale()*cfg.MRCNN.WEIGHT_LOSS_MASK)loss_gradients=blob_utils.get_loss_gradients(model,[loss_mask])model.AddLosses(\\'loss_mask\\')returnloss_gradients#----------------------------------------------------------------------------##Maskheads#----------------------------------------------------------------------------#defmask_rcnn_fcn_head_v1up4convs(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up4convs_gn(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:4*(conv3x3),convT2x2,withGroupNorm\"\"\"returnmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,4)defmask_rcnn_fcn_head_v1up(model,blob_in,dim_in,spatial_scale):\"\"\"v1updesign:2*(conv3x3),convT2x2.\"\"\"returnmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,2)defmask_rcnn_fcn_head_v1upXconvs(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2.\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.Conv(current,\\'_[mask]_fcn\\'+str(i+1),dim_in,dim_inner,kernel=3,dilation=dilation,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v1upXconvs_gn(model,blob_in,dim_in,spatial_scale,num_convs):\"\"\"v1upXconvsdesign:X*(conv3x3),convT2x2,withGroupNorm\"\"\"current=model.RoIFeatureTransform(blob_in,blob_out=\\'_mask_roi_feat\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONdim_inner=cfg.MRCNN.DIM_REDUCEDforiinrange(num_convs):current=model.ConvGN(current,\\'_mask_fcn\\'+str(i+1),dim_in,dim_inner,group_gn=get_group_gn(dim_inner),kernel=3,pad=1*dilation,stride=1,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))current=model.Relu(current,current)dim_in=dim_inner#upsamplelayermodel.ConvTranspose(current,\\'conv5_mask\\',dim_inner,dim_inner,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_innerdefmask_rcnn_fcn_head_v0upshare(model,blob_in,dim_in,spatial_scale):\"\"\"UseaResNet\"conv5\"/\"stage5\"headformaskprediction.Weightsandcomputationaresharedwiththeconv5boxhead.Computationcanonlybesharedduringtraining,sinceinferenceiscascaded.v0upsharedesign:conv5,convT2x2.\"\"\"#Sinceboxandmaskheadareshared,thesemustmatchassertcfg.MRCNN.ROI_XFORM_RESOLUTION==cfg.FAST_RCNN.ROI_XFORM_RESOLUTIONifmodel.train:#sharecomputationwithbboxheadattrainingtimedim_conv5=2048blob_conv5=model.net.SampleAs([\\'res5_2_sum\\',\\'roi_has_mask_int32\\'],[\\'_[mask]_res5_2_sum_sliced\\'])else:#re-computeattesttimeblob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDblob_mask=model.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(cfg.MRCNN.CONV_INIT,{\\'std\\':0.001}),#stdonlyforgaussbias_init=const_fill(0.0))model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefmask_rcnn_fcn_head_v0up(model,blob_in,dim_in,spatial_scale):\"\"\"v0updesign:conv5,deconv2x2(noweightsharingwiththeboxhead).\"\"\"blob_conv5,dim_conv5=add_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale)dim_reduced=cfg.MRCNN.DIM_REDUCEDmodel.ConvTranspose(blob_conv5,\\'conv5_mask\\',dim_conv5,dim_reduced,kernel=2,pad=0,stride=2,weight_init=(\\'GaussianFill\\',{\\'std\\':0.001}),bias_init=const_fill(0.0))blob_mask=model.Relu(\\'conv5_mask\\',\\'conv5_mask\\')returnblob_mask,dim_reduceddefadd_ResNet_roi_conv5_head_for_masks(model,blob_in,dim_in,spatial_scale):\"\"\"AddaResNet\"conv5\"/\"stage5\"headforpredictingmasks.\"\"\"model.RoIFeatureTransform(blob_in,blob_out=\\'_[mask]_pool5\\',blob_rois=\\'mask_rois\\',method=cfg.MRCNN.ROI_XFORM_METHOD,resolution=cfg.MRCNN.ROI_XFORM_RESOLUTION,sampling_ratio=cfg.MRCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)dilation=cfg.MRCNN.DILATIONstride_init=int(cfg.MRCNN.ROI_XFORM_RESOLUTION/7)#bydefault:2s,dim_in=ResNet.add_stage(model,\\'_[mask]_res5\\',\\'_[mask]_pool5\\',3,dim_in,2048,512,dilation,stride_init=stride_init)returns,2048#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG_CNN_M_1024from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG_CNN_M_1024_conv5_body(model):model.Conv(\\'data\\',\\'conv1\\',3,96,7,pad=0,stride=2)model.Relu(\\'conv1\\',\\'conv1\\')model.LRN(\\'conv1\\',\\'norm1\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm1\\',\\'pool1\\',kernel=3,pad=0,stride=2)model.StopGradient(\\'pool1\\',\\'pool1\\')#Noupdatesatconv1andbelow(norm1andpool1havenoparams,#sowecanstopgradientsbeforethem,too)model.Conv(\\'pool1\\',\\'conv2\\',96,256,5,pad=0,stride=2)model.Relu(\\'conv2\\',\\'conv2\\')model.LRN(\\'conv2\\',\\'norm2\\',size=5,alpha=0.0005,beta=0.75,bias=2.)model.MaxPool(\\'norm2\\',\\'pool2\\',kernel=3,pad=0,stride=2)model.Conv(\\'pool2\\',\\'conv3\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv3\\',\\'conv3\\')model.Conv(\\'conv3\\',\\'conv4\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4\\',\\'conv4\\')model.Conv(\\'conv4\\',\\'conv5\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5\\',\\'conv5\\')returnblob_out,512,1./16.defadd_VGG_CNN_M_1024_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=6,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*6*6,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,1024)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,1024#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Optimizationoperatorgraphconstruction.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromcaffe2.pythonimportmujifromdetectron.core.configimportcfgimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)defbuild_data_parallel_model(model,single_gpu_build_func):\"\"\"BuildadataparallelmodelgivenafunctionthatbuildsthemodelonasingleGPU.\"\"\"ifmodel.only_build_forward_pass:single_gpu_build_func(model)elifmodel.train:all_loss_gradients=_build_forward_graph(model,single_gpu_build_func)#AddbackwardpassonallGPUsmodel.AddGradientOperators(all_loss_gradients)ifcfg.NUM_GPUS>1:_add_allreduce_graph(model)forgpu_idinrange(cfg.NUM_GPUS):#Afterallreduce,allGPUsperformSGDupdatesontheiridentical#paramsandgradientsinparallelwithc2_utils.NamedCudaScope(gpu_id):add_single_gpu_param_update_ops(model,gpu_id)else:#Test-timenetworkoperatesonsingleGPU#Test-timeparallelismisimplementedthroughmultiprocessingwithc2_utils.NamedCudaScope(model.target_gpu_id):single_gpu_build_func(model)def_build_forward_graph(model,single_gpu_build_func):\"\"\"ConstructtheforwardgraphoneachGPU.\"\"\"all_loss_gradients={}#WillincludelossgradientsfromallGPUs#BuildthemodeloneachGPUwithcorrectnameanddevicescopingforgpu_idinrange(cfg.NUM_GPUS):withc2_utils.NamedCudaScope(gpu_id):all_loss_gradients.update(single_gpu_build_func(model))returnall_loss_gradientsdef_add_allreduce_graph(model):\"\"\"ConstructthegraphthatperformsAllreduceonthegradients.\"\"\"#Needtoall-reducetheper-GPUgradientsiftrainingwithmorethan1GPUall_params=model.TrainableParams()assertlen(all_params)%cfg.NUM_GPUS==0#ThemodelparametersarereplicatedoneachGPU,getthenumber#distinctparameterblobs(i.e.,thenumberofparameterblobson#eachGPU)params_per_gpu=int(len(all_params)/cfg.NUM_GPUS)withc2_utils.CudaScope(0):#Iterateoverdistinctparameterblobsforiinrange(params_per_gpu):#GradientsfromallGPUsforthisparameterblobgradients=[model.param_to_grad[p]forpinall_params[i::params_per_gpu]]iflen(gradients)>0:ifcfg.USE_NCCL:model.net.NCCLAllreduce(gradients,gradients)else:muji.Allreduce(model.net,gradients,reduced_affix=\\'\\')defadd_single_gpu_param_update_ops(model,gpu_id):#Learningrateof0isadummyvaluetobesetproperlyatthe#startoftraininglr=model.param_init_net.ConstantFill([],\\'lr\\',shape=[1],value=0.0)one=model.param_init_net.ConstantFill([],\\'one\\',shape=[1],value=1.0)wd=model.param_init_net.ConstantFill([],\\'wd\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY)#weightdecayofGroupNorm\\'sparameterswd_gn=model.param_init_net.ConstantFill([],\\'wd_gn\\',shape=[1],value=cfg.SOLVER.WEIGHT_DECAY_GN)forparaminmodel.TrainableParams(gpu_id=gpu_id):logger.debug(\\'param\\'+str(param)+\\'willbeupdated\\')param_grad=model.param_to_grad[param]#Initializemomentumvectorparam_momentum=model.param_init_net.ConstantFill([param],param+\\'_momentum\\',value=0.0)ifparaminmodel.biases:#Specialtreatmentforbiases(mainlytomatchhistoricalimpl.#details):#(1)Donotapplyweightdecay#(2)Usea2xhigherlearningratemodel.Scale(param_grad,param_grad,scale=2.0)elifparaminmodel.gn_params:#SpecialtreatmentforGroupNorm\\'sparametersmodel.WeightedSum([param_grad,one,param,wd_gn],param_grad)elifcfg.SOLVER.WEIGHT_DECAY>0:#Applyweightdecaytonon-biasweightsmodel.WeightedSum([param_grad,one,param,wd],param_grad)#Updateparam_gradandparam_momentuminplacemodel.net.MomentumSGDUpdate([param_grad,param_momentum,lr,param],[param_grad,param_momentum,param],momentum=cfg.SOLVER.MOMENTUM)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"DefinesDetectionModelHelper,theclassthatrepresentsaDetectronmodel.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcaffe2.pythonimportcnnfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromcaffe2.python.modelingimportinitializersfromcaffe2.python.modeling.parameter_infoimportParameterTagsfromdetectron.core.configimportcfgfromdetectron.ops.collect_and_distribute_fpn_rpn_proposals\\\\importCollectAndDistributeFpnRpnProposalsOpfromdetectron.ops.generate_proposal_labelsimportGenerateProposalLabelsOpfromdetectron.ops.generate_proposalsimportGenerateProposalsOpimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.c2asc2_utilslogger=logging.getLogger(__name__)classDetectionModelHelper(cnn.CNNModelHelper):def__init__(self,**kwargs):#HandleargsspecifictotheDetectionModelHelper,otherspassthrough#toCNNModelHelperself.train=kwargs.get(\\'train\\',False)self.num_classes=kwargs.get(\\'num_classes\\',-1)assertself.num_classes>0,\\'num_classesmustbe>0\\'forkin(\\'train\\',\\'num_classes\\'):ifkinkwargs:delkwargs[k]kwargs[\\'order\\']=\\'NCHW\\'#Defensivelysetcudnn_exhaustive_searchtoFalseincasethedefault#changesinCNNModelHelper.Thedetectioncodeusesvariablesize#inputsthatmightnotplaynicelywithcudnn_exhaustive_search.kwargs[\\'cudnn_exhaustive_search\\']=Falsesuper(DetectionModelHelper,self).__init__(**kwargs)self.roi_data_loader=Noneself.losses=[]self.metrics=[]self.do_not_update_params=[]#Paramonthislistarenotupdatedself.net.Proto().type=cfg.MODEL.EXECUTION_TYPEself.net.Proto().num_workers=cfg.NUM_GPUS*4self.prev_use_cudnn=self.use_cudnnself.gn_params=[]#ParamonthislistareGroupNormparametersdefTrainableParams(self,gpu_id=-1):\"\"\"Gettheblobnamesforalltrainableparameters,possiblyfilteredbyGPUid.\"\"\"return[pforpinself.paramsif(pinself.param_to_gradand#phasagradientpnotinself.do_not_update_paramsand#notontheblacklist(gpu_id==-1or#filterforgpuassignment,ifgpu_idsetstr(p).find(\\'gpu_{}\\'.format(gpu_id))==0))]defAffineChannel(self,blob_in,blob_out,dim,inplace=False):\"\"\"AffinetransformationtoreplaceBNinnetworkswhereBNcannotbeused(e.g.,becausetheminibatchsizeistoosmall).Theoperationscanbedoneinplacetosavememory.\"\"\"blob_out=blob_outorself.net.NextName()param_prefix=blob_outscale=self.create_param(param_name=param_prefix+\\'_s\\',initializer=initializers.Initializer(\"ConstantFill\",value=1.),tags=ParameterTags.WEIGHT,shape=[dim,],)bias=self.create_param(param_name=param_prefix+\\'_b\\',initializer=initializers.Initializer(\"ConstantFill\",value=0.),tags=ParameterTags.BIAS,shape=[dim,],)ifinplace:returnself.net.AffineChannel([blob_in,scale,bias],blob_in)else:returnself.net.AffineChannel([blob_in,scale,bias],blob_out)defGenerateProposals(self,blobs_in,blobs_out,anchors,spatial_scale):\"\"\"OpforgeneratingRPNporposals.blobs_in:-\\'rpn_cls_probs\\':4Dtensorofshape(N,A,H,W),whereNisthenumberofminibatchimages,Aisthenumberofanchorsperlocations,and(H,W)isthespatialsizeofthepredictiongrid.Eachvaluerepresentsa\"probabilityofobject\"ratingin[0,1].-\\'rpn_bbox_pred\\':4Dtensorofshape(N,4*A,H,W)ofpredicteddeltasfortransformationanchorboxesintoRPNproposals.-\\'im_info\\':2Dtensorofshape(N,3)wherethethreecolumnsencodetheinputimage\\'s[height,width,scale].Heightandwidtharefortheinputtothenetwork,nottheoriginalimage;scaleisthescalefactorusedtoscaletheoriginalimagetothenetworkinputsize.blobs_out:-\\'rpn_rois\\':2Dtensorofshape(R,5),forRRPNproposalswherethefivecolumnsencode[batchind,x1,y1,x2,y2].Theboxesarew.r.t.thenetworkinput,whichisa*scaled*versionoftheoriginalimage;theseproposalsmustbescaledby1/scale(wherescalecomesfromim_info;seeabove)totransformitbacktotheoriginalinputimagecoordinatesystem.-\\'rpn_roi_probs\\':1Dtensorofobjectnessprobabilityscores(extractedfromrpn_cls_probs;seeabove).\"\"\"cfg_key=\\'TRAIN\\'ifself.trainelse\\'TEST\\'ifcfg[cfg_key].GENERATE_PROPOSALS_ON_GPU:rpn_pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Nrpn_post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nrpn_nms_thresh=cfg[cfg_key].RPN_NMS_THRESHrpn_min_size=float(cfg[cfg_key].RPN_MIN_SIZE)input_name=str(blobs_in[0])lvl=int(input_name[-1])ifinput_name[-1].isdigit()elseNoneanchors_name=\\'anchors{}\\'.format(lvl)iflvlelse\\'anchors\\'foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/{}\\'.format(i,anchors_name),anchors.astype(np.float32))self.net.GenerateProposals(blobs_in+[anchors_name],blobs_out,spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,)else:name=\\'GenerateProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#spatial_scalepassedtothePythonopisonlyusedin#convert_pkl_to_pbself.net.Python(GenerateProposalsOp(anchors,spatial_scale,self.train).forward)(blobs_in,blobs_out,name=name,spatial_scale=spatial_scale)returnblobs_outdefGenerateProposalLabels(self,blobs_in):\"\"\"OpforgeneratingtraininglabelsforRPNproposals.ThisisusedwhentrainingRPNjointlywithFast/MaskR-CNN(asinend-to-endFasterR-CNNtraining).blobs_in:-\\'rpn_rois\\':2DtensorofRPNproposalsoutputbyGenerateProposals-\\'roidb\\':roidbentriesthatwillbelabeled-\\'im_info\\':SeeGenerateProposalsdoc.blobs_out:-(variablesetofblobs):returnswhateverblobsarerequiredfortrainingthemodel.Itdoesthisbyqueryingthedataloaderforthelistofblobsthatareneeded.\"\"\"name=\\'GenerateProposalLabelsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Thelistofblobsisnotknownbeforerun-timebecauseitdependson#thespecificmodelbeingtrained.Querythedataloadertogetthe#listofoutputblobnames.blobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]self.net.Python(GenerateProposalLabelsOp().forward)(blobs_in,blobs_out,name=name)returnblobs_outdefCollectAndDistributeFpnRpnProposals(self):\"\"\"MergeRPNproposalsgeneratedatmultipleFPNlevelsandthendistributethoseproposalstotheirappropriateFPNlevels.AnanchoratoneFPNlevelmaypredictanRoIthatwillmaptoanotherlevel,hencetheneedtoredistributetheproposals.Thisfunctionassumesstandardblobnamesforinputandoutputblobs.Inputblobs:[rpn_rois_fpn,...,rpn_rois_fpn,rpn_roi_probs_fpn,...,rpn_roi_probs_fpn]-rpn_rois_fpnaretheRPNproposalsforFPNleveli;seerpn_roisdocumentationfromGenerateProposals.-rpn_roi_probs_fpnaretheRPNobjectnessprobabilitiesforFPNleveli;seerpn_roi_probsdocumentationfromGenerateProposals.Ifusedduringtraining,thentheinputblobswillalsoinclude:[roidb,im_info](seeGenerateProposalLabels).Outputblobs:[rois_fpn,...,rois_rpn,rois,rois_idx_restore]-rois_fpnaretheRPNproposalsforFPNleveli-rois_idx_restoreisapermutationontheconcatenationofallrois_fpn,i=min...max,suchthatwhenappliedtheRPNRoIsarerestoredtotheiroriginalorderintheinputblobs.Ifusedduringtraining,thentheoutputblobswillalsoinclude:[labels,bbox_targets,bbox_inside_weights,bbox_outside_weights].\"\"\"k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVEL#Prepareinputblobsrois_names=[\\'rpn_rois_fpn\\'+str(l)forlinrange(k_min,k_max+1)]score_names=[\\'rpn_roi_probs_fpn\\'+str(l)forlinrange(k_min,k_max+1)]blobs_in=rois_names+score_namesifself.train:blobs_in+=[\\'roidb\\',\\'im_info\\']blobs_in=[core.ScopedBlobReference(b)forbinblobs_in]name=\\'CollectAndDistributeFpnRpnProposalsOp:\\'+\\',\\'.join([str(b)forbinblobs_in])#Prepareoutputblobsblobs_out=fast_rcnn_roi_data.get_fast_rcnn_blob_names(is_training=self.train)blobs_out=[core.ScopedBlobReference(b)forbinblobs_out]outputs=self.net.Python(CollectAndDistributeFpnRpnProposalsOp(self.train).forward)(blobs_in,blobs_out,name=name)returnoutputsdefDropoutIfTraining(self,blob_in,dropout_rate):\"\"\"Adddropouttoblob_inifthemodelisintrainingmodeanddropout_rateis>0.\"\"\"blob_out=blob_inifself.trainanddropout_rate>0:blob_out=self.Dropout(blob_in,blob_in,ratio=dropout_rate,is_test=False)returnblob_outdefRoIFeatureTransform(self,blobs_in,blob_out,blob_rois=\\'rois\\',method=\\'RoIPoolF\\',resolution=7,spatial_scale=1./16.,sampling_ratio=0):\"\"\"AddthespecifiedRoIpoolingmethod.Thesampling_ratioargumentissupportedforsome,butnotall,RoItransformmethods.RoIFeatureTransformabstractsaway:-UseofFPNornot-Specificsofthetransformmethod\"\"\"assertmethodin{\\'RoIPoolF\\',\\'RoIAlign\\'},\\\\\\'Unknownpoolingmethod:{}\\'.format(method)has_argmax=(method==\\'RoIPoolF\\')ifisinstance(blobs_in,list):#FPNcase:addRoIFeatureTransformtoeachFPNlevelk_max=cfg.FPN.ROI_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.ROI_MIN_LEVEL#finestlevelofpyramidassertlen(blobs_in)==k_max-k_min+1bl_out_list=[]forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedordersc=spatial_scale[k_max-lvl]#inreversedorderbl_rois=blob_rois+\\'_fpn\\'+str(lvl)bl_out=blob_out+\\'_fpn\\'+str(lvl)bl_out_list.append(bl_out)bl_argmax=[\\'_argmax_\\'+bl_out]ifhas_argmaxelse[]self.net.__getattr__(method)([bl_in,bl_rois],[bl_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=sc,sampling_ratio=sampling_ratio)#Thepooledfeaturesfromalllevelsareconcatenatedalongthe#batchdimensionintoasingle4Dtensor.xform_shuffled,_=self.net.Concat(bl_out_list,[blob_out+\\'_shuffled\\',\\'_concat_\\'+blob_out],axis=0)#Unshuffletomatchroisfromdataloaderrestore_bl=blob_rois+\\'_idx_restore_int32\\'xform_out=self.net.BatchPermutation([xform_shuffled,restore_bl],blob_out)else:#Singlefeaturelevelbl_argmax=[\\'_argmax_\\'+blob_out]ifhas_argmaxelse[]#sampling_ratioisignoredforRoIPoolFxform_out=self.net.__getattr__(method)([blobs_in,blob_rois],[blob_out]+bl_argmax,pooled_w=resolution,pooled_h=resolution,spatial_scale=spatial_scale,sampling_ratio=sampling_ratio)#Onlyreturnthefirstblob(thetransformedfeatures)returnxform_out[0]ifisinstance(xform_out,tuple)elsexform_outdefConvShared(self,blob_in,blob_out,dim_in,dim_out,kernel,weight=None,bias=None,**kwargs):\"\"\"Addconvopthatsharesweightsand/orbiaseswithanotherconvop.\"\"\"use_bias=(Falseif(\\'no_bias\\'inkwargsandkwargs[\\'no_bias\\'])elseTrue)ifself.use_cudnn:kwargs[\\'engine\\']=\\'CUDNN\\'kwargs[\\'exhaustive_search\\']=self.cudnn_exhaustive_searchifself.ws_nbytes_limit:kwargs[\\'ws_nbytes_limit\\']=self.ws_nbytes_limitifuse_bias:blobs_in=[blob_in,weight,bias]else:blobs_in=[blob_in,weight]if\\'no_bias\\'inkwargs:delkwargs[\\'no_bias\\']returnself.net.Conv(blobs_in,blob_out,kernel=kernel,order=self.order,**kwargs)defBilinearInterpolation(self,blob_in,blob_out,dim_in,dim_out,up_scale):\"\"\"Bilinearinterpolationinspaceofscale.TakesinputofNxKxHxWandoutputsNxKx(sH)x(sW),wheres:=up_scaleAdaptedfromtheCVPR\\'15FCNcode.See:\"\"\"assertdim_in==dim_outassertup_scale%2==0,\\'Scaleshouldbeeven\\'defupsample_filt(size):factor=(size+1)//2ifsize%2==1:center=factor-1else:center=factor-0.5og=np.ogrid[:size,:size]return((1-abs(og[0]-center)/factor)*(1-abs(og[1]-center)/factor))kernel_size=up_scale*2bil_filt=upsample_filt(kernel_size)kernel=np.zeros((dim_in,dim_out,kernel_size,kernel_size),dtype=np.float32)kernel[range(dim_out),range(dim_in),:,:]=bil_filtblob=self.ConvTranspose(blob_in,blob_out,dim_in,dim_out,kernel_size,stride=int(up_scale),pad=int(up_scale/2),weight_init=(\\'GivenTensorFill\\',{\\'values\\':kernel}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))self.do_not_update_params.append(self.weights[-1])self.do_not_update_params.append(self.biases[-1])returnblobdefConvAffine(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_bn\\',inplace=False):\"\"\"ConvAffineaddsaConvopfollowedbyaAffineChannelop(whichreplacesBNduringfinetuning).\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=1)blob_out=self.AffineChannel(conv_blob,prefix+suffix,dim=dim_out,inplace=inplace)returnblob_outdefConvGN(#argsinthesameorderofConv()self,blob_in,prefix,dim_in,dim_out,kernel,stride,pad,group_gn,#numofgroupsingngroup=1,dilation=1,weight_init=None,bias_init=None,suffix=\\'_gn\\',no_conv_bias=1,):\"\"\"ConvGNaddsaConvopfollowedbyaGroupNormop,includinglearnablescale/bias(gamma/beta)\"\"\"conv_blob=self.Conv(blob_in,prefix,dim_in,dim_out,kernel,stride=stride,pad=pad,group=group,dilation=dilation,weight_init=weight_init,bias_init=bias_init,no_bias=no_conv_bias)ifgroup_gn<1:logger.warning(\\'Layer:{}(dim{}):\\'\\'group_gn<1;resetto1.\\'.format(prefix,dim_in))group_gn=1blob_out=self.SpatialGN(conv_blob,prefix+suffix,dim_out,group=group_gn,#op\\'sargnameis\"group\"epsilon=cfg.GROUP_NORM.EPSILON,)self.gn_params.append(self.params[-1])#addgn\\'sbiastolistself.gn_params.append(self.params[-2])#addgn\\'sscaletolistreturnblob_outdefDisableCudnn(self):self.prev_use_cudnn=self.use_cudnnself.use_cudnn=FalsedefRestorePreviousUseCudnn(self):prev_use_cudnn=self.use_cudnnself.use_cudnn=self.prev_use_cudnnself.prev_use_cudnn=prev_use_cudnndefUpdateWorkspaceLr(self,cur_iter,new_lr):\"\"\"Updatesthemodel\\'scurrentlearningrateandtheworkspace(learningrateandupdatehistory/momentumblobs).\"\"\"#Theworkspaceistheonesourceoftruthforthelr#ThelrisalwaysthesameonallGPUscur_lr=workspace.FetchBlob(\\'gpu_0/lr\\')[0]#TherearenotypeconversionsbetweenthelrinPythonandthelrin#theGPU(botharefloat32),soexactcomparisionisokifcur_lr!=new_lr:ratio=_get_lr_change_ratio(cur_lr,new_lr)ifratio>cfg.SOLVER.LOG_LR_CHANGE_THRESHOLD:logger.info(\\'Changinglearningrate{:.6f}->{:.6f}atiter{:d}\\'.format(cur_lr,new_lr,cur_iter))self._SetNewLr(cur_lr,new_lr)returnnew_lrdef_SetNewLr(self,cur_lr,new_lr):\"\"\"Dotheactualworkofupdatingthemodelandworkspaceblobs.\"\"\"foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):workspace.FeedBlob(\\'gpu_{}/lr\\'.format(i),np.array([new_lr],dtype=np.float32))ratio=_get_lr_change_ratio(cur_lr,new_lr)ifcfg.SOLVER.SCALE_MOMENTUMandcur_lr>1e-7and\\\\ratio>cfg.SOLVER.SCALE_MOMENTUM_THRESHOLD:self._CorrectMomentum(new_lr/cur_lr)def_CorrectMomentum(self,correction):\"\"\"TheMomentumSGDUpdateopimplementstheupdateVasV:=mu*V+lr*grad,wheremuisthemomentumfactor,lristhelearningrate,andgradisthestochasticgradient.SinceVisnotdefinedindependentlyofthelearningrate(asitshouldideallybe),whenthelearningrateischangedweshouldscaletheupdatehistoryVinordertomakeitcompatibleinscalewithlr*grad.\"\"\"logger.info(\\'Scalingupdatehistoryby{:.6f}(newlr/oldlr)\\'.format(correction))foriinrange(cfg.NUM_GPUS):withc2_utils.CudaScope(i):forparaminself.TrainableParams(gpu_id=i):op=core.CreateOperator(\\'Scale\\',[param+\\'_momentum\\'],[param+\\'_momentum\\'],scale=correction)workspace.RunOperatorOnce(op)defGetLossScale(self):\"\"\"Allowawaytoconfigurethelossscaledynamically.Thismaybeusedinadistributeddataparallelsetting.\"\"\"return1.0/cfg.NUM_GPUSdefAddLosses(self,losses):ifnotisinstance(losses,list):losses=[losses]#ConversiontostrallowslossestoincludeBlobReferenceslosses=[c2_utils.UnscopeName(str(l))forlinlosses]self.losses=list(set(self.losses+losses))defAddMetrics(self,metrics):ifnotisinstance(metrics,list):metrics=[metrics]self.metrics=list(set(self.metrics+metrics))def_get_lr_change_ratio(cur_lr,new_lr):eps=1e-10ratio=np.max((new_lr/np.max((cur_lr,eps)),cur_lr/np.max((new_lr,eps))))returnratio#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Handlemappingfromoldnetworkbuildingfunctionnamestonewnames.Flexiblenetworkconfigurationisachievedbyspecifyingthefunctionnamethatbuildsanetworkmodule(e.g.,thenameoftheconvbackboneorthemaskroihead).Howeverwemaywishtochangenamesovertimewithoutbreakingpreviousconfigfiles.Thismoduleprovidesbackwardsnamingcompatibilitybyprovidingamappingfromtheoldnametothenewname.Whenrenamingfunctions,it\\'sgenerallyagoodideatocodemodexistingyamlconfigfiles.Aneasywaytobatchedit,byexample,isashellcommandlike$find.-name\"*.yaml\"-execsed-i-e\\\\\\'s/head_builder\\\\.add_roi_2mlp_head/fast_rcnn_heads.add_roi_2mlp_head/g\\'{}\\\\;toperformtherenaming:head_builder.add_roi_2mlp_head=>fast_rcnn_heads.add_roi_2mlp_head\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literals_RENAME={#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v1up4convs\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up\\':\\'mask_rcnn_heads.mask_rc'],\n",
       " ['<|begin_of_text|>nn_fcn_head_v1up\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0upshare\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0upshare\\',#Removed\"ResNet_\"fromthenamebecauseitwasn\\'trelevent\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v0up\\':\\'mask_rcnn_heads.mask_rcnn_fcn_head_v0up\\',#Removedhead_buildermoduleinfavorofthemorespecificfast_rcnnname\\'head_builder.add_roi_2mlp_head\\':\\'fast_rcnn_heads.add_roi_2mlp_head\\',}defget_new_name(func_name):iffunc_namein_RENAME:func_name=_RENAME[func_name]returnfunc_name#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.c2importconst_fillfromdetectron.utils.c2importgauss_fillimportdetectron.modeling.FPNasFPNimportdetectron.utils.blobasblob_utils#----------------------------------------------------------------------------##RPNandFasterR-CNNoutputsandlosses#----------------------------------------------------------------------------#defadd_generic_rpn_outputs(model,blob_in,dim_in,spatial_scale_in):\"\"\"AddRPNoutputs(objectnessclassificationandboundingboxregression)toanRPNmodel.AbstractsawaytheuseofFPN.\"\"\"loss_gradients=Noneifcfg.FPN.FPN_ON:#DelegatetotheFPNmoduleFPN.add_fpn_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifcfg.MODEL.FASTER_RCNN:#CollectAndDistributeFpnRpnProposalsalsolabelsproposalswhenin#trainingmodemodel.CollectAndDistributeFpnRpnProposals()ifmodel.train:loss_gradients=FPN.add_fpn_rpn_losses(model)else:#NotusingFPN,addRPNtoasinglescaleadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale_in)ifmodel.train:loss_gradients=add_single_scale_rpn_losses(model)returnloss_gradientsdefadd_single_scale_rpn_outputs(model,blob_in,dim_in,spatial_scale):\"\"\"AddRPNoutputstoasinglescalemodel(i.e.,noFPN).\"\"\"anchors=generate_anchors(stride=1./spatial_scale,sizes=cfg.RPN.SIZES,aspect_ratios=cfg.RPN.ASPECT_RATIOS)num_anchors=anchors.shape[0]dim_out=dim_in#RPNhiddenrepresentationmodel.Conv(blob_in,\\'conv_rpn\\',dim_in,dim_out,kernel=3,pad=1,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))model.Relu(\\'conv_rpn\\',\\'conv_rpn\\')#Proposalclassificationscoresmodel.Conv(\\'conv_rpn\\',\\'rpn_cls_logits\\',dim_in,num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))#Proposalbboxregressiondeltasmodel.Conv(\\'conv_rpn\\',\\'rpn_bbox_pred\\',dim_in,4*num_anchors,kernel=1,pad=0,stride=1,weight_init=gauss_fill(0.01),bias_init=const_fill(0.0))ifnotmodel.trainorcfg.MODEL.FASTER_RCNN:#Proposalsareneededduring:#1)inference(==notmodel.train)forRPNonlyandFasterR-CNN#OR#2)trainingforFasterR-CNN#Otherwise(==trainingforRPNonly),proposalsarenotneededmodel.net.Sigmoid(\\'rpn_cls_logits\\',\\'rpn_cls_probs\\')model.GenerateProposals([\\'rpn_cls_probs\\',\\'rpn_bbox_pred\\',\\'im_info\\'],[\\'rpn_rois\\',\\'rpn_roi_probs\\'],anchors=anchors,spatial_scale=spatial_scale)ifcfg.MODEL.FASTER_RCNN:ifmodel.train:#Addopthatgeneratestraininglabelsforin-networkRPNproposalsmodel.GenerateProposalLabels([\\'rpn_rois\\',\\'roidb\\',\\'im_info\\'])else:#Aliasroistorpn_roisforinferencemodel.net.Alias(\\'rpn_rois\\',\\'rois\\')defadd_single_scale_rpn_losses(model):\"\"\"AddlossesforasinglescaleRPNmodel(i.e.,noFPN).\"\"\"#Spatiallynarrowthefull-sizedRPNlabelarraystomatchthefeaturemap#shapemodel.net.SpatialNarrowAs([\\'rpn_labels_int32_wide\\',\\'rpn_cls_logits\\'],\\'rpn_labels_int32\\')forkeyin(\\'targets\\',\\'inside_weights\\',\\'outside_weights\\'):model.net.SpatialNarrowAs([\\'rpn_bbox_\\'+key+\\'_wide\\',\\'rpn_bbox_pred\\'],\\'rpn_bbox_\\'+key)loss_rpn_cls=model.net.SigmoidCrossEntropyLoss([\\'rpn_cls_logits\\',\\'rpn_labels_int32\\'],\\'loss_rpn_cls\\',scale=model.GetLossScale())loss_rpn_bbox=model.net.SmoothL1Loss([\\'rpn_bbox_pred\\',\\'rpn_bbox_targets\\',\\'rpn_bbox_inside_weights\\',\\'rpn_bbox_outside_weights\\'],\\'loss_rpn_bbox\\',beta=1./9.,scale=model.GetLossScale())loss_gradients=blob_utils.get_loss_gradients(model,[loss_rpn_cls,loss_rpn_bbox])model.AddLosses([\\'loss_rpn_cls\\',\\'loss_rpn_bbox\\'])returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"VGG16from\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.core.configimportcfgdefadd_VGG16_conv5_body(model):model.Conv(\\'data\\',\\'conv1_1\\',3,64,3,pad=1,stride=1)model.Relu(\\'conv1_1\\',\\'conv1_1\\')model.Conv(\\'conv1_1\\',\\'conv1_2\\',64,64,3,pad=1,stride=1)model.Relu(\\'conv1_2\\',\\'conv1_2\\')model.MaxPool(\\'conv1_2\\',\\'pool1\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool1\\',\\'conv2_1\\',64,128,3,pad=1,stride=1)model.Relu(\\'conv2_1\\',\\'conv2_1\\')model.Conv(\\'conv2_1\\',\\'conv2_2\\',128,128,3,pad=1,stride=1)model.Relu(\\'conv2_2\\',\\'conv2_2\\')model.MaxPool(\\'conv2_2\\',\\'pool2\\',kernel=2,pad=0,stride=2)model.StopGradient(\\'pool2\\',\\'pool2\\')model.Conv(\\'pool2\\',\\'conv3_1\\',128,256,3,pad=1,stride=1)model.Relu(\\'conv3_1\\',\\'conv3_1\\')model.Conv(\\'conv3_1\\',\\'conv3_2\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_2\\',\\'conv3_2\\')model.Conv(\\'conv3_2\\',\\'conv3_3\\',256,256,3,pad=1,stride=1)model.Relu(\\'conv3_3\\',\\'conv3_3\\')model.MaxPool(\\'conv3_3\\',\\'pool3\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool3\\',\\'conv4_1\\',256,512,3,pad=1,stride=1)model.Relu(\\'conv4_1\\',\\'conv4_1\\')model.Conv(\\'conv4_1\\',\\'conv4_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_2\\',\\'conv4_2\\')model.Conv(\\'conv4_2\\',\\'conv4_3\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv4_3\\',\\'conv4_3\\')model.MaxPool(\\'conv4_3\\',\\'pool4\\',kernel=2,pad=0,stride=2)model.Conv(\\'pool4\\',\\'conv5_1\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_1\\',\\'conv5_1\\')model.Conv(\\'conv5_1\\',\\'conv5_2\\',512,512,3,pad=1,stride=1)model.Relu(\\'conv5_2\\',\\'conv5_2\\')model.Conv(\\'conv5_2\\',\\'conv5_3\\',512,512,3,pad=1,stride=1)blob_out=model.Relu(\\'conv5_3\\',\\'conv5_3\\')returnblob_out,512,1./16.defadd_VGG16_roi_fc_head(model,blob_in,dim_in,spatial_scale):model.RoIFeatureTransform(blob_in,\\'pool5\\',blob_rois=\\'rois\\',method=cfg.FAST_RCNN.ROI_XFORM_METHOD,resolution=7,sampling_ratio=cfg.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO,spatial_scale=spatial_scale)model.FC(\\'pool5\\',\\'fc6\\',dim_in*7*7,4096)model.Relu(\\'fc6\\',\\'fc6\\')model.FC(\\'fc6\\',\\'fc7\\',4096,4096)blob_out=model.Relu(\\'fc7\\',\\'fc7\\')returnblob_out,4096#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RetinaNetmodelheadsandlosses.See:\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.blobasblob_utilsdefget_retinanet_bias_init(model):\"\"\"Initializethebiasesfortheconvopsthatpredictclassprobabilities.Initializationisperformedsuchthatatthestartoftraining,alllocationsarepredictedtobebackgroundwithhighprobability(e.g.,~0.99=1-cfg.RETINANET.PRIOR_PROB).SeetheFocalLosspaperfordetails.\"\"\"prior_prob=cfg.RETINANET.PRIOR_PROBscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=len(cfg.RETINANET.ASPECT_RATIOS)ifcfg.RETINANET.SOFTMAX:#Multiclasssoftmaxcasebias=np.zeros((model.num_classes,1),dtype=np.float32)bias[0]=np.log((model.num_classes-1)*(1-prior_prob)/(prior_prob))bias=np.vstack([biasfor_inrange(scales_per_octave*aspect_ratios)])bias_init=(\\'GivenTensorFill\\',{\\'values\\':bias.astype(dtype=np.float32)})else:#Per-classsigmoid(binaryclassification)casebias_init=(\\'ConstantFill\\',{\\'value\\':-np.log((1-prior_prob)/prior_prob)})returnbias_initdefadd_fpn_retinanet_outputs(model,blobs_in,dim_in,spatial_scales):\"\"\"RetinaNethead.Forclassificationandboxregression,wecanchosetohavethesameconvtoweroraseparatetower.\"bl_feat_list\"storesthelistoffeatureblobsforbboxprediction.Theseblobscanbesharedclsfeatureblobsifwesharethetowerorelseareindependentblobs.\"\"\"dim_out=dim_ink_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidA=len(cfg.RETINANET.ASPECT_RATIOS)*cfg.RETINANET.SCALES_PER_OCTAVE#computeinitforbiasbias_init=get_retinanet_bias_init(model)assertlen(blobs_in)==k_max-k_min+1bbox_feat_list=[]cls_pred_dim=(model.num_classesifcfg.RETINANET.SOFTMAXelse(model.num_classes-1))#unpackedbboxfeatureandaddpredictionlayersbbox_regr_dim=(4*(model.num_classes-1)ifcfg.RETINANET.CLASS_SPECIFIC_BBOXelse4)#==========================================================================#classificationtowerwithlogitsandprobprediction#==========================================================================forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorder#classificationtowerstackconvolutionstartsfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_cls_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_cls_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_cls_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)bl_feat=bl_in#clstowerstackconvolutionends.Addthelogitslayernowiflvl==k_min:retnet_cls_pred=model.Conv(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=bias_init)else:retnet_cls_pred=model.ConvShared(bl_feat,\\'retnet_cls_pred_fpn{}\\'.format(lvl),dim_in,cls_pred_dim*A,3,pad=1,stride=1,weight=\\'retnet_cls_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_cls_pred_fpn{}_b\\'.format(k_min))ifnotmodel.train:ifcfg.RETINANET.SOFTMAX:model.net.GroupSpatialSoftmax(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl),num_classes=cls_pred_dim)else:model.net.Sigmoid(retnet_cls_pred,\\'retnet_cls_prob_fpn{}\\'.format(lvl))ifcfg.RETINANET.SHARE_CLS_BBOX_TOWER:bbox_feat_list.append(bl_feat)#==========================================================================#bboxtowerifnotsharingfeatureswiththeclassificationtowerwith#logitsandprobprediction#==========================================================================ifnotcfg.RETINANET.SHARE_CLS_BBOX_TOWER:forlvlinrange(k_min,k_max+1):bl_in=blobs_in[k_max-lvl]#blobs_inisinreversedorderfornconvinrange(cfg.RETINANET.NUM_CONVS):suffix=\\'n{}_fpn{}\\'.format(nconv,lvl)dim_in,dim_out=dim_in,dim_iniflvl==k_min:bl_out=model.Conv(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:bl_out=model.ConvShared(bl_in,\\'retnet_bbox_conv_\\'+suffix,dim_in,dim_out,3,stride=1,pad=1,weight=\\'retnet_bbox_conv_n{}_fpn{}_w\\'.format(nconv,k_min),bias=\\'retnet_bbox_conv_n{}_fpn{}_b\\'.format(nconv,k_min))bl_in=model.Relu(bl_out,bl_out)#Addoctavescalesandaspectratio#Atleast1convolutionfordealingdifferentaspectratiosbl_feat=bl_inbbox_feat_list.append(bl_feat)#Dependingonthefeatures[shared/separate]forbbox,addpredictionlayerfori,lvlinenumerate(range(k_min,k_max+1)):bbox_pred=\\'retnet_bbox_pred_fpn{}\\'.format(lvl)bl_feat=bbox_feat_list[i]iflvl==k_min:model.Conv(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight_init=(\\'GaussianFill\\',{\\'std\\':0.01}),bias_init=(\\'ConstantFill\\',{\\'value\\':0.}))else:model.ConvShared(bl_feat,bbox_pred,dim_in,bbox_regr_dim*A,3,pad=1,stride=1,weight=\\'retnet_bbox_pred_fpn{}_w\\'.format(k_min),bias=\\'retnet_bbox_pred_fpn{}_b\\'.format(k_min))defadd_fpn_retinanet_losses(model):loss_gradients={}gradients,losses=[],[]k_max=cfg.FPN.RPN_MAX_LEVEL#coarsestlevelofpyramidk_min=cfg.FPN.RPN_MIN_LEVEL#finestlevelofpyramidmodel.AddMetrics([\\'retnet_fg_num\\',\\'retnet_bg_num\\'])#==========================================================================#bboxregressionloss-SelectSmoothL1Lossformultipleanchorsatalocation#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)bbox_loss=model.net.SelectSmoothL1Loss([\\'retnet_bbox_pred_\\'+suffix,\\'retnet_roi_bbox_targets_\\'+suffix,\\'retnet_roi_fg_bbox_locs_\\'+suffix,\\'retnet_fg_num\\'],\\'retnet_loss_bbox_\\'+suffix,beta=cfg.RETINANET.BBOX_REG_BETA,scale=model.GetLossScale()*cfg.RETINANET.BBOX_REG_WEIGHT)gradients.append(bbox_loss)losses.append(\\'retnet_loss_bbox_\\'+suffix)#==========================================================================#clsloss-dependsonsoftmax/sigmoidoutputs#==========================================================================forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_lvl_logits=\\'retnet_cls_pred_\\'+suffixifnotcfg.RETINANET.SOFTMAX:cls_focal_loss=model.net.SigmoidFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes-1)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))else:cls_focal_loss,gated_prob=model.net.SoftmaxFocalLoss([cls_lvl_logits,\\'retnet_cls_labels_\\'+suffix,\\'retnet_fg_num\\'],[\\'fl_{}\\'.format(suffix),\\'retnet_prob_{}\\'.format(suffix)],gamma=cfg.RETINANET.LOSS_GAMMA,alpha=cfg.RETINANET.LOSS_ALPHA,scale=model.GetLossScale(),num_classes=model.num_classes)gradients.append(cls_focal_loss)losses.append(\\'fl_{}\\'.format(suffix))loss_gradients.update(blob_utils.get_loss_gradients(model,gradients))model.AddLosses(losses)returnloss_gradients#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnp#VerifythatwecomputethesameanchorsasShaoqing\\'smatlabimplementation:##>>loadoutput/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat#>>anchors##anchors=##-83-3910056#-175-87192104#-359-183376200#-55-557272#-119-119136136#-247-247264264#-35-795296#-79-16796184#-167-343184360#array([[-83.,-39.,100.,56.],#[-175.,-87.,192.,104.],#[-359.,-183.,376.,200.],#[-55.,-55.,72.,72.],#[-119.,-119.,136.,136.],#[-247.,-247.,264.,264.],#[-35.,-79.,52.,96.],#[-79.,-167.,96.,184.],#[-167.,-343.,184.,360.]])defgenerate_anchors(stride=16,sizes=(32,64,128,256,512),aspect_ratios=(0.5,1,2)):\"\"\"Generatesamatrixofanchorboxesin(x1,y1,x2,y2)format.Anchorsarecenteredonstride/2,have(approximate)sqrtareasofthespecifiedsizes,andaspectratiosasgiven.\"\"\"return_generate_anchors(stride,np.array(sizes,dtype=float)/stride,np.array(aspect_ratios,dtype=float))def_generate_anchors(base_size,scales,aspect_ratios):\"\"\"Generateanchor(reference)windowsbyenumeratingaspectratiosXscaleswrtareference(0,0,base_size-1,base_size-1)window.\"\"\"anchor=np.array([1,1,base_size,base_size],dtype=float)-1anchors=_ratio_enum(anchor,aspect_ratios)anchors=np.vstack([_scale_enum(anchors[i,:],scales)foriinrange(anchors.shape[0])])returnanchorsdef_whctrs(anchor):\"\"\"Returnwidth,height,xcenter,andycenterforananchor(window).\"\"\"w=anchor[2]-anchor[0]+1h=anchor[3]-anchor[1]+1x_ctr=anchor[0]+0.5*(w-1)y_ctr=anchor[1]+0.5*(h-1)returnw,h,x_ctr,y_ctrdef_mkanchors(ws,hs,x_ctr,y_ctr):\"\"\"Givenavectorofwidths(ws)andheights(hs)aroundacenter(x_ctr,y_ctr),outputasetofanchors(windows).\"\"\"ws=ws[:,np.newaxis]hs=hs[:,np.newaxis]anchors=np.hstack((x_ctr-0.5*(ws-1),y_ctr-0.5*(hs-1),x_ctr+0.5*(ws-1),y_ctr+0.5*(hs-1)))returnanchorsdef_ratio_enum(anchor,ratios):\"\"\"Enumerateasetofanchorsforeachaspectratiowrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)size=w*hsize_ratios=size/ratiosws=np.round(np.sqrt(size_ratios))hs=np.round(ws*ratios)anchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchorsdef_scale_enum(anchor,scales):\"\"\"Enumerateasetofanchorsforeachscalewrtananchor.\"\"\"w,h,x_ctr,y_ctr=_whctrs(anchor)ws=w*scaleshs=h*scalesanchors=_mkanchors(ws,hs,x_ctr,y_ctr)returnanchors#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsimportdetectron.modeling.FPNasfpnimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_dataimportdetectron.utils.blobasblob_utilsclassCollectAndDistributeFpnRpnProposalsOp:def__init__(self,train):self._train=traindefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.CollectAndDistributeFpnRpnProposalsforinputs/outputsdocumentation.\"\"\"#inputsis#[rpn_rois_fpn2,...,rpn_rois_fpn6,#rpn_roi_probs_fpn2,...,rpn_roi_probs_fpn6]#IftrainingwithFasterR-CNN,theninputswilladditionallyinclude#+[roidb,im_info]rois=collect(inputs,self._train)ifself._train:#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]im_info=inputs[-1].dataim_scales=im_info[:,2]roidb=blob_utils.deserialize(inputs[-2].data)#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)#ComputetraininglabelsfortheRPNproposals;alsohandles#distributingtheproposalsoverFPNlevelsoutput_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])else:#Forinferencewehaveaspecialcodepaththatavoidssomedata#loaderoverheaddistribute(rois,None,outputs,self._train)defcollect(inputs,is_training):cfg_key=\\'TRAIN\\'ifis_trainingelse\\'TEST\\'post_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nk_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELnum_lvls=k_max-k_min+1roi_inputs=inputs[:num_lvls]score_inputs=inputs[num_lvls:]ifis_training:score_inputs=score_inputs[:-2]#roisarein[[batch_idx,x0,y0,x1,y2],...]format#Combinepredictionsacrossalllevelsandretainthetopscoringrois=np.concatenate([blob.dataforblobinroi_inputs])scores=np.concatenate([blob.dataforblobinscore_inputs]).squeeze()inds=np.argsort(-scores)[:post_nms_topN]rois=rois[inds,:]returnroisdefdistribute(rois,label_blobs,outputs,train):\"\"\"Tounderstandtheoutputbloborderseereturnvalueofdetectron.roi_data.fast_rcnn.get_fast_rcnn_blob_names(is_training=False)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(rois[:,1:5],lvl_min,lvl_max)outputs[0].reshape(rois.shape)outputs[0].data[...]=rois#CreatenewroiblobsforeachFPNlevel#(See:modeling.FPN.add_multilevel_roi_blobswhichissimilarbutannoying#togeneralizetosupportthisparticularcase.)rois_idx_order=np.empty((0,))foroutput_idx,lvlinenumerate(range(lvl_min,lvl_max+1)):idx_lvl=np.where(lvls==lvl)[0]blob_roi_level=rois[idx_lvl,:]outputs[output_idx+1].reshape(blob_roi_level.shape)outputs[output_idx+1].data[...]=blob_roi_levelrois_idx_order=np.concatenate((rois_idx_order,idx_lvl))rois_idx_restore=np.argsort(rois_idx_order)blob_utils.py_op_copy_blob(rois_idx_restore.astype(np.int32),outputs[-1])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshickandSeanBell#--------------------------------------------------------importnumpyasnpfromdetectron.core.configimportcfgimportdetectron.utils.boxesasbox_utilsclassGenerateProposalsOp:\"\"\"Outputobjectdetectionproposalsbyapplyingestimatedbounding-boxtransformationstoasetofregularboxes(called\"anchors\").Seecommentinutils/boxes:bbox_transform_invfordetailsaboutstheoptional`reg_weights`parameter.\"\"\"def__init__(self,anchors,spatial_scale,train,reg_weights=(1.0,1.0,1.0,1.0)):self._anchors=anchorsself._num_anchors=self._anchors.shape[0]self._feat_stride=1./spatial_scaleself._train=trainself._reg_weights=reg_weightsdefforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalsforinputs/outputsdocumentation.\"\"\"#1.foreachlocationiina(H,W)grid:#generateAanchorboxescenteredoncelli#applypredictedbboxdeltastoeachoftheAanchorsatcelli#2.clippredictedboxestoimage#3.removepredictedboxeswitheitherheightorwidth<threshold#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.takethetoppre_nms_topNproposalsbeforeNMS#6.applyNMSwithaloosethreshold(0.7)totheremainingproposals#7.takeafter_nms_topNproposalsafterNMS#8.returnthetopproposals#predictedprobabilityoffgobjectforeachRPNanchorscores=inputs[0].data#predictedachorstransformationsbbox_deltas=inputs[1].data#inputimage(height,width,scale),inwhichscaleisthescalefactor#appliedtotheoriginaldatasetimagetogetthenetworkinputimageim_info=inputs[2].data#1.Generateproposalsfrombboxdeltasandshiftedanchorsheight,width=scores.shape[-2:]#Enumerateallshiftedpositionsonthe(H,W)gridshift_x=np.arange(0,width)*self._feat_strideshift_y=np.arange(0,height)*self._feat_strideshift_x,shift_y=np.meshgrid(shift_x,shift_y,copy=False)#Convertto(K,4),K=H*W,wherethecolumnsare(dx,dy,dx,dy)#shiftpointingtoeachgridlocationshifts=np.vstack((shift_x.ravel(),shift_y.ravel(),shift_x.ravel(),shift_y.ravel())).transpose()#Broacastanchorsovershiftstoenumerateallanchorsatallpositions#inthe(H,W)grid:#-addAanchorsofshape(1,A,4)to#-Kshiftsofshape(K,1,4)toget#-allshiftedanchorsofshape(K,A,4)#-reshapeto(K*A,4)shiftedanchorsnum_images=inputs[0].shape[0]A=self._num_anchorsK=shifts.shape[0]all_anchors=self._anchors[np.newaxis,:,:]+shifts[:,np.newaxis,:]all_anchors=all_anchors.reshape((K*A,4))rois=np.empty((0,5),dtype=np.float32)roi_probs=np.empty((0,1),dtype=np.float32)forim_iinrange(num_images):im_i_boxes,im_i_probs=self.proposals_for_one_image(im_info[im_i,:],all_anchors,bbox_deltas[im_i,:,:,:],scores[im_i,:,:,:])batch_inds=im_i*np.ones((im_i_boxes.shape[0],1),dtype=np.float32)im_i_rois=np.hstack((batch_inds,im_i_boxes))rois=np.append(rois,im_i_rois,axis=0)roi_probs=np.append(roi_probs,im_i_probs,axis=0)outputs[0].reshape(rois.shape)outputs[0].data[...]=roisiflen(outputs)>1:outputs[1].reshape(roi_probs.shape)outputs[1].data[...]=roi_probsdefproposals_for_one_image(self,im_info,all_anchors,bbox_deltas,scores):#Getmode-dependentconfigurationcfg_key=\\'TRAIN\\'ifself._trainelse\\'TEST\\'pre_nms_topN=cfg[cfg_key].RPN_PRE_NMS_TOP_Npost_nms_topN=cfg[cfg_key].RPN_POST_NMS_TOP_Nnms_thresh=cfg[cfg_key].RPN_NMS_THRESHmin_size=cfg[cfg_key].RPN_MIN_SIZE#Transposeandreshapepredictedbboxtransformationstogetthem#intothesameorderastheanchors:#-bboxdeltaswillbe(4*A,H,W)formatfromconvoutput#-transposeto(H,W,4*A)#-reshapeto(H*W*A,4)whererowsareorderedby(H,W,A)#inslowesttofastestordertomatchtheenumeratedanchorsbbox_deltas=bbox_deltas.transpose((1,2,0)).reshape((-1,4))#Samestoryforthescores:#-scoresare(A,H,W)formatfromconvoutput#-transposeto(H,W,A)#-reshapeto(H*W*A,1)whererowsareorderedby(H,W,A)#tomatchtheorderofanchorsandbbox_deltasscores=scores.transpose((1,2,0)).reshape((-1,1))#4.sortall(proposal,score)pairsbyscorefromhighesttolowest#5.taketoppre_nms_topN(e.g.6000)ifpre_nms_topN=len(scores):order=np.argsort(-scores.squeeze())else:#Avoidsortingpossiblylargearrays;FirstpartitiontogettopK#unsortedandthensortjustthose(~20xfasterfor200kscores)inds=np.argpartition(-scores.squeeze(),pre_nms_topN)[:pre_nms_topN]order=np.argsort(-scores[inds].squeeze())order=inds[order]bbox_deltas=bbox_deltas[order,:]all_anchors=all_anchors[order,:]scores=scores[order]#Transformanchorsintoproposalsviabboxtransformationsproposals=box_utils.bbox_transform(all_anchors,bbox_deltas,self._reg_weights)#2.clipproposalstoimage(mayresultinproposalswithzeroarea#thatwillberemovedinthenextstep)proposals=box_utils.clip_tiled_boxes(proposals,im_info[:2])#3.removepredictedboxeswitheitherheightorwidth<min_sizekeep=_filter_boxes(proposals,min_size,im_info)proposals=proposals[keep,:]scores=scores[keep]#6.applyloosenms(e.g.threshold=0.7)#7.takeafter_nms_topN(e.g.300)#8.returnthetopproposals(->RoIstop)ifnms_thresh>0:keep=box_utils.nms(np.hstack((proposals,scores)),nms_thresh)ifpost_nms_topN>0:keep=keep[:post_nms_topN]proposals=proposals[keep,:]scores=scores[keep]returnproposals,scoresdef_filter_boxes(boxes,min_size,im_info):\"\"\"Onlykeepboxeswithbothsides>=min_sizeandcenterwithintheimage.\"\"\"#Computethewidthandheightoftheproposalboxesasmeasuredintheoriginal#imagecoordinatesystem(thisisrequiredtoavoid\"NegativeAreasFound\"#assertionsinotherpartsofthecodethatmeasure).im_scale=im_info[2]ws_orig_scale=(boxes[:,2]-boxes[:,0])/im_scale+1hs_orig_scale=(boxes[:,3]-boxes[:,1])/im_scale+1#Toavoidnumericalissueswerequirethemin_sizetobeatleast1pixelinthe#originalimagemin_size=np.maximum(min_size,1)#Proposalcenteriscomputedrelativetothescaledinputimagews=boxes[:,2]-boxes[:,0]+1hs=boxes[:,3]-boxes[:,1]+1x_ctr=boxes[:,0]+ws/2.y_ctr=boxes[:,1]+hs/2.keep=np.where((ws_orig_scale>=min_size)&(hs_orig_scale>=min_size)&(x_ctr<im_info[1])&(y_ctr<im_info[0]))[0]returnkeep#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingfromdetectron.datasetsimportjson_datasetfromdetectron.datasetsimportroidbasroidb_utilsfromdetectron.utilsimportblobasblob_utilsimportdetectron.roi_data.fast_rcnnasfast_rcnn_roi_datalogger=logging.getLogger(__name__)classGenerateProposalLabelsOp:defforward(self,inputs,outputs):\"\"\"Seemodeling.detector.GenerateProposalLabelsforinputs/outputsdocumentation.\"\"\"#Duringtrainingwereusethedataloadercode.Wepopulateroidb#entriesontheflyusingtheroisgeneratedbyRPN.#im_info:[[im_height,im_width,im_scale],...]rois=inputs[0].dataroidb=blob_utils.deserialize(inputs[1].data)im_info=inputs[2].dataim_scales=im_info[:,2]output_blob_names=fast_rcnn_roi_data.get_fast_rcnn_blob_names()#ForhistoricalconsistencywiththeoriginalFasterR-CNN#implementationweare*not*filteringcrowdproposals.#Thischoiceshouldbeinvestigatedinthefuture(itlikelydoes#notmatter).json_dataset.add_proposals(roidb,rois,im_scales,crowd_thresh=0)roidb_utils.add_bbox_regression_targets(roidb)blobs={k:[]forkinoutput_blob_names}fast_rcnn_roi_data.add_fast_rcnn_blobs(blobs,im_scales,roidb)fori,kinenumerate(output_blob_names):blob_utils.py_op_copy_blob(blobs[k],outputs[i])#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaDetectronnetworkonanimdb(imagedatabase).\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.core.configimportget_output_dirfromdetectron.core.rpn_generatorimportgenerate_rpn_on_datasetfromdetectron.core.rpn_generatorimportgenerate_rpn_on_rangefromdetectron.core.testimportim_detect_allfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnet_utilsimportdetectron.utils.subprocessassubprocess_utilsimportdetectron.utils.visasvis_utilslogger=logging.getLogger(__name__)defget_eval_functions():#Determinewhichparentorchildfunctionshouldhandleinferenceifcfg.MODEL.RPN_ONLY:child_func=generate_rpn_on_rangeparent_func=generate_rpn_on_datasetelse:#GenericcasethathandlesallnetworktypesotherthanRPN-onlynets#andRetinaNetchild_func=test_netparent_func=test_net_on_datasetreturnparent_func,child_funcdefget_inference_dataset(index,is_parent=True):assertis_parentorlen(cfg.TEST.DATASETS)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingledataset\\'dataset_name=cfg.TEST.DATASETS[index]ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertis_parentorlen(cfg.TEST.PROPOSAL_FILES)==1,\\\\\\'Thechildinferenceprocesscanonlyworkonasingleproposalfile\\'assertlen(cfg.TEST.PROPOSAL_FILES)==len(cfg.TEST.DATASETS),\\\\\\'Ifproposalsareused,oneproposalfilemustbespecifiedfor\\'\\\\\\'eachdataset\\'proposal_file=cfg.TEST.PROPOSAL_FILES[index]else:proposal_file=Nonereturndataset_name,proposal_filedefrun_inference(weights_file,ind_range=None,multi_gpu_testing=False,gpu_id=0,check_expected_results=False,):parent_func,child_func=get_eval_functions()is_parent=ind_rangeisNonedefresult_getter():ifis_parent:#Parentcase:#Inthiscasewe\\'reeitherrunninginferenceontheentiredatasetina#singleprocessor(ifmulti_gpu_testingisTrue)usingthisprocessto#launchsubprocessesthateachruninferenceonarangeofthedatasetall_results={}foriinrange(len(cfg.TEST.DATASETS)):dataset_name,proposal_file=get_inference_dataset(i)output_dir=get_output_dir(dataset_name,training=False)results=parent_func(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=multi_gpu_testing)all_results.update(results)returnall_resultselse:#Subprocesschildcase:#Inthiscasetest_netwascalledviasubprocess.Popentoexecuteona#rangeofinputsonasingledatasetdataset_name,proposal_file=get_inference_dataset(0,is_parent=False)output_dir=get_output_dir(dataset_name,training=False)returnchild_func(weights_file,dataset_name,proposal_file,output_dir,ind_range=ind_range,gpu_id=gpu_id)all_results=result_getter()ifcheck_expected_resultsandis_parent:task_evaluation.check_expected_results(all_results,atol=cfg.EXPECTED_RESULTS_ATOL,rtol=cfg.EXPECTED_RESULTS_RTOL)task_evaluation.log_copy_paste_friendly_results(all_results)returnall_resultsdeftest_net_on_dataset(weights_file,dataset_name,proposal_file,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())all_boxes,all_segms,all_keyps=multi_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir)else:all_boxes,all_segms,all_keyps=test_net(weights_file,dataset_name,proposal_file,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))results=task_evaluation.evaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir)returnresultsdefmulti_gpu_test_net_on_dataset(weights_file,dataset_name,proposal_file,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"binary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetandproposalfile(ifany)viathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]ifproposal_file:opts+=[\\'TEST.PROPOSAL_FILES\\',\\'(\"{}\",)\\'.format(proposal_file)]#Runinferenceinparallelinsubprocesses#Outputswillbealistofoutputsfromeachsubprocess,wheretheoutput#ofeachsubprocessisthedictionarysavedbytest_net().outputs=subprocess_utils.process_in_parallel(\\'detection\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessall_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_segms=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]all_keyps=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]fordet_datainoutputs:all_boxes_batch=det_data[\\'all_boxes\\']all_segms_batch=det_data[\\'all_segms\\']all_keyps_batch=det_data[\\'all_keyps\\']forcls_idxinrange(1,cfg.MODEL.NUM_CLASSES):all_boxes[cls_idx]+=all_boxes_batch[cls_idx]all_segms[cls_idx]+=all_segms_batch[cls_idx]all_keyps[cls_idx]+=all_keyps_batch[cls_idx]det_file=os.path.join(output_dir,\\'detections.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdeftest_net(weights_file,dataset_name,proposal_file,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertnotcfg.MODEL.RPN_ONLY,\\\\\\'Userpn_generatetogenerateproposalsfromRPN-onlymodels\\'roidb,dataset,start_ind,end_ind,total_num_images=get_roidb_and_dataset(dataset_name,proposal_file,ind_range)model=initialize_model_from_cfg(weights_file,gpu_id=gpu_id)num_images=len(roidb)num_classes=cfg.MODEL.NUM_CLASSESall_boxes,all_segms,all_keyps=empty_results(num_classes,num_images)timers=defaultdict(Timer)fori,entryinenumerate(roidb):ifcfg.TEST.PRECOMPUTED_PROPOSALS:#Theroidbmaycontainground-truthrois(forexample,iftheroidb#comesfromthetrainingorvalsplit).Weonlywanttoevaluate#detectiononthe*non*-ground-truthrois.Weselectonlytherois#thathavethegt_classesfieldsetto0,whichmeansthere\\'sno#groundtruth.box_proposals=entry[\\'boxes\\'][entry[\\'gt_classes\\']==0]iflen(box_proposals)==0:continueelse:#FasterR-CNNtypemodelsgenerateproposalson-the-flywithan#in-networkRPN;1-stagemodelsdon\\'trequireproposals.box_proposals=Noneim=cv2.imread(entry[\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):cls_boxes_i,cls_segms_i,cls_keyps_i=im_detect_all(model,im,box_proposals,timers)extend_results(i,all_boxes,cls_boxes_i)ifcls_segms_iisnotNone:extend_results(i,all_segms,cls_segms_i)ifcls_keyps_iisnotNone:extend_results(i,all_keyps,cls_keyps_i)ifi%10==0:#Reducelogfilesizeave_total_time=np.sum([t.average_timefortintimers.values()])eta_seconds=ave_total_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))det_time=(timers[\\'im_detect_bbox\\'].average_time+timers[\\'im_detect_mask\\'].average_time+timers[\\'im_detect_keypoints\\'].average_time)misc_time=(timers[\\'misc_bbox\\'].average_time+timers[\\'misc_mask\\'].average_time+timers[\\'misc_keypoints\\'].average_time)logger.info((\\'im_detect:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s+{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,det_time,misc_time,eta))ifcfg.VIS:im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(i,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=cfg.VIS_TH,box_alpha=0.8,dataset=dataset,show_class=True)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:det_name=\\'detection_range_%s_%s.pkl\\'%tuple(ind_range)else:det_name=\\'detections.pkl\\'det_file=os.path.join(output_dir,det_name)save_object(dict(all_boxes=all_boxes,all_segms=all_segms,all_keyps=all_keyps,cfg=cfg_yaml),det_file)logger.info(\\'Wrotedetectionsto:{}\\'.format(os.path.abspath(det_file)))returnall_boxes,all_segms,all_keypsdefinitialize_model_from_cfg(weights_file,gpu_id=0):\"\"\"Initializeamodelfromtheglobalcfg.Loadstest-timeweightsandcreatesthenetworksintheCaffe2workspace.\"\"\"model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)net_utils.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)workspace.CreateNet(model.conv_body_net)ifcfg.MODEL.MASK_ON:workspace.CreateNet(model.mask_net)ifcfg.MODEL.KEYPOINTS_ON:workspace.CreateNet(model.keypoint_net)returnmodeldefget_roidb_and_dataset(dataset_name,proposal_file,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)ifcfg.TEST.PRECOMPUTED_PROPOSALS:assertproposal_file,\\'Noproposalfilegiven\\'roidb=dataset.get_roidb(proposal_file=proposal_file,proposal_limit=cfg.TEST.PROPOSAL_LIMIT)else:roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,dataset,start,end,total_num_imagesdefempty_results(num_classes,num_images):\"\"\"Returnemptyresultslistsforboxes,masks,andkeypoints.Boxdetectionsarecollectedinto:all_boxes[cls][image]=Nx5arraywithcolumns(x1,y1,x2,y2,score)Instancemaskpredictionsarecollectedinto:all_segms[cls][image]=[...]listofCOCORLEencodedmasksthatarein1:1correspondencewiththeboxesinall_boxes[cls][image]Keypointpredictionsarecollectedinto:all_keyps[cls][image]=[...]listofkeypointsresults,eachencodedasa3Darray(#rois,4,#keypoints)withthe4rowscorrespondingto[x,y,logit,prob](See:utils.keypoints.heatmaps_to_keypoints).Keypointsarerecordedforperson(cls=1);theyarein1:1correspondencewiththeboxesinall_boxes[cls][image].\"\"\"#Note:donotbetemptedtouse[[]*N],whichgivesNreferencestothe#*same*emptylist.all_boxes=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_segms=[[[]for_inrange(num_images)]for_inrange(num_classes)]all_keyps=[[[]for_inrange(num_images)]for_inrange(num_classes)]returnall_boxes,all_segms,all_keypsdefextend_results(index,all_res,im_res):\"\"\"Addresultsforanimagetothesetofallresultsatthespecifiedindex.\"\"\"#Skipcls_idx0(__background__)forcls_idxinrange(1,len(im_res)):all_res[cls_idx][index]=im_res[cls_idx]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FasterR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"FunctionsforRPNproposalgeneration.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importdatetimeimportloggingimportnumpyasnpimportosfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspacefromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.modelingimportmodel_builderfromdetectron.utils.ioimportsave_objectfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.netasnuimportdetectron.utils.subprocessassubprocess_utilslogger=logging.getLogger(__name__)defgenerate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,output_dir,multi_gpu=False,gpu_id=0):\"\"\"Runinferenceonadataset.\"\"\"dataset=JsonDataset(dataset_name)test_timer=Timer()test_timer.tic()ifmulti_gpu:num_images=len(dataset.get_roidb())_boxes,_scores,_ids,rpn_file=multi_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir)else:#Processesentiredatasetrangebydefault_boxes,_scores,_ids,rpn_file=generate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,gpu_id=gpu_id)test_timer.toc()logger.info(\\'Totalinferencetime:{:.3f}s\\'.format(test_timer.average_time))returnevaluate_proposal_file(dataset,rpn_file,output_dir)defmulti_gpu_generate_rpn_on_dataset(weights_file,dataset_name,_proposal_file_ignored,num_images,output_dir):\"\"\"Multi-gpuinferenceonadataset.\"\"\"#Retrievethetest_netbinarypathbinary_dir=envu.get_runtime_dir()binary_ext=envu.get_py_bin_ext()binary=os.path.join(binary_dir,\\'test_net\\'+binary_ext)assertos.path.exists(binary),\\'Binary\\\\\\'{}\\\\\\'notfound\\'.format(binary)#Passthetargetdatasetviathecommandlineopts=[\\'TEST.DATASETS\\',\\'(\"{}\",)\\'.format(dataset_name)]opts+=[\\'TEST.WEIGHTS\\',weights_file]#Runinferenceinparallelinsubprocessesoutputs=subprocess_utils.process_in_parallel(\\'rpn_proposals\\',num_images,binary,output_dir,opts)#Collatetheresultsfromeachsubprocessboxes,scores,ids=[],[],[]forrpn_datainoutputs:boxes+=rpn_data[\\'boxes\\']scores+=rpn_data[\\'scores\\']ids+=rpn_data[\\'ids\\']rpn_file=os.path.join(output_dir,\\'rpn_proposals.pkl\\')cfg_yaml=envu.yaml_dump(cfg)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_rpn_on_range(weights_file,dataset_name,_proposal_file_ignored,output_dir,ind_range=None,gpu_id=0):\"\"\"RuninferenceonallimagesinadatasetoroveranindexrangeofimagesinadatasetusingasingleGPU.\"\"\"assertcfg.MODEL.RPN_ONLYorcfg.MODEL.FASTER_RCNNroidb,start_ind,end_ind,total_num_images=get_roidb(dataset_name,ind_range)logger.info(\\'Outputwillbesavedto:{:s}\\'.format(os.path.abspath(output_dir)))model=model_builder.create(cfg.MODEL.TYPE,train=False,gpu_id=gpu_id)nu.initialize_gpu_from_weights_file(model,weights_file,gpu_id=gpu_id,)model_builder.add_inference_inputs(model)workspace.CreateNet(model.net)boxes,scores,ids=generate_proposals_on_roidb(model,roidb,start_ind=start_ind,end_ind=end_ind,total_num_images=total_num_images,gpu_id=gpu_id,)cfg_yaml=envu.yaml_dump(cfg)ifind_rangeisnotNone:rpn_name=\\'rpn_proposals_range_%s_%s.pkl\\'%tuple(ind_range)else:rpn_name=\\'rpn_proposals.pkl\\'rpn_file=os.path.join(output_dir,rpn_name)save_object(dict(boxes=boxes,scores=scores,ids=ids,cfg=cfg_yaml),rpn_file)logger.info(\\'WroteRPNproposalsto{}\\'.format(os.path.abspath(rpn_file)))returnboxes,scores,ids,rpn_filedefgenerate_proposals_on_roidb(model,roidb,start_ind=None,end_ind=None,total_num_images=None,gpu_id=0,):\"\"\"GenerateRPNproposalsonallimagesinanimdb.\"\"\"_t=Timer()num_images=len(roidb)roidb_boxes=[[]for_inrange(num_images)]roidb_scores=[[]for_inrange(num_images)]roidb_ids=[[]for_inrange(num_images)]ifstart_indisNone:start_ind=0end_ind=num_imagestotal_num_images=num_imagesforiinrange(num_images):roidb_ids[i]=roidb[i][\\'id\\']im=cv2.imread(roidb[i][\\'image\\'])withc2_utils.NamedCudaScope(gpu_id):_t.tic()roidb_boxes[i],roidb_scores[i]=im_proposals(model,im)_t.toc()ifi%10==0:ave_time=_t.average_timeeta_seconds=ave_time*(num_images-i-1)eta=str(datetime.timedelta(seconds=int(eta_seconds)))logger.info((\\'rpn_generate:range[{:d},{:d}]of{:d}:\\'\\'{:d}/{:d}{:.3f}s(eta:{})\\').format(start_ind+1,end_ind,total_num_images,start_ind+i+1,start_ind+num_images,ave_time,eta))returnroidb_boxes,roidb_scores,roidb_idsdefim_proposals(model,im):\"\"\"GenerateRPNproposalsonasingleimage.\"\"\"inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)ifcfg.FPN.FPN_ONandcfg.FPN.MULTILEVEL_RPN:k_max=cfg.FPN.RPN_MAX_LEVELk_min=cfg.FPN.RPN_MIN_LEVELrois_names=[core.ScopedName(\\'rpn_rois_fpn\\'+str(l))forlinrange(k_min,k_max+1)]score_names=[core.ScopedName(\\'rpn_roi_probs_fpn\\'+str(l))forlinrange(k_min,k_max+1)]blobs=workspace.FetchBlobs(rois_names+score_names)#Combinepredictionsacrossalllevelsandretainthetopscoringboxes=np.concatenate(blobs[:len(rois_names)])scores=np.concatenate(blobs[len(rois_names):]).squeeze()#Discussion:onecoulddoNMSagainaftercombiningpredictionsfrom#thedifferentFPNlevels.Conceptually,it\\'sprobablytherightthing#todo.Forarbitraryreasons,theoriginalFPNRPNimplementationdid#notdoanotherroundofNMS.inds=np.argsort(-scores)[:cfg.TEST.RPN_POST_NMS_TOP_N]scores=scores[inds]boxes=boxes[inds,:]else:boxes,scores=workspace.FetchBlobs([core.ScopedName(\\'rpn_rois\\'),core.ScopedName(\\'rpn_roi_probs\\')])scores=scores.squeeze()#Column0isthebatchindexinthe(batchind,x1,y1,x2,y2)encoding,#soweremoveitsincewejustwanttoreturnboxes#Scaleproposalsbacktotheoriginalinputimagescaleboxes=boxes[:,1:]/im_scalereturnboxes,scoresdefget_roidb(dataset_name,ind_range):\"\"\"Gettheroidbforthedatasetspecifiedintheglobalcfg.Optionallyrestrictittoarangeofindicesifind_rangeisapairofintegers.\"\"\"dataset=JsonDataset(dataset_name)roidb=dataset.get_roidb()ifind_rangeisnotNone:total_num_images=len(roidb)start,end=ind_rangeroidb=roidb[start:end]else:start=0end=len(roidb)total_num_images=endreturnroidb,start,end,total_num_imagesdefevaluate_proposal_file(dataset,proposal_file,output_dir):\"\"\"Evaluateboxproposalaveragerecall.\"\"\"roidb=dataset.get_roidb(gt=True,proposal_file=proposal_file)results=task_evaluation.evaluate_box_proposals(dataset,roidb)task_evaluation.log_box_proposal_results(results)recall_file=os.path.join(output_dir,\\'rpn_proposal_recall.pkl\\')save_object(results,recall_file)returnresults#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TestaRetinaNetnetworkonanimagedatabase\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportloggingfromcollectionsimportdefaultdictfromcaffe2.pythonimportcore,workspacefromdetectron.core.configimportcfgfromdetectron.modeling.generate_anchorsimportgenerate_anchorsfromdetectron.utils.timerimportTimerimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)def_create_cell_anchors():\"\"\"Generatealltypesofanchorsforallfpnlevels/scales/aspectratios.Thisfunctioniscalledonlyonceatthebeginningofinference.\"\"\"k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELscales_per_octave=cfg.RETINANET.SCALES_PER_OCTAVEaspect_ratios=cfg.RETINANET.ASPECT_RATIOSanchor_scale=cfg.RETINANET.ANCHOR_SCALEA=scales_per_octave*len(aspect_ratios)anchors={}forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=np.zeros((A,4))a=0foroctaveinrange(scales_per_octave):octave_scale=2**(octave/float(scales_per_octave))foraspectinaspect_ratios:anchor_sizes=(stride*octave_scale*anchor_scale,)anchor_aspect_ratios=(aspect,)cell_anchors[a,:]=generate_anchors(stride=stride,sizes=anchor_sizes,aspect_ratios=anchor_aspect_ratios)a+=1anchors[lvl]=cell_anchorsreturnanchorsdefim_detect_bbox(model,im,timers=None):\"\"\"GenerateRetinaNetdetectionsonasingleimage.\"\"\"iftimersisNone:timers=defaultdict(Timer)#Althoughanchorsareinputindependentandcouldbeprecomputed,#recomputingthemperimageonlybringsasmalloverheadanchors=_create_cell_anchors()timers[\\'im_detect_bbox\\'].tic()k_max,k_min=cfg.FPN.RPN_MAX_LEVEL,cfg.FPN.RPN_MIN_LEVELA=cfg.RETINANET.SCALES_PER_OCTAVE*len(cfg.RETINANET.ASPECT_RATIOS)inputs={}inputs[\\'data\\'],im_scale,inputs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)cls_probs,box_preds=[],[]forlvlinrange(k_min,k_max+1):suffix=\\'fpn{}\\'.format(lvl)cls_probs.append(core.ScopedName(\\'retnet_cls_prob_{}\\'.format(suffix)))box_preds.append(core.ScopedName(\\'retnet_bbox_pred_{}\\'.format(suffix)))fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v.astype(np.float32,copy=False))workspace.RunNet(model.net.Proto().name)cls_probs=workspace.FetchBlobs(cls_probs)box_preds=workspace.FetchBlobs(box_preds)#heretheboxes_allare[x0,y0,x1,y1,score]boxes_all=defaultdict(list)cnt=0forlvlinrange(k_min,k_max+1):#createcellanchorsarraystride=2.**lvlcell_anchors=anchors[lvl]#fetchperlevelprobabilitycls_prob=cls_probs[cnt]box_pred=box_preds[cnt]cls_prob=cls_prob.reshape((cls_prob.shape[0],A,int(cls_prob.shape[1]/A),cls_prob.shape[2],cls_prob.shape[3]))box_pred=box_pred.reshape((box_pred.shape[0],A,4,box_pred.shape[2],box_pred.shape[3]))cnt+=1ifcfg.RETINANET.SOFTMAX:cls_prob=cls_prob[:,:,1::,:,:]cls_prob_ravel=cls_prob.ravel()#Insomecases[especiallyforverysmallimgsizes],it\\'spossiblethat#candidate_indisemptyifweimposethreshold0.05atalllevels.This#willleadtoerrorssincenodetectionsarefoundforthisimage.Hence,#forlvl7whichhassmallspatialresolution,wetakethethreshold0.0th=cfg.RETINANET.INFERENCE_THiflvl<k_maxelse0.0candidate_inds=np.where(cls_prob_ravel>th)[0]if(len(candidate_inds)==0):continuepre_nms_topn=min(cfg.RETINANET.PRE_NMS_TOP_N,len(candidate_inds))inds=np.argpartition(cls_prob_ravel[candidate_inds],-pre_nms_topn)[-pre_nms_topn:]inds=candidate_inds[inds]inds_5d=np.array(np.unravel_index(inds,cls_prob.shape)).transpose()classes=inds_5d[:,2]anchor_ids,y,x=inds_5d[:,1],inds_5d[:,3],inds_5d[:,4]scores=cls_prob[:,anchor_ids,classes,y,x]boxes=np.column_stack((x,y,x,y)).astype(dtype=np.float32)boxes*=strideboxes+=cell_anchors[anchor_ids,:]ifnotcfg.RETINANET.CLASS_SPECIFIC_BBOX:box_deltas=box_pred[0,anchor_ids,:,y,x]else:box_cls_inds=classes*4box_deltas=np.vstack([box_pred[0,ind:ind+4,yi,xi]forind,yi,xiinzip(box_cls_inds,y,x)])pred_boxes=(box_utils.bbox_transform(boxes,box_deltas)ifcfg.TEST.BBOX_REGelseboxes)pred_boxes/=im_scalepred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)box_scores=np.zeros((pred_boxes.shape[0],5))box_scores[:,0:4]=pred_boxesbox_scores[:,4]=scoresforclsinrange(1,cfg.MODEL.NUM_CLASSES):inds=np.where(classes==cls-1)[0]iflen(inds)>0:boxes_all[cls].extend(box_scores[inds,:])timers[\\'im_detect_bbox\\'].toc()#Combinepredictionsacrossalllevelsandretainthetopscoringbyclasstimers[\\'misc_bbox\\'].tic()detections=[]forcls,boxesinboxes_all.items():cls_dets=np.vstack(boxes).astype(dtype=np.float32)#doclassspecificnmshereifcfg.TEST.SOFT_NMS.ENABLED:cls_dets,keep=box_utils.soft_nms(cls_dets,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(cls_dets,cfg.TEST.NMS)cls_dets=cls_dets[keep,:]out=np.zeros((len(keep),6))out[:,0:5]=cls_detsout[:,5].fill(cls)detections.append(out)#detections(N,6)format:#detections[:,:4]-boxes#detections[:,4]-scores#detections[:,5]-classesdetections=np.vstack(detections)#sortallagaininds=np.argsort(-detections[:,4])detections=detections[inds[0:cfg.TEST.DETECTIONS_PER_IM],:]#Convertthedetectionstoimagecls_format(seecore/test_engine.py)num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(cfg.MODEL.NUM_CLASSES)]forcinrange(1,num_classes):inds=np.where(detections[:,5]==c)[0]cls_boxes[c]=detections[inds,:5]timers[\\'misc_bbox\\'].toc()returncls_boxes#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Detectronconfigsystem.ThisfilespecifiesdefaultconfigoptionsforDetectron.Youshouldnotchangevaluesinthisfile.Instead,youshouldwriteaconfigfile(inyaml)andusemerge_cfg_from_file(yaml_file)toloaditandoverridethedefaultoptions.Mosttoolsinthetoolsdirectorytakea--cfgoptiontospecifyanoverridefileandanoptionallistofoverride(key,value)pairs:-Seetools/{train,test}_net.pyforexamplecodethatusesmerge_cfg_from_file-Seeconfigs/*/*.yamlforexampleconfigfilesDetectronsupportsalotofdifferentmodeltypes,eachofwhichhasalotofdifferentoptions.TheresultisaHUGEsetofconfigurationoptions.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromastimportliteral_evalfromfuture.utilsimportiteritemsimportcopyimportioimportloggingimportnumpyasnpimportosimportos.pathasospimportsixfromdetectron.utils.collectionsimportAttrDictfromdetectron.utils.ioimportcache_urllogger=logging.getLogger(__name__)__C=AttrDict()#Consumerscangetconfigby:#fromdetectron.core.configimportcfgcfg=__C#Randomnote:avoidusing\\'.ON\\'asaconfigkeysinceyamlconvertsittoTrue;#prefer\\'ENABLED\\'instead#----------------------------------------------------------------------------##Trainingoptions#----------------------------------------------------------------------------#__C.TRAIN=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TRAIN.WEIGHTS=\\'\\'#Datasetstotrainon#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,themodelistrainedontheirunion__C.TRAIN.DATASETS=()#Scalestouseduringtraining#Eachscaleisthepixelsizeofanimage\\'sshortestside#Ifmultiplescalesarelisted,thenoneisselecteduniformlyatrandomfor#eachtrainingimage(i.e.,scalejitterdataaugmentation)__C.TRAIN.SCALES=(600,)#Maxpixelsizeofthelongestsideofascaledinputimage__C.TRAIN.MAX_SIZE=1000#Images*perGPU*inthetrainingminibatch#Totalimagesperminibatch=TRAIN.IMS_PER_BATCH*NUM_GPUS__C.TRAIN.IMS_PER_BATCH=2#RoIminibatchsize*perimage*(numberofregionsofinterest[ROIs])#TotalnumberofRoIspertrainingminibatch=#TRAIN.BATCH_SIZE_PER_IM*TRAIN.IMS_PER_BATCH*NUM_GPUS#E.g.,acommonconfigurationis:512*2*8=8192__C.TRAIN.BATCH_SIZE_PER_IM=64#TargetfractionofRoIminibatchthatislabeledforeground(i.e.class>0)__C.TRAIN.FG_FRACTION=0.25#OverlapthresholdforanRoItobeconsideredforeground(if>=FG_THRESH)__C.TRAIN.FG_THRESH=0.5#OverlapthresholdforanRoItobeconsideredbackground(class=0if#overlapin[LO,HI))__C.TRAIN.BG_THRESH_HI=0.5__C.TRAIN.BG_THRESH_LO=0.0#Usehorizontally-flippedimagesduringtraining?__C.TRAIN.USE_FLIPPED=True#OverlaprequiredbetweenanRoIandaground-truthboxinorderforthat#(RoI,gtbox)pairtobeusedasabounding-boxregressiontrainingexample__C.TRAIN.BBOX_THRESH=0.5#Snapshot(modelcheckpoint)period#DividebyNUM_GPUStodetermineactualperiod(e.g.,80000/8=>10000iters)#toallowforlineartrainingschedulescaling__C.TRAIN.SNAPSHOT_ITERS=80000#Trainusingtheseproposals#Duringtraining,allproposalsspecifiedinthefileareused(nolimitis#applied)#Proposalfilesmustbeincorrespondencewiththedatasetslistedin#TRAIN.DATASETS__C.TRAIN.PROPOSAL_FILES=()#Makeminibatchesfromimagesthathavesimilaraspectratios(i.e.both#tallandthinorbothshortandwide)#Thisfeatureiscriticalforsavingmemory(andmakestrainingslightly#faster)__C.TRAIN.ASPECT_GROUPING=True#----------------------------------------------------------------------------##RPNtrainingoptions#----------------------------------------------------------------------------##RunGenerateProposalsonGPUifsettoTrue__C.TRAIN.GENERATE_PROPOSALS_ON_GPU=False#Minimumoverlaprequiredbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeapositiveexample(IOU>=thresh==>positiveRPN#example)__C.TRAIN.RPN_POSITIVE_OVERLAP=0.7#Maximumoverlapallowedbetweenananchorandground-truthboxforthe#(anchor,gtbox)pairtobeanegativeexamples(IOUnegativeRPN#example)__C.TRAIN.RPN_NEGATIVE_OVERLAP=0.3#Targetfractionofforeground(positive)examplesperRPNminibatch__C.TRAIN.RPN_FG_FRACTION=0.5#TotalnumberofRPNexamplesperimage__C.TRAIN.RPN_BATCH_SIZE_PER_IM=256#NMSthresholdusedonRPNproposals(usedduringend-to-endtrainingwithRPN)__C.TRAIN.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TRAIN.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TRAIN.RPN_POST_NMS_TOP_N=2000#RemoveRPNanchorsthatgooutsidetheimagebyRPN_STRADDLE_THRESHpixels#Setto-1oralargevalue,e.g.100000,todisablepruninganchors__C.TRAIN.RPN_STRADDLE_THRESH=0#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TRAIN.RPN_MIN_SIZE=0#FilterproposalsthatareinsideofcrowdregionsbyCROWD_FILTER_THRESH#\"Inside\"ismeasuredas:proposal-with-crowdintersectionareadividedby#proposalarea__C.TRAIN.CROWD_FILTER_THRESH=0.7#Ignoreground-truthobjectswitharea<thisthreshold__C.TRAIN.GT_MIN_AREA=-1#FreezethebackbonearchitectureduringtrainingifsettoTrue__C.TRAIN.FREEZE_CONV_BODY=False#Trainingwillresumefromthelatestsnapshot(modelcheckpoint)foundinthe#outputdirectory__C.TRAIN.AUTO_RESUME=True#TrainingwillcopyTRAIN.WEIGHTSandtreatitasacandidatecheckpoint__C.TRAIN.COPY_WEIGHTS=False#AddStopGradataspecifiedstagesothebottomlayersarefrozen__C.TRAIN.FREEZE_AT=2#----------------------------------------------------------------------------##Dataloaderoptions(seedetectron/roi_data/loader.pyformoreinfo)#----------------------------------------------------------------------------#__C.DATA_LOADER=AttrDict()#NumberofPythonthreadstouseforthedataloader(warning:usingtoomany#threadscancauseGIL-basedinterferencewithPythonOpsleadingto*slower*#training;4seemstobethesweetspotinourexperience)__C.DATA_LOADER.NUM_THREADS=4#Sizeofthesharedminibatchqueue__C.DATA_LOADER.MINIBATCH_QUEUE_SIZE=64#CapacityoftheperGPUblobsqueue__C.DATA_LOADER.BLOBS_QUEUE_CAPACITY=8#----------------------------------------------------------------------------##Inference(\\'test\\')options#----------------------------------------------------------------------------#__C.TEST=AttrDict()#Initializenetworkwithweightsfromthis.pklfile__C.TEST.WEIGHTS=\\'\\'#Datasetstoteston#Availabledatasetlist:detectron.datasets.dataset_catalog.datasets()#Ifmultipledatasetsarelisted,testingisperformedoneachonesequentially__C.TEST.DATASETS=()#Scaletouseduringtesting__C.TEST.SCALE=600#Maxpixelsizeofthelongestsideofascaledinputimage__C.TEST.MAX_SIZE=1000#Overlapthresholdusedfornon-maximumsuppression(suppressboxeswith#IoU>=thisthreshold)__C.TEST.NMS=0.3#ApplyFastR-CNNstylebounding-boxregressionifTrue__C.TEST.BBOX_REG=True#Testusingtheseproposalfiles(mustcorrespondwithTEST.DATASETS)__C.TEST.PROPOSAL_FILES=()#RunGenerateProposalsonGPUifsettoTrue__C.TEST.GENERATE_PROPOSALS_ON_GPU=False#Limitonthenumberofproposalsperimageusedduringinference__C.TEST.PROPOSAL_LIMIT=2000#NMSthresholdusedonRPNproposals__C.TEST.RPN_NMS_THRESH=0.7#NumberoftopscoringRPNproposalstokeepbeforeapplyingNMS#WhenFPNisused,thisis*perFPNlevel*(nottotal)__C.TEST.RPN_PRE_NMS_TOP_N=12000#NumberoftopscoringRPNproposalstokeepafterapplyingNMS#ThisisthetotalnumberofRPNproposalsproduced(forbothFPNandnon-FPN#cases)__C.TEST.RPN_POST_NMS_TOP_N=2000#ProposalheightandwidthbothneedtobegreaterthanRPN_MIN_SIZE#(atorigimagescale;notscaleusedduringtrainingorinference)__C.TEST.RPN_MIN_SIZE=0#Maximumnumberofdetectionstoreturnperimage(100isbasedonthelimit#establishedfortheCOCOdataset)__C.TEST.DETECTIONS_PER_IM=100#Minimumscorethreshold(assumingscoresina[0,1]range);avaluechosento#balanceobtaininghighrecallwithnothavingtoomanylowprecision#detectionsthatwillslowdowninferencepostprocessingsteps(likeNMS)__C.TEST.SCORE_THRESH=0.05#SavedetectionresultsfilesifTrue#Iffalse,resultsfilesarecleanedup(theycanbelarge)afterlocal#evaluation__C.TEST.COMPETITION_MODE=True#EvaluatedetectionswiththeCOCOjsondatasetevalcodeevenifit\\'snotthe#evaluationcodeforthedataset(e.g.evaluatePASCALVOCresultsusingthe#COCOAPItogetCOCOstyleAPonPASCALVOC)__C.TEST.FORCE_JSON_DATASET_EVAL=False#[Inferredvalue;donotsetdirectlyinaconfig]#Indicatesifprecomputedproposalsareusedattesttime#Notsetfor1-stagemodelsand2-stagemodelswithRPNsubnetworkenabled__C.TEST.PRECOMPUTED_PROPOSALS=True#Evaluateproposalsinclass-specificAverageRecall(AR).#ItmeansthatonefirstcomputesARwithineachcategoryandthenaverages#overthecategories.ItisnotbiasedtowardstheARoffrequentcategories#comparedwithclass-agnosticAR.__C.TEST.CLASS_SPECIFIC_AR=False#----------------------------------------------------------------------------##Test-timeaugmentationsforboundingboxdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.BBOX_AUG=AttrDict()#Enabletest-timeaugmentationforboundingboxdetectionifTrue__C.TEST.BBOX_AUG.ENABLED=False#Heuristicusedtocombinepredictedboxscores#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.SCORE_HEUR=\\'UNION\\'#Heuristicusedtocombinepredictedboxcoordinates#Validoptions:(\\'ID\\',\\'AVG\\',\\'UNION\\')__C.TEST.BBOX_AUG.COORD_HEUR=\\'UNION\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.BBOX_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.BBOX_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.BBOX_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.BBOX_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.BBOX_AUG.SCALE_SIZE_DEP=False__C.TEST.BBOX_AUG.AREA_TH_LO=50**2__C.TEST.BBOX_AUG.AREA_TH_HI=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.BBOX_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-timeaugmentationsformaskdetection#Seeconfigs/test_time_aug/e2e_mask_rcnn_R-50-FPN_2x.yamlforanexample#----------------------------------------------------------------------------#__C.TEST.MASK_AUG=AttrDict()#Enabletest-timeaugmentationforinstancemaskdetectionifTrue__C.TEST.MASK_AUG.ENABLED=False#Heuristicusedtocombinemaskpredictions#SOFTprefixindicatesthatthecomputationisperformedonsoftmasks#Validoptions:(\\'SOFT_AVG\\',\\'SOFT_MAX\\',\\'LOGIT_AVG\\')__C.TEST.MASK_AUG.HEUR=\\'SOFT_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.MASK_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.MASK_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.MASK_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.MASK_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.MASK_AUG.SCALE_SIZE_DEP=False__C.TEST.MASK_AUG.AREA_TH=180**2#Eachaspectratioisrelativetoimagewidth__C.TEST.MASK_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##Test-augmentationsforkeypointsdetection#configs/test_time_aug/keypoint_rcnn_R-50-FPN_1x.yaml#----------------------------------------------------------------------------#__C.TEST.KPS_AUG=AttrDict()#Enabletest-timeaugmentationforkeypointdetectionifTrue__C.TEST.KPS_AUG.ENABLED=False#Heuristicusedtocombinekeypointpredictions#Validoptions:(\\'HM_AVG\\',\\'HM_MAX\\')__C.TEST.KPS_AUG.HEUR=\\'HM_AVG\\'#Horizontalflipattheoriginalscale(idtransform)__C.TEST.KPS_AUG.H_FLIP=False#Eachscaleisthepixelsizeofanimage\\'sshortestside__C.TEST.KPS_AUG.SCALES=()#Maxpixelsizeofthelongerside__C.TEST.KPS_AUG.MAX_SIZE=4000#Horizontalflipateachscale__C.TEST.KPS_AUG.SCALE_H_FLIP=False#Applyscalingbasedonobjectsize__C.TEST.KPS_AUG.SCALE_SIZE_DEP=False__C.TEST.KPS_AUG.AREA_TH=180**2#Eeachaspectratioisrealtivetoimagewidth__C.TEST.KPS_AUG.ASPECT_RATIOS=()#Horizontalflipateachaspectratio__C.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP=False#----------------------------------------------------------------------------##SoftNMS#----------------------------------------------------------------------------#__C.TEST.SOFT_NMS=AttrDict()#UsesoftNMSinsteadofstandardNMSifsettoTrue__C.TEST.SOFT_NMS.ENABLED=False#SeesoftNMSpaperfordefinitionoftheseoptions__C.TEST.SOFT_NMS.METHOD=\\'linear\\'__C.TEST.SOFT_NMS.SIGMA=0.5#ForthesoftNMSoverlapthreshold,wesimplyuseTEST.NMS#----------------------------------------------------------------------------##Boundingboxvoting(fromtheMulti-RegionCNNpaper)#----------------------------------------------------------------------------#__C.TEST.BBOX_VOTE=AttrDict()#UseboxvotingifsettoTrue__C.TEST.BBOX_VOTE.ENABLED=False#WeuseTEST.NMSthresholdfortheNMSstep.VOTE_THoverlapthreshold#isusedtoselectvotingboxes(IoU>=VOTE_TH)foreachboxthatsurvivesNMS__C.TEST.BBOX_VOTE.VOTE_TH=0.8#Themethodusedtocombinescoreswhendoingboundingboxvoting#Validoptionsinclude(\\'ID\\',\\'AVG\\',\\'IOU_AVG\\',\\'GENERALIZED_AVG\\',\\'QUASI_SUM\\')__C.TEST.BBOX_VOTE.SCORING_METHOD=\\'ID\\'#Hyperparameterusedbythescoringmethod(ithasdifferentmeaningsfor#differentmethods)__C.TEST.BBOX_VOTE.SCORING_METHOD_BETA=1.0#----------------------------------------------------------------------------##Modeloptions#----------------------------------------------------------------------------#__C.MODEL=AttrDict()#Thetypeofmodeltouse#Thestringmustmatchafunctioninthemodeling.model_buildermodule#(e.g.,\\'generalized_rcnn\\',\\'mask_rcnn\\',...)__C.MODEL.TYPE=\\'\\'#Thebackboneconvbodytouse#Thestringmustmatchafunctionthatisimportedinmodeling.model_builder#(e.g.,\\'FPN.add_fpn_ResNet101_conv5_body\\'tospecifyaResNet-101-FPN#backbone)__C.MODEL.CONV_BODY=\\'\\'#Numberofclassesinthedataset;mustbeset#E.g.,81forCOCO(80foreground+1background)__C.MODEL.NUM_CLASSES=-1#Useaclassagnosticboundingboxregressorinsteadofthedefaultper-class#regressor__C.MODEL.CLS_AGNOSTIC_BBOX_REG=False#Defaultweightson(dx,dy,dw,dh)fornormalizingbboxregressiontargets#Theseareempiricallychosentoapproximatelyleadtounitvariancetargets__C.MODEL.BBOX_REG_WEIGHTS=(10.,10.,5.,5.)#ThemeaningofFASTER_RCNNdependsonthecontext(trainingvs.inference):#1)Duringtraining,FASTER_RCNN=Truemeansthatend-to-endtrainingwillbe#usedtojointlytraintheRPNsubnetworkandtheFastR-CNNsubnetwork#(FasterR-CNN=RPN+FastR-CNN).#2)Duringinference,FASTER_RCNN=Truemeansthatthemodel\\'sRPNsubnetwork#willbeusedtogenerateproposalsratherthanrelyingonprecomputed#proposals.NotethatFASTER_RCNN=Truecanbeusedatinferencetimeeven#iftheFasterR-CNNmodelwastrainedwithstagewisetraining(which#consistsofalternatingbetweenRPNandFastR-CNNtraininginawaythat#finallyleadstoasinglenetwork).__C.MODEL.FASTER_RCNN=False#Indicatesthemodelmakesinstancemaskpredictions(asinMaskR-CNN)__C.MODEL.MASK_ON=False#Indicatesthemodelmakeskeypointpredictions(asinMaskR-CNNfor#keypoints)__C.MODEL.KEYPOINTS_ON=False#Indicatesthemodel\\'scomputationterminateswiththeproductionofRPN#proposals(i.e.,itoutputsproposalsONLY,noactualobjectdetections)__C.MODEL.RPN_ONLY=False#Caffe2netexecutiontype#Use\\'prof_dag\\'togetprofilingstatistics__C.MODEL.EXECUTION_TYPE=\\'dag\\'#----------------------------------------------------------------------------##RetinaNetoptions#----------------------------------------------------------------------------#__C.RETINANET=AttrDict()#RetinaNetisused(insteadofFast/er/MaskR-CNN/R-FCN/RPN)ifTrue__C.RETINANET.RETINANET_ON=False#Anchoraspectratiostouse__C.RETINANET.ASPECT_RATIOS=(0.5,1.0,2.0)#Anchorscalesperoctave__C.RETINANET.SCALES_PER_OCTAVE=3#AteachFPNlevel,wegenerateanchorsbasedontheirscale,aspect_ratio,#strideofthelevel,andwemultiplytheresultinganchorbyANCHOR_SCALE__C.RETINANET.ANCHOR_SCALE=4#Convolutionstouseintheclsandbboxtower#NOTE:thisdoesn\\'tincludethelastconvforlogits__C.RETINANET.NUM_CONVS=4#Weightforbbox_regressionloss__C.RETINANET.BBOX_REG_WEIGHT=1.0#SmoothL1lossbetaforbboxregression__C.RETINANET.BBOX_REG_BETA=0.11#Duringinference,#locstoselectbasedonclsscorebeforeNMSisperformed#perFPNlevel__C.RETINANET.PRE_NMS_TOP_N=1000#IoUoverlapratioforlabelingananchoraspositive#Anchorswith>=iouoverlaparelabeledpositive__C.RETINANET.POSITIVE_OVERLAP=0.5#IoUoverlapratioforlabelingananchorasnegative#Anchorswith<iouoverlaparelabelednegative__C.RETINANET.NEGATIVE_OVERLAP=0.4#Focallossparameter:alpha__C.RETINANET.LOSS_ALPHA=0.25#Focallossparameter:gamma__C.RETINANET.LOSS_GAMMA=2.0#Priorprobforthepositivesatthebeginningoftraining.Thisisusedtoset#thebiasinitforthelogitslayer__C.RETINANET.PRIOR_PROB=0.01#Whetherclassificationandbboxbranchtowershouldbesharedornot__C.RETINANET.SHARE_CLS_BBOX_TOWER=False#Useclassspecificboundingboxregressioninsteadofthedefaultclass#agnosticregression__C.RETINANET.CLASS_SPECIFIC_BBOX=False#Whethersoftmaxshouldbeusedinclassificationbranchtraining__C.RETINANET.SOFTMAX=False#Inferenceclsscorethreshold,anchorswithscore>INFERENCE_THare#consideredforinference__C.RETINANET.INFERENCE_TH=0.05#----------------------------------------------------------------------------##Solveroptions#Note:allsolveroptionsareusedexactlyasspecified;theimplicationis#thatifyouswitchfromtrainingon1GPUtoNGPUs,youMUSTadjustthe#solverconfigurationaccordingly.Wesuggestusinggradualwarmupandthe#linearlearningratescalingruleasdescribedin#\"Accurate,LargeMinibatchSGD:TrainingImageNetin1Hour\"Goyaletal.##----------------------------------------------------------------------------#__C.SOLVER=AttrDict()#Baselearningrateforthespecifiedschedule__C.SOLVER.BASE_LR=0.001#Scheduletype(seefunctionsinutils.lr_policyforoptions)#E.g.,\\'step\\',\\'steps_with_decay\\',...__C.SOLVER.LR_POLICY=\\'step\\'#SomeLRPolicies(byexample):#\\'step\\'#lr=SOLVER.BASE_LR*SOLVER.GAMMA**(cur_iter//SOLVER.STEP_SIZE)#\\'steps_with_decay\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.GAMMA=0.1#lr=SOLVER.BASE_LR*SOLVER.GAMMA**current_step#iters[0,59999]areincurrent_step=0,iters[60000,79999]arein#current_step=1,andsoon#\\'steps_with_lrs\\'#SOLVER.STEPS=[0,60000,80000]#SOLVER.LRS=[0.02,0.002,0.0002]#lr=LRS[current_step]#\\'cosine_decay\\'#lr=SOLVER.BASE_LR*(cos(PI*cur_iter/SOLVER.MAX_ITER)*0.5+0.5)#\\'exp_decay\\'#lrsmoothlydecaysfromSOLVER.BASE_LRtoSOLVER.GAMMA*SOLVER.BASE_LR#lr=SOLVER.BASE_LR*exp(np.log(SOLVER.GAMMA)*cur_iter/SOLVER.MAX_ITER)#Hyperparameterusedbythespecifiedpolicy#For\\'step\\',thecurrentLRismultipliedbySOLVER.GAMMAateachstep#For\\'exp_decay\\',SOLVER.GAMMAistheratiobetweenthefinalandinitialLR.__C.SOLVER.GAMMA=0.1#Uniformstepsizefor\\'steps\\'policy__C.SOLVER.STEP_SIZE=30000#Non-uniformstepiterationsfor\\'steps_with_decay\\'or\\'steps_with_lrs\\'#policies__C.SOLVER.STEPS=[]#Learningratestousewith\\'steps_with_lrs\\'policy__C.SOLVER.LRS=[]#MaximumnumberofSGDiterations__C.SOLVER.MAX_ITER=40000#MomentumtousewithSGD__C.SOLVER.MOMENTUM=0.9#L2regularizationhyperparameter__C.SOLVER.WEIGHT_DECAY=0.0005#L2regularizationhyperparameterforGroupNorm\\'sparameters__C.SOLVER.WEIGHT_DECAY_GN=0.0#WarmuptoSOLVER.BASE_LRoverthisnumberofSGDiterations__C.SOLVER.WARM_UP_ITERS=500#StartthewarmupfromSOLVER.BASE_LR*SOLVER.WARM_UP_FACTOR__C.SOLVER.WARM_UP_FACTOR=1.0/3.0#WARM_UP_METHODcanbeeither\\'constant\\'or\\'linear\\'(i.e.,gradual)__C.SOLVER.WARM_UP_METHOD=\\'linear\\'#Scalethemomentumupdatehistorybynew_lr/old_lrwhenupdatingthe#learningrate(thisiscorrectgivenMomentumSGDUpdateOp)__C.SOLVER.SCALE_MOMENTUM=True#OnlyapplythecorrectioniftherelativeLRchangeexceedsthisthreshold#(preventseverchangeinlinearwarmupfromscalingthemomentumbyatiny#amount;momentumscalingisonlyimportantiftheLRchangeislarge)__C.SOLVER.SCALE_MOMENTUM_THRESHOLD=1.1#SuppressloggingofchangestoLRunlesstherelativechangeexceedsthis#threshold(preventslinearwarmupfromspammingthetraininglog)__C.SOLVER.LOG_LR_CHANGE_THRESHOLD=1.1#----------------------------------------------------------------------------##FastR-CNNoptions#----------------------------------------------------------------------------#__C.FAST_RCNN=AttrDict()#ThetypeofRoIheadtouseforboundingboxclassificationandregression#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'head_builder.add_roi_2mlp_head\\'tospecifyatwohiddenlayerMLP)__C.FAST_RCNN.ROI_BOX_HEAD=\\'\\'#HiddenlayerdimensionwhenusinganMLPfortheRoIboxhead__C.FAST_RCNN.MLP_HEAD_DIM=1024#HiddenConvlayerdimensionwhenusingConvsfortheRoIboxhead__C.FAST_RCNN.CONV_HEAD_DIM=256#NumberofstackedConvlayersintheRoIboxhead__C.FAST_RCNN.NUM_STACKED_CONVS=4#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)#(RoIPoolFisthesameasRoIPool;ignorethetrailing\\'F\\')__C.FAST_RCNN.ROI_XFORM_METHOD=\\'RoIPoolF\\'#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.FAST_RCNN.ROI_XFORM_SAMPLING_RATIO=0#RoItransformoutputresolution#Note:somemodelsmayhaveconstraintsonwhattheycanuse,e.g.theyuse#pretrainedFClayerslikeinVGG16,andwillignorethisoption__C.FAST_RCNN.ROI_XFORM_RESOLUTION=14#----------------------------------------------------------------------------##RPNoptions#----------------------------------------------------------------------------#__C.RPN=AttrDict()#[Inferedvalue;donotsetdirectlyinaconfig]#IndicatesthatthemodelcontainsanRPNsubnetwork__C.RPN.RPN_ON=False#RPNanchorsizesgiveninabsolutepixelsw.r.t.thescalednetworkinput#Note:theseoptionsare*not*usedbyFPNRPN;seeFPN.RPN*options__C.RPN.SIZES=(64,128,256,512)#StrideofthefeaturemapthatRPNisattached__C.RPN.STRIDE=16#RPNanchoraspectratios__C.RPN.ASPECT_RATIOS=(0.5,1,2)#----------------------------------------------------------------------------##FPNoptions#----------------------------------------------------------------------------#__C.FPN=AttrDict()#FPNisenabledifTrue__C.FPN.FPN_ON=False#ChanneldimensionoftheFPNfeaturelevels__C.FPN.DIM=256#InitializethelateralconnectionstooutputzeroifTrue__C.FPN.ZERO_INIT_LATERAL=False#StrideofthecoarsestFPNlevel#Thisisneededsotheinputcanbepaddedproperly__C.FPN.COARSEST_STRIDE=32##FPNmaybeusedforjustRPN,justobjectdetection,orboth##UseFPNforRoItransformforobjectdetectionifTrue__C.FPN.MULTILEVEL_ROIS=False#HyperparametersfortheRoI-to-FPNlevelmappingheuristic__C.FPN.ROI_CANONICAL_SCALE=224#s0__C.FPN.ROI_CANONICAL_LEVEL=4#k0:wheres0mapsto#CoarsestleveloftheFPNpyramid__C.FPN.ROI_MAX_LEVEL=5#FinestleveloftheFPNpyramid__C.FPN.ROI_MIN_LEVEL=2#UseFPNforRPNifTrue__C.FPN.MULTILEVEL_RPN=False#CoarsestleveloftheFPNpyramid__C.FPN.RPN_MAX_LEVEL=6#FinestleveloftheFPNpyramid__C.FPN.RPN_MIN_LEVEL=2#FPNRPNanchoraspectratios__C.FPN.RPN_ASPECT_RATIOS=(0.5,1,2)#RPNanchorsstartatthissizeonRPN_MIN_LEVEL#Theanchorsizedoubledeachlevelafterthat#Withadefaultof32andlevels2to6,wegetanchorsizesof32to512__C.FPN.RPN_ANCHOR_START_SIZE=32#UseextraFPNlevels,asdoneintheRetinaNetpaper__C.FPN.EXTRA_CONV_LEVELS=False#UseGroupNormintheFPN-specificlayers(lateral,etc.)__C.FPN.USE_GN=False#----------------------------------------------------------------------------##MaskR-CNNoptions(\"MRCNN\"meansMaskR-CNN)#----------------------------------------------------------------------------#__C.MRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancemaskprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'mask_rcnn_heads.ResNet_mask_rcnn_fcn_head_v1up4convs\\')__C.MRCNN.ROI_MASK_HEAD=\\'\\'#Resolutionofmaskpredictions__C.MRCNN.RESOLUTION=14#RoItransformationfunctionandassociatedoptions__C.MRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'#RoItransformationfunction(e.g.,RoIPoolorRoIAlign)__C.MRCNN.ROI_XFORM_RESOLUTION=7#NumberofgridsamplingpointsinRoIAlign(usuallyuse2)#OnlyappliestoRoIAlign__C.MRCNN.ROI_XFORM_SAMPLING_RATIO=0#Numberofchannelsinthemaskhead__C.MRCNN.DIM_REDUCED=256#Usedilatedconvolutioninthemaskhead__C.MRCNN.DILATION=2#Upsamplethepredictedmasksbythisfactor__C.MRCNN.UPSAMPLE_RATIO=1#Useafully-connectedlayertopredictthefinalmasksinsteadofaconvlayer__C.MRCNN.USE_FC_OUTPUT=False#Weightinitializationmethodforthemaskheadandmaskoutputlayers__C.MRCNN.CONV_INIT=\\'GaussianFill\\'#UseclassspecificmaskpredictionsifTrue(otherwiseuseclassagnosticmask#predictions)__C.MRCNN.CLS_SPECIFIC_MASK=True#Multi-tasklossweightformasks__C.MRCNN.WEIGHT_LOSS_MASK=1.0#Binarizationthresholdforconvertingsoftmaskstohardmasks__C.MRCNN.THRESH_BINARIZE=0.5#----------------------------------------------------------------------------##KeypointMaskR-CNNoptions(\"KRCNN\"=MaskR-CNNwithKeypointsupport)#----------------------------------------------------------------------------#__C.KRCNN=AttrDict()#ThetypeofRoIheadtouseforinstancekeypointprediction#Thestringmustmatchafunctionthisisimportedinmodeling.model_builder#(e.g.,\\'keypoint_rcnn_heads.add_roi_pose_head_v1convX\\')__C.KRCNN.ROI_KEYPOINTS_HEAD=\\'\\'#Outputsize(andsizelossiscomputedon),e.g.,56x56__C.KRCNN.HEATMAP_SIZE=-1#Usebilinearinterpolationtoupsamplethefinalheatmapbythisfactor__C.KRCNN.UP_SCALE=-1#ApplyaConvTransposelayertothehiddenrepresentationcomputedbythe#keypointheadpriortopredictingtheper-keypointheatmaps__C.KRCNN.USE_DECONV=False#ChanneldimensionofthehiddenrepresentationproducedbytheConvTranspose__C.KRCNN.DECONV_DIM=256#UseaConvTransposelayertopredicttheper-keypointheatmaps__C.KRCNN.USE_DECONV_OUTPUT=False#Usedilationinthekeypointhead__C.KRCNN.DILATION=1#SizeofthekernelstouseinallConvTransposeoperations__C.KRCNN.DECONV_KERNEL=4#Numberofkeypointsinthedataset(e.g.,17forCOCO)__C.KRCNN.NUM_KEYPOINTS=-1#NumberofstackedConvlayersinkeypointhead__C.KRCNN.NUM_STACKED_CONVS=8#Dimensionofthehiddenrepresentationoutputbythekeypointhead__C.KRCNN.CONV_HEAD_DIM=256#Convkernelsizeusedinthekeypointhead__C.KRCNN.CONV_HEAD_KERNEL=3#Convkernelweightfillingfunction__C.KRCNN.CONV_INIT=\\'GaussianFill\\'#UseNMSbasedonOKSifTrue__C.KRCNN.NMS_OKS=False#Sourceofkeypointconfidence#Validoptions:(\\'bbox\\',\\'logit\\',\\'prob\\')__C.KRCNN.KEYPOINT_CONFIDENCE=\\'bbox\\'#StandardROIXFORMoptions(seeFAST_RCNNorMRCNNoptions)__C.KRCNN.ROI_XFORM_METHOD=\\'RoIAlign\\'__C.KRCNN.ROI_XFORM_RESOLUTION=7__C.KRCNN.ROI_XFORM_SAMPLING_RATIO=0#Minimumnumberoflabeledkeypointsthatmustexistinaminibatch(otherwise#theminibatchisdiscarded)__C.KRCNN.MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH=20#Wheninferingthekeypointlocationsfromtheheatmap,don\\'tscaletheheatmap#belowthisminimumsize__C.KRCNN.INFERENCE_MIN_SIZE=0#Multi-tasklossweighttouseforkeypoints#Recommendedvalues:#-use1.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisTrue#-use4.0ifKRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTSisFalse__C.KRCNN.LOSS_WEIGHT=1.0#NormalizebythetotalnumberofvisiblekeypointsintheminibatchifTrue.#Otherwise,normalizebythetotalnumberofkeypointsthatcouldeverexist#intheminibatch.Seecommentsinmodeling.model_builder.add_keypoint_losses#fordetaileddiscussion.__C.KRCNN.NORMALIZE_BY_VISIBLE_KEYPOINTS=True#----------------------------------------------------------------------------##R-FCNoptions#----------------------------------------------------------------------------#__C.RFCN=AttrDict()#Position-sensitiveRoIpoolingoutputgridsize(heightandwidth)__C.RFCN.PS_GRID_SIZE=3#----------------------------------------------------------------------------##ResNetsoptions(\"ResNets\"=ResNetandResNeXt)#----------------------------------------------------------------------------#__C.RESNETS=AttrDict()#Numberofgroupstouse;1==>ResNet;>1==>ResNeXt__C.RESNETS.NUM_GROUPS=1#Baselinewidthofeachgroup__C.RESNETS.WIDTH_PER_GROUP=64#Placethestride2convonthe1x1filter#UseTrueonlyfortheoriginalMSRAResNet;useFalseforC2andTorchmodels__C.RESNETS.STRIDE_1X1=True#Residualtransformationfunction__C.RESNETS.TRANS_FUNC=\\'bottleneck_transformation\\'#ResNet\\'sstemfunction(conv1andpool1)__C.RESNETS.STEM_FUNC=\\'basic_bn_stem\\'#ResNet\\'sshortcutfunction__C.RESNETS.SHORTCUT_FUNC=\\'basic_bn_shortcut\\'#Applydilationinstage\"res5\"__C.RESNETS.RES5_DILATION=1#----------------------------------------------------------------------------##GroupNormoptions#----------------------------------------------------------------------------#__C.GROUP_NORM=AttrDict()#NumberofdimensionspergroupinGroupNorm(-1ifusingNUM_GROUPS)__C.GROUP_NORM.DIM_PER_GP=-1#NumberofgroupsinGroupNorm(-1ifusingDIM_PER_GP)__C.GROUP_NORM.NUM_GROUPS=32#GroupNorm\\'ssmallconstantinthedenominator__C.GROUP_NORM.EPSILON=1e-5#----------------------------------------------------------------------------##Miscoptions#----------------------------------------------------------------------------##NumberofGPUstouse(appliestobothtrainingandtesting)__C.NUM_GPUS=1#UseNCCLforallreduce,otherwiseusemuji#Warning:ifsettoTrue,youmayexperiencedeadlocks__C.USE_NCCL=False#Themappingfromimagecoordinatestofeaturemapcoordinatesmightcause#someboxesthataredistinctinimagespacetobecomeidenticalinfeature#coordinates.IfDEDUP_BOXES>0,thenDEDUP_BOXESisusedasthescalefactor#foridentifyingduplicateboxes.#1/16iscorrectfor{Alex,Caffe}Net,VGG_CNN_M_1024,andVGG16__C.DEDUP_BOXES=1/16.#Clipboundingboxtransformationpredictionstopreventnp.expfrom#overflowing#Heuristicchoicebasedonthatwouldscalea16pixelanchorupto1000pixels__C.BBOX_XFORM_CLIP=np.log(1000./16.)#Pixelmeanvalues(BGRorder)asa(1,1,3)array#Weusethesamepixelmeanforallnetworkseventhoughit\\'snotexactlywhat#theyweretrainedwith#\"Fun\"fact:thehistoryofwherethesevaluescomesfromislost__C.PIXEL_MEANS=np.array([[[102.9801,115.9465,122.7717]]])#Forreproducibility...butnotreallybecausemodernfastGPUlibrariesuse#non-deterministicopimplementations__C.RNG_SEED=3#Asmallnumberthat\\'susedmanytimes__C.EPS=1e-14#Rootdirectoryofproject__C.ROOT_DIR=os.getcwd()#Outputbasedir__C.OUTPUT_DIR=\\'/tmp\\'#Name(orpathto)thematlabexecutable__C.MATLAB=\\'matlab\\'#Reducememoryusagewithmemongergradientblobsharing__C.MEMONGER=True#Futherreducememorybyallowingforwardpassactivationstobesharedwhen#possible.Notethatthiswillcauseactivationblobinspection(values,#shapes,etc.)tobemeaninglesswhenactivationblobsarereused.__C.MEMONGER_SHARE_ACTIVATIONS=False#Dumpdetectionvisualizations__C.VIS=False#Scorethresholdforvisualization__C.VIS_TH=0.9#Expectedresultsshouldtaketheformofalistofexpectations,each#specifiedbyfourelements(dataset,task,metric,expectedvalue).For#example:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387]]__C.EXPECTED_RESULTS=[]#AbsoluteandrelativetolerancetousewhencomparingtoEXPECTED_RESULTS__C.EXPECTED_RESULTS_RTOL=0.1__C.EXPECTED_RESULTS_ATOL=0.005#Whentheexpectedvaluespecifiesameanandstandarddeviation,wecheck#thattheactualvalueiswithinmean+/-SIGMA_TOL*std__C.EXPECTED_RESULTS_SIGMA_TOL=4#SettosendemailincaseofanEXPECTED_RESULTSfailure__C.EXPECTED_RESULTS_EMAIL=\\'\\'#ModelsandproposalsreferredtobyURLaredownloadedtoalocalcache#specifiedbyDOWNLOAD_CACHE__C.DOWNLOAD_CACHE=\\'/tmp/detectron-download-cache\\'#----------------------------------------------------------------------------##Clusteroptions#----------------------------------------------------------------------------#__C.CLUSTER=AttrDict()#Flagtoindicateifthecodeisrunninginaclusterenvironment__C.CLUSTER.ON_CLUSTER=False#----------------------------------------------------------------------------##Deprecatedoptions#Ifanoptionisremovedfromthecodeandyoudon\\'twanttobreakexisting#yamlconfigs,youcanaddthefullconfigkeyasastringtothesetbelow.#----------------------------------------------------------------------------#_DEPRECATED_KEYS=set({\\'FINAL_MSG\\',\\'MODEL.DILATION\\',\\'ROOT_GPU_ID\\',\\'RPN.ON\\',\\'TRAIN.BBOX_NORMALIZE_TARGETS_PRECOMPUTED\\',\\'TRAIN.DROPOUT\\',\\'USE_GPU_NMS\\',\\'TEST.NUM_TEST_IMAGES\\',})#----------------------------------------------------------------------------##Renamedoptions#Ifyourenameaconfigoption,recordthemappingfromtheoldnametothenew#nameinthedictionarybelow.Optionally,ifthetypealsochanged,youcan#makethevalueatuplethatspecifiesfirsttherenamedkeyandthen#instructionsforhowtoedittheconfigfile.#----------------------------------------------------------------------------#_RENAMED_KEYS={\\'EXAMPLE.RENAMED.KEY\\':\\'EXAMPLE.KEY\\',#Dummyexampletofollow\\'MODEL.PS_GRID_SIZE\\':\\'RFCN.PS_GRID_SIZE\\',\\'MODEL.ROI_HEAD\\':\\'FAST_RCNN.ROI_BOX_HEAD\\',\\'MRCNN.MASK_HEAD_NAME\\':\\'MRCNN.ROI_MASK_HEAD\\',\\'TRAIN.DATASET\\':(\\'TRAIN.DATASETS\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'coco_2014_train\\'->(\\'coco_2014_train\\',)or\"+\"\\'coco_2014_train:coco_2014_valminusminival\\'->\"+\"(\\'coco_2014_train\\',\\'coco_2014_valminusminival\\')\"),\\'TRAIN.PROPOSAL_FILE\\':(\\'TRAIN.PROPOSAL_FILES\\',\"Alsoconverttoatuple,e.g.,\"+\"\\'path/to/file\\'->(\\'path/to/file\\',)or\"+\"\\'path/to/file1:path/to/file2\\'->\"+\"(\\'path/to/file1\\',\\'path/to/file2\\')\"),\\'TEST.SCALES\\':(\\'TEST.SCALE\\',\"Alsoconvertfromatuple,e.g.(600,),\"+\"toainteger,e.g.600.\"),\\'TEST.DATASET\\':(\\'TEST.DATASETS\\',\"Alsoconvertfromastring,e.g\\'coco_2014_minival\\',\"+\"toatuple,e.g.(\\'coco_2014_minival\\',).\"),\\'TEST.PROPOSAL_FILE\\':(\\'TEST.PROPOSAL_FILES\\',\"Alsoconvertfromastring,e.g.\\'/path/to/props.pkl\\',\"+\"toatuple,e.g.(\\'/path/to/props.pkl\\',).\"),}#----------------------------------------------------------------------------##Renamedmodules#Ifamodulecontainingadatastructureusedintheconfig(e.g.AttrDict)#isrenamed/movedandyoudon\\'twanttobreakloadingofexistingyamlconfigs#(e.g.fromweightsfiles)youcanspecifytherenamedmodulebelow.#----------------------------------------------------------------------------#_RENAMED_MODULES={\\'utils.collections\\':\\'detectron.utils.collections\\',}defassert_and_infer_cfg(cache_urls=True,make_immutable=True):\"\"\"Callthisfunctioninyourscriptafteryouhavefinishedsettingallcfgvaluesthatarenecessary(e.g.,mergingaconfigfromafile,mergingcommandlineconfigoptions,etc.).Bydefault,thisfunctionwillalsomarktheglobalcfgasimmutabletopreventchangingtheglobalcfgsettingsduringscriptexecution(whichcanleadtohardtodebugerrorsorcodethat\\'shardertounderstandthanisnecessary).\"\"\"if__C.MODEL.RPN_ONLYor__C.MODEL.FASTER_RCNN:__C.RPN.RPN_ON=Trueif__C.RPN.RPN_ONor__C.RETINANET.RETINANET_ON:__C.TEST.PRECOMPUTED_PROPOSALS=Falseifcache_urls:cache_cfg_urls()ifmake_immutable:cfg.immutable(True)defcache_cfg_urls():\"\"\"DownloadURLsintheconfig,cachethemlocally,andrewritecfgtomakeuseofthelocallycachedfile.\"\"\"__C.TRAIN.WEIGHTS=cache_url(__C.TRAIN.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TEST.WEIGHTS=cache_url(__C.TEST.WEIGHTS,__C.DOWNLOAD_CACHE)__C.TRAIN.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TRAIN.PROPOSAL_FILES)__C.TEST.PROPOSAL_FILES=tuple(cache_url(f,__C.DOWNLOAD_CACHE)forfin__C.TEST.PROPOSAL_FILES)defget_output_dir(datasets,training=True):\"\"\"Gettheoutputdirectorydeterminedbythecurrentglobalconfig.\"\"\"assertisinstance(datasets,tuple([tuple,list]+list(six.string_types))),\\\\\\'datasetsargumentmustbeoftypetuple,listorstring\\'is_string=isinstance(datasets,six.string_types)dataset_name=datasetsifis_stringelse\\':\\'.join(datasets)tag=\\'train\\'iftrainingelse\\'test\\'#////outdir=osp.join(__C.OUTPUT_DIR,tag,dataset_name,__C.MODEL.TYPE)ifnotosp.exists(outdir):os.makedirs(outdir)returnoutdirdefload_cfg(cfg_to_load):\"\"\"Wrapperaroundyaml.loadusedformaintainingbackwardcompatibility\"\"\"file_types=[file,io.IOBase]ifsix.PY2else[io.IOBase]#noqafalsepositiveexpected_types=tuple(file_types+list(six.string_types))assertisinstance(cfg_to_load,expected_types),\\\\\\'Expectedoneof{},got{}\\'.format(expected_types,type(cfg_to_load))ifisinstance(cfg_to_load,tuple(file_types)):cfg_to_load=\\'\\'.join(cfg_to_load.readlines())forold_module,new_moduleiniteritems(_RENAMED_MODULES):#yamlobjectencoding:!!python/object/new:.old_module,new_module=\\'new:\\'+old_module,\\'new:\\'+new_modulecfg_to_load=cfg_to_load.replace(old_module,new_module)#Importinlineduetoacirculardependencybetweenenv.pyandconfig.pyimportdetectron.utils.envasenvureturnenvu.yaml_load(cfg_to_load)defmerge_cfg_from_file(cfg_filename):\"\"\"Loadayamlconfigfileandmergeitintotheglobalconfig.\"\"\"withopen(cfg_filename,\\'r\\')asf:yaml_cfg=AttrDict(load_cfg(f))_merge_a_into_b(yaml_cfg,__C)defmerge_cfg_from_cfg(cfg_other):\"\"\"Merge`cfg_other`intotheglobalconfig.\"\"\"_merge_a_into_b(cfg_other,__C)defmerge_cfg_from_list(cfg_list):\"\"\"Mergeconfigkeys,valuesinalist(e.g.,fromcommandline)intotheglobalconfig.Forexample,`cfg_list=[\\'TEST.NMS\\',0.5]`.\"\"\"assertlen(cfg_list)%2==0forfull_key,vinzip(cfg_list[0::2],cfg_list[1::2]):if_key_is_deprecated(full_key):continueif_key_is_renamed(full_key):_raise_key_rename_error(full_key)key_list=full_key.split(\\'.\\')d=__Cforsubkeyinkey_list[:-1]:assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)d=d[subkey]subkey=key_list[-1]assertsubkeyind,\\'Non-existentkey:{}\\'.format(full_key)value=_decode_cfg_value(v)value=_check_and_coerce_cfg_value_type(value,d[subkey],subkey,full_key)d[subkey]=valuedef_merge_a_into_b(a,b,stack=None):\"\"\"Mergeconfigdictionaryaintoconfigdictionaryb,clobberingtheoptionsinbwhenevertheyarealsospecifiedina.\"\"\"assertisinstance(a,AttrDict),\\\\\\'`a`(curtype{})mustbeaninstanceof{}\\'.format(type(a),AttrDict)assertisinstance(b,AttrDict),\\\\\\'`b`(curtype{})mustbeaninstanceof{}\\'.format(type(b),AttrDict)fork,v_ina.items():full_key=\\'.\\'.join(stack)+\\'.\\'+kifstackisnotNoneelsek#amustspecifykeysthatareinbifknotinb:if_key_is_deprecated(full_key):continueelif_key_is_renamed(full_key):_raise_key_rename_error(full_key)else:raiseKeyError(\\'Non-existentconfigkey:{}\\'.format(full_key))v=copy.deepcopy(v_)v=_decode_cfg_value(v)v=_check_and_coerce_cfg_value_type(v,b[k],k,full_key)#Recursivelymergedictsifisinstance(v,AttrDict):try:stack_push=[k]ifstackisNoneelsestack+[k]_merge_a_into_b(v,b[k],stack=stack_push)exceptBaseException:raiseelse:b[k]=vdef_key_is_deprecated(full_key):iffull_keyin_DEPRECATED_KEYS:logger.warn(\\'Deprecatedconfigkey(ignoring):{}\\'.format(full_key))returnTruereturnFalsedef_key_is_renamed(full_key):returnfull_keyin_RENAMED_KEYSdef_raise_key_rename_error(full_key):new_key=_RENAMED_KEYS[full_key]ifisinstance(new_key,tuple):msg=\\'Note:\\'+new_key[1]new_key=new_key[0]else:msg=\\'\\'raiseKeyError(\\'Key{}wasrenamedto{};pleaseupdateyourconfig.{}\\'.format(full_key,new_key,msg))def_decode_cfg_value(v):\"\"\"Decodesarawconfigvalue(e.g.,fromayamlconfigfilesorcommandlineargument)intoaPythonobject.\"\"\"#Configsparsedfromrawyamlwillcontaindictionarykeysthatneedtobe#convertedtoAttrDictobjectsifisinstance(v,dict):returnAttrDict(v)#Allremainingprocessingisonlyappliedtostringsifnotisinstance(v,six.string_types):returnv#Trytointerpret`v`asa:#string,number,tuple,list,dict,boolean,orNonetry:v=literal_eval(v)#Thefollowingtwoexceptsallowvtopassthroughwhenitrepresentsa#string.##Longerexplanation:#Thetypeofvisalwaysastring(beforecallingliteral_eval),but#sometimesit*represents*astringandothertimesadatastructure,like#alist.Inthecasethatvrepresentsastring,whatwegotbackfromthe#yamlparseris\\'foo\\'*withoutquotes*(so,not\\'\"foo\"\\').literal_evalis#okwith\\'\"foo\"\\',butwillraiseaValueErrorifgiven\\'foo\\'.Inother#cases,likepaths(v=\\'foo/bar\\'andnotv=\\'\"foo/bar\"\\'),literal_eval#willraiseaSyntaxError.exceptValueError:passexceptSyntaxError:passreturnvdef_check_and_coerce_cfg_value_type(value_a,value_b,key,full_key):\"\"\"Checksthat`value_a`,whichisintendedtoreplace`value_b`isoftherighttype.Thetypeiscorrectifitmatchesexactlyorisoneofafewcasesinwhichthetypecanbeeasilycoerced.\"\"\"#Thetypesmustmatch(withsomeexceptions)type_b=type(value_b)type_a=type(value_a)iftype_aistype_b:returnvalue_a#Exceptions:numpyarrays,strings,tuplelistifisinstance(value_b,np.ndarray):value_a=np.array(value_a,dtype=value_b.dtype)elifisinstance(value_b,six.string_types):value_a=str(value_a)elifisinstance(value_a,tuple)andisinstance(value_b,list):value_a=list(value_a)elifisinstance(value_a,list)andisinstance(value_b,tuple):value_a=tuple(value_a)else:raiseValueError(\\'Typemismatch({}vs.{})withvalues({}vs.{})forconfig\\'\\'key:{}\\'.format(type_b,type_a,value_b,value_a,full_key))returnvalue_a#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"InferencefunctionalityformostDetectronmodels.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportcv2importloggingimportnumpyasnpfromcaffe2.pythonimportcorefromcaffe2.pythonimportworkspaceimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.core.test_retinanetastest_retinanetimportdetectron.modeling.FPNasfpnimportdetectron.utils.blobasblob_utilsimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.imageasimage_utilsimportdetectron.utils.keypointsaskeypoint_utilslogger=logging.getLogger(__name__)defim_detect_all(model,im,box_proposals,timers=None):iftimersisNone:timers=defaultdict(Timer)#HandleRetinaNettestingseparatelyfornowifcfg.RETINANET.RETINANET_ON:cls_boxes=test_retinanet.im_detect_bbox(model,im,timers)returncls_boxes,None,Nonetimers[\\'im_detect_bbox\\'].tic()ifcfg.TEST.BBOX_AUG.ENABLED:scores,boxes,im_scale=im_detect_bbox_aug(model,im,box_proposals)else:scores,boxes,im_scale=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)timers[\\'im_detect_bbox\\'].toc()#scoreandboxesarefromthewholeimageafterscorethresholdingandnms#(theyarenotseparatedbyclass)#cls_boxesboxesandscoresareseparatedbyclassandintheformatused#forevaluatingresultstimers[\\'misc_bbox\\'].tic()scores,boxes,cls_boxes=box_results_with_nms_and_limit(scores,boxes)timers[\\'misc_bbox\\'].toc()ifcfg.MODEL.MASK_ONandboxes.shape[0]>0:timers[\\'im_detect_mask\\'].tic()ifcfg.TEST.MASK_AUG.ENABLED:masks=im_detect_mask_aug(model,im,boxes)else:masks=im_detect_mask(model,im_scale,boxes)timers[\\'im_detect_mask\\'].toc()timers[\\'misc_mask\\'].tic()cls_segms=segm_results(cls_boxes,masks,boxes,im.shape[0],im.shape[1])timers[\\'misc_mask\\'].toc()else:cls_segms=Noneifcfg.MODEL.KEYPOINTS_ONandboxes.shape[0]>0:timers[\\'im_detect_keypoints\\'].tic()ifcfg.TEST.KPS_AUG.ENABLED:heatmaps=im_detect_keypoints_aug(model,im,boxes)else:heatmaps=im_detect_keypoints(model,im_scale,boxes)timers[\\'im_detect_keypoints\\'].toc()timers[\\'misc_keypoints\\'].tic()cls_keyps=keypoint_results(cls_boxes,heatmaps,boxes)timers[\\'misc_keypoints\\'].toc()else:cls_keyps=Nonereturncls_boxes,cls_segms,cls_keypsdefim_conv_body_only(model,im,target_scale,target_max_size):\"\"\"Runs`model.conv_body_net`onthegivenimage`im`.\"\"\"im_blob,im_scale,_im_info=blob_utils.get_image_blob(im,target_scale,target_max_size)workspace.FeedBlob(core.ScopedName(\\'data\\'),im_blob)workspace.RunNet(model.conv_body_net.Proto().name)returnim_scaledefim_detect_bbox(model,im,target_scale,target_max_size,boxes=None):\"\"\"Boundingboxobjectdetectionforanimagewithgivenboxproposals.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):colorimagetotest(inBGRorder)boxes(ndarray):Rx4arrayofobjectproposalsin0-indexed[x1,y1,x2,y2]format,orNoneifusingRPNReturns:scores(ndarray):RxKarrayofobjectclassscoresforKclasses(Kincludesbackgroundasobjectcategory0)boxes(ndarray):Rx4*Karrayofpredictedboundingboxesim_scales(list):listofimagescalesusedintheinputblob(asreturnedby_get_blobsandforusewithim_detect_mask,etc.)\"\"\"inputs,im_scale=_get_blobs(im,boxes,target_scale,target_max_size)#WhenmappingfromimageROIstofeaturemapROIs,there\\'ssomealiasing#(somedistinctimageROIsgetmappedtothesamefeatureROI).#Here,weidentifyduplicatefeatureROIs,soweonlycomputefeatures#ontheuniquesubset.ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:v=np.array([1,1e3,1e6,1e9,1e12])hashes=np.round(inputs[\\'rois\\']*cfg.DEDUP_BOXES).dot(v)_,index,inv_index=np.unique(hashes,return_index=True,return_inverse=True)inputs[\\'rois\\']=inputs[\\'rois\\'][index,:]boxes=boxes[index,:]#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROISandnotcfg.MODEL.FASTER_RCNN:_add_multilevel_rois_for_test(inputs,\\'rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.net.Proto().name)#Readoutblobsifcfg.MODEL.FASTER_RCNN:rois=workspace.FetchBlob(core.ScopedName(\\'rois\\'))#unscalebacktorawimagespaceboxes=rois[:,1:5]/im_scale#Softmaxclassprobabilitiesscores=workspace.FetchBlob(core.ScopedName(\\'cls_prob\\')).squeeze()#Incasethereis1proposalscores=scores.reshape([-1,scores.shape[-1]])ifcfg.TEST.BBOX_REG:#Applybounding-boxregressiondeltasbox_deltas=workspace.FetchBlob(core.ScopedName(\\'bbox_pred\\')).squeeze()#Incasethereis1proposalbox_deltas=box_deltas.reshape([-1,box_deltas.shape[-1]])ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:#Removepredictionsforbgclass(compatwithMSRAcode)box_deltas=box_deltas[:,-4:]pred_boxes=box_utils.bbox_transform(boxes,box_deltas,cfg.MODEL.BBOX_REG_WEIGHTS)pred_boxes=box_utils.clip_tiled_boxes(pred_boxes,im.shape)ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REG:pred_boxes=np.tile(pred_boxes,(1,scores.shape[1]))else:#Simplyrepeattheboxes,onceforeachclasspred_boxes=np.tile(boxes,(1,scores.shape[1]))ifcfg.DEDUP_BOXES>0andnotcfg.MODEL.FASTER_RCNN:#Mapscoresandpredictionsbacktotheoriginalsetofboxesscores=scores[inv_index,:]pred_boxes=pred_boxes[inv_index,:]returnscores,pred_boxes,im_scaledefim_detect_bbox_aug(model,im,box_proposals=None):\"\"\"Performsbboxdetectionwithtest-timeaugmentations.Functionsignatureisthesameasforim_detect_bbox.\"\"\"assertnotcfg.TEST.BBOX_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'assertnotcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\',\\\\\\'Coordheuristicmustbeunionwheneverscoreheuristicisunion\\'assertnotcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\'or\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'Scoreheuristicmustbeunionwhenevercoordheuristicisunion\\'assertnotcfg.MODEL.FASTER_RCNNor\\\\cfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\',\\\\\\'UnionheuristicmustbeusedtocombineFasterRCNNpredictions\\'#Collectdetectionscomputedunderdifferenttransformationsscores_ts=[]boxes_ts=[]defadd_preds_t(scores_t,boxes_t):scores_ts.append(scores_t)boxes_ts.append(boxes_t)#Performdetectiononthehorizontallyflippedimageifcfg.TEST.BBOX_AUG.H_FLIP:scores_hf,boxes_hf,_=im_detect_bbox_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals)add_preds_t(scores_hf,boxes_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.BBOX_AUG.SCALES:max_size=cfg.TEST.BBOX_AUG.MAX_SIZEscores_scl,boxes_scl=im_detect_bbox_scale(model,im,scale,max_size,box_proposals)add_preds_t(scores_scl,boxes_scl)ifcfg.TEST.BBOX_AUG.SCALE_H_FLIP:scores_scl_hf,boxes_scl_hf=im_detect_bbox_scale(model,im,scale,max_size,box_proposals,hflip=True)add_preds_t(scores_scl_hf,boxes_scl_hf)#Performdetectionatdifferentaspectratiosforaspect_ratioincfg.TEST.BBOX_AUG.ASPECT_RATIOS:scores_ar,boxes_ar=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals)add_preds_t(scores_ar,boxes_ar)ifcfg.TEST.BBOX_AUG.ASPECT_RATIO_H_FLIP:scores_ar_hf,boxes_ar_hf=im_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals,hflip=True)add_preds_t(scores_ar_hf,boxes_ar_hf)#Computedetectionsfortheoriginalimage(identitytransform)lastto#ensurethattheCaffe2workspaceispopulatedwithblobscorresponding#totheoriginalimageonreturn(postconditionofim_detect_bbox)scores_i,boxes_i,im_scale_i=im_detect_bbox(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals)add_preds_t(scores_i,boxes_i)#Combinethepredictedscoresifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'ID\\':scores_c=scores_ielifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'AVG\\':scores_c=np.mean(scores_ts,axis=0)elifcfg.TEST.BBOX_AUG.SCORE_HEUR==\\'UNION\\':scores_c=np.vstack(scores_ts)else:raiseNotImplementedError(\\'Scoreheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.SCORE_HEUR))#Combinethepredictedboxesifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'ID\\':boxes_c=boxes_ielifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'AVG\\':boxes_c=np.mean(boxes_ts,axis=0)elifcfg.TEST.BBOX_AUG.COORD_HEUR==\\'UNION\\':boxes_c=np.vstack(boxes_ts)else:raiseNotImplementedError(\\'Coordheur{}notsupported\\'.format(cfg.TEST.BBOX_AUG.COORD_HEUR))returnscores_c,boxes_c,im_scale_idefim_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=None):\"\"\"Performsbboxdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_bbox.\"\"\"#Computepredictionsontheflippedimageim_hf=im[:,::-1,:]im_width=im.shape[1]ifnotcfg.MODEL.FASTER_RCNN:box_proposals_hf=box_utils.flip_boxes(box_proposals,im_width)else:box_proposals_hf=Nonescores_hf,boxes_hf,im_scale=im_detect_bbox(model,im_hf,target_scale,target_max_size,boxes=box_proposals_hf)#Invertthedetectionscomputedontheflippedimageboxes_inv=box_utils.flip_boxes(boxes_hf,im_width)returnscores_hf,boxes_inv,im_scaledefim_detect_bbox_scale(model,im,target_scale,target_max_size,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenscale.Returnspredictionsintheoriginalimagespace.\"\"\"ifhflip:scores_scl,boxes_scl,_=im_detect_bbox_hflip(model,im,target_scale,target_max_size,box_proposals=box_proposals)else:scores_scl,boxes_scl,_=im_detect_bbox(model,im,target_scale,target_max_size,boxes=box_proposals)returnscores_scl,boxes_scldefim_detect_bbox_aspect_ratio(model,im,aspect_ratio,box_proposals=None,hflip=False):\"\"\"Computesbboxdetectionsatthegivenwidth-relativeaspectratio.Returnspredictionsintheoriginalimagespace.\"\"\"#Computepredictionsonthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)ifnotcfg.MODEL.FASTER_RCNN:box_proposals_ar=box_utils.aspect_ratio(box_proposals,aspect_ratio)else:box_proposals_ar=Noneifhflip:scores_ar,boxes_ar,_=im_detect_bbox_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,box_proposals=box_proposals_ar)else:scores_ar,boxes_ar,_=im_detect_bbox(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes=box_proposals_ar)#Invertthedetectedboxesboxes_inv=box_utils.aspect_ratio(boxes_ar,1.0/aspect_ratio)returnscores_ar,boxes_invdefim_detect_mask(model,im_scale,boxes):\"\"\"Inferinstancesegmentationmasks.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_masks(ndarray):RxKxMxMarrayofclassspecificsoftmasksoutputbythenetwork(mustbeprocessedbysegm_resultstoconvertintohardmasksintheoriginalimagecoordinatespace)\"\"\"M=cfg.MRCNN.RESOLUTIONifboxes.shape[0]==0:pred_masks=np.zeros((0,M,M),np.float32)returnpred_masksinputs={\\'mask_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'mask_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.mask_net.Proto().name)#Fetchmaskspred_masks=workspace.FetchBlob(core.ScopedName(\\'mask_fcn_probs\\')).squeeze()ifcfg.MRCNN.CLS_SPECIFIC_MASK:pred_masks=pred_masks.reshape([-1,cfg.MODEL.NUM_CLASSES,M,M])else:pred_masks=pred_masks.reshape([-1,1,M,M])returnpred_masksdefim_detect_mask_aug(model,im,boxes):\"\"\"Performsmaskdetectionwithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:masks(ndarray):RxKxMxMarrayofclassspecificsoftmasks\"\"\"assertnotcfg.TEST.MASK_AUG.SCALE_SIZE_DEP,\\\\\\'Sizedependentscalingnotimplemented\\'#Collectmaskscomputedunderdifferenttransformationsmasks_ts=[]#Computemasksfortheoriginalimage(identitytransform)im_scale_i=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_i=im_detect_mask(model,im_scale_i,boxes)masks_ts.append(masks_i)#Performmaskdetectiononthehorizontallyflippedimageifcfg.TEST.MASK_AUG.H_FLIP:masks_hf=im_detect_mask_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)masks_ts.append(masks_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.MASK_AUG.SCALES:max_size=cfg.TEST.MASK_AUG.MAX_SIZEmasks_scl=im_detect_mask_scale(model,im,scale,max_size,boxes)masks_ts.append(masks_scl)ifcfg.TEST.MASK_AUG.SCALE_H_FLIP:masks_scl_hf=im_detect_mask_scale(model,im,scale,max_size,boxes,hflip=True)masks_ts.append(masks_scl_hf)#Computemasksatdifferentaspectratiosforaspect_ratioincfg.TEST.MASK_AUG.ASPECT_RATIOS:masks_ar=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes)masks_ts.append(masks_ar)ifcfg.TEST.MASK_AUG.ASPECT_RATIO_H_FLIP:masks_ar_hf=im_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)masks_ts.append(masks_ar_hf)#Combinethepredictedsoftmasksifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_AVG\\':masks_c=np.mean(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'SOFT_MAX\\':masks_c=np.amax(masks_ts,axis=0)elifcfg.TEST.MASK_AUG.HEUR==\\'LOGIT_AVG\\':deflogit(y):return-1.0*np.log((1.0-y)/np.maximum(y,1e-20))logit_masks=[logit(y)foryinmasks_ts]logit_masks=np.mean(logit_masks,axis=0)masks_c=1.0/(1.0+np.exp(-logit_masks))else:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.MASK_AUG.HEUR))returnmasks_cdefim_detect_mask_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Performsmaskdetectiononthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_mask_aug.\"\"\"#Computethemasksfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)masks_hf=im_detect_mask(model,im_scale,boxes_hf)#Invertthepredictedsoftmasksmasks_inv=masks_hf[:,:,:,::-1]returnmasks_invdefim_detect_mask_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computesmasksatthegivenscale.\"\"\"ifhflip:masks_scl=im_detect_mask_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)masks_scl=im_detect_mask(model,im_scale,boxes)returnmasks_scldefim_detect_mask_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Computesmaskdetectionsatthegivenwidth-relativeaspectratio.\"\"\"#Performmaskdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:masks_ar=im_detect_mask_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)masks_ar=im_detect_mask(model,im_scale,boxes_ar)returnmasks_ardefim_detect_keypoints(model,im_scale,boxes):\"\"\"Inferinstancekeypointposes.Thisfunctionmustbecalledafterim_detect_bboxasitassumesthattheCaffe2workspaceisalreadypopulatedwiththenecessaryblobs.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim_scales(list):imageblobscalesasreturnedbyim_detect_bboxboxes(ndarray):Rx4arrayofboundingboxdetections(e.g.,asreturnedbyim_detect_bbox)Returns:pred_heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits(softmaxinputs)foreachoftheJkeypointtypesoutputbythenetwork(mustbeprocessedbykeypoint_resultstoconvertintopointpredictionsintheoriginalimagecoordinatespace)\"\"\"M=cfg.KRCNN.HEATMAP_SIZEifboxes.shape[0]==0:pred_heatmaps=np.zeros((0,cfg.KRCNN.NUM_KEYPOINTS,M,M),np.float32)returnpred_heatmapsinputs={\\'keypoint_rois\\':_get_rois_blob(boxes,im_scale)}#Addmulti-levelroisforFPNifcfg.FPN.MULTILEVEL_ROIS:_add_multilevel_rois_for_test(inputs,\\'keypoint_rois\\')fork,vininputs.items():workspace.FeedBlob(core.ScopedName(k),v)workspace.RunNet(model.keypoint_net.Proto().name)pred_heatmaps=workspace.FetchBlob(core.ScopedName(\\'kps_score\\')).squeeze()#Incaseof1ifpred_heatmaps.ndim==3:pred_heatmaps=np.expand_dims(pred_heatmaps,axis=0)returnpred_heatmapsdefim_detect_keypoints_aug(model,im,boxes):\"\"\"Computeskeypointpredictionswithtest-timeaugmentations.Arguments:model(DetectionModelHelper):thedetectionmodeltouseim(ndarray):BGRimagetotestboxes(ndarray):Rx4arrayofboundingboxesReturns:heatmaps(ndarray):RxJxMxMarrayofkeypointlocationlogits\"\"\"#Collectheatmapspredictedunderdifferenttransformationsheatmaps_ts=[]#Tagpredictionscomputedunderdownscalingandupscalingtransformationsds_ts=[]us_ts=[]defadd_heatmaps_t(heatmaps_t,ds_t=False,us_t=False):heatmaps_ts.append(heatmaps_t)ds_ts.append(ds_t)us_ts.append(us_t)#Computetheheatmapsfortheoriginalimage(identitytransform)im_scale=im_conv_body_only(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_i=im_detect_keypoints(model,im_scale,boxes)add_heatmaps_t(heatmaps_i)#Performkeypointsdetectiononthehorizontallyflippedimageifcfg.TEST.KPS_AUG.H_FLIP:heatmaps_hf=im_detect_keypoints_hflip(model,im,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_hf)#Computedetectionsatdifferentscalesforscaleincfg.TEST.KPS_AUG.SCALES:ds_scl=scale<cfg.TEST.SCALEus_scl=scale>cfg.TEST.SCALEheatmaps_scl=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes)add_heatmaps_t(heatmaps_scl,ds_scl,us_scl)ifcfg.TEST.KPS_AUG.SCALE_H_FLIP:heatmaps_scl_hf=im_detect_keypoints_scale(model,im,scale,cfg.TEST.KPS_AUG.MAX_SIZE,boxes,hflip=True)add_heatmaps_t(heatmaps_scl_hf,ds_scl,us_scl)#Computekeypointsatdifferentaspectratiosforaspect_ratioincfg.TEST.KPS_AUG.ASPECT_RATIOS:heatmaps_ar=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes)add_heatmaps_t(heatmaps_ar)ifcfg.TEST.KPS_AUG.ASPECT_RATIO_H_FLIP:heatmaps_ar_hf=im_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=True)add_heatmaps_t(heatmaps_ar_hf)#Selecttheheuristicfunctionforcombiningtheheatmapsifcfg.TEST.KPS_AUG.HEUR==\\'HM_AVG\\':np_f=np.meanelifcfg.TEST.KPS_AUG.HEUR==\\'HM_MAX\\':np_f=np.amaxelse:raiseNotImplementedError(\\'Heuristic{}notsupported\\'.format(cfg.TEST.KPS_AUG.HEUR))defheur_f(hms_ts):returnnp_f(hms_ts,axis=0)#Combinetheheatmapsifcfg.TEST.KPS_AUG.SCALE_SIZE_DEP:heatmaps_c=combine_heatmaps_size_dep(heatmaps_ts,ds_ts,us_ts,boxes,heur_f)else:heatmaps_c=heur_f(heatmaps_ts)returnheatmaps_cdefim_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes):\"\"\"Computeskeypointpredictionsonthehorizontallyflippedimage.Functionsignatureisthesameasforim_detect_keypoints_aug.\"\"\"#Computekeypointsfortheflippedimageim_hf=im[:,::-1,:]boxes_hf=box_utils.flip_boxes(boxes,im.shape[1])im_scale=im_conv_body_only(model,im_hf,target_scale,target_max_size)heatmaps_hf=im_detect_keypoints(model,im_scale,boxes_hf)#Invertthepredictedkeypointsheatmaps_inv=keypoint_utils.flip_heatmaps(heatmaps_hf)returnheatmaps_invdefim_detect_keypoints_scale(model,im,target_scale,target_max_size,boxes,hflip=False):\"\"\"Computeskeypointpredictionsatthegivenscale.\"\"\"ifhflip:heatmaps_scl=im_detect_keypoints_hflip(model,im,target_scale,target_max_size,boxes)else:im_scale=im_conv_body_only(model,im,target_scale,target_max_size)heatmaps_scl=im_detect_keypoints(model,im_scale,boxes)returnheatmaps_scldefim_detect_keypoints_aspect_ratio(model,im,aspect_ratio,boxes,hflip=False):\"\"\"Detectskeypointsatthegivenwidth-relativeaspectratio.\"\"\"#Performkeypointdetectiononthetransformedimageim_ar=image_utils.aspect_ratio_rel(im,aspect_ratio)boxes_ar=box_utils.aspect_ratio(boxes,aspect_ratio)ifhflip:heatmaps_ar=im_detect_keypoints_hflip(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE,boxes_ar)else:im_scale=im_conv_body_only(model,im_ar,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)heatmaps_ar=im_detect_keypoints(model,im_scale,boxes_ar)returnheatmaps_ardefcombine_heatmaps_size_dep(hms_ts,ds_ts,us_ts,boxes,heur_f):\"\"\"Combinesheatmapswhiletakingobjectsizesintoaccount.\"\"\"assertlen(hms_ts)==len(ds_ts)andlen(ds_ts)==len(us_ts),\\\\\\'Allsetsofhmsmustbetaggedwithdownscalingandupscalingflags\\'#Classifyobjectsintosmall+mediumandlargebasedontheirboxareasareas=box_utils.boxes_area(boxes)sm_objs=areas<cfg.TEST.KPS_AUG.AREA_THl_objs=areas>=cfg.TEST.KPS_AUG.AREA_TH#Combineheatmapscomputedunderdifferenttransformationsforeachobjecthms_c=np.zeros_like(hms_ts[0])foriinrange(hms_c.shape[0]):hms_to_combine=[]forhms_t,ds_t,us_tinzip(hms_ts,ds_ts,us_ts):#Discarddownscalingpredictionsforsmallandmediumobjectsifsm_objs[i]andds_t:continue#Discardupscalingpredictionsforlargeobjectsifl_objs[i]andus_t:continuehms_to_combine.append(hms_t[i])hms_c[i]=heur_f(hms_to_combine)returnhms_cdefbox_results_with_nms_and_limit(scores,boxes):\"\"\"Returnsbounding-boxdetectionresultsbythresholdingonscoresandapplyingnon-maximumsuppression(NMS).`boxes`hasshape(#detections,4*#classes),whereeachrowrepresentsalistofpredictedboundingboxesforeachoftheobjectclassesinthedataset(includingthebackgroundclass).Thedetectionsineachroworiginatefromthesameobjectproposal.`scores`hasshape(#detection,#classes),whereeachrowrepresentsalistofobjectdetectionconfidencescoresforeachoftheobjectclassesinthedataset(includingthebackgroundclass).`scores[i,j]``correspondstotheboxat`boxes[i,j*4:(j+1)*4]`.\"\"\"num_classes=cfg.MODEL.NUM_CLASSEScls_boxes=[[]for_inrange(num_classes)]#ApplythresholdondetectionprobabilitiesandapplyNMS#Skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):inds=np.where(scores[:,j]>cfg.TEST.SCORE_THRESH)[0]scores_j=scores[inds,j]boxes_j=boxes[inds,j*4:(j+1)*4]dets_j=np.hstack((boxes_j,scores_j[:,np.newaxis])).astype(np.float32,copy=False)ifcfg.TEST.SOFT_NMS.ENABLED:nms_dets,_=box_utils.soft_nms(dets_j,sigma=cfg.TEST.SOFT_NMS.SIGMA,overlap_thresh=cfg.TEST.NMS,score_thresh=0.0001,method=cfg.TEST.SOFT_NMS.METHOD)else:keep=box_utils.nms(dets_j,cfg.TEST.NMS)nms_dets=dets_j[keep,:]#Refinethepost-NMSboxesusingbounding-boxvotingifcfg.TEST.BBOX_VOTE.ENABLED:nms_dets=box_utils.box_voting(nms_dets,dets_j,cfg.TEST.BBOX_VOTE.VOTE_TH,scoring_method=cfg.TEST.BBOX_VOTE.SCORING_METHOD)cls_boxes[j]=nms_dets#Limittomax_per_imagedetections**overallclasses**ifcfg.TEST.DETECTIONS_PER_IM>0:image_scores=np.hstack([cls_boxes[j][:,-1]forjinrange(1,num_classes)])iflen(image_scores)>cfg.TEST.DETECTIONS_PER_IM:image_thresh=np.sort(image_scores)[-cfg.TEST.DETECTIONS_PER_IM]forjinrange(1,num_classes):keep=np.where(cls_boxes[j][:,-1]>=image_thresh)[0]cls_boxes[j]=cls_boxes[j][keep,:]im_results=np.vstack([cls_boxes[j]forjinrange(1,num_classes)])boxes=im_results[:,:-1]scores=im_results[:,-1]returnscores,boxes,cls_boxesdefsegm_results(cls_boxes,masks,ref_boxes,im_h,im_w):num_classes=cfg.MODEL.NUM_CLASSEScls_segms=[[]for_inrange(num_classes)]mask_ind=0#Toworkaroundanissuewithcv2.resize(itseemstoautomaticallypad#withrepeatedbordervalues),wemanuallyzero-padthemasksby1pixel#priortoresizingbacktotheoriginalimageresolution.Thisprevents#\"tophat\"artifacts.Wethereforeneedtoexpandthereferenceboxesbyan#appropriatefactor.M=cfg.MRCNN.RESOLUTIONscale=(M+2.0)/Mref_boxes=box_utils.expand_boxes(ref_boxes,scale)ref_boxes=ref_boxes.astype(np.int32)padded_mask=np.zeros((M+2,M+2),dtype=np.float32)#skipj=0,becauseit\\'sthebackgroundclassforjinrange(1,num_classes):segms=[]for_inrange(cls_boxes[j].shape[0]):ifcfg.MRCNN.CLS_SPECIFIC_MASK:padded_mask[1:-1,1:-1]=masks[mask_ind,j,:,:]else:padded_mask[1:-1,1:-1]=masks[mask_ind,0,:,:]ref_box=ref_boxes[mask_ind,:]w=ref_box[2]-ref_box[0]+1h=ref_box[3]-ref_box[1]+1w=np.maximum(w,1)h=np.maximum(h,1)mask=cv2.resize(padded_mask,(w,h))mask=np.array(mask>cfg.MRCNN.THRESH_BINARIZE,dtype=np.uint8)im_mask=np.zeros((im_h,im_w),dtype=np.uint8)x_0=max(ref_box[0],0)x_1=min(ref_box[2]+1,im_w)y_0=max(ref_box[1],0)y_1=min(ref_box[3]+1,im_h)im_mask[y_0:y_1,x_0:x_1]=mask[(y_0-ref_box[1]):(y_1-ref_box[1]),(x_0-ref_box[0]):(x_1-ref_box[0])]#GetRLEencodingusedbytheCOCOevaluationAPIrle=mask_util.encode(np.array(im_mask[:,:,np.newaxis],order=\\'F\\'))[0]segms.append(rle)mask_ind+=1cls_segms[j]=segmsassertmask_ind==masks.shape[0]returncls_segmsdefkeypoint_results(cls_boxes,pred_heatmaps,ref_boxes):num_classes=cfg.MODEL.NUM_CLASSEScls_keyps=[[]for_inrange(num_classes)]person_idx=keypoint_utils.get_person_class_index()xy_preds=keypoint_utils.heatmaps_to_keypoints(pred_heatmaps,ref_boxes)#NMSOKSifcfg.KRCNN.NMS_OKS:keep=keypoint_utils.nms_oks(xy_preds,ref_boxes,0.3)xy_preds=xy_preds[keep,:,:]ref_boxes=ref_boxes[keep,:]pred_heatmaps=pred_heatmaps[keep,:,:,:]cls_boxes[person_idx]=cls_boxes[person_idx][keep,:]kps=[xy_preds[i]foriinrange(xy_preds.shape[0])]cls_keyps[person_idx]=kpsreturncls_keypsdef_get_rois_blob(im_rois,im_scale):\"\"\"ConvertsRoIsintonetworkinputs.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesim_scale_factors(list):scalefactorsasreturnedby_get_image_blobReturns:blob(ndarray):Rx5matrixofRoIsintheimagepyramidwithcolumns[level,x1,y1,x2,y2]\"\"\"rois,levels=_project_im_rois(im_rois,im_scale)rois_blob=np.hstack((levels,rois))returnrois_blob.astype(np.float32,copy=False)def_project_im_rois(im_rois,scales):\"\"\"ProjectimageRoIsintotheimagepyramidbuiltby_get_image_blob.Arguments:im_rois(ndarray):Rx4matrixofRoIsinoriginalimagecoordinatesscales(list):scalefactorsasreturnedby_get_image_blobReturns:rois(ndarray):Rx4matrixofprojectedRoIcoordinateslevels(ndarray):imagepyramidlevelsusedbyeachprojectedRoI\"\"\"rois=im_rois.astype(float,copy=False)*scaleslevels=np.zeros((im_rois.shape[0],1),dtype=int)returnrois,levelsdef_add_multilevel_rois_for_test(blobs,name):\"\"\"DistributesasetofRoIsacrossFPNpyramidlevelsbycreatingnewlevelspecificRoIblobs.Arguments:blobs(dict):dictionaryofblobsname(str):akeyin\\'blobs\\'identifyingthesourceRoIblobReturns:[byref]blobs(dict):newkeysnamedby`name+\\'fpn\\'+level`areaddedtodicteachwithavaluethat\\'sanR_levelx5ndarrayofRoIs(see_get_rois_blobforformat)\"\"\"lvl_min=cfg.FPN.ROI_MIN_LEVELlvl_max=cfg.FPN.ROI_MAX_LEVELlvls=fpn.map_rois_to_fpn_levels(blobs[name][:,1:5],lvl_min,lvl_max)fpn.add_multilevel_roi_blobs(blobs,name,blobs[name],lvls,lvl_min,lvl_max)def_get_blobs(im,rois,target_scale,target_max_size):\"\"\"ConvertanimageandRoIswithinthatimageintonetworkinputs.\"\"\"blobs={}blobs[\\'data\\'],im_scale,blobs[\\'im_info\\']=\\\\blob_utils.get_image_blob(im,target_scale,target_max_size)ifroisisnotNone:blobs[\\'rois\\']=_get_rois_blob(rois,im_scale)returnblobs,im_scale#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#Fast/erR-CNN#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyBharathHariharan#--------------------------------------------------------\"\"\"PythonimplementationofthePASCALVOCdevkit\\'sAPevaluationcode.\"\"\"importloggingimportnumpyasnpimportosimportxml.etree.ElementTreeasETfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defparse_rec(filename):\"\"\"ParseaPASCALVOCxmlfile.\"\"\"tree=ET.parse(filename)objects=[]forobjintree.findall(\\'object\\'):obj_struct={}obj_struct[\\'name\\']=obj.find(\\'name\\').textobj_struct[\\'pose\\']=obj.find(\\'pose\\').textobj_struct[\\'truncated\\']=int(obj.find(\\'truncated\\').text)obj_struct[\\'difficult\\']=int(obj.find(\\'difficult\\').text)bbox=obj.find(\\'bndbox\\')obj_struct[\\'bbox\\']=[int(bbox.find(\\'xmin\\').text),int(bbox.find(\\'ymin\\').text),int(bbox.find(\\'xmax\\').text),int(bbox.find(\\'ymax\\').text)]objects.append(obj_struct)returnobjectsdefvoc_ap(rec,prec,use_07_metric=False):\"\"\"ComputeVOCAPgivenprecisionandrecall.Ifuse_07_metricistrue,usestheVOC0711-pointmethod(default:False).\"\"\"ifuse_07_metric:#11pointmetricap=0.fortinnp.arange(0.,1.1,0.1):ifnp.sum(rec>=t)==0:p=0else:p=np.max(prec[rec>=t])ap=ap+p/11.else:#correctAPcalculation#firstappendsentinelvaluesattheendmrec=np.concatenate(([0.],rec,[1.]))mpre=np.concatenate(([0.],prec,[0.]))#computetheprecisionenvelopeforiinrange(mpre.size-1,0,-1):mpre[i-1]=np.maximum(mpre[i-1],mpre[i])#tocalculateareaunderPRcurve,lookforpoints#whereXaxis(recall)changesvaluei=np.where(mrec[1:]!=mrec[:-1])[0]#andsum(\\\\Deltarecall)*precap=np.sum((mrec[i+1]-mrec[i])*mpre[i+1])returnapdefvoc_eval(detpath,annopath,imagesetfile,classname,cachedir,ovthresh=0.5,use_07_metric=False):\"\"\"rec,prec,ap=voc_eval(detpath,annopath,imagesetfile,classname,[ovthresh],[use_07_metric])ToplevelfunctionthatdoesthePASCALVOCevaluation.detpath:Pathtodetectionsdetpath.format(classname)shouldproducethedetectionresultsfile.annopath:Pathtoannotationsannopath.format(imagename)shouldbethexmlannotationsfile.imagesetfile:Textfilecontainingthelistofimages,oneimageperline.classname:Categoryname(duh)cachedir:Directoryforcachingtheannotations[ovthresh]:Overlapthreshold(default=0.5)[use_07_metric]:WhethertouseVOC07\\'s11pointAPcomputation(defaultFalse)\"\"\"#assumesdetectionsareindetpath.format(classname)#assumesannotationsareinannopath.format(imagename)#assumesimagesetfileisatextfilewitheachlineanimagename#cachedircachestheannotationsinapicklefile#firstloadgtifnotos.path.isdir(cachedir):os.mkdir(cachedir)imageset=os.path.splitext(os.path.basename(imagesetfile))[0]cachefile=os.path.join(cachedir,imageset+\\'_annots.pkl\\')#readlistofimageswithopen(imagesetfile,\\'r\\')asf:lines=f.readlines()imagenames=[x.strip()forxinlines]ifnotos.path.isfile(cachefile):#loadannotsrecs={}fori,imagenameinenumerate(imagenames):recs[imagename]=parse_rec(annopath.format(imagename))ifi%100==0:logger.info(\\'Readingannotationfor{:d}/{:d}\\'.format(i+1,len(imagenames)))#savelogger.info(\\'Savingcachedannotationsto{:s}\\'.format(cachefile))save_object(recs,cachefile)else:recs=load_object(cachefile)#extractgtobjectsforthisclassclass_recs={}npos=0forimagenameinimagenames:R=[objforobjinrecs[imagename]ifobj[\\'name\\']==classname]bbox=np.array([x[\\'bbox\\']forxinR])difficult=np.array([x[\\'difficult\\']forxinR]).astype(bool)det=[False]*len(R)npos=npos+sum(~difficult)class_recs[imagename]={\\'bbox\\':bbox,\\'difficult\\':difficult,\\'det\\':det}#readdetsdetfile=detpath.format(classname)withopen(detfile,\\'r\\')asf:lines=f.readlines()splitlines=[x.strip().split(\\'\\')forxinlines]image_ids=[x[0]forxinsplitlines]confidence=np.array([float(x[1])forxinsplitlines])BB=np.array([[float(z)forzinx[2:]]forxinsplitlines])#sortbyconfidencesorted_ind=np.argsort(-confidence)BB=BB[sorted_ind,:]image_ids=[image_ids[x]forxinsorted_ind]#godowndetsandmarkTPsandFPsnd=len(image_ids)tp=np.zeros(nd)fp=np.zeros(nd)fordinrange(nd):R=class_recs[image_ids[d]]bb=BB[d,:].astype(float)ovmax=-np.infBBGT=R[\\'bbox\\'].astype(float)ifBBGT.size>0:#computeoverlaps#intersectionixmin=np.maximum(BBGT[:,0],bb[0])iymin=np.maximum(BBGT[:,1],bb[1])ixmax=np.minimum(BBGT[:,2],bb[2])iymax=np.minimum(BBGT[:,3],bb[3])iw=np.maximum(ixmax-ixmin+1.,0.)ih=np.maximum(iymax-iymin+1.,0.)inters=iw*ih#unionuni=((bb[2]-bb[0]+1.)*(bb[3]-bb[1]+1.)+(BBGT[:,2]-BBGT[:,0]+1.)*(BBGT[:,3]-BBGT[:,1]+1.)-inters)overlaps=inters/uniovmax=np.max(overlaps)jmax=np.argmax(overlaps)ifovmax>ovthresh:ifnotR[\\'difficult\\'][jmax]:ifnotR[\\'det\\'][jmax]:tp[d]=1.R[\\'det\\'][jmax]=1else:fp[d]=1.else:fp[d]=1.#computeprecisionrecallfp=np.cumsum(fp)tp=np.cumsum(tp)rec=tp/float(npos)#avoiddividebyzeroincasethefirstdetectionmatchesadifficult#groundtruthprec=tp/np.maximum(tp+fp,np.finfo(np.float64).eps)ap=voc_ap(rec,prec,use_07_metric)returnrec,prec,ap#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforevaluatingresultscomputedforajsondataset.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportjsonimportloggingimportnumpyasnpimportosimportsiximportuuidfrompycocotools.cocoevalimportCOCOevalfromdetectron.core.configimportcfgfromdetectron.utils.ioimportsave_objectimportdetectron.utils.boxesasbox_utilslogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_segmentation_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Segmentation\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_segms_results_file(json_dataset,all_boxes,all_segms,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"segmentation\":[...],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_segms_results_one_category(json_dataset,all_boxes[cls_ind],all_segms[cls_ind],cat_id))logger.info(\\'Writingsegmentationresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:#\"counts\"isanarrayencodedbymask_utilasabyte-stream.Python3\\'s#jsonwriterwhich/alwaysproducesstrings/cannotserializeabytestream#unlessyoudecodeit.Thankfully,utf-8worksout(whichisalsowhat#thepycocotools/_mask.pyxdoes.ifsix.PY3:forrinresults:rle=r[\\'segmentation\\']if\\'counts\\'inrle:rle[\\'counts\\']=rle[\\'counts\\'].decode(\"utf8\")json.dump(results,fid)def_coco_segms_results_one_category(json_dataset,boxes,segms,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)assertlen(segms)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]rles=segms[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'segmentation\\':rles[k],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_segmentation_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'segm\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'segmentation_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldefevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'bbox_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_bbox_results_file(json_dataset,all_boxes,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_detection_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Bbox\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_bbox_results_file(json_dataset,all_boxes,res_file):#[{\"image_id\":42,#\"category_id\":18,#\"bbox\":[258.15,41.29,348.26,243.78],#\"score\":0.236},...]results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_boxes):breakcat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_bbox_results_one_category(json_dataset,all_boxes[cls_ind],cat_id))logger.info(\\'Writingbboxresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_bbox_results_one_category(json_dataset,boxes,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(boxes)==len(image_ids)fori,image_idinenumerate(image_ids):dets=boxes[i]ifisinstance(dets,list)andlen(dets)==0:continuedets=dets.astype(float)scores=dets[:,-1]xywh_dets=box_utils.xyxy_to_xywh(dets[:,0:4])xs=xywh_dets[:,0]ys=xywh_dets[:,1]ws=xywh_dets[:,2]hs=xywh_dets[:,3]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'bbox\\':[xs[k],ys[k],ws[k],hs[k]],\\'score\\':scores[k]}forkinrange(dets.shape[0])])returnresultsdef_do_detection_eval(json_dataset,res_file,output_dir):coco_dt=json_dataset.COCO.loadRes(str(res_file))coco_eval=COCOeval(json_dataset.COCO,coco_dt,\\'bbox\\')coco_eval.evaluate()coco_eval.accumulate()_log_detection_eval_metrics(json_dataset,coco_eval)eval_file=os.path.join(output_dir,\\'detection_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))returncoco_evaldef_log_detection_eval_metrics(json_dataset,coco_eval):def_get_thr_ind(coco_eval,thr):ind=np.where((coco_eval.params.iouThrs>thr-1e-5)&(coco_eval.params.iouThrs<thr+1e-5))[0][0]iou_thr=coco_eval.params.iouThrs[ind]assertnp.isclose(iou_thr,thr)returnindIoU_lo_thresh=0.5IoU_hi_thresh=0.95ind_lo=_get_thr_ind(coco_eval,IoU_lo_thresh)ind_hi=_get_thr_ind(coco_eval,IoU_hi_thresh)#precisionhasdims(iou,recall,cls,arearange,maxdets)#arearangeindex0:allarearanges#maxdetsindex2:100perimageprecision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,:,0,2]ap_default=np.mean(precision[precision>-1])logger.info(\\'~~~~Meanandper-categoryAP@IoU=[{:.2f},{:.2f}]~~~~\\'.format(IoU_lo_thresh,IoU_hi_thresh))logger.info(\\'{:.1f}\\'.format(100*ap_default))forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continue#minus1becauseof__background__precision=coco_eval.eval[\\'precision\\'][ind_lo:(ind_hi+1),:,cls_ind-1,0,2]ap=np.mean(precision[precision>-1])logger.info(\\'{:.1f}\\'.format(100*ap))logger.info(\\'~~~~Summarymetrics~~~~\\')coco_eval.summarize()defevaluate_box_proposals(json_dataset,roidb,thresholds=None,area=\\'all\\',l'],\n",
       " ['<|begin_of_text|>imit=None,class_specific=False):\"\"\"Evaluatedetectionproposalrecallmetrics.ThisfunctionisamuchfasteralternativetotheofficialCOCOAPIrecallevaluationcode.However,itproducesslightlydifferentresults.\"\"\"#Recordmaxoverlapvalueforeachgtbox#Returnvectorofoverlapvaluesareas={\\'all\\':0,\\'small\\':1,\\'medium\\':2,\\'large\\':3,\\'96-128\\':4,\\'128-256\\':5,\\'256-512\\':6,\\'512-inf\\':7}area_ranges=[[0**2,1e5**2],#all[0**2,32**2],#small[32**2,96**2],#medium[96**2,1e5**2],#large[96**2,128**2],#96-128[128**2,256**2],#128-256[256**2,512**2],#256-512[512**2,1e5**2]]#512-infassertareainareas,\\'Unknownarearange:{}\\'.format(area)area_range=area_ranges[areas[area]]gt_overlaps=np.zeros(0)gt_classes=np.zeros(0)num_pos=0forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_areas=entry[\\'seg_areas\\'][gt_inds]valid_gt_inds=np.where((gt_areas>=area_range[0])&(gt_areas<=area_range[1]))[0]gt_boxes=gt_boxes[valid_gt_inds,:]_gt_classes=entry[\"gt_classes\"][valid_gt_inds]assertgt_boxes.shape[0]==_gt_classes.shape[0]gt_classes=np.hstack((gt_classes,_gt_classes))num_pos+=len(valid_gt_inds)non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]boxes=entry[\\'boxes\\'][non_gt_inds,:]ifboxes.shape[0]==0:continueiflimitisnotNoneandboxes.shape[0]>limit:boxes=boxes[:limit,:]overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))_gt_overlaps=np.zeros((gt_boxes.shape[0]))forjinrange(min(boxes.shape[0],gt_boxes.shape[0])):#findwhichproposalboxmaximallycoverseachgtboxargmax_overlaps=overlaps.argmax(axis=0)#andgettheiouamountofcoverageforeachgtboxmax_overlaps=overlaps.max(axis=0)#findwhichgtboxis\\'best\\'covered(i.e.\\'best\\'=mostiou)gt_ind=max_overlaps.argmax()gt_ovr=max_overlaps.max()assertgt_ovr>=0#findtheproposalboxthatcoversthebestcoveredgtboxbox_ind=argmax_overlaps[gt_ind]#recordtheioucoverageofthisgtbox_gt_overlaps[j]=overlaps[box_ind,gt_ind]assert_gt_overlaps[j]==gt_ovr#marktheproposalboxandthegtboxasusedoverlaps[box_ind,:]=-1overlaps[:,gt_ind]=-1#appendrecordedioucoveragelevelgt_overlaps=np.hstack((gt_overlaps,_gt_overlaps))ifthresholdsisNone:step=0.05thresholds=np.arange(0.5,0.95+1e-5,step)ifnotclass_specific:gt_overlaps=np.sort(gt_overlaps)recalls=np.zeros_like(thresholds)#computerecallforeachiouthresholdfori,tinenumerate(thresholds):recalls[i]=(gt_overlaps>=t).sum()/float(num_pos)ar=recalls.mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}else:gt_classes_unique=np.unique(gt_classes)recalls=np.zeros((gt_classes_unique.shape[0],thresholds.shape[0]))#computerecallforeachcategoryandeachiouthresholdfori,category_idinenumerate(gt_classes_unique):inds=(gt_classes==category_id)num_pos_per_category=float(inds.sum())forj,threshinenumerate(thresholds):recalls[i][j]=(gt_overlaps[inds]>=thresh).sum()/num_pos_per_categoryar=recalls.mean(axis=1).mean()return{\\'ar\\':ar,\\'recalls\\':recalls,\\'thresholds\\':thresholds,\\'gt_overlaps\\':gt_overlaps,\\'num_pos\\':num_pos}defevaluate_keypoints(json_dataset,all_boxes,all_keypoints,output_dir,use_salt=True,cleanup=False):res_file=os.path.join(output_dir,\\'keypoints_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file)#Onlydoevaluationonnon-testsets(annotationsareundisclosedontest)ifjson_dataset.name.find(\\'test\\')==-1:coco_eval=_do_keypoint_eval(json_dataset,res_file,output_dir)else:logger.warning(\\'{}evalignoredasannotationsareundisclosedontest:{}ignored\\'.format(\"Keypoints\",json_dataset.name))coco_eval=None#Optionallycleanupresultsjsonfileifcleanup:os.remove(res_file)returncoco_evaldef_write_coco_keypoint_results_file(json_dataset,all_boxes,all_keypoints,res_file):results=[]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continueifcls_ind>=len(all_keypoints):breaklogger.info(\\'Collecting{}results({:d}/{:d})\\'.format(cls,cls_ind,len(all_keypoints)-1))cat_id=json_dataset.category_to_id_map[cls]results.extend(_coco_kp_results_one_category(json_dataset,all_boxes[cls_ind],all_keypoints[cls_ind],cat_id))logger.info(\\'Writingkeypointresultsjsonto:{}\\'.format(os.path.abspath(res_file)))withopen(res_file,\\'w\\')asfid:json.dump(results,fid)def_coco_kp_results_one_category(json_dataset,boxes,kps,cat_id):results=[]image_ids=json_dataset.COCO.getImgIds()image_ids.sort()assertlen(kps)==len(image_ids)assertlen(boxes)==len(image_ids)use_box_score=Falseifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'logit\\':#Thisisugly;seeutils.keypoints.heatmap_to_keypointsforthemagic#indexesscore_index=2elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'prob\\':score_index=3elifcfg.KRCNN.KEYPOINT_CONFIDENCE==\\'bbox\\':use_box_score=Trueelse:raiseValueError(\\'KRCNN.KEYPOINT_CONFIDENCEmustbe\"logit\",\"prob\",or\"bbox\"\\')fori,image_idinenumerate(image_ids):iflen(boxes[i])==0:continuekps_dets=kps[i]scores=boxes[i][:,-1].astype(float)iflen(kps_dets)==0:continueforjinrange(len(kps_dets)):xy=[]kps_score=0forkinrange(kps_dets[j].shape[1]):xy.append(float(kps_dets[j][0,k]))xy.append(float(kps_dets[j][1,k]))xy.append(1)ifnotuse_box_score:kps_score+=kps_dets[j][score_index,k]ifuse_box_score:kps_score=scores[j]else:kps_score/=kps_dets[j].shape[1]results.extend([{\\'image_id\\':image_id,\\'category_id\\':cat_id,\\'keypoints\\':xy,\\'score\\':kps_score}])returnresultsdef_do_keypoint_eval(json_dataset,res_file,output_dir):ann_type=\\'keypoints\\'imgIds=json_dataset.COCO.getImgIds()imgIds.sort()coco_dt=json_dataset.COCO.loadRes(res_file)coco_eval=COCOeval(json_dataset.COCO,coco_dt,ann_type)coco_eval.params.imgIds=imgIdscoco_eval.evaluate()coco_eval.accumulate()eval_file=os.path.join(output_dir,\\'keypoint_results.pkl\\')save_object(coco_eval,eval_file)logger.info(\\'Wrotejsonevalresultsto:{}\\'.format(eval_file))coco_eval.summarize()returncoco_eval#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Collectionofavailabledatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportos#Pathtodatadir_DATA_DIR=os.path.join(os.path.dirname(__file__),\\'data\\')#Requireddatasetentrykeys_IM_DIR=\\'image_directory\\'_ANN_FN=\\'annotation_file\\'#Optionaldatasetentrykeys_IM_PREFIX=\\'image_prefix\\'_DEVKIT_DIR=\\'devkit_directory\\'_RAW_DIR=\\'raw_dir\\'#Availabledatasets_DATASETS={\\'cityscapes_fine_instanceonly_seg_train\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_train.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_val\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',#usefilteredvalidationasthereisanissueconvertingcontours_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_filtered_gtFine_val.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'cityscapes_fine_instanceonly_seg_test\\':{_IM_DIR:_DATA_DIR+\\'/cityscapes/images\\',_ANN_FN:_DATA_DIR+\\'/cityscapes/annotations/instancesonly_gtFine_test.json\\',_RAW_DIR:_DATA_DIR+\\'/cityscapes/raw\\'},\\'coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_train2014.json\\'},\\'coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_val2014.json\\'},\\'coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_minival2014.json\\'},\\'coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/instances_valminusminival2014.json\\'},\\'coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'coco_2017_test\\':{#2017testuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_2017_test-dev\\':{#2017test-devuses2015testimages_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2017.json\\',_IM_PREFIX:\\'COCO_test2015_\\'},\\'coco_stuff_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_train.json\\'},\\'coco_stuff_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/coco_stuff_val.json\\'},\\'keypoints_coco_2014_train\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_train2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_train2014.json\\'},\\'keypoints_coco_2014_val\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_val2014.json\\'},\\'keypoints_coco_2014_minival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_minival2014.json\\'},\\'keypoints_coco_2014_valminusminival\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_val2014\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/person_keypoints_valminusminival2014.json\\'},\\'keypoints_coco_2015_test\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test2015.json\\'},\\'keypoints_coco_2015_test-dev\\':{_IM_DIR:_DATA_DIR+\\'/coco/coco_test2015\\',_ANN_FN:_DATA_DIR+\\'/coco/annotations/image_info_test-dev2015.json\\'},\\'voc_2007_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2007_test\\':{_IM_DIR:_DATA_DIR+\\'/VOC2007/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2007/annotations/voc_2007_test.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2007/VOCdevkit2007\\'},\\'voc_2012_train\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_train.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'},\\'voc_2012_val\\':{_IM_DIR:_DATA_DIR+\\'/VOC2012/JPEGImages\\',_ANN_FN:_DATA_DIR+\\'/VOC2012/annotations/voc_2012_val.json\\',_DEVKIT_DIR:_DATA_DIR+\\'/VOC2012/VOCdevkit2012\\'}}defdatasets():\"\"\"Retrievethelistofavailabledatasetnames.\"\"\"return_DATASETS.keys()defcontains(name):\"\"\"Determineifthedatasetisinthecatalog.\"\"\"returnnamein_DATASETS.keys()defget_im_dir(name):\"\"\"Retrievetheimagedirectoryforthedataset.\"\"\"return_DATASETS[name][_IM_DIR]defget_ann_fn(name):\"\"\"Retrievetheannotationfileforthedataset.\"\"\"return_DATASETS[name][_ANN_FN]defget_im_prefix(name):\"\"\"Retrievetheimageprefixforthedataset.\"\"\"return_DATASETS[name][_IM_PREFIX]if_IM_PREFIXin_DATASETS[name]else\\'\\'defget_devkit_dir(name):\"\"\"Retrievethedevkitdirforthedataset.\"\"\"return_DATASETS[name][_DEVKIT_DIR]defget_raw_dir(name):\"\"\"Retrievetherawdirforthedataset.\"\"\"return_DATASETS[name][_RAW_DIR]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"PASCALVOCdatasetevaluationinterface.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportloggingimportnumpyasnpimportosimportshutilimportuuidfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_devkit_dirfromdetectron.datasets.voc_evalimportvoc_evalfromdetectron.utils.ioimportsave_objectlogger=logging.getLogger(__name__)defevaluate_boxes(json_dataset,all_boxes,output_dir,use_salt=True,cleanup=True,use_matlab=False):salt=\\'_{}\\'.format(str(uuid.uuid4()))ifuse_saltelse\\'\\'filenames=_write_voc_results_files(json_dataset,all_boxes,salt)_do_python_eval(json_dataset,salt,output_dir)ifuse_matlab:_do_matlab_eval(json_dataset,salt,output_dir)ifcleanup:forfilenameinfilenames:shutil.copy(filename,output_dir)os.remove(filename)returnNonedef_write_voc_results_files(json_dataset,all_boxes,salt):filenames=[]image_set_path=voc_info(json_dataset)[\\'image_set_path\\']assertos.path.exists(image_set_path),\\\\\\'Imagesetpathdoesnotexist:{}\\'.format(image_set_path)withopen(image_set_path,\\'r\\')asf:image_index=[x.strip()forxinf.readlines()]#Sanitycheckthatorderofimagesinjsondatasetmatchesorderinthe#imagesetroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):index=os.path.splitext(os.path.split(entry[\\'image\\'])[1])[0]assertindex==image_index[i]forcls_ind,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuelogger.info(\\'WritingVOCresultsfor:{}\\'.format(cls))filename=_get_voc_results_file_template(json_dataset,salt).format(cls)filenames.append(filename)assertlen(all_boxes[cls_ind])==len(image_index)withopen(filename,\\'wt\\')asf:forim_ind,indexinenumerate(image_index):dets=all_boxes[cls_ind][im_ind]iftype(dets)==list:assertlen(dets)==0,\\\\\\'detsshouldbenumpy.ndarrayoremptylist\\'continue#theVOCdevkitexpects1-basedindicesforkinrange(dets.shape[0]):f.write(\\'{:s}{:.3f}{:.1f}{:.1f}{:.1f}{:.1f}\\\\n\\'.format(index,dets[k,-1],dets[k,0]+1,dets[k,1]+1,dets[k,2]+1,dets[k,3]+1))returnfilenamesdef_get_voc_results_file_template(json_dataset,salt):info=voc_info(json_dataset)year=info[\\'year\\']image_set=info[\\'image_set\\']devkit_path=info[\\'devkit_path\\']#VOCdevkit/results/VOC2007/Main/_det_test_aeroplane.txtfilename=\\'comp4\\'+salt+\\'_det_\\'+image_set+\\'_{:s}.txt\\'returnos.path.join(devkit_path,\\'results\\',\\'VOC\\'+year,\\'Main\\',filename)def_do_python_eval(json_dataset,salt,output_dir=\\'output\\'):info=voc_info(json_dataset)year=info[\\'year\\']anno_path=info[\\'anno_path\\']image_set_path=info[\\'image_set_path\\']devkit_path=info[\\'devkit_path\\']cachedir=os.path.join(devkit_path,\\'annotations_cache\\')aps=[]#ThePASCALVOCmetricchangedin2010use_07_metric=Trueifint(year)<2010elseFalselogger.info(\\'VOC07metric?\\'+(\\'Yes\\'ifuse_07_metricelse\\'No\\'))ifnotos.path.isdir(output_dir):os.mkdir(output_dir)for_,clsinenumerate(json_dataset.classes):ifcls==\\'__background__\\':continuefilename=_get_voc_results_file_template(json_dataset,salt).format(cls)rec,prec,ap=voc_eval(filename,anno_path,image_set_path,cls,cachedir,ovthresh=0.5,use_07_metric=use_07_metric)aps+=[ap]logger.info(\\'APfor{}={:.4f}\\'.format(cls,ap))res_file=os.path.join(output_dir,cls+\\'_pr.pkl\\')save_object({\\'rec\\':rec,\\'prec\\':prec,\\'ap\\':ap},res_file)logger.info(\\'MeanAP={:.4f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'Results:\\')forapinaps:logger.info(\\'{:.3f}\\'.format(ap))logger.info(\\'{:.3f}\\'.format(np.mean(aps)))logger.info(\\'~~~~~~~~\\')logger.info(\\'\\')logger.info(\\'----------------------------------------------------------\\')logger.info(\\'Resultscomputedwiththe**unofficial**Pythonevalcode.\\')logger.info(\\'ResultsshouldbeveryclosetotheofficialMATLABcode.\\')logger.info(\\'Use`./tools/reval.py--matlab...`foryourpaper.\\')logger.info(\\'--Thanks,TheManagement\\')logger.info(\\'----------------------------------------------------------\\')def_do_matlab_eval(json_dataset,salt,output_dir=\\'output\\'):importsubprocesslogger.info(\\'-----------------------------------------------------\\')logger.info(\\'ComputingresultswiththeofficialMATLABevalcode.\\')logger.info(\\'-----------------------------------------------------\\')info=voc_info(json_dataset)path=os.path.join(cfg.ROOT_DIR,\\'detectron\\',\\'datasets\\',\\'VOCdevkit-matlab-wrapper\\')cmd=\\'cd{}&&\\'.format(path)cmd+=\\'{:s}-nodisplay-nodesktop\\'.format(cfg.MATLAB)cmd+=\\'-r\"dbstopiferror;\\'cmd+=\\'voc_eval(\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\',\\\\\\'{:s}\\\\\\');quit;\"\\'\\\\.format(info[\\'devkit_path\\'],\\'comp4\\'+salt,info[\\'image_set\\'],output_dir)logger.info(\\'Running:\\\\n{}\\'.format(cmd))subprocess.call(cmd,shell=True)defvoc_info(json_dataset):year=json_dataset.name[4:8]image_set=json_dataset.name[9:]devkit_path=get_devkit_dir(json_dataset.name)assertos.path.exists(devkit_path),\\\\\\'Devkitdirectory{}notfound\\'.format(devkit_path)anno_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'Annotations\\',\\'{:s}.xml\\')image_set_path=os.path.join(devkit_path,\\'VOC\\'+year,\\'ImageSets\\',\\'Main\\',image_set+\\'.txt\\')returndict(year=year,image_set=image_set,devkit_path=devkit_path,anno_path=anno_path,image_set_path=image_set_path)#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################mappingcococategoriestocityscapes(ourconvertedjson)id#cityscapes#INFOroidb.py:220:1bicycle:7286#INFOroidb.py:220:2car:53684#INFOroidb.py:220:3person:35704#INFOroidb.py:220:4train:336#INFOroidb.py:220:5truck:964#INFOroidb.py:220:6motorcycle:1468#INFOroidb.py:220:7bus:758#INFOroidb.py:220:8rider:3504#coco(val5k)#INFOroidb.py:220:1person:21296#INFOroidb.py:220:2bicycle:628#INFOroidb.py:220:3car:3818#INFOroidb.py:220:4motorcycle:732#INFOroidb.py:220:5airplane:286<------irrelevant#INFOroidb.py:220:6bus:564#INFOroidb.py:220:7train:380#INFOroidb.py:220:8truck:828defcityscapes_to_coco(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(-1meansrandinit)}returnlookup[cityscapes_id]defcityscapes_to_coco_with_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:1,#person4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:1,#rider(\"person\",*riderhashumanright!*)}returnlookup[cityscapes_id]defcityscapes_to_coco_without_person_rider(cityscapes_id):lookup={0:0,#...background1:2,#bicycle2:3,#car3:-1,#person(ignore)4:7,#train5:8,#truck6:4,#motorcycle7:6,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]defcityscapes_to_coco_all_random(cityscapes_id):lookup={0:-1,#...background1:-1,#bicycle2:-1,#car3:-1,#person(ignore)4:-1,#train5:-1,#truck6:-1,#motorcycle7:-1,#bus8:-1,#rider(ignore)}returnlookup[cityscapes_id]#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Functionsforcommonroidbmanipulations.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfrompast.builtinsimportbasestringimportloggingimportnumpyasnpfromdetectron.core.configimportcfgfromdetectron.datasets.json_datasetimportJsonDatasetimportdetectron.utils.boxesasbox_utilsimportdetectron.utils.keypointsaskeypoint_utilsimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)defcombined_roidb_for_training(dataset_names,proposal_files):\"\"\"Loadandconcatenateroidbsforoneormoredatasets,alongwithoptionalobjectproposals.Theroidbentriesarethenpreparedforuseintraining,whichinvolvescachingcertaintypesofmetadataforeachroidbentry.\"\"\"defget_roidb(dataset_name,proposal_file):ds=JsonDataset(dataset_name)roidb=ds.get_roidb(gt=True,proposal_file=proposal_file,crowd_filter_thresh=cfg.TRAIN.CROWD_FILTER_THRESH)ifcfg.TRAIN.USE_FLIPPED:logger.info(\\'Appendinghorizontally-flippedtrainingexamples...\\')extend_with_flipped_entries(roidb,ds)logger.info(\\'Loadeddataset:{:s}\\'.format(ds.name))returnroidbifisinstance(dataset_names,basestring):dataset_names=(dataset_names,)ifisinstance(proposal_files,basestring):proposal_files=(proposal_files,)iflen(proposal_files)==0:proposal_files=(None,)*len(dataset_names)assertlen(dataset_names)==len(proposal_files)roidbs=[get_roidb(*args)forargsinzip(dataset_names,proposal_files)]roidb=roidbs[0]forrinroidbs[1:]:roidb.extend(r)roidb=filter_for_training(roidb)logger.info(\\'Computingbounding-boxregressiontargets...\\')add_bbox_regression_targets(roidb)logger.info(\\'done\\')_compute_and_log_stats(roidb)returnroidbdefextend_with_flipped_entries(roidb,dataset):\"\"\"Flipeachentryinthegivenroidbandreturnanewroidbthatistheconcatenationoftheoriginalroidbandtheflippedentries.\"Flipping\"anentrymeansthatthatimageandassociatedmetadata(e.g.,groundtruthboxesandobjectproposals)arehorizontallyflipped.\"\"\"flipped_roidb=[]forentryinroidb:width=entry[\\'width\\']boxes=entry[\\'boxes\\'].copy()oldx1=boxes[:,0].copy()oldx2=boxes[:,2].copy()boxes[:,0]=width-oldx2-1boxes[:,2]=width-oldx1-1assert(boxes[:,2]>=boxes[:,0]).all()flipped_entry={}dont_copy=(\\'boxes\\',\\'segms\\',\\'gt_keypoints\\',\\'flipped\\')fork,vinentry.items():ifknotindont_copy:flipped_entry[k]=vflipped_entry[\\'boxes\\']=boxesflipped_entry[\\'segms\\']=segm_utils.flip_segms(entry[\\'segms\\'],entry[\\'height\\'],entry[\\'width\\'])ifdataset.keypointsisnotNone:flipped_entry[\\'gt_keypoints\\']=keypoint_utils.flip_keypoints(dataset.keypoints,dataset.keypoint_flip_map,entry[\\'gt_keypoints\\'],entry[\\'width\\'])flipped_entry[\\'flipped\\']=Trueflipped_roidb.append(flipped_entry)roidb.extend(flipped_roidb)deffilter_for_training(roidb):\"\"\"RemoveroidbentriesthathavenousableRoIsbasedonconfigsettings.\"\"\"defis_valid(entry):#Validimageshave:#(1)AtleastoneforegroundRoIOR#(2)AtleastonebackgroundRoIoverlaps=entry[\\'max_overlaps\\']#findboxeswithsufficientoverlapfg_inds=np.where(overlaps>=cfg.TRAIN.FG_THRESH)[0]#SelectbackgroundRoIsasthosewithin[BG_THRESH_LO,BG_THRESH_HI)bg_inds=np.where((overlaps<cfg.TRAIN.BG_THRESH_HI)&(overlaps>=cfg.TRAIN.BG_THRESH_LO))[0]#imageisonlyvalidifsuchboxesexistvalid=len(fg_inds)>0orlen(bg_inds)>0ifcfg.MODEL.KEYPOINTS_ON:#Ifwe\\'retrainingforkeypoints,excludeimageswithnokeypointsvalid=validandentry[\\'has_visible_keypoints\\']returnvalidnum=len(roidb)filtered_roidb=[entryforentryinroidbifis_valid(entry)]num_after=len(filtered_roidb)logger.info(\\'Filtered{}roidbentries:{}->{}\\'.format(num-num_after,num,num_after))returnfiltered_roidbdefadd_bbox_regression_targets(roidb):\"\"\"Addinformationneededtotrainbounding-boxregressors.\"\"\"forentryinroidb:entry[\\'bbox_targets\\']=compute_bbox_regression_targets(entry)defcompute_bbox_regression_targets(entry):\"\"\"Computebounding-boxregressiontargetsforanimage.\"\"\"#Indicesofground-truthROIsrois=entry[\\'boxes\\']overlaps=entry[\\'max_overlaps\\']labels=entry[\\'max_classes\\']gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]#Targetshasformat(class,tx,ty,tw,th)targets=np.zeros((rois.shape[0],5),dtype=np.float32)iflen(gt_inds)==0:#Bailiftheimagehasnoground-truthROIsreturntargets#Indicesofexamplesforwhichwetrytomakepredictionsex_inds=np.where(overlaps>=cfg.TRAIN.BBOX_THRESH)[0]#GetIoUoverlapbetweeneachexROIandgtROIex_gt_overlaps=box_utils.bbox_overlaps(rois[ex_inds,:].astype(dtype=np.float32,copy=False),rois[gt_inds,:].astype(dtype=np.float32,copy=False))#FindwhichgtROIeachexROIhasmaxoverlapwith:#thiswillbetheexROI\\'sgttargetgt_assignment=ex_gt_overlaps.argmax(axis=1)gt_rois=rois[gt_inds[gt_assignment],:]ex_rois=rois[ex_inds,:]#Useclass\"1\"forallboxesifusingclass_agnostic_bbox_regtargets[ex_inds,0]=(1ifcfg.MODEL.CLS_AGNOSTIC_BBOX_REGelselabels[ex_inds])targets[ex_inds,1:]=box_utils.bbox_transform_inv(ex_rois,gt_rois,cfg.MODEL.BBOX_REG_WEIGHTS)returntargetsdef_compute_and_log_stats(roidb):classes=roidb[0][\\'dataset\\'].classeschar_len=np.max([len(c)forcinclasses])hist_bins=np.arange(len(classes)+1)#Histogramofground-truthobjectsgt_hist=np.zeros((len(classes)),dtype=int)forentryinroidb:gt_inds=np.where((entry[\\'gt_classes\\']>0)&(entry[\\'is_crowd\\']==0))[0]gt_classes=entry[\\'gt_classes\\'][gt_inds]gt_hist+=np.histogram(gt_classes,bins=hist_bins)[0]logger.debug(\\'Ground-truthclasshistogram:\\')fori,vinenumerate(gt_hist):logger.debug(\\'{:d}{:s}:{:d}\\'.format(i,classes[i].rjust(char_len),v))logger.debug(\\'-\\'*char_len)logger.debug(\\'{:s}:{:d}\\'.format(\\'total\\'.rjust(char_len),np.sum(gt_hist)))#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Evaluationinterfaceforsupportedtasks(boxdetection,instancesegmentation,keypointdetection,...).ResultsarestoredinanOrderedDictwiththefollowingnestedstructure::::isanyvaliddataset(e.g.,\\'coco_2014_minival\\')isin[\\'box\\',\\'mask\\',\\'keypoint\\',\\'box_proposal\\']canbe[\\'AP\\',\\'AP50\\',\\'AP75\\',\\'APs\\',\\'APm\\',\\'APl\\',\\'\\',\\'\\',\\'\\',\\'\\',...]isafloatingpointnumber\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportOrderedDictimportloggingimportosimportpprintfromdetectron.core.configimportcfgfromdetectron.utils.loggingimportsend_emailimportdetectron.datasets.cityscapes_json_dataset_evaluator\\\\ascs_json_dataset_evaluatorimportdetectron.datasets.json_dataset_evaluatorasjson_dataset_evaluatorimportdetectron.datasets.voc_dataset_evaluatorasvoc_dataset_evaluatorlogger=logging.getLogger(__name__)defevaluate_all(dataset,all_boxes,all_segms,all_keyps,output_dir,use_matlab=False):\"\"\"Evaluate\"all\"tasks,where\"all\"includesboxdetection,instancesegmentation,andkeypointdetection.\"\"\"all_results=evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)logger.info(\\'Evaluatingboundingboxesisdone!\\')ifcfg.MODEL.MASK_ON:results=evaluate_masks(dataset,all_boxes,all_segms,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingsegmentationsisdone!\\')ifcfg.MODEL.KEYPOINTS_ON:results=evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir)all_results[dataset.name].update(results[dataset.name])logger.info(\\'Evaluatingkeypointsisdone!\\')returnall_resultsdefevaluate_boxes(dataset,all_boxes,output_dir,use_matlab=False):\"\"\"Evaluateboundingboxdetection.\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_cityscapes_evaluator(dataset):logger.warn(\\'CityscapesbboxevaluatedusingCOCOmetrics/conversions\\')coco_eval=json_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_salt=not_comp,cleanup=not_comp)box_results=_coco_eval_to_box_results(coco_eval)elif_use_voc_evaluator(dataset):#ForVOC,alwaysusesaltandalwayscleanupbecauseresultsare#writtentothesharedVOCdevkitresultsdirectoryvoc_eval=voc_dataset_evaluator.evaluate_boxes(dataset,all_boxes,output_dir,use_matlab=use_matlab)box_results=_voc_eval_to_box_results(voc_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,box_results)])defevaluate_masks(dataset,all_boxes,all_segms,output_dir):\"\"\"Evaluateinstancesegmentation.\"\"\"logger.info(\\'Evaluatingsegmentations\\')not_comp=notcfg.TEST.COMPETITION_MODEif_use_json_dataset_evaluator(dataset):coco_eval=json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_coco_eval_to_mask_results(coco_eval)elif_use_cityscapes_evaluator(dataset):cs_eval=cs_json_dataset_evaluator.evaluate_masks(dataset,all_boxes,all_segms,output_dir,use_salt=not_comp,cleanup=not_comp)mask_results=_cs_eval_to_mask_results(cs_eval)else:raiseNotImplementedError(\\'Noevaluatorfordataset:{}\\'.format(dataset.name))returnOrderedDict([(dataset.name,mask_results)])defevaluate_keypoints(dataset,all_boxes,all_keyps,output_dir):\"\"\"Evaluatehumankeypointdetection(i.e.,2Dposeestimation).\"\"\"logger.info(\\'Evaluatingdetections\\')not_comp=notcfg.TEST.COMPETITION_MODEassertdataset.name.startswith(\\'keypoints_coco_\\'),\\\\\\'OnlyCOCOkeypointsarecurrentlysupported\\'coco_eval=json_dataset_evaluator.evaluate_keypoints(dataset,all_boxes,all_keyps,output_dir,use_salt=not_comp,cleanup=not_comp)keypoint_results=_coco_eval_to_keypoint_results(coco_eval)returnOrderedDict([(dataset.name,keypoint_results)])defevaluate_box_proposals(dataset,roidb):\"\"\"Evaluateboundingboxobjectproposals.\"\"\"res=_empty_box_proposal_results()areas={\\'all\\':\\'\\',\\'small\\':\\'s\\',\\'medium\\':\\'m\\',\\'large\\':\\'l\\'}forlimitin[100,1000]:forarea,suffixinareas.items():stats=json_dataset_evaluator.evaluate_box_proposals(dataset,roidb,area=area,limit=limit,class_specific=cfg.TEST.CLASS_SPECIFIC_AR)key=\\'AR{}@{:d}\\'.format(suffix,limit)res[\\'box_proposal\\'][key]=stats[\\'ar\\']returnOrderedDict([(dataset.name,res)])deflog_box_proposal_results(results):\"\"\"Logboundingboxproposalresults.\"\"\"fordatasetinresults.keys():keys=results[dataset][\\'box_proposal\\'].keys()pad=max([len(k)forkinkeys])logger.info(dataset)fork,vinresults[dataset][\\'box_proposal\\'].items():logger.info(\\'{}:{:.3f}\\'.format(k.ljust(pad),v))deflog_copy_paste_friendly_results(results):\"\"\"Logresultsinaformatthatmakesiteasytocopy-and-pasteinaspreadsheet.Linesareprefixedwith\\'copypaste:\\'tomakegreppingeasy.\"\"\"fordatasetinresults.keys():logger.info(\\'copypaste:Dataset:{}\\'.format(dataset))fortask,metricsinresults[dataset].items():logger.info(\\'copypaste:Task:{}\\'.format(task))metric_names=metrics.keys()metric_vals=[\\'{:.4f}\\'.format(v)forvinmetrics.values()]logger.info(\\'copypaste:\\'+\\',\\'.join(metric_names))logger.info(\\'copypaste:\\'+\\',\\'.join(metric_vals))defcheck_expected_results(results,atol=0.005,rtol=0.1):\"\"\"Checkactualresultsagainstexpectedresultsstoredincfg.EXPECTED_RESULTS.Optionallyemailifthematchexceedsthespecifiedtolerance.Expectedresultsshouldtaketheformofalistofexpectations,eachspecifiedbyfourelements:[dataset,task,metric,expectedvalue].Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',0.387],...].Theexpectedvaluemayalsobeformattedasalist[mean,std]providinganempiricalmeanandstandarddeviationfromwhichavalidrangeiscomputedusingcfg.EXPECTED_RESULTS_SIGMA_TOL.Forexample:[[\\'coco_2014_minival\\',\\'box_proposal\\',\\'\\',[0.387,0.001]],...]\"\"\"#cfgcontainsareferencesetofresultsthatwewanttocheckagainstiflen(cfg.EXPECTED_RESULTS)==0:returnfordataset,task,metric,expected_valincfg.EXPECTED_RESULTS:assertdatasetinresults,\\'Dataset{}notinresults\\'.format(dataset)asserttaskinresults[dataset],\\'Task{}notinresults\\'.format(task)assertmetricinresults[dataset][task],\\\\\\'Metric{}notinresults\\'.format(metric)actual_val=results[dataset][task][metric]ok=Falseifisinstance(expected_val,list):assertlen(expected_val)==2,(\\'Expectedresultmustbein(mean,std)format\\')mean,std=expected_vallo=mean-cfg.EXPECTED_RESULTS_SIGMA_TOL*stdhi=mean+cfg.EXPECTED_RESULTS_SIGMA_TOL*stdok=(lo<actual_val)and(actual_val<hi)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.mean={:.4f},std={:.4},range=({:.4f},{:.4f})\\').format(dataset,task,metric,actual_val,mean,std,lo,hi)else:err=abs(actual_val-expected_val)tol=atol+rtol*abs(expected_val)ok=(err>tol)msg=(\\'{}>{}>{}sanitycheck(actualvs.expected):\\'\\'{:.3f}vs.{:.3f},err={:.3f},tol={:.3f}\\').format(dataset,task,metric,actual_val,expected_val,err,tol)ifnotok:msg=\\'FAIL:\\'+msglogger.error(msg)ifcfg.EXPECTED_RESULTS_EMAIL!=\\'\\':subject=\\'Detectronend-to-endtestfailure\\'job_name=os.environ[\\'DETECTRON_JOB_NAME\\']if\\'DETECTRON_JOB_NAME\\'inos.environelse\\'\\'job_id=os.environ[\\'WORKFLOW_RUN_ID\\']if\\'WORKFLOW_RUN_ID\\'inos.environelse\\'\\'body=[\\'Name:\\',job_name,\\'RunID:\\',job_id,\\'Failure:\\',msg,\\'Config:\\',pprint.pformat(cfg),\\'Env:\\',pprint.pformat(dict(os.environ)),]send_email(subject,\\'\\\\n\\\\n\\'.join(body),cfg.EXPECTED_RESULTS_EMAIL)else:msg=\\'PASS:\\'+msglogger.info(msg)def_use_json_dataset_evaluator(dataset):\"\"\"Checkifthedatasetusesthegeneraljsondatasetevaluator.\"\"\"returndataset.name.find(\\'coco_\\')>-1orcfg.TEST.FORCE_JSON_DATASET_EVALdef_use_cityscapes_evaluator(dataset):\"\"\"CheckifthedatasetusestheCityscapesdatasetevaluator.\"\"\"returndataset.name.find(\\'cityscapes_\\')>-1def_use_voc_evaluator(dataset):\"\"\"CheckifthedatasetusesthePASCALVOCdatasetevaluator.\"\"\"returndataset.name[:4]==\\'voc_\\'#IndicesinthestatsarrayforCOCOboxesandmasksCOCO_AP=0COCO_AP50=1COCO_AP75=2COCO_APS=3COCO_APM=4COCO_APL=5#SlightdifferenceforkeypointsCOCO_KPS_APM=3COCO_KPS_APL=4#----------------------------------------------------------------------------##Helperfunctionsforproducingproperlyformattedresults.#----------------------------------------------------------------------------#def_coco_eval_to_box_results(coco_eval):res=_empty_box_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'box\\'][\\'AP\\']=s[COCO_AP]res[\\'box\\'][\\'AP50\\']=s[COCO_AP50]res[\\'box\\'][\\'AP75\\']=s[COCO_AP75]res[\\'box\\'][\\'APs\\']=s[COCO_APS]res[\\'box\\'][\\'APm\\']=s[COCO_APM]res[\\'box\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_mask_results(coco_eval):res=_empty_mask_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'mask\\'][\\'AP\\']=s[COCO_AP]res[\\'mask\\'][\\'AP50\\']=s[COCO_AP50]res[\\'mask\\'][\\'AP75\\']=s[COCO_AP75]res[\\'mask\\'][\\'APs\\']=s[COCO_APS]res[\\'mask\\'][\\'APm\\']=s[COCO_APM]res[\\'mask\\'][\\'APl\\']=s[COCO_APL]returnresdef_coco_eval_to_keypoint_results(coco_eval):res=_empty_keypoint_results()ifcoco_evalisnotNone:s=coco_eval.statsres[\\'keypoint\\'][\\'AP\\']=s[COCO_AP]res[\\'keypoint\\'][\\'AP50\\']=s[COCO_AP50]res[\\'keypoint\\'][\\'AP75\\']=s[COCO_AP75]res[\\'keypoint\\'][\\'APm\\']=s[COCO_KPS_APM]res[\\'keypoint\\'][\\'APl\\']=s[COCO_KPS_APL]returnresdef_voc_eval_to_box_results(voc_eval):#Notsupported(returnemptyresults)return_empty_box_results()def_cs_eval_to_mask_results(cs_eval):#Notsupported(returnemptyresults)return_empty_mask_results()def_empty_box_results():returnOrderedDict({\\'box\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_mask_results():returnOrderedDict({\\'mask\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APs\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_keypoint_results():returnOrderedDict({\\'keypoint\\':OrderedDict([(\\'AP\\',-1),(\\'AP50\\',-1),(\\'AP75\\',-1),(\\'APm\\',-1),(\\'APl\\',-1),])})def_empty_box_proposal_results():returnOrderedDict({\\'box_proposal\\':OrderedDict([(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),(\\'\\',-1),])})#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"FunctionsforevaluatingresultsonCityscapes.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcv2importloggingimportosimportuuidimportpycocotools.maskasmask_utilfromdetectron.core.configimportcfgfromdetectron.datasets.dataset_catalogimportget_raw_dirlogger=logging.getLogger(__name__)defevaluate_masks(json_dataset,all_boxes,all_segms,output_dir,use_salt=True,cleanup=False):ifcfg.CLUSTER.ON_CLUSTER:#Ontheclusteravoidsavingthesefilesinthejobdirectoryoutput_dir=\\'/tmp\\'res_file=os.path.join(output_dir,\\'segmentations_\\'+json_dataset.name+\\'_results\\')ifuse_salt:res_file+=\\'_{}\\'.format(str(uuid.uuid4()))res_file+=\\'.json\\'results_dir=os.path.join(output_dir,\\'results\\')ifnotos.path.exists(results_dir):os.mkdir(results_dir)os.environ[\\'CITYSCAPES_DATASET\\']=get_raw_dir(json_dataset.name)os.environ[\\'CITYSCAPES_RESULTS\\']=output_dir#LoadtheCityscapesevalscript*after*settingtherequiredenvvars,#sincethescriptreadstheirvaluesintoglobalvariables(atloadtime).importcityscapesscripts.evaluation.evalInstanceLevelSemanticLabeling\\\\ascityscapes_evalroidb=json_dataset.get_roidb()fori,entryinenumerate(roidb):im_name=entry[\\'image\\']basename=os.path.splitext(os.path.basename(im_name))[0]txtname=os.path.join(output_dir,basename+\\'pred.txt\\')withopen(txtname,\\'w\\')asfid_txt:ifi%10==0:logger.info(\\'i:{}:{}\\'.format(i,basename))forjinrange(1,len(all_segms)):clss=json_dataset.classes[j]clss_id=cityscapes_eval.name2label[clss].idsegms=all_segms[j][i]boxes=all_boxes[j][i]ifsegms==[]:continuemasks=mask_util.decode(segms)forkinrange(boxes.shape[0]):score=boxes[k,-1]mask=masks[:,:,k]pngname=os.path.join(\\'results\\',basename+\\'_\\'+clss+\\'_{}.png\\'.format(k))#writetxtfid_txt.write(\\'{}{}{}\\\\n\\'.format(pngname,clss_id,score))#savemaskcv2.imwrite(os.path.join(output_dir,pngname),mask*255)logger.info(\\'Evaluating...\\')cityscapes_eval.main([])returnNone#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Providestubobjectsthatcanactasstand-in\"dummy\"datasetsforsimpleusecases,likegettingallclassesinadataset.Thisexistssothatdemoscanberunwithoutrequiringuserstodownload/installdatasetsfirst.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromdetectron.utils.collectionsimportAttrDictdefget_coco_dataset():\"\"\"AdummyCOCOdatasetthatincludesonlythe\\'classes\\'field.\"\"\"ds=AttrDict()classes=[\\'__background__\\',\\'person\\',\\'bicycle\\',\\'car\\',\\'motorcycle\\',\\'airplane\\',\\'bus\\',\\'train\\',\\'truck\\',\\'boat\\',\\'trafficlight\\',\\'firehydrant\\',\\'stopsign\\',\\'parkingmeter\\',\\'bench\\',\\'bird\\',\\'cat\\',\\'dog\\',\\'horse\\',\\'sheep\\',\\'cow\\',\\'elephant\\',\\'bear\\',\\'zebra\\',\\'giraffe\\',\\'backpack\\',\\'umbrella\\',\\'handbag\\',\\'tie\\',\\'suitcase\\',\\'frisbee\\',\\'skis\\',\\'snowboard\\',\\'sportsball\\',\\'kite\\',\\'baseballbat\\',\\'baseballglove\\',\\'skateboard\\',\\'surfboard\\',\\'tennisracket\\',\\'bottle\\',\\'wineglass\\',\\'cup\\',\\'fork\\',\\'knife\\',\\'spoon\\',\\'bowl\\',\\'banana\\',\\'apple\\',\\'sandwich\\',\\'orange\\',\\'broccoli\\',\\'carrot\\',\\'hotdog\\',\\'pizza\\',\\'donut\\',\\'cake\\',\\'chair\\',\\'couch\\',\\'pottedplant\\',\\'bed\\',\\'diningtable\\',\\'toilet\\',\\'tv\\',\\'laptop\\',\\'mouse\\',\\'remote\\',\\'keyboard\\',\\'cellphone\\',\\'microwave\\',\\'oven\\',\\'toaster\\',\\'sink\\',\\'refrigerator\\',\\'book\\',\\'clock\\',\\'vase\\',\\'scissors\\',\\'teddybear\\',\\'hairdrier\\',\\'toothbrush\\']ds.classes={i:namefori,nameinenumerate(classes)}returnds#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"RepresentationofthestandardCOCOjsondatasetformat.Whenworkingwithanewdataset,westronglysuggesttoconvertthedatasetintotheCOCOjsonformatandusetheexistingcode;itisnotrecommendedtowritecodetosupportnewdatasetformats.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportcopyimportloggingimportnumpyasnpimportosimportscipy.sparse#MusthappenbeforeimportingCOCOAPI(whichimportsmatplotlib)importdetectron.utils.envasenvuenvu.set_up_matplotlib()#COCOAPIfrompycocotoolsimportmaskasCOCOmaskfrompycocotools.cocoimportCOCOfromdetectron.core.configimportcfgfromdetectron.utils.timerimportTimerimportdetectron.datasets.dataset_catalogasdataset_catalogimportdetectron.utils.boxesasbox_utilsfromdetectron.utils.ioimportload_objectimportdetectron.utils.segmsassegm_utilslogger=logging.getLogger(__name__)classJsonDataset:\"\"\"AclassrepresentingaCOCOjsondataset.\"\"\"def__init__(self,name):assertdataset_catalog.contains(name),\\\\\\'Unknowndatasetname:{}\\'.format(name)assertos.path.exists(dataset_catalog.get_im_dir(name)),\\\\\\'Imdir\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_im_dir(name))assertos.path.exists(dataset_catalog.get_ann_fn(name)),\\\\\\'Annfn\\\\\\'{}\\\\\\'notfound\\'.format(dataset_catalog.get_ann_fn(name))logger.debug(\\'Creating:{}\\'.format(name))self.name=nameself.image_directory=dataset_catalog.get_im_dir(name)self.image_prefix=dataset_catalog.get_im_prefix(name)self.COCO=COCO(dataset_catalog.get_ann_fn(name))self.debug_timer=Timer()#Setupdatasetclassescategory_ids=self.COCO.getCatIds()categories=[c[\\'name\\']forcinself.COCO.loadCats(category_ids)]self.category_to_id_map=dict(zip(categories,category_ids))self.classes=[\\'__background__\\']+categoriesself.num_classes=len(self.classes)self.json_category_id_to_contiguous_id={v:i+1fori,vinenumerate(self.COCO.getCatIds())}self.contiguous_category_id_to_json_id={v:kfork,vinself.json_category_id_to_contiguous_id.items()}self._init_keypoints()defget_roidb(self,gt=False,proposal_file=None,min_proposal_size=2,proposal_limit=-1,crowd_filter_thresh=0):\"\"\"Returnanroidbcorrespondingtothejsondataset.Optionally:-includegroundtruthboxesintheroidb-addproposalsspecifiedinaproposalsfile-filterproposalsbasedonaminimumsidelength-filterproposalsthatintersectwithcrowdregions\"\"\"assertgtisTrueorcrowd_filter_thresh==0,\\\\\\'Crowdfilterthresholdmustbe0ifground-truthannotations\\'\\\\\\'arenotincluded.\\'image_ids=self.COCO.getImgIds()image_ids.sort()roidb=copy.deepcopy(self.COCO.loadImgs(image_ids))forentryinroidb:self._prep_roidb_entry(entry)ifgt:#Includeground-truthobjectannotationsself.debug_timer.tic()forentryinroidb:self._add_gt_annotations(entry)logger.debug(\\'_add_gt_annotationstook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))ifproposal_fileisnotNone:#Includeproposalsfromafileself.debug_timer.tic()self._add_proposals_from_file(roidb,proposal_file,min_proposal_size,proposal_limit,crowd_filter_thresh)logger.debug(\\'_add_proposals_from_filetook{:.3f}s\\'.format(self.debug_timer.toc(average=False)))_add_class_assignments(roidb)returnroidbdef_prep_roidb_entry(self,entry):\"\"\"Addsemptymetadatafieldstoanroidbentry.\"\"\"#Referencebacktotheparentdatasetentry[\\'dataset\\']=self#Makefile_nameanabspathim_path=os.path.join(self.image_directory,self.image_prefix+entry[\\'file_name\\'])assertos.path.exists(im_path),\\'Image\\\\\\'{}\\\\\\'notfound\\'.format(im_path)entry[\\'image\\']=im_pathentry[\\'flipped\\']=Falseentry[\\'has_visible_keypoints\\']=False#Emptyplaceholdersentry[\\'boxes\\']=np.empty((0,4),dtype=np.float32)entry[\\'segms\\']=[]entry[\\'gt_classes\\']=np.empty((0),dtype=np.int32)entry[\\'seg_areas\\']=np.empty((0),dtype=np.float32)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(np.empty((0,self.num_classes),dtype=np.float32))entry[\\'is_crowd\\']=np.empty((0),dtype=bool)#\\'box_to_gt_ind_map\\':Shapeis(#rois).Mapsfromeachroitotheindex#inthelistofroisthatsatisfynp.where(entry[\\'gt_classes\\']>0)entry[\\'box_to_gt_ind_map\\']=np.empty((0),dtype=np.int32)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.empty((0,3,self.num_keypoints),dtype=np.int32)#Removeunwantedfieldsthatcomefromthejsonfile(iftheyexist)forkin[\\'date_captured\\',\\'url\\',\\'license\\',\\'file_name\\']:ifkinentry:delentry[k]def_add_gt_annotations(self,entry):\"\"\"Addgroundtruthannotationmetadatatoanroidbentry.\"\"\"ann_ids=self.COCO.getAnnIds(imgIds=entry[\\'id\\'],iscrowd=None)objs=self.COCO.loadAnns(ann_ids)#Sanitizebboxes--someareinvalidvalid_objs=[]valid_segms=[]width=entry[\\'width\\']height=entry[\\'height\\']forobjinobjs:#crowdregionsareRLEencodedifsegm_utils.is_poly(obj[\\'segmentation\\']):#Validpolygonshave>=3points,sorequire>=6coordinatesobj[\\'segmentation\\']=[pforpinobj[\\'segmentation\\']iflen(p)>=6]ifobj[\\'area\\']<cfg.TRAIN.GT_MIN_AREA:continueif\\'ignore\\'inobjandobj[\\'ignore\\']==1:continue#Convertform(x1,y1,w,h)to(x1,y1,x2,y2)x1,y1,x2,y2=box_utils.xywh_to_xyxy(obj[\\'bbox\\'])x1,y1,x2,y2=box_utils.clip_xyxy_to_image(x1,y1,x2,y2,height,width)#Requirenon-zerosegareaandmorethan1x1boxsizeifobj[\\'area\\']>0andx2>x1andy2>y1:obj[\\'clean_bbox\\']=[x1,y1,x2,y2]valid_objs.append(obj)valid_segms.append(obj[\\'segmentation\\'])num_valid_objs=len(valid_objs)boxes=np.zeros((num_valid_objs,4),dtype=entry[\\'boxes\\'].dtype)gt_classes=np.zeros((num_valid_objs),dtype=entry[\\'gt_classes\\'].dtype)gt_overlaps=np.zeros((num_valid_objs,self.num_classes),dtype=entry[\\'gt_overlaps\\'].dtype)seg_areas=np.zeros((num_valid_objs),dtype=entry[\\'seg_areas\\'].dtype)is_crowd=np.zeros((num_valid_objs),dtype=entry[\\'is_crowd\\'].dtype)box_to_gt_ind_map=np.zeros((num_valid_objs),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)ifself.keypointsisnotNone:gt_keypoints=np.zeros((num_valid_objs,3,self.num_keypoints),dtype=entry[\\'gt_keypoints\\'].dtype)im_has_visible_keypoints=Falseforix,objinenumerate(valid_objs):cls=self.json_category_id_to_contiguous_id[obj[\\'category_id\\']]boxes[ix,:]=obj[\\'clean_bbox\\']gt_classes[ix]=clsseg_areas[ix]=obj[\\'area\\']is_crowd[ix]=obj[\\'iscrowd\\']box_to_gt_ind_map[ix]=ixifself.keypointsisnotNone:gt_keypoints[ix,:,:]=self._get_gt_keypoints(obj)ifnp.sum(gt_keypoints[ix,2,:])>0:im_has_visible_keypoints=Trueifobj[\\'iscrowd\\']:#Setoverlapto-1forallclassesforcrowdobjects#sotheywillbeexcludedduringtraininggt_overlaps[ix,:]=-1.0else:gt_overlaps[ix,cls]=1.0entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes,axis=0)entry[\\'segms\\'].extend(valid_segms)#Tomatchtheoriginalimplementation:#entry[\\'boxes\\']=np.append(#entry[\\'boxes\\'],boxes.astype(int).astype(float),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],gt_classes)entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],seg_areas)entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],is_crowd)entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map)ifself.keypointsisnotNone:entry[\\'gt_keypoints\\']=np.append(entry[\\'gt_keypoints\\'],gt_keypoints,axis=0)entry[\\'has_visible_keypoints\\']=im_has_visible_keypointsdef_add_proposals_from_file(self,roidb,proposal_file,min_proposal_size,top_k,crowd_thresh):\"\"\"Addproposalsfromaproposalsfiletoanroidb.\"\"\"logger.info(\\'Loadingproposalsfrom:{}\\'.format(proposal_file))proposals=load_object(proposal_file)id_field=\\'indexes\\'if\\'indexes\\'inproposalselse\\'ids\\'#compatfix_remove_proposals_not_in_roidb(proposals,roidb,id_field)_sort_proposals(proposals,id_field)box_list=[]fori,entryinenumerate(roidb):ifi%2500==0:logger.info(\\'{:d}/{:d}\\'.format(i+1,len(roidb)))boxes=proposals[\\'boxes\\'][i]#Sanitycheckthattheseboxesareforthecorrectimageidassertentry[\\'id\\']==proposals[id_field][i]#Removeduplicateboxesandverysmallboxesandthentaketopkboxes=box_utils.clip_boxes_to_image(boxes,entry[\\'height\\'],entry[\\'width\\'])keep=box_utils.unique_boxes(boxes)boxes=boxes[keep,:]keep=box_utils.filter_small_boxes(boxes,min_proposal_size)boxes=boxes[keep,:]iftop_k>0:boxes=boxes[:top_k,:]box_list.append(boxes)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)def_init_keypoints(self):\"\"\"InitializeCOCOkeypointinformation.\"\"\"self.keypoints=Noneself.keypoint_flip_map=Noneself.keypoints_to_id_map=Noneself.num_keypoints=0#Thusfaronlythe\\'person\\'categoryhaskeypointsif\\'person\\'inself.category_to_id_map:cat_info=self.COCO.loadCats([self.category_to_id_map[\\'person\\']])else:return#Checkiftheannotationscontainkeypointdataornotif\\'keypoints\\'incat_info[0]:keypoints=cat_info[0][\\'keypoints\\']self.keypoints_to_id_map=dict(zip(keypoints,range(len(keypoints))))self.keypoints=keypointsself.num_keypoints=len(keypoints)self.keypoint_flip_map={\\'left_eye\\':\\'right_eye\\',\\'left_ear\\':\\'right_ear\\',\\'left_shoulder\\':\\'right_shoulder\\',\\'left_elbow\\':\\'right_elbow\\',\\'left_wrist\\':\\'right_wrist\\',\\'left_hip\\':\\'right_hip\\',\\'left_knee\\':\\'right_knee\\',\\'left_ankle\\':\\'right_ankle\\'}def_get_gt_keypoints(self,obj):\"\"\"Returngroundtruthkeypoints.\"\"\"if\\'keypoints\\'notinobj:returnNonekp=np.array(obj[\\'keypoints\\'])x=kp[0::3]#0-indexedxcoordinatesy=kp[1::3]#0-indexedycoordinates#0:notlabeled;1:labeled,notinsidemask;#2:labeledandinsidemaskv=kp[2::3]num_keypoints=len(obj[\\'keypoints\\'])/3assertnum_keypoints==self.num_keypointsgt_kps=np.ones((3,self.num_keypoints),dtype=np.int32)foriinrange(self.num_keypoints):gt_kps[0,i]=x[i]gt_kps[1,i]=y[i]gt_kps[2,i]=v[i]returngt_kpsdefadd_proposals(roidb,rois,scales,crowd_thresh):\"\"\"Addproposalboxes(rois)toanroidbthathasground-truthannotationsbutnoproposals.Iftheproposalsarenotattheoriginalimagescale,specifythescalefactorthatseparatetheminscales.\"\"\"box_list=[]foriinrange(len(roidb)):inv_im_scale=1./scales[i]idx=np.where(rois[:,0]==i)[0]box_list.append(rois[idx,1:]*inv_im_scale)_merge_proposal_boxes_into_roidb(roidb,box_list)ifcrowd_thresh>0:_filter_crowd_proposals(roidb,crowd_thresh)_add_class_assignments(roidb)def_merge_proposal_boxes_into_roidb(roidb,box_list):\"\"\"Addproposalboxestoeachroidbentry.\"\"\"assertlen(box_list)==len(roidb)fori,entryinenumerate(roidb):boxes=box_list[i]num_boxes=boxes.shape[0]gt_overlaps=np.zeros((num_boxes,entry[\\'gt_overlaps\\'].shape[1]),dtype=entry[\\'gt_overlaps\\'].dtype)box_to_gt_ind_map=-np.ones((num_boxes),dtype=entry[\\'box_to_gt_ind_map\\'].dtype)#Note:unlikeinotherplaces,hereweintentionallyincludeallgt#rois,evenonesmarkedascrowd.Boxesthatoverlapwithcrowdswill#befilteredoutlater(see:_filter_crowd_proposals).gt_inds=np.where(entry[\\'gt_classes\\']>0)[0]iflen(gt_inds)>0:gt_boxes=entry[\\'boxes\\'][gt_inds,:]gt_classes=entry[\\'gt_classes\\'][gt_inds]proposal_to_gt_overlaps=box_utils.bbox_overlaps(boxes.astype(dtype=np.float32,copy=False),gt_boxes.astype(dtype=np.float32,copy=False))#Gtboxthatoverlapseachinputboxthemost#(tiesarebrokenarbitrarilybyclassorder)argmaxes=proposal_to_gt_overlaps.argmax(axis=1)#Amountofthatoverlapmaxes=proposal_to_gt_overlaps.max(axis=1)#Thoseboxeswithnon-zerooverlapwithgtboxesI=np.where(maxes>0)[0]#Recordmaxoverlapswiththeclassoftheappropriategtboxgt_overlaps[I,gt_classes[argmaxes[I]]]=maxes[I]box_to_gt_ind_map[I]=gt_inds[argmaxes[I]]entry[\\'boxes\\']=np.append(entry[\\'boxes\\'],boxes.astype(entry[\\'boxes\\'].dtype,copy=False),axis=0)entry[\\'gt_classes\\']=np.append(entry[\\'gt_classes\\'],np.zeros((num_boxes),dtype=entry[\\'gt_classes\\'].dtype))entry[\\'seg_areas\\']=np.append(entry[\\'seg_areas\\'],np.zeros((num_boxes),dtype=entry[\\'seg_areas\\'].dtype))entry[\\'gt_overlaps\\']=np.append(entry[\\'gt_overlaps\\'].toarray(),gt_overlaps,axis=0)entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(entry[\\'gt_overlaps\\'])entry[\\'is_crowd\\']=np.append(entry[\\'is_crowd\\'],np.zeros((num_boxes),dtype=entry[\\'is_crowd\\'].dtype))entry[\\'box_to_gt_ind_map\\']=np.append(entry[\\'box_to_gt_ind_map\\'],box_to_gt_ind_map.astype(entry[\\'box_to_gt_ind_map\\'].dtype,copy=False))def_filter_crowd_proposals(roidb,crowd_thresh):\"\"\"Findsproposalsthatareinsidecrowdregionsandmarksthemasoverlap=-1witheachground-truthrois,whichmeanstheywillbeexcludedfromtraining.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()crowd_inds=np.where(entry[\\'is_crowd\\']==1)[0]non_gt_inds=np.where(entry[\\'gt_classes\\']==0)[0]iflen(crowd_inds)==0orlen(non_gt_inds)==0:continuecrowd_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][crowd_inds,:])non_gt_boxes=box_utils.xyxy_to_xywh(entry[\\'boxes\\'][non_gt_inds,:])iscrowd_flags=[int(True)]*len(crowd_inds)ious=COCOmask.iou(non_gt_boxes,crowd_boxes,iscrowd_flags)bad_inds=np.where(ious.max(axis=1)>crowd_thresh)[0]gt_overlaps[non_gt_inds[bad_inds],:]=-1entry[\\'gt_overlaps\\']=scipy.sparse.csr_matrix(gt_overlaps)def_add_class_assignments(roidb):\"\"\"Computeobjectcategoryassignmentforeachboxassociatedwitheachroidbentry.\"\"\"forentryinroidb:gt_overlaps=entry[\\'gt_overlaps\\'].toarray()#maxoverlapwithgtoverclasses(columns)max_overlaps=gt_overlaps.max(axis=1)#gtclassthathadthemaxoverlapmax_classes=gt_overlaps.argmax(axis=1)entry[\\'max_classes\\']=max_classesentry[\\'max_overlaps\\']=max_overlaps#sanitychecks#ifmaxoverlapis0,theclassmustbebackground(class0)zero_inds=np.where(max_overlaps==0)[0]assertall(max_classes[zero_inds]==0)#ifmaxoverlap>0,theclassmustbeafgclass(notclass0)nonzero_inds=np.where(max_overlaps>0)[0]assertall(max_classes[nonzero_inds]!=0)def_sort_proposals(proposals,id_field):\"\"\"Sortproposalsbythespecifiedidfield.\"\"\"order=np.argsort(proposals[id_field])fields_to_sort=[\\'boxes\\',id_field,\\'scores\\']forkinfields_to_sort:proposals[k]=[proposals[k][i]foriinorder]def_remove_proposals_not_in_roidb(proposals,roidb,id_field):#fixproposalssotheydon\\'tcontainentriesforimagesnotintheroidbroidb_ids=set({entry[\"id\"]forentryinroidb})keep=[ifori,idinenumerate(proposals[id_field])ifidinroidb_ids]forfin[\\'boxes\\',id_field,\\'scores\\']:proposals[f]=[proposals[f][i]foriinkeep]#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.Allowsforusingacombinationofmultiplemodels.Forexample,onemodelmaybeusedforRPN,anothermodelforFastR-CNNstyleboxdetection,yetanothermodeltopredictmasks,andyetanothermodeltopredictkeypoints.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportosimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportload_cfgfromdetectron.core.configimportmerge_cfg_from_cfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.rpn_generatorasrpn_engineimportdetectron.core.test_engineasmodel_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.envasenvuimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)#infer.py#--im[path/to/image.jpg]\\\\#--rpn-model[path/to/rpn/model.pkl]\\\\#--rpn-cfg[path/to/rpn/config.yaml]\\\\#--output-dir[path/to/output/dir]\\\\#[model1][config1][model2][config2]...defparse_args():parser=argparse.ArgumentParser(description=\\'Inferenceonanimage\\')parser.add_argument(\\'--im\\',dest=\\'im_file\\',help=\\'inputimage\\',default=None,type=str)parser.add_argument(\\'--rpn-pkl\\',dest=\\'rpn_pkl\\',help=\\'rpnmodelfile(pkl)\\',default=None,type=str)parser.add_argument(\\'--rpn-cfg\\',dest=\\'rpn_cfg\\',help=\\'cfgmodelfile(yaml)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer)\\',default=\\'/tmp/infer\\',type=str)parser.add_argument(\\'models_to_run\\',help=\\'pairsofmodels&configs,listedlikeso:[pkl1][yaml1][pkl2][yaml2]...\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defget_rpn_box_proposals(im,args):cfg.immutable(False)merge_cfg_from_file(args.rpn_cfg)cfg.NUM_GPUS=1cfg.MODEL.RPN_ONLY=Truecfg.TEST.RPN_PRE_NMS_TOP_N=10000cfg.TEST.RPN_POST_NMS_TOP_N=2000assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(args.rpn_pkl)withc2_utils.NamedCudaScope(0):boxes,scores=rpn_engine.im_proposals(model,im)returnboxes,scoresdefmain(args):logger=logging.getLogger(__name__)dummy_coco_dataset=dummy_datasets.get_coco_dataset()cfg_orig=load_cfg(envu.yaml_dump(cfg))im=cv2.imread(args.im_file)ifargs.rpn_pklisnotNone:proposal_boxes,_proposal_scores=get_rpn_box_proposals(im,args)workspace.ResetWorkspace()else:proposal_boxes=Nonecls_boxes,cls_segms,cls_keyps=None,None,Noneforiinrange(0,len(args.models_to_run),2):pkl=args.models_to_run[i]yml=args.models_to_run[i+1]cfg.immutable(False)merge_cfg_from_cfg(cfg_orig)merge_cfg_from_file(yml)iflen(pkl)>0:weights_file=pklelse:weights_file=cfg.TEST.WEIGHTScfg.NUM_GPUS=1assert_and_infer_cfg(cache_urls=False)model=model_engine.initialize_model_from_cfg(weights_file)withc2_utils.NamedCudaScope(0):cls_boxes_,cls_segms_,cls_keyps_=\\\\model_engine.im_detect_all(model,im,proposal_boxes)cls_boxes=cls_boxes_ifcls_boxes_isnotNoneelsecls_boxescls_segms=cls_segms_ifcls_segms_isnotNoneelsecls_segmscls_keyps=cls_keyps_ifcls_keyps_isnotNoneelsecls_keypsworkspace.ResetWorkspace()out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(args.im_file)+\\'.pdf\\'))logger.info(\\'Processing{}->{}\\'.format(args.im_file,out_name))vis_utils.vis_one_image(im[:,:,::-1],args.im_file,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=0.7,kp_thresh=2)defcheck_args(args):assert((args.rpn_pklisnotNoneandargs.rpn_cfgisnotNone)or(args.rpn_pklisNoneandargs.rpn_cfgisNone))ifargs.rpn_pklisnotNone:args.rpn_pkl=cache_url(args.rpn_pkl,cfg.DOWNLOAD_CACHE)assertos.path.exists(args.rpn_pkl)assertos.path.exists(args.rpn_cfg)ifargs.models_to_runisnotNone:assertlen(args.models_to_run)%2==0fori,model_fileinenumerate(args.models_to_run):iflen(model_file)>0:ifi%2==0:model_file=cache_url(model_file,cfg.DOWNLOAD_CACHE)args.models_to_run[i]=model_fileassertos.path.exists(model_file),\\\\\\'\\\\\\'{}\\\\\\'doesnotexist\\'.format(model_file)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()check_args(args)main(args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceononeormoredatasets.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importosimportpprintimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TestaFastR-CNNnetwork\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)parser.add_argument(\\'--wait\\',dest=\\'wait\\',help=\\'waituntilnetfileexists\\',default=True,type=bool)parser.add_argument(\\'--vis\\',dest=\\'vis\\',help=\\'visualizedetections\\',action=\\'store_true\\')parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'usingcfg.NUM_GPUSforinference\\',action=\\'store_true\\')parser.add_argument(\\'--range\\',dest=\\'range\\',help=\\'start(inclusive)andend(exclusive)indices\\',default=None,type=int,nargs=2)parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])logger=setup_logging(__name__)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()logger.info(\\'Testingwithconfig:\\')logger.info(pprint.pformat(cfg))whilenotos.path.exists(cfg.TEST.WEIGHTS)andargs.wait:logger.info(\\'Waitingfor\\\\\\'{}\\\\\\'toexist...\\'.format(cfg.TEST.WEIGHTS))time.sleep(10)run_inference(cfg.TEST.WEIGHTS,ind_range=args.range,multi_gpu_testing=args.multi_gpu_testing,check_expected_results=True,)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scriptforvisualizingresultssavedinadetections.pklfile.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2importosimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectimportdetectron.utils.visasvis_utils#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--dataset\\',dest=\\'dataset\\',help=\\'dataset\\',default=\\'coco_2014_minival\\',type=str)parser.add_argument(\\'--detections\\',dest=\\'detections\\',help=\\'detectionspklfile\\',default=\\'\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'detectionprobthreshold\\',default=0.9,type=float)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'./tmp/vis-output\\',type=str)parser.add_argument(\\'--first\\',dest=\\'first\\',help=\\'onlyvisualizethefirstkimages\\',default=0,type=int)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefvis(dataset,detections_pkl,thresh,output_dir,limit=0):ds=JsonDataset(dataset)roidb=ds.get_roidb()dets=load_object(detections_pkl)assertall(kindetsforkin[\\'all_boxes\\',\\'all_segms\\',\\'all_keyps\\']),\\\\\\'Expecteddetectionspklfileintheformatusedbytest_engine.py\\'all_boxes=dets[\\'all_boxes\\']all_segms=dets[\\'all_segms\\']all_keyps=dets[\\'all_keyps\\']defid_or_index(ix,val):iflen(val)==0:returnvalelse:returnval[ix]forix,entryinenumerate(roidb):iflimit>0andix>=limit:breakifix%10==0:print(\\'{:d}/{:d}\\'.format(ix+1,len(roidb)))im=cv2.imread(entry[\\'image\\'])im_name=os.path.splitext(os.path.basename(entry[\\'image\\']))[0]cls_boxes_i=[id_or_index(ix,cls_k_boxes)forcls_k_boxesinall_boxes]cls_segms_i=[id_or_index(ix,cls_k_segms)forcls_k_segmsinall_segms]cls_keyps_i=[id_or_index(ix,cls_k_keyps)forcls_k_keypsinall_keyps]vis_utils.vis_one_image(im[:,:,::-1],\\'{:d}_{:s}\\'.format(ix,im_name),os.path.join(output_dir,\\'vis\\'),cls_boxes_i,segms=cls_segms_i,keypoints=cls_keyps_i,thresh=thresh,box_alpha=0.8,dataset=ds,show_class=True)if__name__==\\'__main__\\':opts=parse_args()vis(opts.dataset,opts.detections,opts.thresh,opts.output_dir,limit=opts.first)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"TrainanetworkwithDetectron.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importloggingimportnumpyasnpimportpprintimportsysfromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.core.configimportmerge_cfg_from_listfromdetectron.core.test_engineimportrun_inferencefromdetectron.utils.loggingimportsetup_loggingimportdetectron.utils.c2asc2_utilsimportdetectron.utils.trainc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'TrainanetworkwithDetectron\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'Configfilefortraining(andoptionallytesting)\\',default=None,type=str)parser.add_argument(\\'--multi-gpu-testing\\',dest=\\'multi_gpu_testing\\',help=\\'Usecfg.NUM_GPUSGPUsforinference\\',action=\\'store_true\\')parser.add_argument(\\'--skip-test\\',dest=\\'skip_test\\',help=\\'Donottestthefinalmodel\\',action=\\'store_true\\')parser.add_argument(\\'opts\\',help=\\'Seedetectron/core/config.pyforalloptions\\',default=None,nargs=argparse.REMAINDER)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain():#InitializeC2workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\',\\'--caffe2_gpu_memory_tracking=1\\'])#Setuploggingandloadconfigoptionslogger=setup_logging(__name__)logging.getLogger(\\'detectron.roi_data.loader\\').setLevel(logging.INFO)args=parse_args()logger.info(\\'Calledwithargs:\\')logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)assert_and_infer_cfg()smi_output,cuda_ver,cudnn_ver=c2_utils.get_nvidia_info()logger.info(\"cudaversion:{}\".format(cuda_ver))logger.info(\"cudnnversion:{}\".format(cudnn_ver))logger.info(\"nvidia-smioutput:\\\\n{}\".format(smi_output))logger.info(\\'Trainingwithconfig:\\')logger.info(pprint.pformat(cfg))#Notethatwhilewesetthenumpyrandomseednetworktrainingwillnotbe#deterministicingeneral.Therearesourcesofnon-determinismthatcannot#beremovedwithareasonbleexecution-speedtradeoff(suchascertain#non-deterministiccudnnfunctions).np.random.seed(cfg.RNG_SEED)#Executethetrainingruncheckpoints=detectron.utils.train.train_model()#Testthetrainedmodelifnotargs.skip_test:test_model(checkpoints[\\'final\\'],args.multi_gpu_testing,args.opts)deftest_model(model_file,multi_gpu_testing,opts=None):\"\"\"Testamodel.\"\"\"#Clearmemorybeforeinferenceworkspace.ResetWorkspace()#Runinferencerun_inference(model_file,multi_gpu_testing=multi_gpu_testing,check_expected_results=True,)if__name__==\\'__main__\\':main()#!/usr/bin/envpython3#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Scripttoconvertthemodel(.yamland.pkl)trainedbytrain_nettoastandardCaffe2modelinpbformat(model.pbandmodel_init.pb).Theconvertedmodelisgoodforproductionusage,asitcouldrunindependentlyandefficientlyonCPU,GPUandmobilewithoutdependingonthedetectroncodebase.PleaseseeCaffe2tutorial(forloadingtheconvertedmodel,andrun_model_pb()forrunningthemodelforinference.\"\"\"from__future__importabsolute_import,division,print_function,unicode_literalsimportargparseimportcopyimportosimportpprintimportsysimportcaffe2.python.utilsasputilsimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importdetectron.core.test_engineastest_engineimportdetectron.utils.blobasblob_utilsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.model_convert_utilsasmutilsimportdetectron.utils.visasvis_utilsimportnumpyasnpfromcaffe2.caffe2.fb.predictorimportpredictor_exporter,predictor_py_utilsfromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcore,workspacefromcaffe2.python.predictor_constantsimportpredictor_constantsfromdetectron.core.configimport(assert_and_infer_cfg,cfg,merge_cfg_from_file,merge_cfg_from_list,)fromdetectron.modelingimportgenerate_anchorsfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.model_convert_utilsimportconvert_op_in_proto,op_filterc2_utils.import_contrib_ops()c2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)logger=setup_logging(__name__)defparse_args():parser=argparse.ArgumentParser(description=\"Convertatrainednetworktopbformat\")parser.add_argument(\"--cfg\",dest=\"cfg_file\",help=\"optionalconfigfile\",default=None,type=str)parser.add_argument(\"--net_name\",dest=\"net_name\",help=\"optionalnameforthenet\",default=\"detectron\",type=str,)parser.add_argument(\"--out_dir\",dest=\"out_dir\",help=\"outputdir\",default=None,type=str)parser.add_argument(\"--test_img\",dest=\"test_img\",help=\"optionaltestimage,usedtoverifythemodelconversion\",default=None,type=str,)parser.add_argument(\"--fuse_af\",dest=\"fuse_af\",help=\"1tofuse_af\",default=1,type=int)parser.add_argument(\"--device\",dest=\"device\",help=\"Devicetorunthemodelon\",choices=[\"cpu\",\"gpu\"],default=\"cpu\",type=str,)parser.add_argument(\"--net_execution_type\",dest=\"net_execution_type\",help=\"caffe2netexecutiontype\",choices=[\"simple\",\"dag\"],default=\"simple\",type=str,)parser.add_argument(\"--use_nnpack\",dest=\"use_nnpack\",help=\"Usennpackforconv\",default=1,type=int,)parser.add_argument(\"--logdb\",dest=\"logdb\",help=\"outputtologfiledbinsteadofpbfiles\",default=0,type=int,)parser.add_argument(\"opts\",help=\"Seedetectron/core/config.pyforalloptions\",default=None,nargs=argparse.REMAINDER,)iflen(sys.argv)==1:parser.print_help()sys.exit(1)ret=parser.parse_args()ret.out_dir=os.path.abspath(ret.out_dir)ifret.device==\"gpu\"andret.use_nnpack:logger.warn(\"Shouldnotusemobileengineforgpumodel.\")ret.use_nnpack=0returnretdefunscope_name(name):returnc2_utils.UnscopeName(name)defreset_names(names):foriinrange(len(names)):names[i]=unscope_name(names[i])defconvert_collect_and_distribute(op,blobs,roi_canonical_scale,roi_canonical_level,roi_max_level,roi_min_level,rpn_max_level,rpn_min_level,rpn_post_nms_topN,):print(\"ConvertingCollectAndDistributeFpnRpnProposals\"\"Python->C++:\\\\n{}\".format(op))assertop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"),\"NotvalidCollectAndDistributeFpnRpnProposalsOp\"inputs=[xforxinop.input]ret=core.CreateOperator(\"CollectAndDistributeFpnRpnProposals\",inputs,list(op.output),roi_canonical_scale=roi_canonical_scale,roi_canonical_level=roi_canonical_level,roi_max_level=roi_max_level,roi_min_level=roi_min_level,rpn_max_level=rpn_max_level,rpn_min_level=rpn_min_level,rpn_post_nms_topN=rpn_post_nms_topN,)returnretdefconvert_gen_proposals(op,blobs,rpn_pre_nms_topN,rpn_post_nms_topN,rpn_nms_thresh,rpn_min_size):print(\"ConvertingGenerateProposalsPython->C++:\\\\n{}\".format(op))assertop.name.startswith(\"GenerateProposalsOp\"),\"NotvalidGenerateProposalsOp\"spatial_scale=mutils.get_op_arg_valf(op,\"spatial_scale\",None)assertspatial_scaleisnotNonelvl=int(op.input[0][-1])ifop.input[0][-1].isdigit()elseNoneinputs=[xforxinop.input]anchor_name=\"anchor{}\".format(lvl)iflvlelse\"anchor\"inputs.append(anchor_name)anchor_sizes=((cfg.FPN.RPN_ANCHOR_START_SIZE*2.0**(lvl-cfg.FPN.RPN_MIN_LEVEL),)iflvlelsecfg.RPN.SIZES)blobs[anchor_name]=get_anchors(spatial_scale,anchor_sizes)print(\"anchors{}\".format(blobs[anchor_name]))ret=core.CreateOperator(\"GenerateProposals\",inputs,list(op.output),spatial_scale=spatial_scale,pre_nms_topN=rpn_pre_nms_topN,post_nms_topN=rpn_post_nms_topN,nms_thresh=rpn_nms_thresh,min_size=rpn_min_size,correct_transform_coords=True,)returnret,anchor_namedefget_anchors(spatial_scale,anchor_sizes):anchors=generate_anchors.generate_anchors(stride=1.0/spatial_scale,sizes=anchor_sizes,aspect_ratios=cfg.RPN.ASPECT_RATIOS,).astype(np.float32)returnanchorsdefreset_blob_names(blobs):ret={unscope_name(x):blobs[x]forxinblobs}blobs.clear()blobs.update(ret)defconvert_net(args,net,blobs):@op_filter()defconvert_op_name(op):ifargs.device!=\"gpu\":ifop.engine!=\"DEPTHWISE_3x3\":op.engine=\"\"op.device_option.CopyFrom(caffe2_pb2.DeviceOption())reset_names(op.input)reset_names(op.output)return[op]@op_filter(type=\"Python\")defconvert_python(op):ifop.name.startswith(\"GenerateProposalsOp\"):gen_proposals_op,ext_input=convert_gen_proposals(op,blobs,rpn_min_size=float(cfg.TEST.RPN_MIN_SIZE),rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,rpn_pre_nms_topN=cfg.TEST.RPN_PRE_NMS_TOP_N,rpn_nms_thresh=cfg.TEST.RPN_NMS_THRESH,)net.external_input.extend([ext_input])return[gen_proposals_op]elifop.name.startswith(\"CollectAndDistributeFpnRpnProposalsOp\"):collect_dist_op=convert_collect_and_distribute(op,blobs,roi_canonical_scale=cfg.FPN.ROI_CANONICAL_SCALE,roi_canonical_level=cfg.FPN.ROI_CANONICAL_LEVEL,roi_max_level=cfg.FPN.ROI_MAX_LEVEL,roi_min_level=cfg.FPN.ROI_MIN_LEVEL,rpn_max_level=cfg.FPN.RPN_MAX_LEVEL,rpn_min_level=cfg.FPN.RPN_MIN_LEVEL,rpn_post_nms_topN=cfg.TEST.RPN_POST_NMS_TOP_N,)return[collect_dist_op]else:raiseValueError(\"FailedtoconvertPythonop{}\".format(op.name))#OnlyconvertUpsampleNearesttoResizeNearestwhenconvertingtopbsothattheexistingmodelsisunchanged##issuecomment-410248561@op_filter(type=\"UpsampleNearest\")defconvert_upsample_nearest(op):forarginop.arg:ifarg.name==\"scale\":scale=arg.ibreakelse:raiseKeyError(\\'Noattribute\"scale\"inUpsampleNearestop\\')resize_nearest_op=core.CreateOperator(\"ResizeNearest\",list(op.input),list(op.output),name=op.name,width_scale=float(scale),height_scale=float(scale),)returnresize_nearest_op@op_filter()defconvert_rpn_rois(op):forjinrange(len(op.input)):ifop.input[j]==\"rois\":print(\"Convertingop{}inputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.input[j]=\"rpn_rois\"forjinrange(len(op.output)):ifop.output[j]==\"rois\":print(\"Convertingop{}outputname:rois->rpn_rois:\\\\n{}\".format(op.type,op))op.output[j]=\"rpn_rois\"return[op]@op_filter(type_in=[\"StopGradient\",\"Alias\"])defconvert_remove_op(op):print(\"Removingop{}:\\\\n{}\".format(op.type,op))return[]#Wewanttoapplytoalloperators,includingconverted#sorunseparatelyconvert_op_in_proto(net,convert_remove_op)convert_op_in_proto(net,convert_upsample_nearest)convert_op_in_proto(net,convert_python)convert_op_in_proto(net,convert_op_name)convert_op_in_proto(net,convert_rpn_rois)reset_names(net.external_input)reset_names(net.external_output)reset_blob_names(blobs)defadd_bbox_ops(args,net,blobs):new_ops=[]new_external_outputs=[]#Operatorsforbboxesop_box=core.CreateOperator(\"BBoxTransform\",[\"rpn_rois\",\"bbox_pred\",\"im_info\"],[\"pred_bbox\"],weights=cfg.MODEL.BBOX_REG_WEIGHTS,apply_scale=False,correct_transform_coords=True,)new_ops.extend([op_box])blob_prob=\"cls_prob\"blob_box=\"pred_bbox\"op_nms=core.CreateOperator(\"BoxWithNMSLimit\",[blob_prob,blob_box],[\"score_nms\",\"bbox_nms\",\"class_nms\"],arg=[putils.MakeArgument(\"score_thresh\",cfg.TEST.SCORE_THRESH),putils.MakeArgument(\"nms\",cfg.TEST.NMS),putils.MakeArgument(\"detections_per_im\",cfg.TEST.DETECTIONS_PER_IM),putils.MakeArgument(\"soft_nms_enabled\",cfg.TEST.SOFT_NMS.ENABLED),putils.MakeArgument(\"soft_nms_method\",cfg.TEST.SOFT_NMS.METHOD),putils.MakeArgument(\"soft_nms_sigma\",cfg.TEST.SOFT_NMS.SIGMA),],)new_ops.extend([op_nms])new_external_outputs.extend([\"score_nms\",\"bbox_nms\",\"class_nms\"])net.Proto().op.extend(new_ops)net.Proto().external_output.extend(new_external_outputs)defconvert_model_gpu(args,net,init_net):assertargs.device==\"gpu\"ret_net=copy.deepcopy(net)ret_init_net=copy.deepcopy(init_net)cdo_cuda=mutils.get_device_option_cuda()cdo_cpu=mutils.get_device_option_cpu()CPU_OPS=[[\"CollectAndDistributeFpnRpnProposals\",None],[\"GenerateProposals\",None],[\"BBoxTransform\",None],[\"BoxWithNMSLimit\",None],]CPU_BLOBS=[\"im_info\",\"anchor\"]@op_filter()defconvert_op_gpu(op):forxinCPU_OPS:ifmutils.filter_op(op,type=x[0],inputs=x[1]):returnNoneop.device_option.CopyFrom(cdo_cuda)return[op]@op_filter()defconvert_init_op_gpu(op):ifop.output[0]inCPU_BLOBS:op.device_option.CopyFrom(cdo_cpu)else:op.device_option.CopyFrom(cdo_cuda)return[op]convert_op_in_proto(ret_init_net.Proto(),convert_init_op_gpu)convert_op_in_proto(ret_net.Proto(),convert_op_gpu)ret=core.InjectDeviceCopiesAmongNets([ret_init_net,ret_net])return[ret[0][1],ret[0][0]]defgen_init_net(net,blobs,empty_blobs):blobs=copy.deepcopy(blobs)forxinempty_blobs:blobs[x]=np.array([],dtype=np.float32)init_net=mutils.gen_init_net_from_blobs(blobs,net.external_inputs)init_net=core.Net(init_net)returninit_netdef_save_image_graphs(args,all_net,all_init_net):print(\"Savingmodelgraph...\")mutils.save_graph(all_net.Proto(),os.path.join(args.out_dir,\"model_def.png\"),op_only=False)print(\"Modeldefimagesavedto{}.\".format(args.out_dir))def_save_models(all_net,all_init_net,args):print(\"Writingconvertedmodelto{}...\".format(args.out_dir))fname=\"model\"ifnotos.path.exists(args.out_dir):os.makedirs(args.out_dir)withopen(os.path.join(args.out_dir,fname+\".pb\"),\"wb\")asf:f.write(all_net.Proto().SerializeToString())withopen(os.path.join(args.out_dir,fname+\".pbtxt\"),\"wb\")asf:f.write(str(all_net.Proto()))withopen(os.path.join(args.out_dir,fname+\"_init.pb\"),\"wb\")asf:f.write(all_init_net.Proto().SerializeToString())_save_image_graphs(args,all_net,all_init_net)defload_model(args):model=test_engine.initialize_model_from_cfg(cfg.TEST.WEIGHTS)blobs=mutils.get_ws_blobs()returnmodel,blobsdef_get_result_blobs(check_blobs):ret={}forxincheck_blobs:sn=core.ScopedName(x)ifworkspace.HasBlob(sn):ret[x]=workspace.FetchBlob(sn)else:ret[x]=Nonereturnretdef_sort_results(boxes,segms,keypoints,classes):indices=np.argsort(boxes[:,-1])[::-1]ifboxesisnotNone:boxes=boxes[indices,:]ifsegmsisnotNone:segms=[segms[x]forxinindices]ifkeypointsisnotNone:keypoints=[keypoints[x]forxinindices]ifclassesisnotNone:ifisinstance(classes,list):classes=[classes[x]forxinindices]else:classes=classes[indices]returnboxes,segms,keypoints,classesdefrun_model_cfg(args,im,check_blobs):workspace.ResetWorkspace()model,_=load_model(args)withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=test_engine.im_detect_all(model,im,None,None)boxes,segms,keypoints,classes=vis_utils.convert_from_cls_format(cls_boxes,cls_segms,cls_keyps)#sorttheresultsbasedonscoreforcomparisionboxes,segms,keypoints,classes=_sort_results(boxes,segms,keypoints,classes)#writefinalresultsbacktoworkspacedef_ornone(res):returnnp.array(res)ifresisnotNoneelsenp.array([],dtype=np.float32)withc2_utils.NamedCudaScope(0):workspace.FeedBlob(core.ScopedName(\"result_boxes\"),_ornone(boxes))workspace.FeedBlob(core.ScopedName(\"result_segms\"),_ornone(segms))workspace.FeedBlob(core.ScopedName(\"result_keypoints\"),_ornone(keypoints))workspace.FeedBlob(core.ScopedName(\"result_classids\"),_ornone(classes))#getresultblobswithc2_utils.NamedCudaScope(0):ret=_get_result_blobs(check_blobs)returnretdef_prepare_blobs(im,pixel_means,target_size,max_size):\"\"\"Reference:blob.prep_im_for_blob()\"\"\"im=im.astype(np.float32,copy=False)im-=pixel_meansim_shape=im.shapeim_size_min=np.min(im_shape[0:2])im_size_max=np.max(im_shape[0:2])im_scale=float(target_size)/float(im_size_min)ifnp.round(im_scale*im_size_max)>max_size:im_scale=float(max_size)/float(im_size_max)im=cv2.resize(im,None,None,fx=im_scale,fy=im_scale,interpolation=cv2.INTER_LINEAR)#Reusecodeinblob_utilsandfitFPNblob=blob_utils.im_list_to_blob([im])blobs={}blobs[\"data\"]=blobblobs[\"im_info\"]=np.array([[blob.shape[2],blob.shape[3],im_scale]],dtype=np.float32)returnblobsdefrun_model_pb(args,net,init_net,im,check_blobs):workspace.ResetWorkspace()workspace.RunNetOnce(init_net)mutils.create_input_blobs_for_net(net.Proto())workspace.CreateNet(net)#input_blobs,_=core_test._get_blobs(im,None)input_blobs=_prepare_blobs(im,cfg.PIXEL_MEANS,cfg.TEST.SCALE,cfg.TEST.MAX_SIZE)gpu_blobs=[]ifargs.device==\"gpu\":gpu_blobs=[\"data\"]fork,vininput_blobs.items():workspace.FeedBlob(core.ScopedName(k),v,mutils.get_device_option_cuda()ifkingpu_blobselsemutils.get_device_option_cpu(),)try:workspace.RunNet(net)scores=workspace.FetchBlob(\"score_nms\")classids=workspace.FetchBlob(\"class_nms\")boxes=workspace.FetchBlob(\"bbox_nms\")exceptExceptionase:print(\"Runningpbmodelfailed.\\\\n{}\".format(e))#maynotdetectanythingatallR=0scores=np.zeros((R,),dtype=np.float32)boxes=np.zeros((R,4),dtype=np.float32)classids=np.zeros((R,),dtype=np.float32)boxes=np.column_stack((boxes,scores))#sorttheresultsbasedonscoreforcomparisionboxes,_,_,classids=_sort_results(boxes,None,None,classids)#writefinalresultbacktoworkspaceworkspace.FeedBlob(\"result_boxes\",boxes)workspace.FeedBlob(\"result_classids\",classids)ret=_get_result_blobs(check_blobs)returnretdefverify_model(args,model_pb,test_img_file):check_blobs=[\"result_boxes\",\"result_classids\"]#resultprint(\"Loadingtestfile{}...\".format(test_img_file))test_img=cv2.imread(test_img_file)asserttest_imgisnotNonedef_run_cfg_func(im,blobs):returnrun_model_cfg(args,im,check_blobs)def_run_pb_func(im,blobs):returnrun_model_pb(args,model_pb[0],model_pb[1],im,check_blobs)print(\"Checkingmodels...\")assertmutils.compare_model(_run_cfg_func,_run_pb_func,test_img,check_blobs)def_export_to_logfiledb(args,net,init_net,inputs,out_file,extra_out_tensors=None):out_tensors=list(net.Proto().external_output)ifextra_out_tensorsisnotNone:out_tensors+=extra_out_tensorsparams=list(set(net.Proto().external_input)-set(inputs))net_type=Nonepredictor_export_meta=predictor_exporter.PredictorExportMeta(predict_net=net,parameters=params,inputs=inputs,outputs=out_tensors,net_type=net_type,)logger.info(\"ExportingCaffe2modelto{}\".format(out_file))predictor_exporter.save_to_db(db_type=\"log_file_db\",db_destination=out_file,predictor_export_meta=predictor_export_meta,)defmain():workspace.GlobalInit([\"caffe2\",\"--caffe2_log_level=0\"])args=parse_args()logger.info(\"Calledwithargs:\")logger.info(args)ifargs.cfg_fileisnotNone:merge_cfg_from_file(args.cfg_file)ifargs.optsisnotNone:merge_cfg_from_list(args.opts)cfg.NUM_GPUS=1assert_and_infer_cfg()logger.info(\"Convertingmodelwithconfig:\")logger.info(pprint.pformat(cfg))#scriptwillstopwhenitcan\\'tfindanoperatorrather#thanstoppingbasedontheseflags##assertnotcfg.MODEL.KEYPOINTS_ON,\"Keypointmodelnotsupported.\"#assertnotcfg.MODEL.MASK_ON,\"Maskmodelnotsupported.\"#assertnotcfg.FPN.FPN_ON,\"FPNnotsupported.\"#assertnotcfg.RETINANET.RETINANET_ON,\"RetinaNetmodelnotsupported.\"#loadmodelfromcfgmodel,blobs=load_model(args)net=core.Net(\"\")net.Proto().op.extend(copy.deepcopy(model.net.Proto().op))net.Proto().external_input.extend(copy.deepcopy(model.net.Proto().external_input))net.Proto().external_output.extend(copy.deepcopy(model.net.Proto().external_output))net.Proto().type=args.net_execution_typenet.Proto().num_workers=1ifargs.net_execution_type==\"simple\"else4#Resetthedevice_option,changetounscopenameandreplacepythonoperatorsconvert_net(args,net.Proto(),blobs)#addoperatorsforbboxadd_bbox_ops(args,net,blobs)ifargs.fuse_af:print(\"Fusingaffinechannel...\")net,blobs=mutils.fuse_net_affine(net,blobs)ifargs.use_nnpack:mutils.update_mobile_engines(net.Proto())#generateinitnetempty_blobs=[\"data\",\"im_info\"]init_net=gen_init_net(net,blobs,empty_blobs)ifargs.device==\"gpu\":[net,init_net]=convert_model_gpu(args,net,init_net)net.Proto().name=args.net_nameinit_net.Proto().name=args.net_name+\"_init\"ifargs.test_imgisnotNone:verify_model(args,[net,init_net],args.test_img)ifargs.logdb==1:output_file=os.path.join(args.out_dir,\"model.logfiledb\")_export_to_logfiledb(args,net,init_net,empty_blobs,output_file)else:_save_models(net,init_net,args)if__name__==\"__main__\":main()#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScriptforconvertingCaffe(<=1.0)modelsintothethesimplestatedictformatusedbyDetectron.Forexample,thisscriptcanconverttheorignalResNetmodelsreleasedbyMSRA.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysfromcaffe.protoimportcaffe_pb2fromcaffe2.protoimportcaffe2_pb2fromcaffe2.pythonimportcaffe_translatorfromcaffe2.pythonimportutilsfromgoogle.protobufimporttext_formatfromdetectron.utils.ioimportsave_objectdefparse_args():parser=argparse.ArgumentParser(description=\\'DumpweightsfromaCaffemodel\\')parser.add_argument(\\'--prototxt\\',dest=\\'prototxt_file_name\\',help=\\'Networkdefinitionprototxtfilepath\\',default=None,type=str)parser.add_argument(\\'--caffemodel\\',dest=\\'caffemodel_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefnormalize_resnet_name(name):ifname.find(\\'res\\')==0andname.find(\\'res_\\')==-1:#E.g.,#res4b11_branch2c->res4_11_branch2c#res2a_branch1->res2_0_branch1chunk=name[len(\\'res\\'):name.find(\\'_\\')]name=(\\'res\\'+chunk[0]+\\'_\\'+str(int(chunk[2:])iflen(chunk)>2#e.g.,\"b1\"->1elseord(chunk[1])-ord(\\'a\\'))+#e.g.,\"a\"->0name[name.find(\\'_\\'):])returnnamedefpickle_weights(out_file_name,weights):blobs={normalize_resnet_name(blob.name):utils.Caffe2TensorToNumpyArray(blob)forblobinweights.protos}save_object(blobs,out_file_name)print(\\'Wroteblobs:\\')print(sorted(blobs.keys()))defadd_missing_biases(caffenet_weights):forlayerincaffenet_weights.layer:iflayer.type==\\'Convolution\\'andlen(layer.blobs)==1:num_filters=layer.blobs[0].shape.dim[0]bias_blob=caffe_pb2.BlobProto()bias_blob.data.extend(np.zeros(num_filters))bias_blob.num,bias_blob.channels,bias_blob.height=1,1,1bias_blob.width=num_filterslayer.blobs.extend([bias_blob])defremove_spatial_bn_layers(caffenet,caffenet_weights):#Layertypesassociatedwithspatialbatchnormremove_types=[\\'BatchNorm\\',\\'Scale\\']def_remove_layers(net):foriinreversed(range(len(net.layer))):ifnet.layer[i].typeinremove_types:net.layer.pop(i)#Firstremovelayersfromcaffenetproto_remove_layers(caffenet)#We\\'llreturnthesesowecansavethebatchnormparametersbn_layers=[layerforlayerincaffenet_weights.layeriflayer.typeinremove_types]_remove_layers(caffenet_weights)def_create_tensor(arr,shape,name):t=caffe2_pb2.TensorProto()t.name=namet.data_type=caffe2_pb2.TensorProto.FLOATt.dims.extend(shape.dim)t.float_data.extend(arr)assertlen(t.float_data)==np.prod(t.dims),\\'Datasize,shapemismatch\\'returntbn_tensors=[]for(bn,scl)inzip(bn_layers[0::2],bn_layers[1::2]):assertbn.name[len(\\'bn\\'):]==scl.name[len(\\'scale\\'):],\\'Pairmismatch\\'blob_out=\\'res\\'+bn.name[len(\\'bn\\'):]+\\'_bn\\'bn_mean=np.asarray(bn.blobs[0].data)bn_var=np.asarray(bn.blobs[1].data)scale=np.asarray(scl.blobs[0].data)bias=np.asarray(scl.blobs[1].data)std=np.sqrt(bn_var+1e-5)new_scale=scale/stdnew_bias=bias-bn_mean*scale/stdnew_scale_tensor=_create_tensor(new_scale,bn.blobs[0].shape,blob_out+\\'_s\\')new_bias_tensor=_create_tensor(new_bias,bn.blobs[0].shape,blob_out+\\'_b\\')bn_tensors.extend([new_scale_tensor,new_bias_tensor])returnbn_tensorsdefremove_layers_without_parameters(caffenet,caffenet_weights):foriinreversed(range(len(caffenet_weights.layer))):iflen(caffenet_weights.layer[i].blobs)==0:#Searchforthecorrespondinglayerincaffenetandremoveitname=caffenet_weights.layer[i].namefound=Falseforjinrange(len(caffenet.layer)):ifcaffenet.layer[j].name==name:caffenet.layer.pop(j)found=Truebreakifnotfoundandname[-len(\\'_split\\'):]!=\\'_split\\':print(\\'Warning:layer{}notfoundincaffenet\\'.format(name))caffenet_weights.layer.pop(i)defnormalize_shape(caffenet_weights):forlayerincaffenet_weights.layer:forblobinlayer.blobs:shape=(blob.num,blob.channels,blob.height,blob.width)iflen(blob.data)!=np.prod(shape):shape=tuple(blob.shape.dim)iflen(shape)==1:#Handlebiasesshape=(1,1,1,shape[0])iflen(shape)==2:#HandleInnerProductlayersshape=(1,1,shape[0],shape[1])assertlen(shape)==4blob.num,blob.channels,blob.height,blob.width=shapedefload_and_convert_caffe_model(prototxt_file_name,caffemodel_file_name):caffenet=caffe_pb2.NetParameter()caffenet_weights=caffe_pb2.NetParameter()text_format.Merge(open(prototxt_file_name).read(),caffenet)caffenet_weights.ParseFromString(open(caffemodel_file_name).read())#C2convlayerscurrentrequirebiases,buttheyareoptionalinC1#Addzerosasbiasesistheyaremissingadd_missing_biases(caffenet_weights)#Weonlycareaboutgettingparameters,soremovelayersw/oparametersremove_layers_without_parameters(caffenet,caffenet_weights)#BatchNormisnotimplementedinthetranslator*and*weneedtofoldScale#layersintothenewC2SpatialBNop,henceweremovethebatchnormlayers#andapplycustomtranslationscodebn_weights=remove_spatial_bn_layers(caffenet,caffenet_weights)#Setnum,channel,heightandwidthforblobsthatuseshape.diminsteadnormalize_shape(caffenet_weights)#Translatetherestofthemodelnet,pretrained_weights=caffe_translator.TranslateModel(caffenet,caffenet_weights)pretrained_weights.protos.extend(bn_weights)returnnet,pretrained_weightsif__name__==\\'__main__\\':args=parse_args()assertos.path.exists(args.prototxt_file_name),\\\\\\'Prototxtfiledoesnotexist\\'assertos.path.exists(args.caffemodel_file_name),\\\\\\'Weightsfiledoesnotexist\\'net,weights=load_and_convert_caffe_model(args.prototxt_file_name,args.caffemodel_file_name)pickle_weights(args.out_file_name,weights)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.###############################################################################ConvertadetectionmodeltrainedforCOCOintoamodelthatcanbefine-tuned#oncityscapes##cityscapes_to_cocofrom__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportnumpyasnpimportosimportsysimportdetectron.datasets.coco_to_cityscapes_idascsfromdetectron.utils.ioimportload_objectfromdetectron.utils.ioimportsave_objectNUM_CS_CLS=9NUM_COCO_CLS=81defparse_args():parser=argparse.ArgumentParser(description=\\'ConvertaCOCOpre-trainedmodelforusewithCityscapes\\')parser.add_argument(\\'--coco_model\\',dest=\\'coco_model_file_name\\',help=\\'Pretrainednetworkweightsfilepath\\',default=None,type=str)parser.add_argument(\\'--convert_func\\',dest=\\'convert_func\\',help=\\'Blobconversionfunction\\',default=\\'cityscapes_to_coco\\',type=str)parser.add_argument(\\'--output\\',dest=\\'out_file_name\\',help=\\'Outputfilepath\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert_coco_blobs_to_cityscape_blobs(model_dict):fork,vinmodel_dict[\\'blobs\\'].items():ifv.shape[0]==NUM_COCO_CLSorv.shape[0]==4*NUM_COCO_CLS:coco_blob=model_dict[\\'blobs\\'][k]print(\\'ConvertingCOCOblob{}withshape{}\\'.format(k,coco_blob.shape))cs_blob=convert_coco_blob_to_cityscapes_blob(coco_blob,args.convert_func)print(\\'->convertedshape{}\\'.format(cs_blob.shape))model_dict[\\'blobs\\'][k]=cs_blobdefconvert_coco_blob_to_cityscapes_blob(coco_blob,convert_func):#cocoblob(81,...)or(81*4,...)coco_shape=coco_blob.shapeleading_factor=int(coco_shape[0]/NUM_COCO_CLS)tail_shape=list(coco_shape[1:])assertleading_factor==1orleading_factor==4#Reshapein[num_classes,...]formforeasiermanipulationscoco_blob=coco_blob.reshape([NUM_COCO_CLS,-1]+tail_shape)#DefaultinitializationusesGaussianwithmeanandstdtomatchthe#existingparametersstd=coco_blob.std()mean=coco_blob.mean()cs_shape=[NUM_CS_CLS]+list(coco_blob.shape[1:])cs_blob=(np.random.randn(*cs_shape)*std+mean).astype(np.float32)#ReplacerandomparameterswithCOCOparametersifclassmappingexistsforiinrange(NUM_CS_CLS):coco_cls_id=getattr(cs,convert_func)(i)ifcoco_cls_id>=0:#otherwiseignore(randinit)cs_blob[i]=coco_blob[coco_cls_id]cs_shape=[NUM_CS_CLS*leading_factor]+tail_shapereturncs_blob.reshape(cs_shape)defremove_momentum(model_dict):forkinmodel_dict[\\'blobs\\'].keys():ifk.endswith(\\'_momentum\\'):delmodel_dict[\\'blobs\\'][k]defload_and_convert_coco_model(args):model_dict=load_object(args.coco_model_file_name)remove_momentum(model_dict)convert_coco_blobs_to_cityscape_blobs(model_dict)returnmodel_dictif__name__==\\'__main__\\':args=parse_args()print(args)assertos.path.exists(args.coco_model_file_name),\\\\\\'Weightsfiledoesnotexist\\'weights=load_and_convert_coco_model(args)save_object(weights,args.out_file_name)print(\\'Wroteblobsto{}:\\'.format(args.out_file_name))print(sorted(weights[\\'blobs\\'].keys()))#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimporth5pyimportjsonimportosimportimageioimportsysimportcityscapesscripts.evaluation.instances2dict_with_polygonsascsimportdetectron.utils.segmsassegms_utilimportdetectron.utils.boxesasbboxs_utildefparse_args():parser=argparse.ArgumentParser(description=\\'Convertdataset\\')parser.add_argument(\\'--dataset\\',help=\"cocostuff,cityscapes\",default=None,type=str)parser.add_argument(\\'--outdir\\',help=\"outputdirforjsonfiles\",default=None,type=str)parser.add_argument(\\'--datadir\\',help=\"datadirforannotationstobeconverted\",default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defconvert_coco_stuff_mat(data_dir,out_dir):\"\"\"Converttopngandsavejsonwithpath.Thiscurrentlyonlycontainsthesegmentationlabelsforobjects+stuffincocostuff-ifweneedtocombinewithotherlabelsfromoriginalCOCOthatwillbeaTODO.\"\"\"sets=[\\'train\\',\\'val\\']categories=[]json_name=\\'coco_stuff_%s.json\\'ann_dict={}fordata_setinsets:file_list=os.path.join(data_dir,\\'%s.txt\\')images=[]withopen(file_list%data_set)asf:forimg_id,img_nameinenumerate(f):img_name=img_name.replace(\\'coco\\',\\'COCO\\').strip(\\'\\\\n\\')image={}mat_file=os.path.join(data_dir,\\'annotations/%s.mat\\'%img_name)data=h5py.File(mat_file,\\'r\\')labelMap=data.get(\\'S\\')iflen(categories)==0:labelNames=data.get(\\'names\\')foridx,ninenumerate(labelNames):categories.append({\"id\":idx,\"name\":\\'\\'.join(chr(i)foriindata[n[0]])})ann_dict[\\'categories\\']=categoriesimageio.imsave(os.path.join(data_dir,img_name+\\'.png\\'),labelMap)image[\\'width\\']=labelMap.shape[0]image[\\'height\\']=labelMap.shape[1]image[\\'file_name\\']=img_nameimage[\\'seg_file_name\\']=img_nameimage[\\'id\\']=img_idimages.append(image)ann_dict[\\'images\\']=imagesprint(\"Numimages:%s\"%len(images))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))#forCityscapesdefgetLabelID(self,instID):if(instID<1000):returninstIDelse:returnint(instID/1000)defconvert_cityscapes_instance_only(data_dir,out_dir):\"\"\"ConvertfromcityscapesformattoCOCOinstancesegformat-polygons\"\"\"sets=[\\'gtFine_val\\',#\\'gtFine_train\\',#\\'gtFine_test\\',#\\'gtCoarse_train\\',#\\'gtCoarse_val\\',#\\'gtCoarse_train_extra\\']ann_dirs=[\\'gtFine_trainvaltest/gtFine/val\\',#\\'gtFine_trainvaltest/gtFine/train\\',#\\'gtFine_trainvaltest/gtFine/test\\',#\\'gtCoarse/train\\',#\\'gtCoarse/train_extra\\',#\\'gtCoarse/val\\']json_name=\\'instancesonly_filtered_%s.json\\'ends_in=\\'%s_polygons.json\\'img_id=0ann_id=0cat_id=1category_dict={}category_instancesonly=[\\'person\\',\\'rider\\',\\'car\\',\\'truck\\',\\'bus\\',\\'train\\',\\'motorcycle\\',\\'bicycle\\',]fordata_set,ann_dirinzip(sets,ann_dirs):print(\\'Starting%s\\'%data_set)ann_dict={}images=[]annotations=[]ann_dir=os.path.join(data_dir,ann_dir)forroot,_,filesinos.walk(ann_dir):forfilenameinfiles:iffilename.endswith(ends_in%data_set.split(\\'_\\')[0]):iflen(images)%50==0:print(\"Processed%simages,%sannotations\"%(len(images),len(annotations)))json_ann=json.load(open(os.path.join(root,filename)))image={}image[\\'id\\']=img_idimg_id+=1image[\\'width\\']=json_ann[\\'imgWidth\\']image[\\'height\\']=json_ann[\\'imgHeight\\']image[\\'file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\'leftImg8bit.png\\'image[\\'seg_file_name\\']=filename[:-len(ends_in%data_set.split(\\'_\\')[0])]+\\\\\\'%s_instanceIds.png\\'%data_set.split(\\'_\\')[0]images.append(image)fullname=os.path.join(root,image[\\'seg_file_name\\'])objects=cs.instances2dict_with_polygons([fullname],verbose=False)[fullname]forobject_clsinobjects:ifobject_clsnotincategory_instancesonly:continue#skipnon-instancecategoriesforobjinobjects[object_cls]:ifobj[\\'contours\\']==[]:print(\\'Warning:emptycontours.\\')continue#skipnon-instancecategorieslen_p=[len(p)forpinobj[\\'contours\\']]ifmin(len_p)<=4:print(\\'Warning:invalidcontours.\\')continue#skipnon-instancecategoriesann={}ann[\\'id\\']=ann_idann_id+=1ann[\\'image_id\\']=image[\\'id\\']ann[\\'segmentation\\']=obj[\\'contours\\']ifobject_clsnotincategory_dict:category_dict[object_cls]=cat_idcat_id+=1ann[\\'category_id\\']=category_dict[object_cls]ann[\\'iscrowd\\']=0ann[\\'area\\']=obj[\\'pixelCount\\']ann[\\'bbox\\']=bboxs_util.xyxy_to_xywh(segms_util.polys_to_boxes([ann[\\'segmentation\\']])).tolist()[0]annotations.append(ann)ann_dict[\\'images\\']=imagescategories=[{\"id\":category_dict[name],\"name\":name}fornameincategory_dict]ann_dict[\\'categories\\']=categoriesann_dict[\\'annotations\\']=annotationsprint(\"Numcategories:%s\"%len(categories))print(\"Numimages:%s\"%len(images))print(\"Numannotations:%s\"%len(annotations))withopen(os.path.join(out_dir,json_name%data_set),\\'wb\\')asoutfile:outfile.write(json.dumps(ann_dict))if__name__==\\'__main__\\':args=parse_args()ifargs.dataset==\"cityscapes_instance_only\":convert_cityscapes_instance_only(args.datadir,args.outdir)elifargs.dataset==\"cocostuff\":convert_coco_stuff_mat(args.datadir,args.outdir)else:print(\"Datasetnotsupported:%s\"%args.dataset)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Givenafullsetofresults(boxes,masks,orkeypoints)onthe2017COCOtestset,thisscriptextractstheresultssubsetthatcorrespondsto2017test-dev.Thetest-devsubsetcanthenbesubmittedtotheCOCOevaluationserver.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportjsonimportosimportsysfromdetectron.datasets.dataset_catalogimportget_ann_fnfromdetectron.utils.timerimportTimerdefparse_args():parser=argparse.ArgumentParser()parser.add_argument(\\'--json\\',dest=\\'json_file\\',help=\\'detectionsjsonfile\\',default=\\'\\',type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'outputdirectory\\',default=\\'/tmp\\',type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefconvert(json_file,output_dir):print(\\'Reading:{}\\'.format(json_file))withopen(json_file,\\'r\\')asfid:dt=json.load(fid)print(\\'done!\\')test_image_info=get_ann_fn(\\'coco_2017_test\\')withopen(test_image_info,\\'r\\')asfid:info_test=json.load(fid)image_test=info_test[\\'images\\']image_test_id=[i[\\'id\\']foriinimage_test]print(\\'{}has{}images\\'.format(test_image_info,len(image_test_id)))test_dev_image_info=get_ann_fn(\\'coco_2017_test-dev\\')withopen(test_dev_image_info,\\'r\\')asfid:info_testdev=json.load(fid)image_testdev=info_testdev[\\'images\\']image_testdev_id=[i[\\'id\\']foriinimage_testdev]print(\\'{}has{}images\\'.format(test_dev_image_info,len(image_testdev_id)))dt_testdev=[]print(\\'Filteringtest-devfromtest...\\')t=Timer()t.tic()foriinrange(len(dt)):ifi%1000==0:print(\\'{}/{}\\'.format(i,len(dt)))ifdt[i][\\'image_id\\']inimage_testdev_id:dt_testdev.append(dt[i])print(\\'Donefiltering({:2}s)!\\'.format(t.toc()))filename,file_extension=os.path.splitext(os.path.basename(json_file))filename=filename+\\'_test-dev\\'filename=os.path.join(output_dir,filename+file_extension)withopen(filename,\\'w\\')asfid:info_test=json.dump(dt_testdev,fid)print(\\'Donewriting:{}!\\'.format(filename))if__name__==\\'__main__\\':opts=parse_args()convert(opts.json_file,opts.output_dir)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.################################################################################Basedon:#--------------------------------------------------------#FastR-CNN#Copyright(c)2015Microsoft#LicensedunderTheMITLicense[seeLICENSEfordetails]#WrittenbyRossGirshick#--------------------------------------------------------\"\"\"Reval=re-eval.Re-evaluatesaveddetections.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportargparseimportosimportsysfromdetectron.core.configimportcfgfromdetectron.datasetsimporttask_evaluationfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportload_objectfromdetectron.utils.loggingimportsetup_loggingimportdetectron.core.configascore_configdefparse_args():parser=argparse.ArgumentParser(description=\\'Re-evaluateresults\\')parser.add_argument(\\'output_dir\\',nargs=1,help=\\'resultsdirectory\\',type=str)parser.add_argument(\\'--dataset\\',dest=\\'dataset_name\\',help=\\'datasettore-evaluate\\',default=\\'voc_2007_test\\',type=str)parser.add_argument(\\'--matlab\\',dest=\\'matlab_eval\\',help=\\'usematlabforevaluation\\',action=\\'store_true\\')parser.add_argument(\\'--comp\\',dest=\\'comp_mode\\',help=\\'competitionmode\\',action=\\'store_true\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg_file\\',help=\\'optionalconfigfile\\',default=None,type=str)iflen(sys.argv)==1:parser.print_help()sys.exit(1)args=parser.parse_args()returnargsdefdo_reval(dataset_name,output_dir,args):dataset=JsonDataset(dataset_name)dets=load_object(os.path.join(output_dir,\\'detections.pkl\\'))#Overrideconfigwiththeonesavedinthedetectionsfileifargs.cfg_fileisnotNone:core_config.merge_cfg_from_cfg(core_config.load_cfg(dets[\\'cfg\\']))else:core_config._merge_a_into_b(core_config.load_cfg(dets[\\'cfg\\']),cfg)results=task_evaluation.evaluate_all(dataset,dets[\\'all_boxes\\'],dets[\\'all_segms\\'],dets[\\'all_keyps\\'],output_dir,use_matlab=args.matlab_eval)task_evaluation.log_copy_paste_friendly_results(results)if__name__==\\'__main__\\':setup_logging(__name__)args=parse_args()ifargs.comp_mode:cfg.TEST.COMPETITION_MODE=Trueoutput_dir=os.path.abspath(args.output_dir[0])do_reval(args.dataset_name,output_dir,args)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"ScripttoconvertSelectiveSearchproposalboxesintotheDetectronproposalfileformat.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsimportnumpyasnpimportscipy.ioassioimportsysfromdetectron.datasets.json_datasetimportJsonDatasetfromdetectron.utils.ioimportsave_objectif__name__==\\'__main__\\':dataset_name=sys.argv[1]file_in=sys.argv[2]file_out=sys.argv[3]ds=JsonDataset(dataset_name)roidb=ds.get_roidb()raw_data=sio.loadmat(file_in)[\\'boxes\\'].ravel()assertraw_data.shape[0]==len(roidb)boxes=[]scores=[]ids=[]foriinrange(raw_data.shape[0]):ifi%1000==0:print(\\'{}/{}\\'.format(i+1,len(roidb)))#selectivesearchboxesare1-indexedand(y1,x1,y2,x2)i_boxes=raw_data[i][:,(1,0,3,2)]-1boxes.append(i_boxes.astype(np.float32))scores.append(np.zeros((i_boxes.shape[0]),dtype=np.float32))ids.append(roidb[i][\\'id\\'])save_object(dict(boxes=boxes,scores=scores,indexes=ids),file_out)#!/usr/bin/envpython#Copyright(c)2017-present,Facebook,Inc.##LicensedundertheApacheLicense,Version2.0(the\"License\");#youmaynotusethisfileexceptincompliancewiththeLicense.#YoumayobtainacopyoftheLicenseat####Unlessrequiredbyapplicablelaworagreedtoinwriting,software#distributedundertheLicenseisdistributedonan\"ASIS\"BASIS,#WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.#SeetheLicenseforthespecificlanguagegoverningpermissionsand#limitationsundertheLicense.##############################################################################\"\"\"Performinferenceonasingleimageorallimageswithacertainextension(e.g.,.jpg)inafolder.\"\"\"from__future__importabsolute_importfrom__future__importdivisionfrom__future__importprint_functionfrom__future__importunicode_literalsfromcollectionsimportdefaultdictimportargparseimportcv2#NOQA(Mustimportbeforeimportingcaffe2duetobugincv2)importglobimportloggingimportosimportsysimporttimefromcaffe2.pythonimportworkspacefromdetectron.core.configimportassert_and_infer_cfgfromdetectron.core.configimportcfgfromdetectron.core.configimportmerge_cfg_from_filefromdetectron.utils.ioimportcache_urlfromdetectron.utils.loggingimportsetup_loggingfromdetectron.utils.timerimportTimerimportdetectron.core.test_engineasinfer_engineimportdetectron.datasets.dummy_datasetsasdummy_datasetsimportdetectron.utils.c2asc2_utilsimportdetectron.utils.visasvis_utilsc2_utils.import_detectron_ops()#OpenCLmaybeenabledbydefaultinOpenCV3;disableitbecauseit\\'snot#threadsafeandcausesunwantedGPUmemoryallocations.cv2.ocl.setUseOpenCL(False)defparse_args():parser=argparse.ArgumentParser(description=\\'End-to-endinference\\')parser.add_argument(\\'--cfg\\',dest=\\'cfg\\',help=\\'cfgmodelfile(/path/to/model_config.yaml)\\',default=None,type=str)parser.add_argument(\\'--wts\\',dest=\\'weights\\',help=\\'weightsmodelfile(/path/to/model_weights.pkl)\\',default=None,type=str)parser.add_argument(\\'--output-dir\\',dest=\\'output_dir\\',help=\\'directoryforvisualizationpdfs(default:/tmp/infer_simple)\\',default=\\'/tmp/infer_simple\\',type=str)parser.add_argument(\\'--image-ext\\',dest=\\'image_ext\\',help=\\'imagefilenameextension(default:jpg)\\',default=\\'jpg\\',type=str)parser.add_argument(\\'--always-out\\',dest=\\'out_when_no_box\\',help=\\'outputimageevenwhennoobjectisfound\\',action=\\'store_true\\')parser.add_argument(\\'--output-ext\\',dest=\\'output_ext\\',help=\\'outputimagefileformat(default:pdf)\\',default=\\'pdf\\',type=str)parser.add_argument(\\'--thresh\\',dest=\\'thresh\\',help=\\'Thresholdforvisualizingdetections\\',default=0.7,type=float)parser.add_argument(\\'--kp-thresh\\',dest=\\'kp_thresh\\',help=\\'Thresholdforvisualizingkeypoints\\',default=2.0,type=float)parser.add_argument(\\'im_or_folder\\',help=\\'imageorfolderofimages\\',default=None)iflen(sys.argv)==1:parser.print_help()sys.exit(1)returnparser.parse_args()defmain(args):logger=logging.getLogger(__name__)merge_cfg_from_file(args.cfg)cfg.NUM_GPUS=1args.weights=cache_url(args.weights,cfg.DOWNLOAD_CACHE)assert_and_infer_cfg(cache_urls=False)assertnotcfg.MODEL.RPN_ONLY,\\\\\\'RPNmodelsarenotsupported\\'assertnotcfg.TEST.PRECOMPUTED_PROPOSALS,\\\\\\'Modelsthatrequireprecomputedproposalsarenotsupported\\'model=infer_engine.initialize_model_from_cfg(args.weights)dummy_coco_dataset=dummy_datasets.get_coco_dataset()ifos.path.isdir(args.im_or_folder):im_list=glob.iglob(args.im_or_folder+\\'/*.\\'+args.image_ext)else:im_list=[args.im_or_folder]fori,im_nameinenumerate(im_list):out_name=os.path.join(args.output_dir,\\'{}\\'.format(os.path.basename(im_name)+\\'.\\'+args.output_ext))logger.info(\\'Processing{}->{}\\'.format(im_name,out_name))im=cv2.imread(im_name)timers=defaultdict(Timer)t=time.time()withc2_utils.NamedCudaScope(0):cls_boxes,cls_segms,cls_keyps=infer_engine.im_detect_all(model,im,None,timers=timers)logger.info(\\'Inferencetime:{:.3f}s\\'.format(time.time()-t))fork,vintimers.items():logger.info(\\'|{}:{:.3f}s\\'.format(k,v.average_time))ifi==0:logger.info(\\'\\\\Note:inferenceonthefirstimagewillbeslowerthanthe\\'\\'rest(cachesandauto-tuningneedtowarmup)\\')vis_utils.vis_one_image(im[:,:,::-1],#BGR->RGBforvisualizationim_name,args.output_dir,cls_boxes,cls_segms,cls_keyps,dataset=dummy_coco_dataset,box_alpha=0.3,show_class=True,thresh=args.thresh,kp_thresh=args.kp_thresh,ext=args.output_ext,out_when_no_box=args.out_when_no_box)if__name__==\\'__main__\\':workspace.GlobalInit([\\'caffe2\\',\\'--caffe2_log_level=0\\'])setup_logging(__name__)args=parse_args()main(args)']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29a2998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thisismyt', 'est1234te', 'stsuperdu', 'pie89test', 'ititvonli', 'si']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "effd4757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thisi', 'smyte', 'st123', '4text', '0']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d99ae26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thisi', 'smyte', 'st123', '4te']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52a760b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_with_chunks = create_subprompts(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ba310fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_with_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
