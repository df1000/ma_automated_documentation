{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23189abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a29bc",
   "metadata": {},
   "source": [
    "markdown format passt noch nicht. sieht scheiÃŸe aus --> mit print() sieht das Format gut aus\n",
    "with open('../test_readme/my_test_readme.md', 'w') as file:\n",
    "file.write(readme)\n",
    "varible so speichern und dann sieht das format gut aus ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db662d",
   "metadata": {},
   "source": [
    "### Original README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa1bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_evaluation_data/model1/awslabs_aws-config-to-elasticsearch_evaluation_output.json', 'r') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b61b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import your AWS Config Snapshots into ElasticSearch\n",
      "===================================================\n",
      "### Author: Vladimir Budilov\n",
      "* [YouTube](https://www.youtube.com/channel/UCBl-ENwdTlUsLY05yGgXyxw)\n",
      "* [LinkedIn](https://www.linkedin.com/in/vbudilov/)\n",
      "* [Medium](https://medium.com/@budilov)\n",
      "* [Twitter](https://twitter.com/VladimirBudilov)\n",
      "\n",
      "### What problem does this app solve?\n",
      "You have a lot of resources in your AWS account and want to search and visualize them. For example, you'd like to know your EC2 Avaiability Zone distribution or how many EC2 instances are uzing a particular Security Group\n",
      "\n",
      "### What does this app do?\n",
      "It will ingest your AWS Config Snapshots into ElasticSearch for further analysis with Kibana. Please\n",
      "refer to [this blog post](https://aws.amazon.com/blogs/developer/how-to-analyze-aws-config-snapshots-with-elasticsearch-and-kibana/)\n",
      "for a more in-depth explanation of this solution.\n",
      "\n",
      "\n",
      "### Getting the code\n",
      "```\n",
      "git clone --depth 1 git@github.com:awslabs/aws-config-to-elasticsearch.git\n",
      "```\n",
      "\n",
      "### The code\n",
      "#### Prerequisites\n",
      "* Python 2.7\n",
      "* An ELK stack, up and running\n",
      "* Install the required packages. The requirements.txt file is included with this repo.\n",
      "```\n",
      "pip install -r ./requirements.txt\n",
      "```\n",
      "\n",
      "#### The command\n",
      "```bash\n",
      "./esingest.py\n",
      "usage: esingest.py [-h] [--region REGION] --destination DESTINATION [--verbose]\n",
      "\n",
      "```\n",
      "\n",
      "1. Let's say that you have your ElasticSearch node running on localhost:9200 and you want to import only your us-east-1 snapshot, then you'd run the following command:\n",
      "```bash\n",
      "./esingest.py -d localhost:9200 -r us-east-1\n",
      "```\n",
      "\n",
      "2. If you want to import Snapshots from all of your AWS Config-enabled regions, run the command without the '-r' parameter:\n",
      "```bash\n",
      "./esingest.py -d localhost:9200\n",
      "```\n",
      "3. To run the command in verbose mode, use the -v parameter\n",
      "```bash\n",
      "./esingest.py -v -d localhost:9200 -r us-east-1\n",
      "```\n",
      "\n",
      "### Cleanup\n",
      "\n",
      "####DON'T RUN THESE COMMANDS IF YOU DON'T WANT TO LOSE EVERYTHING IN YOUR ELASTICSEARCH NODE!\n",
      "\n",
      "#####_THIS COMMAND WILL ERASE EVERYTHING FROM YOUR ES NODE --- BE CAREFUL BEFORE RUNNING_\n",
      "```bash\n",
      "curl -XDELETE localhost:9200/_all\n",
      "```\n",
      "\n",
      "In order to avoid losing all of your data, you can just iterate over all of your indexes and delete them that way. The below command will print out all of your indexes that contain 'aws::'. You can then run a DELETE on just these indexes.\n",
      "```bash\n",
      "curl 'localhost:9200/_cat/indices' | awk '{print $3}' | grep \"aws::\"\n",
      "```\n",
      "\n",
      "Also delete the template which allows for creationg of a 'raw' string value alongside every 'analyzed' one\n",
      "```bash\n",
      "curl -XDELETE localhost:9200/_template/configservice\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loaded_data['readme_original']['readme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ae51",
   "metadata": {},
   "source": [
    "### Generated README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a4b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_evaluation_data/model1/awslabs_aws-config-to-elasticsearch_evaluation_output.json', 'r') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc4f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## aws-config-to-elasticsearch\n",
      "\n",
      "## Description\n",
      "The \"aws-config-to-elasticsearch\" repository is a Python script that retrieves AWS Config snapshots from Amazon S3 and loads them into an Elasticsearch instance.\n",
      "\n",
      "## Installation\n",
      "To install the required dependencies, run the following command:\n",
      "```bash\n",
      "pip install boto3 requests json argparse\n",
      "```\n",
      "## Usage\n",
      "To use the script, you can run it from the command line with the following arguments:\n",
      "```bash\n",
      "python main.py --region <region> --es-host <elasticsearch-host> --es-port <elasticsearch-port>\n",
      "```\n",
      "Replace `<region>` with the AWS region you want to retrieve snapshots from, `<elasticsearch-host>` with the hostname or IP address of your Elasticsearch instance, and `<elasticsearch-port>` with the port number of your Elasticsearch instance.\n",
      "\n",
      "## Contributing\n",
      "Contributions are welcome! If you'd like to contribute to the project, please fork the repository and submit a pull request with your changes.\n",
      "\n",
      "## License\n",
      "Licensed under the Apache License, Version 2.0.\n"
     ]
    }
   ],
   "source": [
    "print(loaded_data['readme_genereated']['readme'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
