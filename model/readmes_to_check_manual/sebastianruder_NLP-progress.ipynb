{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23189abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a29bc",
   "metadata": {},
   "source": [
    "markdown format passt noch nicht. sieht scheiÃŸe aus --> mit print() sieht das Format gut aus\n",
    "with open('../test_readme/my_test_readme.md', 'w') as file:\n",
    "file.write(readme)\n",
    "varible so speichern und dann sieht das format gut aus ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db662d",
   "metadata": {},
   "source": [
    "### Original README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfa1bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_evaluation_data/model1/sebastianruder_NLP-progress_evaluation_output.json', 'r') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44b61b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tracking Progress in Natural Language Processing\n",
      "\n",
      "## Table of contents\n",
      "\n",
      "### English\n",
      "\n",
      "- [Automatic speech recognition](english/automatic_speech_recognition.md)\n",
      "- [CCG](english/ccg.md)\n",
      "- [Common sense](english/common_sense.md)\n",
      "- [Constituency parsing](english/constituency_parsing.md)\n",
      "- [Coreference resolution](english/coreference_resolution.md)\n",
      "- [Data-to-Text Generation](english/data_to_text_generation.md)\n",
      "- [Dependency parsing](english/dependency_parsing.md)\n",
      "- [Dialogue](english/dialogue.md)\n",
      "- [Domain adaptation](english/domain_adaptation.md)\n",
      "- [Entity linking](english/entity_linking.md)\n",
      "- [Grammatical error correction](english/grammatical_error_correction.md)\n",
      "- [Information extraction](english/information_extraction.md)\n",
      "- [Intent Detection and Slot Filling](english/intent_detection_slot_filling.md) \n",
      "- [Keyphrase Extraction and Generation](english/keyphrase_extraction_generation.md)\n",
      "- [Language modeling](english/language_modeling.md)\n",
      "- [Lexical normalization](english/lexical_normalization.md)\n",
      "- [Machine translation](english/machine_translation.md)\n",
      "- [Missing elements](english/missing_elements.md)\n",
      "- [Multi-task learning](english/multi-task_learning.md)\n",
      "- [Multi-modal](english/multimodal.md)\n",
      "- [Named entity recognition](english/named_entity_recognition.md)\n",
      "- [Natural language inference](english/natural_language_inference.md)\n",
      "- [Part-of-speech tagging](english/part-of-speech_tagging.md)\n",
      "- [Paraphrase Generation](english/paraphrase-generation.md)\n",
      "- [Question answering](english/question_answering.md)\n",
      "- [Relation prediction](english/relation_prediction.md)\n",
      "- [Relationship extraction](english/relationship_extraction.md)\n",
      "- [Semantic textual similarity](english/semantic_textual_similarity.md)\n",
      "- [Semantic parsing](english/semantic_parsing.md)\n",
      "- [Semantic role labeling](english/semantic_role_labeling.md)\n",
      "- [Sentiment analysis](english/sentiment_analysis.md)\n",
      "- [Shallow syntax](english/shallow_syntax.md)\n",
      "- [Simplification](english/simplification.md)\n",
      "- [Stance detection](english/stance_detection.md)\n",
      "- [Summarization](english/summarization.md)\n",
      "- [Taxonomy learning](english/taxonomy_learning.md)\n",
      "- [Temporal processing](english/temporal_processing.md)\n",
      "- [Text classification](english/text_classification.md)\n",
      "- [Word sense disambiguation](english/word_sense_disambiguation.md)\n",
      "\n",
      "### Vietnamese\n",
      "\n",
      "- [Dependency parsing](vietnamese/vietnamese.md#dependency-parsing)\n",
      "- [Intent detection and Slot filling](vietnamese/vietnamese.md#intent-detection-and-slot-filling)\n",
      "- [Machine translation](vietnamese/vietnamese.md#machine-translation)\n",
      "- [Named entity recognition](vietnamese/vietnamese.md#named-entity-recognition)\n",
      "- [Part-of-speech tagging](vietnamese/vietnamese.md#part-of-speech-tagging)\n",
      "- [Semantic parsing](vietnamese/vietnamese.md#semantic-parsing)\n",
      "- [Word segmentation](vietnamese/vietnamese.md#word-segmentation)\n",
      "\n",
      "### Hindi\n",
      "\n",
      "- [Chunking](hindi/hindi.md#chunking)\n",
      "- [Part-of-speech tagging](hindi/hindi.md#part-of-speech-tagging)\n",
      "- [Machine Translation](hindi/hindi.md#machine-translation)\n",
      "\n",
      "### Chinese\n",
      "\n",
      "- [Entity linking](chinese/chinese.md#entity-linking)\n",
      "- [Chinese word segmentation](chinese/chinese_word_segmentation.md)\n",
      "- [Question answering](chinese/question_answering.md)\n",
      "\n",
      "For more tasks, datasets and results in Chinese, check out the [Chinese NLP](https://chinesenlp.xyz/#/) website.\n",
      "\n",
      "### French\n",
      "\n",
      "- [Question answering](french/question_answering.md)\n",
      "- [Summarization](french/summarization.md)\n",
      "\n",
      "### Russian\n",
      "\n",
      "- [Question answering](russian/question_answering.md)\n",
      "- [Sentiment Analysis](russian/sentiment-analysis.md)\n",
      "- [Summarization](russian/summarization.md)\n",
      "\n",
      "### Spanish\n",
      "\n",
      "- [Named Entity Recognition](spanish/named_entity_recognition.md)\n",
      "- [Entity linking](spanish/entity_linking.md#entity-linking)\n",
      "- [Summarization](spanish/summarization.md)\n",
      "\n",
      "### Portuguese\n",
      "\n",
      "- [Question Answering](portuguese/question_answering.md)\n",
      "\n",
      "### Korean\n",
      "\n",
      "- [Question Answering](korean/question_answering.md)\n",
      "\n",
      "### Nepali\n",
      "\n",
      "- [Machine Translation](nepali/nepali.md#machine-translation)\n",
      "\n",
      "### Bengali\n",
      "- [Part-of-speech Tagging](bengali/part_of_speech_tagging.md)\n",
      "- [Emotion Detection](bengali/emotion_detection.md)\n",
      "- [Sentiment Analysis](bengali/sentiment_analysis.md)\n",
      "\n",
      "### Persian\n",
      "- [Named entity recognition](persian/named_entity_recognition.md)\n",
      "- [Natural language inference](persian/natural_language_inference.md)\n",
      "- [Summarization](persian/summarization.md)\n",
      "\n",
      "### Turkish\n",
      "\n",
      "- [Summarization](turkish/summarization.md)\n",
      "\n",
      "### German\n",
      "\n",
      "- [Question Answering](german/question_answering.md)\n",
      "- [Summarization](german/summarization.md)\n",
      "\n",
      "### Arabic\n",
      "- [Language modeling](arabic/language_modeling.md)\n",
      "\n",
      "\n",
      "This document aims to track the progress in Natural Language Processing (NLP) and give an overview\n",
      "of the state-of-the-art (SOTA) across the most common NLP tasks and their corresponding datasets.\n",
      "\n",
      "It aims to cover both traditional and core NLP tasks such as dependency parsing and part-of-speech tagging\n",
      "as well as more recent ones such as reading comprehension and natural language inference. The main objective\n",
      "is to provide the reader with a quick overview of benchmark datasets and the state-of-the-art for their\n",
      "task of interest, which serves as a stepping stone for further research. To this end, if there is a \n",
      "place where results for a task are already published and regularly maintained, such as a public leaderboard,\n",
      "the reader will be pointed there.\n",
      "\n",
      "If you want to find this document again in the future, just go to [`nlpprogress.com`](https://nlpprogress.com/)\n",
      "or [`nlpsota.com`](http://nlpsota.com/) in your browser.\n",
      "\n",
      "### Contributing\n",
      "\n",
      "#### Guidelines\n",
      "\n",
      "**Results** &nbsp; Results reported in published papers are preferred; an exception may be made for influential preprints.\n",
      "\n",
      "**Datasets** &nbsp; Datasets should have been used for evaluation in at least one published paper besides \n",
      "the one that introduced the dataset.\n",
      "\n",
      "**Code** &nbsp; We recommend to add a link to an implementation \n",
      "if available. You can add a `Code` column (see below) to the table if it does not exist.\n",
      "In the `Code` column, indicate an official implementation with [Official](http://link_to_implementation).\n",
      "If an unofficial implementation is available, use [Link](http://link_to_implementation) (see below).\n",
      "If no implementation is available, you can leave the cell empty.\n",
      "\n",
      "#### Adding a new result\n",
      "\n",
      "If you would like to add a new result, you can just click on the small edit button in the top-right\n",
      "corner of the file for the respective task (see below).\n",
      "\n",
      "![Click on the edit button to add a file](img/edit_file.png)\n",
      "\n",
      "This allows you to edit the file in Markdown. Simply add a row to the corresponding table in the\n",
      "same format. Make sure that the table stays sorted (with the best result on top). \n",
      "After you've made your change, make sure that the table still looks ok by clicking on the\n",
      "\"Preview changes\" tab at the top of the page. If everything looks good, go to the bottom of the page,\n",
      "where you see the below form. \n",
      "\n",
      "![Fill out the file change information](img/propose_file_change.png)\n",
      "\n",
      "Add a name for your proposed change, an optional description, indicate that you would like to\n",
      "\"Create a new branch for this commit and start a pull request\", and click on \"Propose file change\".\n",
      "\n",
      "#### Adding a new dataset or task\n",
      "\n",
      "For adding a new dataset or task, you can also follow the steps above. Alternatively, you can fork the repository.\n",
      "In both cases, follow the steps below:\n",
      "\n",
      "1. If your task is completely new, create a new file and link to it in the table of contents above.\n",
      "2. If not, add your task or dataset to the respective section of the corresponding file (in alphabetical order).\n",
      "3. Briefly describe the dataset/task and include relevant references. \n",
      "4. Describe the evaluation setting and evaluation metric.\n",
      "5. Show how an annotated example of the dataset/task looks like.\n",
      "6. Add a download link if available.\n",
      "7. Copy the below table and fill in at least two results (including the state-of-the-art)\n",
      "  for your dataset/task (change Score to the metric of your dataset). If your dataset/task\n",
      "  has multiple metrics, add them to the right of `Score`.\n",
      "1. Submit your change as a pull request.\n",
      "  \n",
      "| Model           | Score  |  Paper / Source | Code |\n",
      "| ------------- | :-----:| --- | --- |\n",
      "|  |  |  | |\n",
      "\n",
      "\n",
      "### Wish list\n",
      "\n",
      "These are tasks and datasets that are still missing:\n",
      "\n",
      "- Bilingual dictionary induction\n",
      "- Discourse parsing\n",
      "- Keyphrase extraction\n",
      "- Knowledge base population (KBP)\n",
      "- More dialogue tasks\n",
      "- Semi-supervised learning\n",
      "- Frame-semantic parsing (FrameNet full-sentence analysis)\n",
      "\n",
      "### Exporting into a structured format\n",
      "\n",
      "You can extract all the data into a structured, machine-readable JSON format with parsed tasks, descriptions and SOTA tables. \n",
      "\n",
      "The instructions are in [structured/README.md](structured/README.md).\n",
      "\n",
      "### Instructions for building the site locally\n",
      "\n",
      "Instructions for building the website locally using Jekyll can be found [here](jekyll_instructions.md).\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loaded_data['readme_original']['readme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9ae51",
   "metadata": {},
   "source": [
    "### Generated README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4a4b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output_evaluation_data/model1/sebastianruder_NLP-progress_evaluation_output.json', 'r') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dc4f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## NLP-progress\n",
      "================\n",
      "\n",
      "## Description\n",
      "------------\n",
      "\n",
      "The NLP-progress repository is a tool for parsing and extracting structured data from markdown files, specifically in the context of Natural Language Processing (NLP) tasks, datasets, and models. It provides a set of functions to extract relevant information from markdown files, including task descriptions, subtasks, datasets, and SOTA tables.\n",
      "\n",
      "## Installation\n",
      "------------\n",
      "\n",
      "To install the repository, you will need to have Python installed on your system. You can install the required dependencies using pip:\n",
      "```bash\n",
      "pip install argparse os re json typing\n",
      "```\n",
      "You can then clone the repository and run the script using:\n",
      "```bash\n",
      "python nlp_progress.py\n",
      "```\n",
      "## Usage\n",
      "-----\n",
      "\n",
      "The repository provides several functions for parsing and extracting data from markdown files. The main functions are:\n",
      "\n",
      "* `parse_markdown_file`: parses a single markdown file and extracts structured data from it.\n",
      "* `parse_markdown_directory`: parses all markdown files in a given directory and extracts structured data from them.\n",
      "* `extract_dataset_desc_links`: extracts links from the description of a dataset.\n",
      "* `extract_sota_table`: parses a SOTA (State-of-the-Art) table from markdown lines.\n",
      "* `extract_model_name_and_author`: extracts the model name and author from a markdown string.\n",
      "* `extract_paper_title_and_link`: extracts the title and link to a paper from a markdown string.\n",
      "* `extract_code_links`: extracts links to code implementations from a markdown string.\n",
      "\n",
      "You can use these functions by importing the repository and calling the corresponding function:\n",
      "```python\n",
      "from nlp_progress import parse_markdown_file, parse_markdown_directory, extract_dataset_desc_links, ...\n",
      "\n",
      "# Parse a single markdown file\n",
      "data = parse_markdown_file('path/to/file.md')\n",
      "\n",
      "# Parse all markdown files in a directory\n",
      "data = parse_markdown_directory('path/to/directory')\n",
      "\n",
      "# Extract links from a dataset description\n",
      "links = extract_dataset_desc_links('dataset description')\n",
      "```\n",
      "## Contributing\n",
      "------------\n",
      "\n",
      "Contributions are welcome! If you'd like to contribute to the repository, please fork the repository and submit a pull request. Make sure to follow the standard guidelines for contributing to open-source projects.\n",
      "\n",
      "## License\n",
      "-------\n",
      "\n",
      "The NLP-progress repository is released under the MIT License. See the LICENSE file for details.\n"
     ]
    }
   ],
   "source": [
    "print(loaded_data['readme_genereated']['readme'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
