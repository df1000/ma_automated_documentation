{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Lisa Wallner  \n",
    "**Description:** In this notebook a file with the relevant metadata of multiple GitHub repositories will be created.  \n",
    "**Depencencies:**  \n",
    "+ data/raw_data_zip/raw_data_no_range.zip  \n",
    "+ data/raw_data_zip/raw_data_0_22196.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langdetect import detect\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r') as file:\n",
    "        loaded_data = json.load(file)\n",
    "    \n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rezip_files(path, range_type):\n",
    "    \n",
    "    original_zip = path # path to the original ZIP file\n",
    "    if range_type == 'range':\n",
    "        extracted_dir = '../data/raw_data/range' # directory where the extract contents are saved\n",
    "    else:\n",
    "        extracted_dir = '../data/raw_data/no_range'\n",
    "\n",
    "    with zipfile.ZipFile(original_zip, 'r') as zip_ref: \n",
    "        zip_ref.extractall(extracted_dir) # extract all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns which are requiered for preprocessing and further steps\n",
    "columns = [\n",
    "    'id', \n",
    "    'name', \n",
    "    'full_name', \n",
    "    'html_url', \n",
    "    'description', \n",
    "    'url', \n",
    "    'labels_url', \n",
    "    'created_at', \n",
    "    'updated_at', \n",
    "    'pushed_at', \n",
    "    'size', \n",
    "    'stargazers_count', \n",
    "    'watchers_count', \n",
    "    'language', \n",
    "    'has_issues', \n",
    "    'has_projects', \n",
    "    'has_downloads', \n",
    "    'has_wiki', \n",
    "    'has_pages', \n",
    "    'has_discussions', \n",
    "    'forks_count', \n",
    "    'open_issues_count', \n",
    "    'license', \n",
    "    'allow_forking', \n",
    "    'topics', \n",
    "    'visibility', \n",
    "    'forks', \n",
    "    'open_issues', \n",
    "    'watchers', \n",
    "    'default_branch', \n",
    "    'score'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two paths to save .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with repos up to 22196 stars\n",
    "file_no_range = '../data/df_repos_metadata_up_to_max_test.json'\n",
    "# file with repos 0 to 22196 stars\n",
    "file_range = '../data/df_repos_metadata_0_to_22196_test.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get column names for metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_columns = load_json(path='../data/helper/help_columns.json')\n",
    "keys = list(help_columns[0].keys()) # get keys of loaded_data as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paths of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded zip files of metadata in raw_data\n",
    "path_no_range = '../data/raw_data_zip/raw_data_no_range.zip'\n",
    "path_range = '../data/raw_data_zip/raw_data_range_0_22196.zip'\n",
    "rezip_files(path=path_no_range, range_type='no_range')\n",
    "rezip_files(path=path_range, range_type='range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_range = Path('../data/raw_data/range') \n",
    "all_files_range = [file.name for file in path_range.iterdir() if file.is_file()]\n",
    "\n",
    "path_no_range = Path('../data/raw_data/no_range') \n",
    "all_files_no_range = [file.name for file in path_no_range.iterdir() if file.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open all jsons and load repo metadata into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty df with keys of loaded_data as columns\n",
    "df_raw_range = pd.DataFrame(columns=keys)\n",
    "df_raw_no_range = pd.DataFrame(columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7375/967994083.py:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_raw_range = pd.concat([df_raw_range, df_tmp], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for file in all_files_range:\n",
    "    data = load_json(path=f'../data/raw_data/range/{file}')\n",
    "    #  iterate through subdictionary in data and concatenate the content of the subdictionary to df_repos\n",
    "    for repo in data:\n",
    "        # create tmp df_repo for each repo\n",
    "        df_tmp = pd.DataFrame(data=[repo], columns=keys)\n",
    "        # concatenate df_repos with df_repo\n",
    "        df_raw_range = pd.concat([df_raw_range, df_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier weitermachen!!!! So fixen, dass es gut aussieht. Evtl. nochmal einen Stand aus vorherigen Branches ziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 1), indices imply (1, 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#  iterate through subdictionary in data and concatenate the content of the subdictionary to df_repos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m repo \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# create tmp df_repo for each repo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df_tmp = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# concatenate df_repos with df_repo\u001b[39;00m\n\u001b[32m      8\u001b[39m     df_raw_no_range = pd.concat([df_raw_no_range, df_tmp], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/ma_automated_documentation/.venv/lib/python3.12/site-packages/pandas/core/frame.py:867\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    859\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m             arrays,\n\u001b[32m    861\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m             typ=manager,\n\u001b[32m    865\u001b[39m         )\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    877\u001b[39m         {},\n\u001b[32m    878\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         typ=manager,\n\u001b[32m    882\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/ma_automated_documentation/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[32m    332\u001b[39m index, columns = _get_axes(\n\u001b[32m    333\u001b[39m     values.shape[\u001b[32m0\u001b[39m], values.shape[\u001b[32m1\u001b[39m], index=index, columns=columns\n\u001b[32m    334\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/stuff/ma_automated_documentation/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[39m, in \u001b[36m_check_values_indices_shape_match\u001b[39m\u001b[34m(values, index, columns)\u001b[39m\n\u001b[32m    418\u001b[39m passed = values.shape\n\u001b[32m    419\u001b[39m implied = (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Shape of passed values is (1, 1), indices imply (1, 82)"
     ]
    }
   ],
   "source": [
    "for file in all_files_no_range:\n",
    "    data = load_json(path=f'../data/raw_data/no_range/{file}')\n",
    "    #  iterate through subdictionary in data and concatenate the content of the subdictionary to df_repos\n",
    "    for repo in data:\n",
    "        # create tmp df_repo for each repo\n",
    "        df_tmp = pd.DataFrame(data=[repo], columns=keys)\n",
    "        # concatenate df_repos with df_repo\n",
    "        df_raw_no_range = pd.concat([df_raw_no_range, df_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataframes and remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    if k in columns:\n",
    "        continue\n",
    "    else:\n",
    "        df_raw_range = df_raw_range.drop([k], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 591 entries, 0 to 590\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 591 non-null    object \n",
      " 1   name               591 non-null    object \n",
      " 2   full_name          591 non-null    object \n",
      " 3   html_url           591 non-null    object \n",
      " 4   description        579 non-null    object \n",
      " 5   url                591 non-null    object \n",
      " 6   labels_url         591 non-null    object \n",
      " 7   created_at         591 non-null    object \n",
      " 8   updated_at         591 non-null    object \n",
      " 9   pushed_at          591 non-null    object \n",
      " 10  size               591 non-null    object \n",
      " 11  stargazers_count   591 non-null    object \n",
      " 12  watchers_count     591 non-null    object \n",
      " 13  language           591 non-null    object \n",
      " 14  has_issues         591 non-null    object \n",
      " 15  has_projects       591 non-null    object \n",
      " 16  has_downloads      591 non-null    object \n",
      " 17  has_wiki           591 non-null    object \n",
      " 18  has_pages          591 non-null    object \n",
      " 19  has_discussions    591 non-null    object \n",
      " 20  forks_count        591 non-null    object \n",
      " 21  open_issues_count  591 non-null    object \n",
      " 22  license            547 non-null    object \n",
      " 23  allow_forking      591 non-null    object \n",
      " 24  topics             591 non-null    object \n",
      " 25  visibility         591 non-null    object \n",
      " 26  forks              591 non-null    object \n",
      " 27  open_issues        591 non-null    object \n",
      " 28  watchers           591 non-null    object \n",
      " 29  default_branch     591 non-null    object \n",
      " 30  score              591 non-null    float64\n",
      "dtypes: float64(1), object(30)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw_range.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    if k in columns:\n",
    "        continue\n",
    "    else:\n",
    "        df_raw_no_range = df_raw_no_range.drop([k], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save df_repos in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = df_raw_range.to_json(orient='records', lines=False, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_range, 'w') as file:\n",
    "    file.write(tmp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = df_raw_no_range.to_json(orient='records', lines=False, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_no_range, 'w') as file:\n",
    "    file.write(tmp_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load json data for further analysis (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_name, 'r') as file:\n",
    "#     loaded_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame(data=loaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path = Path(\"../data\")\n",
    "# all_dfs = [file.name for file in directory_path.iterdir() if file.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_repos_metadata_star_up_to_max.json', 'df_repos_metadata_0_to_22196.json']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/df_repos_metadata_star_up_to_max.json', 'r') as file:\n",
    "#     loaded_data = json.load(file)\n",
    "# tmp_df = pd.DataFrame(data=loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>stargazers_count</th>\n",
       "      <th>watchers_count</th>\n",
       "      <th>forks_count</th>\n",
       "      <th>open_issues_count</th>\n",
       "      <th>forks</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>watchers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.842129e+08</td>\n",
       "      <td>1.316390e+05</td>\n",
       "      <td>21701.457143</td>\n",
       "      <td>21701.457143</td>\n",
       "      <td>3555.066667</td>\n",
       "      <td>375.716190</td>\n",
       "      <td>3555.066667</td>\n",
       "      <td>375.716190</td>\n",
       "      <td>21701.457143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.800213e+08</td>\n",
       "      <td>4.986652e+05</td>\n",
       "      <td>29908.569921</td>\n",
       "      <td>29908.569921</td>\n",
       "      <td>5971.414570</td>\n",
       "      <td>1003.159613</td>\n",
       "      <td>5971.414570</td>\n",
       "      <td>1003.159613</td>\n",
       "      <td>29908.569921</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.655400e+04</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7193.000000</td>\n",
       "      <td>7193.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7193.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.880424e+07</td>\n",
       "      <td>5.378500e+03</td>\n",
       "      <td>8829.500000</td>\n",
       "      <td>8829.500000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>8829.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.615837e+08</td>\n",
       "      <td>2.407950e+04</td>\n",
       "      <td>12306.500000</td>\n",
       "      <td>12306.500000</td>\n",
       "      <td>1814.000000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>1814.000000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>12306.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.702785e+08</td>\n",
       "      <td>8.391375e+04</td>\n",
       "      <td>21947.250000</td>\n",
       "      <td>21947.250000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>21947.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.548733e+08</td>\n",
       "      <td>1.087097e+07</td>\n",
       "      <td>335520.000000</td>\n",
       "      <td>335520.000000</td>\n",
       "      <td>49242.000000</td>\n",
       "      <td>16073.000000</td>\n",
       "      <td>49242.000000</td>\n",
       "      <td>16073.000000</td>\n",
       "      <td>335520.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          size  stargazers_count  watchers_count  \\\n",
       "count  1.050000e+03  1.050000e+03       1050.000000     1050.000000   \n",
       "mean   2.842129e+08  1.316390e+05      21701.457143    21701.457143   \n",
       "std    2.800213e+08  4.986652e+05      29908.569921    29908.569921   \n",
       "min    2.655400e+04  7.000000e+00       7193.000000     7193.000000   \n",
       "25%    4.880424e+07  5.378500e+03       8829.500000     8829.500000   \n",
       "50%    1.615837e+08  2.407950e+04      12306.500000    12306.500000   \n",
       "75%    5.702785e+08  8.391375e+04      21947.250000    21947.250000   \n",
       "max    9.548733e+08  1.087097e+07     335520.000000   335520.000000   \n",
       "\n",
       "        forks_count  open_issues_count         forks   open_issues  \\\n",
       "count   1050.000000        1050.000000   1050.000000   1050.000000   \n",
       "mean    3555.066667         375.716190   3555.066667    375.716190   \n",
       "std     5971.414570        1003.159613   5971.414570   1003.159613   \n",
       "min      108.000000           0.000000    108.000000      0.000000   \n",
       "25%      989.000000          56.000000    989.000000     56.000000   \n",
       "50%     1814.000000         139.500000   1814.000000    139.500000   \n",
       "75%     3423.000000         331.000000   3423.000000    331.000000   \n",
       "max    49242.000000       16073.000000  49242.000000  16073.000000   \n",
       "\n",
       "            watchers   score  \n",
       "count    1050.000000  1050.0  \n",
       "mean    21701.457143     1.0  \n",
       "std     29908.569921     0.0  \n",
       "min      7193.000000     1.0  \n",
       "25%      8829.500000     1.0  \n",
       "50%     12306.500000     1.0  \n",
       "75%     21947.250000     1.0  \n",
       "max    335520.000000     1.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(21947.25)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantile_75 = tmp_df['stargazers_count'].describe().loc['75%']\n",
    "# quantile_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_df = tmp_df[tmp_df['stargazers_count'] > quantile_75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, 150 to 1019\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 263 non-null    int64  \n",
      " 1   name               263 non-null    object \n",
      " 2   full_name          263 non-null    object \n",
      " 3   html_url           263 non-null    object \n",
      " 4   description        259 non-null    object \n",
      " 5   url                263 non-null    object \n",
      " 6   labels_url         263 non-null    object \n",
      " 7   created_at         263 non-null    object \n",
      " 8   updated_at         263 non-null    object \n",
      " 9   pushed_at          263 non-null    object \n",
      " 10  size               263 non-null    int64  \n",
      " 11  stargazers_count   263 non-null    int64  \n",
      " 12  watchers_count     263 non-null    int64  \n",
      " 13  language           263 non-null    object \n",
      " 14  has_issues         263 non-null    bool   \n",
      " 15  has_projects       263 non-null    bool   \n",
      " 16  has_downloads      263 non-null    bool   \n",
      " 17  has_wiki           263 non-null    bool   \n",
      " 18  has_pages          263 non-null    bool   \n",
      " 19  has_discussions    263 non-null    bool   \n",
      " 20  forks_count        263 non-null    int64  \n",
      " 21  open_issues_count  263 non-null    int64  \n",
      " 22  license            247 non-null    object \n",
      " 23  allow_forking      263 non-null    bool   \n",
      " 24  topics             263 non-null    object \n",
      " 25  visibility         263 non-null    object \n",
      " 26  forks              263 non-null    int64  \n",
      " 27  open_issues        263 non-null    int64  \n",
      " 28  watchers           263 non-null    int64  \n",
      " 29  default_branch     263 non-null    object \n",
      " 30  score              263 non-null    float64\n",
      "dtypes: bool(7), float64(1), int64(9), object(14)\n",
      "memory usage: 53.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#tmp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/df_repos_metadata_0_to_22196.json', 'r') as file:\n",
    "#     loaded_data = json.load(file)\n",
    "# tmp_df1 = pd.DataFrame(data=loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = pd.concat([df_raw_range, df_raw_no_range])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 854 entries, 0 to 1019\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 854 non-null    int64  \n",
      " 1   name               854 non-null    object \n",
      " 2   full_name          854 non-null    object \n",
      " 3   html_url           854 non-null    object \n",
      " 4   description        838 non-null    object \n",
      " 5   url                854 non-null    object \n",
      " 6   labels_url         854 non-null    object \n",
      " 7   created_at         854 non-null    object \n",
      " 8   updated_at         854 non-null    object \n",
      " 9   pushed_at          854 non-null    object \n",
      " 10  size               854 non-null    int64  \n",
      " 11  stargazers_count   854 non-null    int64  \n",
      " 12  watchers_count     854 non-null    int64  \n",
      " 13  language           854 non-null    object \n",
      " 14  has_issues         854 non-null    bool   \n",
      " 15  has_projects       854 non-null    bool   \n",
      " 16  has_downloads      854 non-null    bool   \n",
      " 17  has_wiki           854 non-null    bool   \n",
      " 18  has_pages          854 non-null    bool   \n",
      " 19  has_discussions    854 non-null    bool   \n",
      " 20  forks_count        854 non-null    int64  \n",
      " 21  open_issues_count  854 non-null    int64  \n",
      " 22  license            794 non-null    object \n",
      " 23  allow_forking      854 non-null    bool   \n",
      " 24  topics             854 non-null    object \n",
      " 25  visibility         854 non-null    object \n",
      " 26  forks              854 non-null    int64  \n",
      " 27  open_issues        854 non-null    int64  \n",
      " 28  watchers           854 non-null    int64  \n",
      " 29  default_branch     854 non-null    object \n",
      " 30  score              854 non-null    float64\n",
      "dtypes: bool(7), float64(1), int64(9), object(14)\n",
      "memory usage: 172.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_repos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter df_repos for language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos['language_spoken'] = df_repos['description'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_repos[df_repos['language_spoken'] == 'en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the behavior of the api is sometimes confusing\n",
    "# i got some duplicates in the dataframe --> remove them\n",
    "df_cleaned = df_repos.drop_duplicates(subset=['full_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save df_repos as .json for further analysis / work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = df_cleaned.to_json(orient='records', lines=False, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/df_repos_metadata.json', 'w') as file:\n",
    "#     file.write(tmp_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
