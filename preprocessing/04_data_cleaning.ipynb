{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3771b032",
   "metadata": {},
   "source": [
    "pro repo brauche ich ein .json mit folgenden key-value-pairs  \n",
    "- repo_name\n",
    "- repo_owner\n",
    "- readme\n",
    "- requirements\n",
    "- license\n",
    "- source_code (.py & .ipynb)\n",
    "- source_code_comments (.py & .ipynb)\n",
    "\n",
    "alle .py & .ipynb files sollen zu einem string zusammengefasst werden  \n",
    "ich will keinen coden von zus√§tzlichen packages verwenden! das wird sonst riesig  \n",
    "\n",
    "ich gehe durch alle files vom repo und concatenate die entsprechend files in einem string  \n",
    "danach cleaning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6355ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ac905306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_md(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                md_content = file.read()\n",
    "    return md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "199febb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = '../data/repo_unzip/abi-screenshot-to-code-ff18ae0'\n",
    "input_data_path = '../data/input_data'\n",
    "\n",
    "repo_parts = repo_path.split('/')[-1].split('-')\n",
    "\n",
    "repo_name = reduce(lambda x, y: x + '-' + y, repo_parts[:-1])\n",
    "repo_owner = repo_path.split('/')[3].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "956f9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abi-screenshot-to-code\n",
      "abi\n"
     ]
    }
   ],
   "source": [
    "print(repo_name)\n",
    "print(repo_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d616f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = {\n",
    "    'repo_owner': repo_owner,\n",
    "    'repo_name': repo_name,\n",
    "    'requirements': None,\n",
    "    'readme': None,\n",
    "    'license': None,\n",
    "    'sorce_code_comments': None,\n",
    "    'source_code': None,\n",
    "    'source_code_compressed': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b30e6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_readme = False\n",
    "check_license = False\n",
    "check_requirements = False\n",
    "list_source_code = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "40424755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root, dirs, files in os.walk(repo_path):\n",
    "#     # Process the files first\n",
    "#     print(\"Processing files at the top level:\")\n",
    "#     for file in files:\n",
    "#         file_path = os.path.join(root, file)\n",
    "#         print(f\"File: {file_path}\")\n",
    "\n",
    "#     # Then process the directories\n",
    "#     print(\"\\nProcessing directories at the top level:\")\n",
    "#     for directory in dirs:\n",
    "#         dir_path = os.path.join(root, directory)\n",
    "#         print(f\"Directory: {dir_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ca9ff219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0\n",
      "dirs: ['backend', 'blog', '.github', 'frontend', '.vscode']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0: ['design-docs.md', 'docker-compose.yml', '.gitattributes', '.gitignore', 'Troubleshooting.md', 'Evaluation.md', 'LICENSE', 'README.md']\n",
      "dirs_testi: ['backend', 'blog', 'frontend']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend\n",
      "dirs: ['debug', 'prompts', 'codegen', 'fs_logging', 'evals', 'video', 'image_processing', 'ws', 'image_generation', 'routes']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend: ['run_evals.py', 'video_to_app.py', 'start.py', 'main.py', 'poetry.lock', 'Dockerfile', '.gitignore', 'config.py', 'utils.py', 'mock_llm.py', 'run_image_generation_evals.py', 'llm.py', 'pyproject.toml', '.pre-commit-config.yaml', 'README.md', 'pyrightconfig.json', 'custom_types.py']\n",
      "dirs_testi: ['debug', 'prompts', 'codegen', 'fs_logging', 'evals', 'video', 'image_processing', 'ws', 'image_generation', 'routes']\n",
      "file: run_evals.py was added to list_source_code\n",
      "file: video_to_app.py was added to list_source_code\n",
      "file: start.py was added to list_source_code\n",
      "file: main.py was added to list_source_code\n",
      "file: config.py was added to list_source_code\n",
      "file: utils.py was added to list_source_code\n",
      "file: mock_llm.py was added to list_source_code\n",
      "file: run_image_generation_evals.py was added to list_source_code\n",
      "file: llm.py was added to list_source_code\n",
      "file: custom_types.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/debug\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/debug: ['DebugFileWriter.py', '__init__.py']\n",
      "dirs_testi: []\n",
      "file: DebugFileWriter.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/prompts\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/prompts: ['test_prompts.py', 'screenshot_system_prompts.py', 'types.py', '__init__.py', 'claude_prompts.py', 'imported_code_prompts.py']\n",
      "dirs_testi: []\n",
      "file: test_prompts.py was added to list_source_code\n",
      "file: screenshot_system_prompts.py was added to list_source_code\n",
      "file: types.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "file: claude_prompts.py was added to list_source_code\n",
      "file: imported_code_prompts.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/codegen\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/codegen: ['test_utils.py', '__init__.py', 'utils.py']\n",
      "dirs_testi: []\n",
      "file: test_utils.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "file: utils.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/fs_logging\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/fs_logging: ['core.py', '__init__.py']\n",
      "dirs_testi: []\n",
      "file: core.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/evals\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/evals: ['core.py', 'config.py', '__init__.py', 'runner.py', 'utils.py']\n",
      "dirs_testi: []\n",
      "file: core.py was added to list_source_code\n",
      "file: config.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "file: runner.py was added to list_source_code\n",
      "file: utils.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/video\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/video: ['utils.py']\n",
      "dirs_testi: []\n",
      "file: utils.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_processing\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_processing: ['__init__.py', 'utils.py']\n",
      "dirs_testi: []\n",
      "file: __init__.py was added to list_source_code\n",
      "file: utils.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/ws\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/ws: ['constants.py', '__init__.py']\n",
      "dirs_testi: []\n",
      "file: constants.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_generation\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_generation: ['core.py', '__init__.py', 'replicate.py']\n",
      "dirs_testi: []\n",
      "file: core.py was added to list_source_code\n",
      "file: __init__.py was added to list_source_code\n",
      "file: replicate.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/routes\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/routes: ['screenshot.py', 'generate_code.py', 'evals.py', 'home.py']\n",
      "dirs_testi: []\n",
      "file: screenshot.py was added to list_source_code\n",
      "file: generate_code.py was added to list_source_code\n",
      "file: evals.py was added to list_source_code\n",
      "file: home.py was added to list_source_code\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/blog\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/blog: ['evaluating-claude.md']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.github\n",
      "dirs: ['ISSUE_TEMPLATE']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.github: ['FUNDING.yml']\n",
      "dirs_testi: ['ISSUE_TEMPLATE']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.github/ISSUE_TEMPLATE\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.github/ISSUE_TEMPLATE: ['custom.md', 'bug_report.md', 'feature_request.md']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend\n",
      "dirs: ['public', 'src']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend: ['vite.config.ts', '.env.example', 'jest.config.js', 'Dockerfile', 'postcss.config.js', '.gitignore', 'yarn.lock', '.eslintrc.cjs', 'tsconfig.json', 'tsconfig.node.json', 'package.json', 'tailwind.config.js', 'components.json', 'index.html']\n",
      "dirs_testi: ['public', 'src']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public\n",
      "dirs: ['favicon', 'brand']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public: []\n",
      "dirs_testi: ['favicon', 'brand']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public/favicon\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public/favicon: ['coding.png', 'main.png']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public/brand\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/public/brand: ['twitter-summary-card.png']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src\n",
      "dirs: ['store', 'components', 'tests', 'lib', 'hooks']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src: ['.env.jest.example', 'App.tsx', 'config.ts', 'setupTests.ts', 'types.ts', 'index.css', 'urls.ts', 'vite-env.d.ts', 'generateCode.ts', 'main.tsx', 'constants.ts']\n",
      "dirs_testi: ['store', 'components', 'lib', 'hooks']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/store\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/store: ['app-store.ts', 'project-store.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components\n",
      "dirs: ['variants', 'recording', 'evals', 'preview', 'start-pane', 'ui', 'messages', 'select-and-edit', 'commits', 'settings', 'core', 'history', 'sidebar']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components: ['TermsOfServiceDialog.tsx', 'ImportCodeSection.tsx', 'UrlInputSection.tsx', 'ImageUpload.tsx']\n",
      "dirs_testi: ['variants', 'recording', 'evals', 'preview', 'start-pane', 'ui', 'messages', 'select-and-edit', 'commits', 'settings', 'core', 'history', 'sidebar']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/variants\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/variants: ['Variants.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/recording\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/recording: ['ScreenRecorder.tsx', 'utils.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/evals\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/evals: ['EvalsPage.tsx', 'AllEvalsPage.tsx', 'RunEvalsPage.tsx', 'RatingPicker.tsx', 'PairwiseEvalsPage.tsx', 'BestOfNEvalsPage.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/preview\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/preview: ['CodeTab.tsx', 'extractHtml.ts', 'CodeMirror.tsx', 'simpleHash.ts', 'CodePreview.tsx', 'PreviewComponent.tsx', 'download.ts', 'PreviewPane.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/start-pane\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/start-pane: ['StartPane.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/ui\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/ui: ['label.tsx', 'select.tsx', 'collapsible.tsx', 'hover-card.tsx', 'textarea.tsx', 'checkbox.tsx', 'progress.tsx', 'input.tsx', 'button.tsx', 'tabs.tsx', 'dialog.tsx', 'alert-dialog.tsx', 'separator.tsx', 'scroll-area.tsx', 'popover.tsx', 'accordion.tsx', 'badge.tsx', 'switch.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/messages\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/messages: ['DeprecationMessage.tsx', 'OnboardingNote.tsx', 'PicoBadge.tsx', 'TipLink.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/select-and-edit\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/select-and-edit: ['utils.ts', 'SelectAndEditModeToggleButton.tsx', 'EditPopup.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/commits\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/commits: ['types.ts', 'utils.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/settings\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/settings: ['GenerationSettings.tsx', 'SettingsDialog.tsx', 'OutputSettingsSection.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/core\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/core: ['Spinner.tsx', 'KeyboardShortcutBadge.tsx', 'StackLabel.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/history\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/history: ['HistoryDisplay.tsx', 'utils.ts', 'utils.test.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/sidebar\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/components/sidebar: ['Sidebar.tsx']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/tests\n",
      "dirs: ['fixtures']\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/tests: ['qa.test.ts']\n",
      "dirs_testi: ['fixtures']\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/tests/fixtures\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/tests/fixtures: ['simple_ui_with_image.png', 'simple_button.png']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/lib\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/lib: ['takeScreenshot.ts', 'utils.ts', 'stacks.ts', 'models.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/hooks\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/hooks: ['useBrowserTabIndicator.ts', 'usePersistedState.ts', 'useThrottle.ts']\n",
      "dirs_testi: []\n",
      "root: ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.vscode\n",
      "dirs: []\n",
      "files for root ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.vscode: ['settings.json']\n",
      "dirs_testi: []\n",
      "last file was ../data/repo_unzip/abi-screenshot-to-code-ff18ae0/.vscode/settings.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exclude_dirs = ('.', '.github', '.vscode', '.gitattributes', 'dist', 'env', '.venv', 'vendor', 'third_party', 'tmp', 'temp', 'logs', 'assets', 'static', 'build', 'tests', 'docs', 'documentation') \n",
    "\n",
    "for root, dirs, files in os.walk(repo_path):    \n",
    "    #dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "    print(f'root: {root}')\n",
    "    print(f'dirs: {dirs}')\n",
    "    print(f'files for root {root}: {files}')\n",
    "    dirs_testi = [d for d in dirs if d not in exclude_dirs]\n",
    "    print(f'dirs_testi: {dirs_testi}')\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.lower() in ('readme.md', 'readme') and check_readme is False:\n",
    "                tmp_json['readme'] = read_md(file_path)\n",
    "                check_readme = True\n",
    "            elif file.lower() in ('license.md', 'license') and check_license is False:\n",
    "                tmp_json['license'] = read_md(file_path)\n",
    "                check_license = True\n",
    "            elif file == 'requirements.txt' and check_requirements is False:\n",
    "                with open(file_path) as data:\n",
    "                    requirements_content = data.readlines()\n",
    "                    tmp_json['requirements'] = ''.join(line.strip() for line in requirements_content)\n",
    "                    check_requirements = True\n",
    "            elif file.endswith(('.py', '.ipynb')):\n",
    "                with open(file_path, 'r', errors='ignore') as f:\n",
    "                    list_source_code.append((file_path, f.read()))\n",
    "                print(f'file: {file} was added to list_source_code')\n",
    "        except Exception as e:\n",
    "            print(f'Error during processing file {file_path}: {e}')\n",
    "\n",
    "    #dirs[:] = [d for d in dirs if not d.startswith(exclude_dirs)] # filter out directories that start with the defined prefixes\n",
    "    #dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "print(f'last file was {file_path}')\n",
    "\n",
    "tmp_json['source_code_comments'] = list_source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a14b690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "aeb17f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_json['source_code_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fa097baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# screenshot-to-code\\n\\n**NEW! üöÄ Interested in building full-stack apps with backends and databases using AI?** [Beta test our new tool for FREE.](https://fullyprivatechat.com/)\\n\\nA simple tool to convert screenshots, mockups and Figma designs into clean, functional code using AI. Now supporting Claude Sonnet 3.7!\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045\\n\\nSupported stacks:\\n\\n- HTML + Tailwind\\n- HTML + CSS\\n- React + Tailwind\\n- Vue + Tailwind\\n- Bootstrap\\n- Ionic + Tailwind\\n- SVG\\n\\nSupported AI models:\\n\\n- Claude Sonnet 3.7 - Best model!\\n- GPT-4o - also recommended!\\n- DALL-E 3 or Flux Schnell (using Replicate) for image generation\\n\\nSee the [Examples](#-examples) section below for more demos.\\n\\nWe also just added experimental support for taking a video/screen recording of a website in action and turning that into a functional prototype.\\n\\n![google in app quick 3](https://github.com/abi/screenshot-to-code/assets/23818/8758ffa4-9483-4b9b-bb66-abd6d1594c33)\\n\\n[Learn more about video here](https://github.com/abi/screenshot-to-code/wiki/Screen-Recording-to-Code).\\n\\n[Follow me on Twitter for updates](https://twitter.com/_abi_).\\n\\n## üåç  Hosted Version\\n\\n[Try it live on the hosted version (paid)](https://screenshottocode.com).\\n\\n## üõ† Getting Started\\n\\nThe app has a React/Vite frontend and a FastAPI backend.\\n\\nKeys needed:\\n\\n- [OpenAI API key with access to GPT-4](https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md) or Anthropic key (optional)\\n- Both are recommended so you can compare results from both Claude and GPT4o\\n\\nIf you\\'d like to run the app with Ollama open source models (not recommended due to poor quality results), [follow this comment](https://github.com/abi/screenshot-to-code/issues/354#issuecomment-2435479853).\\n\\nRun the backend (I use Poetry for package management - `pip install poetry` if you don\\'t have it):\\n\\n```bash\\ncd backend\\necho \"OPENAI_API_KEY=sk-your-key\" > .env\\necho \"ANTHROPIC_API_KEY=your-key\" > .env\\npoetry install\\npoetry shell\\npoetry run uvicorn main:app --reload --port 7001\\n```\\nYou can also set up the keys using the settings dialog on the front-end (click the gear icon after loading the frontend).\\n\\nRun the frontend:\\n\\n```bash\\ncd frontend\\nyarn\\nyarn dev\\n```\\n\\nOpen http://localhost:5173 to use the app.\\n\\nIf you prefer to run the backend on a different port, update VITE_WS_BACKEND_URL in `frontend/.env.local`\\n\\nFor debugging purposes, if you don\\'t want to waste GPT4-Vision credits, you can run the backend in mock mode (which streams a pre-recorded response):\\n\\n```bash\\nMOCK=true poetry run uvicorn main:app --reload --port 7001\\n```\\n\\n## Docker\\n\\nIf you have Docker installed on your system, in the root directory, run:\\n\\n```bash\\necho \"OPENAI_API_KEY=sk-your-key\" > .env\\ndocker-compose up -d --build\\n```\\n\\nThe app will be up and running at http://localhost:5173. Note that you can\\'t develop the application with this setup as the file changes won\\'t trigger a rebuild.\\n\\n## üôã\\u200d‚ôÇÔ∏è FAQs\\n\\n- **I\\'m running into an error when setting up the backend. How can I fix it?** [Try this](https://github.com/abi/screenshot-to-code/issues/3#issuecomment-1814777959). If that still doesn\\'t work, open an issue.\\n- **How do I get an OpenAI API key?** See https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md\\n- **How can I configure an OpenAI proxy?** - If you\\'re not able to access the OpenAI API directly (due to e.g. country restrictions), you can try a VPN or you can configure the OpenAI base URL to use a proxy: Set OPENAI_BASE_URL in the `backend/.env` or directly in the UI in the settings dialog. Make sure the URL has \"v1\" in the path so it should look like this: `https://xxx.xxxxx.xxx/v1`\\n- **How can I update the backend host that my front-end connects to?** - Configure VITE_HTTP_BACKEND_URL and VITE_WS_BACKEND_URL in front/.env.local For example, set VITE_HTTP_BACKEND_URL=http://124.10.20.1:7001\\n- **Seeing UTF-8 errors when running the backend?** - On windows, open the .env file with notepad++, then go to Encoding and select UTF-8.\\n- **How can I provide feedback?** For feedback, feature requests and bug reports, open an issue or ping me on [Twitter](https://twitter.com/_abi_).\\n\\n## üìö Examples\\n\\n**NYTimes**\\n\\n| Original                                                                                                                                                        | Replica                                                                                                                                                         |\\n| --------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| <img width=\"1238\" alt=\"Screenshot 2023-11-20 at 12 54 03 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/3b644dfa-9ca6-4148-84a7-3405b6671922\"> | <img width=\"1414\" alt=\"Screenshot 2023-11-20 at 12 59 56 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/26201c9f-1a28-4f35-a3b1-1f04e2b8ce2a\"> |\\n\\n**Instagram page (with not Taylor Swift pics)**\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1\\n\\n**Hacker News** but it gets the colors wrong at first so we nudge it\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d\\n'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_json['readme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5831c7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_generation/core.py',\n",
       "  'import asyncio\\nimport re\\nfrom typing import Dict, List, Literal, Union\\nfrom openai import AsyncOpenAI\\nfrom bs4 import BeautifulSoup\\n\\nfrom image_generation.replicate import call_replicate\\n\\n\\nasync def process_tasks(\\n    prompts: List[str],\\n    api_key: str,\\n    base_url: str | None,\\n    model: Literal[\"dalle3\", \"flux\"],\\n):\\n    import time\\n\\n    start_time = time.time()\\n    if model == \"dalle3\":\\n        tasks = [generate_image_dalle(prompt, api_key, base_url) for prompt in prompts]\\n    else:\\n        tasks = [generate_image_replicate(prompt, api_key) for prompt in prompts]\\n    results = await asyncio.gather(*tasks, return_exceptions=True)\\n    end_time = time.time()\\n    generation_time = end_time - start_time\\n    print(f\"Image generation time: {generation_time:.2f} seconds\")\\n\\n    processed_results: List[Union[str, None]] = []\\n    for result in results:\\n        if isinstance(result, BaseException):\\n            print(f\"An exception occurred: {result}\")\\n            processed_results.append(None)\\n        else:\\n            processed_results.append(result)\\n\\n    return processed_results\\n\\n\\nasync def generate_image_dalle(\\n    prompt: str, api_key: str, base_url: str | None\\n) -> Union[str, None]:\\n    client = AsyncOpenAI(api_key=api_key, base_url=base_url)\\n    res = await client.images.generate(\\n        model=\"dall-e-3\",\\n        quality=\"standard\",\\n        style=\"natural\",\\n        n=1,\\n        size=\"1024x1024\",\\n        prompt=prompt,\\n    )\\n    await client.close()\\n    return res.data[0].url\\n\\n\\nasync def generate_image_replicate(prompt: str, api_key: str) -> str:\\n\\n    # We use Flux Schnell\\n    return await call_replicate(\\n        {\\n            \"prompt\": prompt,\\n            \"num_outputs\": 1,\\n            \"aspect_ratio\": \"1:1\",\\n            \"output_format\": \"png\",\\n            \"output_quality\": 100,\\n        },\\n        api_key,\\n    )\\n\\n\\ndef extract_dimensions(url: str):\\n    # Regular expression to match numbers in the format \\'300x200\\'\\n    matches = re.findall(r\"(\\\\d+)x(\\\\d+)\", url)\\n\\n    if matches:\\n        width, height = matches[0]  # Extract the first match\\n        width = int(width)\\n        height = int(height)\\n        return (width, height)\\n    else:\\n        return (100, 100)\\n\\n\\ndef create_alt_url_mapping(code: str) -> Dict[str, str]:\\n    soup = BeautifulSoup(code, \"html.parser\")\\n    images = soup.find_all(\"img\")\\n\\n    mapping: Dict[str, str] = {}\\n\\n    for image in images:\\n        if not image[\"src\"].startswith(\"https://placehold.co\"):\\n            mapping[image[\"alt\"]] = image[\"src\"]\\n\\n    return mapping\\n\\n\\nasync def generate_images(\\n    code: str,\\n    api_key: str,\\n    base_url: Union[str, None],\\n    image_cache: Dict[str, str],\\n    model: Literal[\"dalle3\", \"flux\"] = \"dalle3\",\\n) -> str:\\n    # Find all images\\n    soup = BeautifulSoup(code, \"html.parser\")\\n    images = soup.find_all(\"img\")\\n\\n    # Extract alt texts as image prompts\\n    alts: List[str | None] = []\\n    for img in images:\\n        # Only include URL if the image starts with https://placehold.co\\n        # and it\\'s not already in the image_cache\\n        if (\\n            \"src\" in img\\n            and img[\"src\"].startswith(\"https://placehold.co\")\\n            and image_cache.get(img.get(\"alt\")) is None\\n        ):\\n            alts.append(img.get(\"alt\", None))\\n\\n    # Exclude images with no alt text\\n    filtered_alts: List[str] = [alt for alt in alts if alt is not None]\\n\\n    # Remove duplicates\\n    prompts = list(set(filtered_alts))\\n\\n    # Return early if there are no images to replace\\n    if len(prompts) == 0:\\n        return code\\n\\n    # Generate images\\n    results = await process_tasks(prompts, api_key, base_url, model)\\n\\n    # Create a dict mapping alt text to image URL\\n    mapped_image_urls = dict(zip(prompts, results))\\n\\n    # Merge with image_cache\\n    mapped_image_urls = {**mapped_image_urls, **image_cache}\\n\\n    # Replace old image URLs with the generated URLs\\n    for img in images:\\n        # Skip images that don\\'t start with https://placehold.co (leave them alone)\\n        if not img[\"src\"].startswith(\"https://placehold.co\"):\\n            continue\\n\\n        new_url = mapped_image_urls[img.get(\"alt\")]\\n\\n        if new_url:\\n            # Set width and height attributes\\n            width, height = extract_dimensions(img[\"src\"])\\n            img[\"width\"] = width\\n            img[\"height\"] = height\\n            # Replace img[\\'src\\'] with the mapped image URL\\n            img[\"src\"] = new_url\\n        else:\\n            print(\"Image generation failed for alt text:\" + img.get(\"alt\"))\\n\\n    # Return the modified HTML\\n    # (need to prettify it because BeautifulSoup messes up the formatting)\\n    return soup.prettify()\\n'),\n",
       " ('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_generation/__init__.py',\n",
       "  ''),\n",
       " ('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/image_generation/replicate.py',\n",
       "  'import asyncio\\nimport httpx\\n\\n\\nasync def call_replicate(input: dict[str, str | int], api_token: str) -> str:\\n    headers = {\\n        \"Authorization\": f\"Bearer {api_token}\",\\n        \"Content-Type\": \"application/json\",\\n    }\\n\\n    data = {\"input\": input}\\n\\n    async with httpx.AsyncClient() as client:\\n        try:\\n            response = await client.post(\\n                \"https://api.replicate.com/v1/models/black-forest-labs/flux-schnell/predictions\",\\n                headers=headers,\\n                json=data,\\n            )\\n            response.raise_for_status()\\n            response_json = response.json()\\n\\n            # Extract the id from the response\\n            prediction_id = response_json.get(\"id\")\\n            if not prediction_id:\\n                raise ValueError(\"Prediction ID not found in initial response.\")\\n\\n            # Polling every 0.1 seconds until the status is succeeded or error (upto 10s)\\n            num_polls = 0\\n            max_polls = 100\\n            while num_polls < max_polls:\\n                num_polls += 1\\n\\n                await asyncio.sleep(0.1)\\n\\n                # Check the status\\n                status_check_url = (\\n                    f\"https://api.replicate.com/v1/predictions/{prediction_id}\"\\n                )\\n                status_response = await client.get(status_check_url, headers=headers)\\n                status_response.raise_for_status()\\n                status_response_json = status_response.json()\\n                status = status_response_json.get(\"status\")\\n\\n                # If status is succeeded or if there\\'s an error, break out of the loop\\n                if status == \"succeeded\":\\n                    return status_response_json[\"output\"][0]\\n                elif status == \"error\":\\n                    raise ValueError(\\n                        f\"Inference errored out: {status_response_json.get(\\'error\\', \\'Unknown error\\')}\"\\n                    )\\n                elif status == \"failed\":\\n                    raise ValueError(\"Inference failed\")\\n\\n            # If we\\'ve reached here, it means we\\'ve exceeded the max number of polls\\n            raise TimeoutError(\"Inference timed out\")\\n\\n        except httpx.HTTPStatusError as e:\\n            raise ValueError(f\"HTTP error occurred: {e}\")\\n        except httpx.RequestError as e:\\n            raise ValueError(f\"An error occurred while requesting: {e}\")\\n        except asyncio.TimeoutError:\\n            raise TimeoutError(\"Request timed out\")\\n        except Exception as e:\\n            raise ValueError(f\"An unexpected error occurred: {e}\")\\n'),\n",
       " ('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/routes/screenshot.py',\n",
       "  'import base64\\nfrom fastapi import APIRouter\\nfrom pydantic import BaseModel\\nimport httpx\\n\\nrouter = APIRouter()\\n\\n\\ndef bytes_to_data_url(image_bytes: bytes, mime_type: str) -> str:\\n    base64_image = base64.b64encode(image_bytes).decode(\"utf-8\")\\n    return f\"data:{mime_type};base64,{base64_image}\"\\n\\n\\nasync def capture_screenshot(\\n    target_url: str, api_key: str, device: str = \"desktop\"\\n) -> bytes:\\n    api_base_url = \"https://api.screenshotone.com/take\"\\n\\n    params = {\\n        \"access_key\": api_key,\\n        \"url\": target_url,\\n        \"full_page\": \"true\",\\n        \"device_scale_factor\": \"1\",\\n        \"format\": \"png\",\\n        \"block_ads\": \"true\",\\n        \"block_cookie_banners\": \"true\",\\n        \"block_trackers\": \"true\",\\n        \"cache\": \"false\",\\n        \"viewport_width\": \"342\",\\n        \"viewport_height\": \"684\",\\n    }\\n\\n    if device == \"desktop\":\\n        params[\"viewport_width\"] = \"1280\"\\n        params[\"viewport_height\"] = \"832\"\\n\\n    async with httpx.AsyncClient(timeout=60) as client:\\n        response = await client.get(api_base_url, params=params)\\n        if response.status_code == 200 and response.content:\\n            return response.content\\n        else:\\n            raise Exception(\"Error taking screenshot\")\\n\\n\\nclass ScreenshotRequest(BaseModel):\\n    url: str\\n    apiKey: str\\n\\n\\nclass ScreenshotResponse(BaseModel):\\n    url: str\\n\\n\\n@router.post(\"/api/screenshot\")\\nasync def app_screenshot(request: ScreenshotRequest):\\n    # Extract the URL from the request body\\n    url = request.url\\n    api_key = request.apiKey\\n\\n    # TODO: Add error handling\\n    image_bytes = await capture_screenshot(url, api_key=api_key)\\n\\n    # Convert the image bytes to a data url\\n    data_url = bytes_to_data_url(image_bytes, \"image/png\")\\n\\n    return ScreenshotResponse(url=data_url)\\n'),\n",
       " ('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/routes/generate_code.py',\n",
       "  'import asyncio\\nfrom dataclasses import dataclass\\nimport traceback\\nfrom fastapi import APIRouter, WebSocket\\nimport openai\\nfrom codegen.utils import extract_html_content\\nfrom config import (\\n    ANTHROPIC_API_KEY,\\n    GEMINI_API_KEY,\\n    IS_PROD,\\n    NUM_VARIANTS,\\n    OPENAI_API_KEY,\\n    OPENAI_BASE_URL,\\n    REPLICATE_API_KEY,\\n    SHOULD_MOCK_AI_RESPONSE,\\n)\\nfrom custom_types import InputMode\\nfrom llm import (\\n    Completion,\\n    Llm,\\n    stream_claude_response,\\n    stream_claude_response_native,\\n    stream_gemini_response,\\n    stream_openai_response,\\n)\\nfrom fs_logging.core import write_logs\\nfrom mock_llm import mock_completion\\nfrom typing import Any, Callable, Coroutine, Dict, List, Literal, cast, get_args\\nfrom image_generation.core import generate_images\\nfrom prompts import create_prompt\\nfrom prompts.claude_prompts import VIDEO_PROMPT\\nfrom prompts.types import Stack\\n\\n# from utils import pprint_prompt\\nfrom ws.constants import APP_ERROR_WEB_SOCKET_CODE  # type: ignore\\n\\n\\nrouter = APIRouter()\\n\\n\\n# Generate images, if needed\\nasync def perform_image_generation(\\n    completion: str,\\n    should_generate_images: bool,\\n    openai_api_key: str | None,\\n    openai_base_url: str | None,\\n    image_cache: dict[str, str],\\n):\\n    replicate_api_key = REPLICATE_API_KEY\\n    if not should_generate_images:\\n        return completion\\n\\n    if replicate_api_key:\\n        image_generation_model = \"flux\"\\n        api_key = replicate_api_key\\n    else:\\n        if not openai_api_key:\\n            print(\\n                \"No OpenAI API key and Replicate key found. Skipping image generation.\"\\n            )\\n            return completion\\n        image_generation_model = \"dalle3\"\\n        api_key = openai_api_key\\n\\n    print(\"Generating images with model: \", image_generation_model)\\n\\n    return await generate_images(\\n        completion,\\n        api_key=api_key,\\n        base_url=openai_base_url,\\n        image_cache=image_cache,\\n        model=image_generation_model,\\n    )\\n\\n\\n@dataclass\\nclass ExtractedParams:\\n    stack: Stack\\n    input_mode: InputMode\\n    should_generate_images: bool\\n    openai_api_key: str | None\\n    anthropic_api_key: str | None\\n    openai_base_url: str | None\\n    generation_type: Literal[\"create\", \"update\"]\\n\\n\\nasync def extract_params(\\n    params: Dict[str, str], throw_error: Callable[[str], Coroutine[Any, Any, None]]\\n) -> ExtractedParams:\\n    # Read the code config settings (stack) from the request.\\n    generated_code_config = params.get(\"generatedCodeConfig\", \"\")\\n    if generated_code_config not in get_args(Stack):\\n        await throw_error(f\"Invalid generated code config: {generated_code_config}\")\\n        raise ValueError(f\"Invalid generated code config: {generated_code_config}\")\\n    validated_stack = cast(Stack, generated_code_config)\\n\\n    # Validate the input mode\\n    input_mode = params.get(\"inputMode\")\\n    if input_mode not in get_args(InputMode):\\n        await throw_error(f\"Invalid input mode: {input_mode}\")\\n        raise ValueError(f\"Invalid input mode: {input_mode}\")\\n    validated_input_mode = cast(InputMode, input_mode)\\n\\n    openai_api_key = get_from_settings_dialog_or_env(\\n        params, \"openAiApiKey\", OPENAI_API_KEY\\n    )\\n\\n    # If neither is provided, we throw an error later only if Claude is used.\\n    anthropic_api_key = get_from_settings_dialog_or_env(\\n        params, \"anthropicApiKey\", ANTHROPIC_API_KEY\\n    )\\n\\n    # Base URL for OpenAI API\\n    openai_base_url: str | None = None\\n    # Disable user-specified OpenAI Base URL in prod\\n    if not IS_PROD:\\n        openai_base_url = get_from_settings_dialog_or_env(\\n            params, \"openAiBaseURL\", OPENAI_BASE_URL\\n        )\\n    if not openai_base_url:\\n        print(\"Using official OpenAI URL\")\\n\\n    # Get the image generation flag from the request. Fall back to True if not provided.\\n    should_generate_images = bool(params.get(\"isImageGenerationEnabled\", True))\\n\\n    # Extract and validate generation type\\n    generation_type = params.get(\"generationType\", \"create\")\\n    if generation_type not in [\"create\", \"update\"]:\\n        await throw_error(f\"Invalid generation type: {generation_type}\")\\n        raise ValueError(f\"Invalid generation type: {generation_type}\")\\n    generation_type = cast(Literal[\"create\", \"update\"], generation_type)\\n\\n    return ExtractedParams(\\n        stack=validated_stack,\\n        input_mode=validated_input_mode,\\n        should_generate_images=should_generate_images,\\n        openai_api_key=openai_api_key,\\n        anthropic_api_key=anthropic_api_key,\\n        openai_base_url=openai_base_url,\\n        generation_type=generation_type,\\n    )\\n\\n\\ndef get_from_settings_dialog_or_env(\\n    params: dict[str, str], key: str, env_var: str | None\\n) -> str | None:\\n    value = params.get(key)\\n    if value:\\n        print(f\"Using {key} from client-side settings dialog\")\\n        return value\\n\\n    if env_var:\\n        print(f\"Using {key} from environment variable\")\\n        return env_var\\n\\n    return None\\n\\n\\n@router.websocket(\"/generate-code\")\\nasync def stream_code(websocket: WebSocket):\\n    await websocket.accept()\\n    print(\"Incoming websocket connection...\")\\n\\n    ## Communication protocol setup\\n    async def throw_error(\\n        message: str,\\n    ):\\n        print(message)\\n        await websocket.send_json({\"type\": \"error\", \"value\": message})\\n        await websocket.close(APP_ERROR_WEB_SOCKET_CODE)\\n\\n    async def send_message(\\n        type: Literal[\"chunk\", \"status\", \"setCode\", \"error\"],\\n        value: str,\\n        variantIndex: int,\\n    ):\\n        # Print for debugging on the backend\\n        if type == \"error\":\\n            print(f\"Error (variant {variantIndex}): {value}\")\\n        elif type == \"status\":\\n            print(f\"Status (variant {variantIndex}): {value}\")\\n\\n        await websocket.send_json(\\n            {\"type\": type, \"value\": value, \"variantIndex\": variantIndex}\\n        )\\n\\n    ## Parameter extract and validation\\n\\n    # TODO: Are the values always strings?\\n    params: dict[str, str] = await websocket.receive_json()\\n    print(\"Received params\")\\n\\n    extracted_params = await extract_params(params, throw_error)\\n    stack = extracted_params.stack\\n    input_mode = extracted_params.input_mode\\n    openai_api_key = extracted_params.openai_api_key\\n    openai_base_url = extracted_params.openai_base_url\\n    anthropic_api_key = extracted_params.anthropic_api_key\\n    should_generate_images = extracted_params.should_generate_images\\n    generation_type = extracted_params.generation_type\\n\\n    print(f\"Generating {stack} code in {input_mode} mode\")\\n\\n    for i in range(NUM_VARIANTS):\\n        await send_message(\"status\", \"Generating code...\", i)\\n\\n    ### Prompt creation\\n\\n    # Image cache for updates so that we don\\'t have to regenerate images\\n    image_cache: Dict[str, str] = {}\\n\\n    try:\\n        prompt_messages, image_cache = await create_prompt(params, stack, input_mode)\\n    except:\\n        await throw_error(\\n            \"Error assembling prompt. Contact support at support@picoapps.xyz\"\\n        )\\n        raise\\n\\n    # pprint_prompt(prompt_messages)  # type: ignore\\n\\n    ### Code generation\\n\\n    async def process_chunk(content: str, variantIndex: int):\\n        await send_message(\"chunk\", content, variantIndex)\\n\\n    if SHOULD_MOCK_AI_RESPONSE:\\n        completion_results = [\\n            await mock_completion(process_chunk, input_mode=input_mode)\\n        ]\\n        completions = [result[\"code\"] for result in completion_results]\\n    else:\\n        try:\\n            if input_mode == \"video\":\\n                if not anthropic_api_key:\\n                    await throw_error(\\n                        \"Video only works with Anthropic models. No Anthropic API key found. Please add the environment variable ANTHROPIC_API_KEY to backend/.env or in the settings dialog\"\\n                    )\\n                    raise Exception(\"No Anthropic key\")\\n\\n                completion_results = [\\n                    await stream_claude_response_native(\\n                        system_prompt=VIDEO_PROMPT,\\n                        messages=prompt_messages,  # type: ignore\\n                        api_key=anthropic_api_key,\\n                        callback=lambda x: process_chunk(x, 0),\\n                        model=Llm.CLAUDE_3_OPUS,\\n                        include_thinking=True,\\n                    )\\n                ]\\n                completions = [result[\"code\"] for result in completion_results]\\n            else:\\n\\n                # Depending on the presence and absence of various keys,\\n                # we decide which models to run\\n                variant_models = []\\n\\n                # For creation, use Claude Sonnet 3.7\\n                # For updates, we use Claude Sonnet 3.5 until we have tested Claude Sonnet 3.7\\n                if generation_type == \"create\":\\n                    claude_model = Llm.CLAUDE_3_7_SONNET_2025_02_19\\n                else:\\n                    claude_model = Llm.CLAUDE_3_5_SONNET_2024_06_20\\n\\n                if openai_api_key and anthropic_api_key:\\n                    variant_models = [\\n                        claude_model,\\n                        Llm.GPT_4O_2024_11_20,\\n                    ]\\n                elif openai_api_key:\\n                    variant_models = [\\n                        Llm.GPT_4O_2024_11_20,\\n                        Llm.GPT_4O_2024_11_20,\\n                    ]\\n                elif anthropic_api_key:\\n                    variant_models = [\\n                        claude_model,\\n                        Llm.CLAUDE_3_5_SONNET_2024_06_20,\\n                    ]\\n                else:\\n                    await throw_error(\\n                        \"No OpenAI or Anthropic API key found. Please add the environment variable OPENAI_API_KEY or ANTHROPIC_API_KEY to backend/.env or in the settings dialog. If you add it to .env, make sure to restart the backend server.\"\\n                    )\\n                    raise Exception(\"No OpenAI or Anthropic key\")\\n\\n                tasks: List[Coroutine[Any, Any, Completion]] = []\\n                for index, model in enumerate(variant_models):\\n                    if model == Llm.GPT_4O_2024_11_20 or model == Llm.O1_2024_12_17:\\n                        if openai_api_key is None:\\n                            await throw_error(\"OpenAI API key is missing.\")\\n                            raise Exception(\"OpenAI API key is missing.\")\\n\\n                        tasks.append(\\n                            stream_openai_response(\\n                                prompt_messages,\\n                                api_key=openai_api_key,\\n                                base_url=openai_base_url,\\n                                callback=lambda x, i=index: process_chunk(x, i),\\n                                model=model,\\n                            )\\n                        )\\n                    elif GEMINI_API_KEY and (\\n                        model == Llm.GEMINI_2_0_PRO_EXP\\n                        or model == Llm.GEMINI_2_0_FLASH_EXP\\n                        or model == Llm.GEMINI_2_0_FLASH\\n                    ):\\n                        tasks.append(\\n                            stream_gemini_response(\\n                                prompt_messages,\\n                                api_key=GEMINI_API_KEY,\\n                                callback=lambda x, i=index: process_chunk(x, i),\\n                                model=model,\\n                            )\\n                        )\\n                    elif (\\n                        model == Llm.CLAUDE_3_5_SONNET_2024_06_20\\n                        or model == Llm.CLAUDE_3_5_SONNET_2024_10_22\\n                        or model == Llm.CLAUDE_3_7_SONNET_2025_02_19\\n                    ):\\n                        if anthropic_api_key is None:\\n                            await throw_error(\"Anthropic API key is missing.\")\\n                            raise Exception(\"Anthropic API key is missing.\")\\n\\n                        # For creation, use Claude Sonnet 3.7\\n                        # For updates, we use Claude Sonnet 3.5 until we have tested Claude Sonnet 3.7\\n                        if params[\"generationType\"] == \"create\":\\n                            claude_model = Llm.CLAUDE_3_7_SONNET_2025_02_19\\n                        else:\\n                            claude_model = Llm.CLAUDE_3_5_SONNET_2024_06_20\\n\\n                        tasks.append(\\n                            stream_claude_response(\\n                                prompt_messages,\\n                                api_key=anthropic_api_key,\\n                                callback=lambda x, i=index: process_chunk(x, i),\\n                                model=claude_model,\\n                            )\\n                        )\\n\\n                # Run the models in parallel and capture exceptions if any\\n                completions = await asyncio.gather(*tasks, return_exceptions=True)\\n\\n                # If all generations failed, throw an error\\n                all_generations_failed = all(\\n                    isinstance(completion, BaseException) for completion in completions\\n                )\\n                if all_generations_failed:\\n                    await throw_error(\"Error generating code. Please contact support.\")\\n\\n                    # Print the all the underlying exceptions for debugging\\n                    for completion in completions:\\n                        if isinstance(completion, BaseException):\\n                            traceback.print_exception(completion)\\n                    raise Exception(\"All generations failed\")\\n\\n                # If some completions failed, replace them with empty strings\\n                for index, completion in enumerate(completions):\\n                    if isinstance(completion, BaseException):\\n                        completions[index] = Completion(duration=0, code=\"\")\\n                        print(\"Generation failed for variant\", index)\\n                        print(completion)\\n                    else:\\n                        print(\\n                            f\"{variant_models[index].value} completion took {completion[\\'duration\\']:.2f} seconds\"\\n                        )\\n\\n                completions = [\\n                    result[\"code\"]\\n                    for result in completions\\n                    if not isinstance(result, BaseException)\\n                ]\\n\\n        except openai.AuthenticationError as e:\\n            print(\"[GENERATE_CODE] Authentication failed\", e)\\n            error_message = (\\n                \"Incorrect OpenAI key. Please make sure your OpenAI API key is correct, or create a new OpenAI API key on your OpenAI dashboard.\"\\n                + (\\n                    \" Alternatively, you can purchase code generation credits directly on this website.\"\\n                    if IS_PROD\\n                    else \"\"\\n                )\\n            )\\n            return await throw_error(error_message)\\n        except openai.NotFoundError as e:\\n            print(\"[GENERATE_CODE] Model not found\", e)\\n            error_message = (\\n                e.message\\n                + \". Please make sure you have followed the instructions correctly to obtain an OpenAI key with GPT vision access: https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md\"\\n                + (\\n                    \" Alternatively, you can purchase code generation credits directly on this website.\"\\n                    if IS_PROD\\n                    else \"\"\\n                )\\n            )\\n            return await throw_error(error_message)\\n        except openai.RateLimitError as e:\\n            print(\"[GENERATE_CODE] Rate limit exceeded\", e)\\n            error_message = (\\n                \"OpenAI error - \\'You exceeded your current quota, please check your plan and billing details.\\'\"\\n                + (\\n                    \" Alternatively, you can purchase code generation credits directly on this website.\"\\n                    if IS_PROD\\n                    else \"\"\\n                )\\n            )\\n            return await throw_error(error_message)\\n\\n    ## Post-processing\\n\\n    # Strip the completion of everything except the HTML content\\n    completions = [extract_html_content(completion) for completion in completions]\\n\\n    # Write the messages dict into a log so that we can debug later\\n    write_logs(prompt_messages, completions[0])\\n\\n    ## Image Generation\\n\\n    for index, _ in enumerate(completions):\\n        await send_message(\"status\", \"Generating images...\", index)\\n\\n    image_generation_tasks = [\\n        perform_image_generation(\\n            completion,\\n            should_generate_images,\\n            openai_api_key,\\n            openai_base_url,\\n            image_cache,\\n        )\\n        for completion in completions\\n    ]\\n\\n    updated_completions = await asyncio.gather(*image_generation_tasks)\\n\\n    for index, updated_html in enumerate(updated_completions):\\n        await send_message(\"setCode\", updated_html, index)\\n        await send_message(\"status\", \"Code generation complete.\", index)\\n\\n    await websocket.close()\\n'),\n",
       " ('../data/repo_unzip/abi-screenshot-to-code-ff18ae0/backend/routes/evals.py',\n",
       "  'import os\\nfrom fastapi import APIRouter, Query, Request, HTTPException\\nfrom pydantic import BaseModel\\nfrom evals.utils import image_to_data_url\\nfrom evals.config import EVALS_DIR\\nfrom typing import Set\\nfrom evals.runner import run_image_evals\\nfrom typing import List, Dict\\nfrom llm import Llm\\nfrom prompts.types import Stack\\nfrom pathlib import Path\\nimport base64\\n\\nrouter = APIRouter()\\n\\n# Update this if the number of outputs generated per input changes\\nN = 1\\n\\n\\nclass Eval(BaseModel):\\n    input: str\\n    outputs: list[str]\\n\\n\\n@router.get(\"/evals\", response_model=list[Eval])\\nasync def get_evals(folder: str):\\n    if not folder:\\n        raise HTTPException(status_code=400, detail=\"Folder path is required\")\\n\\n    folder_path = Path(folder)\\n    if not folder_path.exists():\\n        raise HTTPException(status_code=404, detail=f\"Folder not found: {folder}\")\\n\\n    try:\\n        evals: list[Eval] = []\\n        # Get all HTML files from folder\\n        files = {\\n            f: os.path.join(folder, f)\\n            for f in os.listdir(folder)\\n            if f.endswith(\".html\")\\n        }\\n\\n        # Extract base names\\n        base_names: Set[str] = set()\\n        for filename in files.keys():\\n            base_name = (\\n                filename.rsplit(\"_\", 1)[0]\\n                if \"_\" in filename\\n                else filename.replace(\".html\", \"\")\\n            )\\n            base_names.add(base_name)\\n\\n        for base_name in base_names:\\n            input_path = os.path.join(EVALS_DIR, \"inputs\", f\"{base_name}.png\")\\n            if not os.path.exists(input_path):\\n                continue\\n\\n            # Find matching output file\\n            output_file = None\\n            for filename, filepath in files.items():\\n                if filename.startswith(base_name):\\n                    output_file = filepath\\n                    break\\n\\n            if output_file:\\n                input_data = await image_to_data_url(input_path)\\n                with open(output_file, \"r\", encoding=\"utf-8\") as f:\\n                    output_html = f.read()\\n                evals.append(Eval(input=input_data, outputs=[output_html]))\\n\\n        return evals\\n\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\"Error processing evals: {str(e)}\")\\n\\n\\nclass PairwiseEvalResponse(BaseModel):\\n    evals: list[Eval]\\n    folder1_name: str\\n    folder2_name: str\\n\\n\\n@router.get(\"/pairwise-evals\", response_model=PairwiseEvalResponse)\\nasync def get_pairwise_evals(\\n    folder1: str = Query(\\n        \"...\",\\n        description=\"Absolute path to first folder\",\\n    ),\\n    folder2: str = Query(\\n        \"..\",\\n        description=\"Absolute path to second folder\",\\n    ),\\n):\\n    if not os.path.exists(folder1) or not os.path.exists(folder2):\\n        return {\"error\": \"One or both folders do not exist\"}\\n\\n    evals: list[Eval] = []\\n\\n    # Get all HTML files from first folder\\n    files1 = {\\n        f: os.path.join(folder1, f) for f in os.listdir(folder1) if f.endswith(\".html\")\\n    }\\n    files2 = {\\n        f: os.path.join(folder2, f) for f in os.listdir(folder2) if f.endswith(\".html\")\\n    }\\n\\n    # Find common base names (ignoring any suffixes)\\n    common_names: Set[str] = set()\\n    for f1 in files1.keys():\\n        base_name: str = f1.rsplit(\"_\", 1)[0] if \"_\" in f1 else f1.replace(\".html\", \"\")\\n        for f2 in files2.keys():\\n            if f2.startswith(base_name):\\n                common_names.add(base_name)\\n\\n    # For each matching pair, create an eval\\n    for base_name in common_names:\\n        # Find the corresponding input image\\n        input_image = None\\n        input_path = os.path.join(EVALS_DIR, \"inputs\", f\"{base_name}.png\")\\n        if os.path.exists(input_path):\\n            input_image = await image_to_data_url(input_path)\\n        else:\\n            input_image = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\"  # 1x1 transparent PNG\\n\\n        # Get the HTML contents\\n        output1 = None\\n        output2 = None\\n\\n        # Find matching files in folder1\\n        for f1 in files1.keys():\\n            if f1.startswith(base_name):\\n                with open(files1[f1], \"r\") as f:\\n                    output1 = f.read()\\n                break\\n\\n        # Find matching files in folder2\\n        for f2 in files2.keys():\\n            if f2.startswith(base_name):\\n                with open(files2[f2], \"r\") as f:\\n                    output2 = f.read()\\n                break\\n\\n        if output1 and output2:\\n            evals.append(Eval(input=input_image, outputs=[output1, output2]))\\n\\n    # Extract folder names for the UI\\n    folder1_name = os.path.basename(folder1)\\n    folder2_name = os.path.basename(folder2)\\n\\n    return PairwiseEvalResponse(\\n        evals=evals, folder1_name=folder1_name, folder2_name=folder2_name\\n    )\\n\\n\\nclass RunEvalsRequest(BaseModel):\\n    models: List[str]\\n    stack: Stack\\n\\n\\n@router.post(\"/run_evals\", response_model=List[str])\\nasync def run_evals(request: RunEvalsRequest) -> List[str]:\\n    \"\"\"Run evaluations on all images in the inputs directory for multiple models\"\"\"\\n    all_output_files: List[str] = []\\n\\n    for model in request.models:\\n        output_files = await run_image_evals(model=model, stack=request.stack)\\n        all_output_files.extend(output_files)\\n\\n    return all_output_files\\n\\n\\n@router.get(\"/models\", response_model=Dict[str, List[str]])\\nasync def get_models():\\n    current_models = [\\n        model.value\\n        for model in Llm\\n        if model != Llm.GPT_4_TURBO_2024_04_09\\n        and model != Llm.GPT_4_VISION\\n        and model != Llm.CLAUDE_3_SONNET\\n        and model != Llm.CLAUDE_3_OPUS\\n        and model != Llm.CLAUDE_3_HAIKU\\n    ]\\n\\n    # Import Stack type from prompts.types and get all literal values\\n    available_stacks = list(Stack.__args__)\\n\\n    return {\"models\": current_models, \"stacks\": available_stacks}\\n\\n\\nclass BestOfNEvalsResponse(BaseModel):\\n    evals: list[Eval]\\n    folder_names: list[str]\\n\\n\\n@router.get(\"/best-of-n-evals\", response_model=BestOfNEvalsResponse)\\nasync def get_best_of_n_evals(request: Request):\\n    # Get all query parameters\\n    query_params = dict(request.query_params)\\n\\n    # Extract all folder paths (folder1, folder2, folder3, etc.)\\n    folders = []\\n    i = 1\\n    while f\"folder{i}\" in query_params:\\n        folders.append(query_params[f\"folder{i}\"])\\n        i += 1\\n\\n    if not folders:\\n        return {\"error\": \"No folders provided\"}\\n\\n    # Validate folders exist\\n    for folder in folders:\\n        if not os.path.exists(folder):\\n            return {\"error\": f\"Folder does not exist: {folder}\"}\\n\\n    evals: list[Eval] = []\\n    folder_names = [os.path.basename(folder) for folder in folders]\\n\\n    # Get HTML files from all folders\\n    files_by_folder = []\\n    for folder in folders:\\n        files = {\\n            f: os.path.join(folder, f)\\n            for f in os.listdir(folder)\\n            if f.endswith(\".html\")\\n        }\\n        files_by_folder.append(files)\\n\\n    # Find common base names across all folders\\n    common_names: Set[str] = set()\\n    base_names_first_folder = {\\n        f.rsplit(\"_\", 1)[0] if \"_\" in f else f.replace(\".html\", \"\")\\n        for f in files_by_folder[0].keys()\\n    }\\n\\n    for base_name in base_names_first_folder:\\n        found_in_all = True\\n        for folder_files in files_by_folder[1:]:\\n            if not any(f.startswith(base_name) for f in folder_files.keys()):\\n                found_in_all = False\\n                break\\n        if found_in_all:\\n            common_names.add(base_name)\\n\\n    # For each matching set, create an eval\\n    for base_name in common_names:\\n        # Find the corresponding input image\\n        input_image = None\\n        input_path = os.path.join(EVALS_DIR, \"inputs\", f\"{base_name}.png\")\\n        if os.path.exists(input_path):\\n            input_image = await image_to_data_url(input_path)\\n        else:\\n            input_image = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII=\"\\n\\n        # Get HTML contents from all folders\\n        outputs = []\\n        for folder_files in files_by_folder:\\n            output_content = None\\n            for filename in folder_files.keys():\\n                if filename.startswith(base_name):\\n                    with open(folder_files[filename], \"r\") as f:\\n                        output_content = f.read()\\n                    break\\n            if output_content:\\n                outputs.append(output_content)\\n            else:\\n                outputs.append(\"<html><body>Output not found</body></html>\")\\n\\n        if len(outputs) == len(folders):  # Only add if we have outputs from all folders\\n            evals.append(Eval(input=input_image, outputs=outputs))\\n\\n    return BestOfNEvalsResponse(evals=evals, folder_names=folder_names)\\n')]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_json['source_code_comments'][-7:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1c8fe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{input_data_path}/{repo_owner}_{repo_name}.json', 'w') as file:\n",
    "#     file.write(tmp_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
