{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3771b032",
   "metadata": {},
   "source": [
    "pro repo brauche ich ein .json mit folgenden key-value-pairs  \n",
    "- repo_name\n",
    "- repo_owner\n",
    "- readme\n",
    "- requirements\n",
    "- license\n",
    "- source_code (.py & .ipynb)\n",
    "- source_code_comments (.py & .ipynb)\n",
    "\n",
    "alle .py & .ipynb files sollen zu einem string zusammengefasst werden  \n",
    "ich will keinen coden von zusätzlichen packages verwenden! das wird sonst riesig  \n",
    "\n",
    "ich gehe durch alle files vom repo und concatenate die entsprechend files in einem string  \n",
    "danach cleaning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6355ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac905306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_md(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                md_content = file.read()\n",
    "    return md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987f339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "df = pd.DataFrame(columns=['repo_owner', 'repo_name', 'source_code_comments', 'source_code', 'source_code_cleaned_comments', 'source_code_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b100fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wistbean_learn_python3_spider\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"wistbean_learn_python3_spider_2025-04-21_09-07-08\"\n",
    "pattern = r\"^(.*?)(_?\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2})$\"\n",
    "match = re.match(pattern, text)\n",
    "\n",
    "if match:\n",
    "    result = match.group(1)  # Extracting the part before the date\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199febb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repo_path_unzip = '../data/repo_data_unzip/zylon-ai_private-gpt_2025-04-21_09-12-28'\n",
    "repo_path_unzip = '../data/repo_data_unzip/wistbean_learn_python3_spider_2025-04-21_09-07-08'\n",
    "input_data_path = '../data/input_data'\n",
    "\n",
    "repo_parts = repo_path_unzip.split('/')[-1]\n",
    "\n",
    "#repo_name = '-'.join(reduce(lambda x, y: x + '-' + y, repo_parts[:-1]).split('-')[1:])\n",
    "repo_name = repo_parts[1]\n",
    "repo_owner = repo_parts[0]\n",
    "#repo_owner = repo_path_unzip.split('/')[3].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca0d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX-net_XX-Net\n"
     ]
    }
   ],
   "source": [
    "#repo_path_unzip = '../data/repo_data_unzip/turboderp_exllama_2025-04-21_09-10-34' #ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/zylon-ai_private-gpt_2025-04-21_09-12-28' # ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/wistbean_learn_python3_spider_2025-04-21_09-07-08' #ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/XiaoMi_ha_xiaomi_home_2025-04-21_11-00-04' # ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/Vision-CAIR_MiniGPT-4_2025-04-21_11-01-14' # ok \n",
    "#repo_path_unzip = '../data/repo_data_unzip/rochacbruno_python-week-2022_2025-04-21_09-15-55' # ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/xai-org_grok-1_2025-04-21_09-11-24' # ok\n",
    "#repo_path_unzip = '../data/repo_data_unzip/simonw_files-to-prompt_2025-04-21_09-12-17' #ok \n",
    "#repo_path_unzip = '../data/repo_data_unzip/Lcry_a-sheep-assistant_2025-04-21_11-02-06' # ok\n",
    "repo_path_unzip = '../data/repo_data_unzip/XX-net_XX-Net_2025-04-21_09-04-50'\n",
    "\n",
    "input_data_path = '../data/input_data'\n",
    "\n",
    "repo_parts = repo_path_unzip.split('/')[-1]\n",
    "pattern = r\"^(.*?)(_?\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2})$\"\n",
    "match = re.match(pattern, repo_parts)\n",
    "if match:\n",
    "    result = match.group(1)  # Extracting the part before the date\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e9738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XX-Net\n",
      "XX-net\n"
     ]
    }
   ],
   "source": [
    "pattern2 = r'-'\n",
    "\n",
    "if re.search(pattern2, result):\n",
    "    repo_owner = result.split('_')[0]\n",
    "    repo_name = result.split('_')[1]\n",
    "else:\n",
    "\n",
    "    repo_owner = result.split('_')[0]\n",
    "    repo_name = result.split('_')[1:]\n",
    "    repo_name = '_'.join(repo_name)\n",
    "\n",
    "print(repo_name)\n",
    "print(repo_owner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha_xiaomi_home\n",
      "XiaoMi\n"
     ]
    }
   ],
   "source": [
    "print(repo_name)\n",
    "print(repo_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d616f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_json = {\n",
    "    'repo_owner': repo_owner,\n",
    "    'repo_name': repo_name,\n",
    "    'requirements': None,\n",
    "    'readme': None,\n",
    "    'license': None,\n",
    "    'source_code_comments': None,\n",
    "    'source_code': None,\n",
    "    'source_code_cleaned_comments': None,\n",
    "    'source_code_cleaned': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b30e6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_readme = False\n",
    "check_license = False\n",
    "check_requirements = False\n",
    "list_source_code = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca9ff219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last file was ../data/repo_data_unzip/abi-screenshot-to-code-ff18ae0/frontend/src/hooks/useThrottle.ts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exclude_dirs = ('dist', 'env', 'venv', 'vendor', 'third_party', 'tmp', 'temp', 'logs', 'assets', 'static', 'build', 'tests', 'docs', 'documentation') \n",
    "\n",
    "for root, dirs, files in os.walk(repo_path_unzip): # root: current directory path | dirs: list of subdirectories in the current path | files: list of files in the current directory\n",
    "    # filters directories which are listed in exclude_dirs from dirs\n",
    "    dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith('.')] # dirs[:]: update the list (list from os.walk()) dirs instead of creating a new one (generated with Microsoft Copilot)\n",
    "    # print(f'root: {root}')\n",
    "    # print(f'dirs: {dirs}')\n",
    "    # print(f'files for root {root}: {files}')\n",
    "\n",
    "    for file in files: # iterate through all files in files list\n",
    "        try:\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.lower() in ('readme.md', 'readme') and check_readme is False:\n",
    "                tmp_json['readme'] = read_md(file_path)\n",
    "                check_readme = True\n",
    "            elif file.lower() in ('license.md', 'license') and check_license is False:\n",
    "                tmp_json['license'] = read_md(file_path)\n",
    "                check_license = True\n",
    "            elif file == 'requirements.txt' and check_requirements is False:\n",
    "                with open(file_path) as data:\n",
    "                    requirements_content = data.readlines()\n",
    "                    tmp_json['requirements'] = ''.join(line.strip() for line in requirements_content)\n",
    "                    check_requirements = True\n",
    "            elif file.endswith(('.py', '.ipynb')):\n",
    "                with open(file_path, 'r', errors='ignore') as f:\n",
    "                    # list_source_code.append((file_path, f.read())) # to check if all files are in list_source_code add file_path\n",
    "                    list_source_code.append(f.read())\n",
    "                # print(f'from {file_path} the file: {file} was added to list_source_code')\n",
    "        except Exception as e:\n",
    "            print(f'Error during processing file {file_path}: {e}')\n",
    "\n",
    "# print(f'last file was {file_path}')\n",
    "\n",
    "source_code_comments = ''.join(line.strip() for line in list_source_code)\n",
    "tmp_json['source_code_comments'] = source_code_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb17f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_source_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa097baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# screenshot-to-code\\n\\n**NEW! 🚀 Interested in building full-stack apps with backends and databases using AI?** [Beta test our new tool for FREE.](https://fullyprivatechat.com/)\\n\\nA simple tool to convert screenshots, mockups and Figma designs into clean, functional code using AI. Now supporting Claude Sonnet 3.7!\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/6cebadae-2fe3-4986-ac6a-8fb9db030045\\n\\nSupported stacks:\\n\\n- HTML + Tailwind\\n- HTML + CSS\\n- React + Tailwind\\n- Vue + Tailwind\\n- Bootstrap\\n- Ionic + Tailwind\\n- SVG\\n\\nSupported AI models:\\n\\n- Claude Sonnet 3.7 - Best model!\\n- GPT-4o - also recommended!\\n- DALL-E 3 or Flux Schnell (using Replicate) for image generation\\n\\nSee the [Examples](#-examples) section below for more demos.\\n\\nWe also just added experimental support for taking a video/screen recording of a website in action and turning that into a functional prototype.\\n\\n![google in app quick 3](https://github.com/abi/screenshot-to-code/assets/23818/8758ffa4-9483-4b9b-bb66-abd6d1594c33)\\n\\n[Learn more about video here](https://github.com/abi/screenshot-to-code/wiki/Screen-Recording-to-Code).\\n\\n[Follow me on Twitter for updates](https://twitter.com/_abi_).\\n\\n## 🌍  Hosted Version\\n\\n[Try it live on the hosted version (paid)](https://screenshottocode.com).\\n\\n## 🛠 Getting Started\\n\\nThe app has a React/Vite frontend and a FastAPI backend.\\n\\nKeys needed:\\n\\n- [OpenAI API key with access to GPT-4](https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md) or Anthropic key (optional)\\n- Both are recommended so you can compare results from both Claude and GPT4o\\n\\nIf you\\'d like to run the app with Ollama open source models (not recommended due to poor quality results), [follow this comment](https://github.com/abi/screenshot-to-code/issues/354#issuecomment-2435479853).\\n\\nRun the backend (I use Poetry for package management - `pip install poetry` if you don\\'t have it):\\n\\n```bash\\ncd backend\\necho \"OPENAI_API_KEY=sk-your-key\" > .env\\necho \"ANTHROPIC_API_KEY=your-key\" > .env\\npoetry install\\npoetry shell\\npoetry run uvicorn main:app --reload --port 7001\\n```\\nYou can also set up the keys using the settings dialog on the front-end (click the gear icon after loading the frontend).\\n\\nRun the frontend:\\n\\n```bash\\ncd frontend\\nyarn\\nyarn dev\\n```\\n\\nOpen http://localhost:5173 to use the app.\\n\\nIf you prefer to run the backend on a different port, update VITE_WS_BACKEND_URL in `frontend/.env.local`\\n\\nFor debugging purposes, if you don\\'t want to waste GPT4-Vision credits, you can run the backend in mock mode (which streams a pre-recorded response):\\n\\n```bash\\nMOCK=true poetry run uvicorn main:app --reload --port 7001\\n```\\n\\n## Docker\\n\\nIf you have Docker installed on your system, in the root directory, run:\\n\\n```bash\\necho \"OPENAI_API_KEY=sk-your-key\" > .env\\ndocker-compose up -d --build\\n```\\n\\nThe app will be up and running at http://localhost:5173. Note that you can\\'t develop the application with this setup as the file changes won\\'t trigger a rebuild.\\n\\n## 🙋\\u200d♂️ FAQs\\n\\n- **I\\'m running into an error when setting up the backend. How can I fix it?** [Try this](https://github.com/abi/screenshot-to-code/issues/3#issuecomment-1814777959). If that still doesn\\'t work, open an issue.\\n- **How do I get an OpenAI API key?** See https://github.com/abi/screenshot-to-code/blob/main/Troubleshooting.md\\n- **How can I configure an OpenAI proxy?** - If you\\'re not able to access the OpenAI API directly (due to e.g. country restrictions), you can try a VPN or you can configure the OpenAI base URL to use a proxy: Set OPENAI_BASE_URL in the `backend/.env` or directly in the UI in the settings dialog. Make sure the URL has \"v1\" in the path so it should look like this: `https://xxx.xxxxx.xxx/v1`\\n- **How can I update the backend host that my front-end connects to?** - Configure VITE_HTTP_BACKEND_URL and VITE_WS_BACKEND_URL in front/.env.local For example, set VITE_HTTP_BACKEND_URL=http://124.10.20.1:7001\\n- **Seeing UTF-8 errors when running the backend?** - On windows, open the .env file with notepad++, then go to Encoding and select UTF-8.\\n- **How can I provide feedback?** For feedback, feature requests and bug reports, open an issue or ping me on [Twitter](https://twitter.com/_abi_).\\n\\n## 📚 Examples\\n\\n**NYTimes**\\n\\n| Original                                                                                                                                                        | Replica                                                                                                                                                         |\\n| --------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| <img width=\"1238\" alt=\"Screenshot 2023-11-20 at 12 54 03 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/3b644dfa-9ca6-4148-84a7-3405b6671922\"> | <img width=\"1414\" alt=\"Screenshot 2023-11-20 at 12 59 56 PM\" src=\"https://github.com/abi/screenshot-to-code/assets/23818/26201c9f-1a28-4f35-a3b1-1f04e2b8ce2a\"> |\\n\\n**Instagram page (with not Taylor Swift pics)**\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/503eb86a-356e-4dfc-926a-dabdb1ac7ba1\\n\\n**Hacker News** but it gets the colors wrong at first so we nudge it\\n\\nhttps://github.com/abi/screenshot-to-code/assets/23818/3fec0f77-44e8-4fb3-a769-ac7410315e5d\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_json['readme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6df25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tmp_json['source_code']))\n",
    "# print(len(tmp_json['source_code_comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9baeead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    single_line_comments_pattern = r'#.*' # (generated with Microsoft Copilot)\n",
    "    mulit_line_comments_pattern = r\"\\\"\\\"\\\".*?\\\"\\\"\\\"|'''.*?'''\" # (generated with Microsoft Copilot)\n",
    "    cleaned_str = re.sub(single_line_comments_pattern, '', text)\n",
    "    cleaned_str = re.sub(mulit_line_comments_pattern, '', cleaned_str, flags=re.DOTALL) # (generated with Microsoft Copilot)\n",
    "\n",
    "    return cleaned_str\n",
    "\n",
    "\n",
    "def remove_space_newline(text):\n",
    "    cleaned_str = text.replace(' ', '').replace('\\n', '')\n",
    "\n",
    "    return cleaned_str\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "  \n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+' # (source: https://github.com/souradipp76/ReadMeReady --> scripts/data.ipynb)\n",
    "    cleaned_str = re.sub(url_pattern, '', text)\n",
    "  \n",
    "    return cleaned_str\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = r'<.*?>' # (source: https://github.com/souradipp76/ReadMeReady --> scripts/data.ipynb)\n",
    "    cleaned_str = re.sub(html_pattern, '', text)\n",
    "  \n",
    "    return cleaned_str\n",
    "\n",
    "\n",
    "def remove_emoji(text): # (source: https://github.com/souradipp76/ReadMeReady --> scripts/data.ipynb)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\" \n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    cleaned_str = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    return cleaned_str\n",
    "\n",
    "\n",
    "def clean_code(text):\n",
    "    clean1 = remove_space_newline(text)\n",
    "    clean2 = remove_urls(clean1)\n",
    "    clean3 = remove_html(clean2)\n",
    "    cleaned_str = remove_emoji(clean3)\n",
    "\n",
    "    return cleaned_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b30609d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code_no_comments = remove_comments(source_code_comments)\n",
    "tmp_json['source_code'] = source_code_no_comments\n",
    "\n",
    "tmp_json['source_code_cleaned'] = clean_code(source_code_no_comments)\n",
    "tmp_json['source_code_cleaned_comments'] = clean_code(source_code_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f953b731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repo_owner', 'repo_name', 'source_code_comments', 'source_code',\n",
       "       'source_code_cleaned_comments', 'source_code_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91b178e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {\n",
    "    'repo_owner': tmp_json['repo_owner'],\n",
    "    'repo_name': tmp_json['repo_name'],\n",
    "    'source_code_comments': len(tmp_json['source_code_comments']),\n",
    "    'source_code': len(tmp_json['source_code']),\n",
    "    'source_code_cleaned_comments': len(tmp_json['source_code_cleaned_comments']),\n",
    "    'source_code_cleaned': len(tmp_json['source_code_cleaned'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4771f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df._append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7884b882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>source_code_comments</th>\n",
       "      <th>source_code</th>\n",
       "      <th>source_code_cleaned_comments</th>\n",
       "      <th>source_code_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abi</td>\n",
       "      <td>screenshot-to-code</td>\n",
       "      <td>197048</td>\n",
       "      <td>74793</td>\n",
       "      <td>105032</td>\n",
       "      <td>50206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  repo_owner           repo_name  source_code_comments  source_code  \\\n",
       "0        abi  screenshot-to-code                197048        74793   \n",
       "\n",
       "   source_code_cleaned_comments  source_code_cleaned  \n",
       "0                        105032                50206  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1540ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197048\n",
      "74793\n",
      "105032\n",
      "50206\n"
     ]
    }
   ],
   "source": [
    "print(len(tmp_json['source_code_comments']))\n",
    "print(len(tmp_json['source_code']))\n",
    "print(len(tmp_json['source_code_cleaned_comments']))\n",
    "print(len(tmp_json['source_code_cleaned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ad437c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['repo_owner', 'repo_name', 'requirements', 'readme', 'license', 'source_code_comments', 'source_code', 'source_code_cleaned_comments', 'source_code_cleaned'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c8fe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{input_data_path}/{repo_owner}_{repo_name}.json', 'w') as file:\n",
    "#     json.dump(tmp_json, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22327dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/repo_data_unzip/abi-screenshot-to-code-ff18ae0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_path_unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf71cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unzip file for saving memory\n",
    "shutil.rmtree(repo_path_unzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c2afd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/input_data/abi_screenshot-to-code.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    loaded_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5075caa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197048\n",
      "74793\n",
      "105032\n",
      "50206\n"
     ]
    }
   ],
   "source": [
    "print(len(loaded_data['source_code_comments']))\n",
    "print(len(loaded_data['source_code']))\n",
    "print(len(loaded_data['source_code_cleaned_comments']))\n",
    "print(len(loaded_data['source_code_cleaned']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
